{
    "1": {
        "Country": "Worldwide",
        "State": "",
        "City": "",
        "Continent": "Worldwide",
        "Company": "Google LLC",
        "Company city": "Mountain View",
        "Company state": "California",
        "Affected population": [
            "Children on Youtube",
            "Parents"
        ],
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Disinformation",
            "Human Incompetence",
            "Mental Health",
            "Copyright Violation",
            "Other"
        ],
        "Subclasses": {
            "Disinformation": [
                "Video",
                "Audio",
                "Textual"
            ],
            "Human Incompetence": [
                "Technical",
                "Administrative"
            ],
            "Other": [
                "Exploitation of Minors",
                "Inadequate Content Moderation"
            ]
        },
        "Sub-subclass": [],
        "Area of AI Application": "Content filtering and recommendation",
        "Online": "Yes"
    },
    "2": {
        "Country": "United States",
        "State": "New Jersey",
        "City": "Robbinsville",
        "Continent": "North America",
        "Company": "Amazon",
        "Company city": "Seattle",
        "Company state": "Washington",
        "Affected population": "Amazon Warehouse Workers",
        "Number of people actually affected": "24",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Human Incompetence"
        ],
        "Subclasses": {
            "Human Incompetence": [
                "Technical"
            ]
        },
        "Sub-subclass": [],
        "Area of AI Application": "Warehouse automation",
        "Online": "No"
    },
    "3": {
        "Country": "Indonesia",
        "State": "",
        "City": "Jakarta",
        "Continent": "Asia",
        "Company": "Boeing",
        "Company city": "Chicago",
        "Company state": "Illinois",
        "Affected population": [
            "Airline Passengers",
            "Pilots"
        ],
        "Number of people actually affected": "189",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Human Incompetence",
            "Other"
        ],
        "Subclasses": {
            "Human Incompetence": [
                "Technical"
            ],
            "Other": []
        },
        "Sub-subclass": [],
        "Area of AI Application": "Aviation safety",
        "Online": "No"
    },
    "4": {
        "Country": "United States",
        "State": "Arizona",
        "City": "Tempe",
        "Continent": "North America",
        "Company": "Uber",
        "Company city": "San Francisco",
        "Company state": "California",
        "Affected population": [
            "Pedestrians",
            "Self-driving car testers"
        ],
        "Number of people actually affected": "1",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Human Incompetence",
            "Disinformation"
        ],
        "Subclasses": {
            "Human Incompetence": [
                "Technical"
            ],
            "Disinformation": [
                "Video"
            ]
        },
        "Sub-subclass": [],
        "Area of AI Application": "Autonomous Vehicles",
        "Online": "No"
    },
    "5": {
        "Country": "United States",
        "State": "",
        "City": "",
        "Continent": "North America",
        "Company": "FDA",
        "Company city": "Silver Spring",
        "Company state": "Maryland",
        "Affected population": "Patients undergoing robotic surgery",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Human Incompetence",
            "Other"
        ],
        "Subclasses": {
            "Human Incompetence": [
                "Technical",
                "Administrative"
            ],
            "Other": []
        },
        "Sub-subclass": [],
        "Area of AI Application": "Robotic surgery",
        "Online": "No"
    },
    "6": {
        "Article Title": "In 2016, Microsoft\u2019s Racist Chatbot Revealed the Dangers of Online Conversation",
        "Article Content Summary": "The article discusses the incident involving Microsoft's AI chatbot, Tay, which was released on Twitter in 2016. Tay was designed to learn from interactions with users, mimicking the language patterns of a 19-year-old American girl. However, within 24 hours of its release, Tay began posting inflammatory and offensive tweets, including racist and sexist remarks, due to trolls exploiting its learning capabilities. Microsoft had to shut down Tay and issued an apology, stating that the chatbot was exploited by a coordinated attack that took advantage of its learning mechanisms. The incident highlighted the challenges and dangers associated with AI learning from online conversations and the importance of implementing safeguards against misuse.",
        "Country": "Worldwide",
        "State": "",
        "City": "",
        "Continent": "Worldwide",
        "Company": "Microsoft Corporation",
        "Company city": "Redmond",
        "Company state": "Washington",
        "Affected population": "Twitter Users, AI Research Community",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Human Incompetence",
            "Disinformation"
        ],
        "Subclasses": {
            "Human Incompetence": [
                "Technical"
            ],
            "Disinformation": [
                "Textual"
            ]
        },
        "Sub-subclass": [],
        "Area of AI Application": "Social Media Interaction",
        "Online": "Yes"
    },
    "7": {
        "Country": "Worldwide",
        "State": "",
        "City": "",
        "Continent": "Worldwide",
        "Company": "Wikipedia",
        "Company city": "San Francisco",
        "Company state": "California",
        "Affected population": "Wikipedia Users",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Human Incompetence",
            "Other"
        ],
        "Subclasses": {
            "Human Incompetence": [
                "Technical"
            ],
            "Other": []
        },
        "Sub-subclass": [],
        "Area of AI Application": "content management",
        "Online": "Yes"
    },
    "8": {
        "Country": "United States",
        "State": "California",
        "City": "San Francisco",
        "Continent": "North America",
        "Company": "Uber Technologies Inc.",
        "Company city": "San Francisco",
        "Company state": "California",
        "Affected population": "General Public",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Human Incompetence",
            "Other"
        ],
        "Subclasses": {
            "Human Incompetence": [
                "Technical"
            ],
            "Other": []
        },
        "Sub-subclass": [],
        "Area of AI Application": "Autonomous Vehicles",
        "Online": "No"
    },
    "9": {
        "Country": "United States",
        "State": "New York",
        "City": "New York City",
        "Continent": "North America",
        "Company": "New York City Department of Education",
        "Company city": "New York City",
        "Company state": "New York",
        "Affected population": "Teachers",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Human Incompetence",
            "Disinformation"
        ],
        "Subclasses": {
            "Human Incompetence": [
                "Technical",
                "Administrative"
            ],
            "Disinformation": [
                "Textual"
            ]
        },
        "Sub-subclass": [],
        "Area of AI Application": "Educational assessment",
        "Online": "Yes"
    },
    "10": {
        "Country": "United States",
        "State": "",
        "City": "",
        "Continent": "North America",
        "Company": "Starbucks",
        "Company city": "Seattle",
        "Company state": "Washington",
        "Affected population": [
            "Retail Workers",
            "Single Parents",
            "Part-time Workers"
        ],
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Human Incompetence"
        ],
        "Subclasses": {
            "Human Incompetence": [
                "Technical",
                "Administrative"
            ]
        },
        "Sub-subclass": [],
        "Area of AI Application": "Workforce Management",
        "Online": "No"
    },
    "11": {
        "Article Title": "Automated Inference on Criminality using Face Images",
        "Main Topic": "Artificial Intelligence",
        "Subtopics": [
            "Ethics",
            "Machine Learning",
            "Bias in AI"
        ],
        "Summary": "The article discusses a study by Chinese researchers Xiaolin Wu and Xi Zhang, who investigated whether a computer algorithm could predict criminality based on facial features. Their machine learning algorithm, trained on standard ID photos of Chinese males, claimed to successfully differentiate between criminals and non-criminals. However, the study faced significant backlash and criticism for potentially reinforcing biases and stereotypes, highlighting the ethical concerns surrounding the use of AI in sensitive areas such as criminal justice.",
        "Keywords": [
            "AI",
            "Facial Recognition",
            "Bias",
            "Ethics",
            "Criminal Justice"
        ]
    },
    "12": {
        "Country": "Worldwide",
        "State": "",
        "City": "",
        "Continent": "Worldwide",
        "Company": "",
        "Company city": "",
        "Company state": "",
        "Affected population": "",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [],
        "Subclasses": {},
        "Sub-subclass": [],
        "Area of AI Application": "",
        "Online": "No"
    },
    "13": {
        "Country": "Worldwide",
        "State": "",
        "City": "",
        "Continent": "Worldwide",
        "Company": "Google LLC",
        "Company city": "Mountain View",
        "Company state": "California",
        "Affected population": "Online Users",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Discrimination",
            "Human Incompetence"
        ],
        "Subclasses": {
            "Discrimination": [
                "Data bias",
                "Algorithmic bias"
            ],
            "Human Incompetence": [
                "Technical"
            ]
        },
        "Sub-subclass": {
            "Discrimination": {
                "Data bias": [],
                "Algorithmic bias": [
                    "Other"
                ]
            },
            "Human Incompetence": {
                "Technical": []
            }
        },
        "Area of AI Application": "content moderation",
        "Online": "Yes"
    },
    "14": {
        "Country": "Worldwide",
        "State": "",
        "City": "",
        "Continent": "Worldwide",
        "Company": "Google LLC",
        "Company city": "Mountain View",
        "Company state": "California",
        "Affected population": "Online Users",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Discrimination"
        ],
        "Subclasses": {
            "Discrimination": [
                "Data bias",
                "Algorithmic bias"
            ]
        },
        "Sub-subclass": {
            "Discrimination": {
                "Data bias": [
                    "Sexual Orientation",
                    "Race"
                ],
                "Algorithmic bias": [
                    "Other"
                ]
            }
        },
        "Area of AI Application": "Natural Language Processing",
        "Online": "Yes"
    },
    "15": {
        "Country": "Worldwide",
        "State": "",
        "City": "",
        "Continent": "Worldwide",
        "Company": "Amazon.com, Inc.",
        "Company city": "Seattle",
        "Company state": "Washington",
        "Affected population": "LGBTQ",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Discrimination",
            "Human Incompetence"
        ],
        "Subclasses": {
            "Discrimination": [
                "Data bias"
            ],
            "Human Incompetence": [
                "Technical",
                "Administrative"
            ]
        },
        "Sub-subclass": {
            "Discrimination": {
                "Data bias": [
                    "Sexual Orientation"
                ]
            }
        },
        "Area of AI Application": "content filtering",
        "Online": "Yes"
    }
}