ARTICLE TITLE: Alleged Gender Discrimination in Facebook Job Ads Algorithm
All the ads that we posted were shown - via one of Facebook’s mandatory ad campaign objectives – to users that Facebook thought were most likely to click on the website they linked to. And for all the ads, we specified only the following: that the ads must be shown to adults who lived in or had recently been in either country.

The Facebook users who were shown our job ads, whom Facebook thought our ads were relevant and of interest to, were decided entirely by the company’s algorithm.

We are concerned that in showing job ads predominantly to one gender the company’s ad delivery algorithm is not just replicating, but exacerbating the biases we see in society, narrowing opportunities for users, and frustrating progress and equity in the workplace and society at large.

The right to not to be discriminated against on the basis of sex was hard won, fought for and secured in law by the women’s rights movement. Such discrimination is expressly prohibited in the European Convention on Human Rights and is further enshrined in EU law and in both the French and Dutch constitutions.

But it is clearly not enough to leave these laws on the statute book. These are rights which we need to keep applying and defending even in this modern era of Big Tech algorithms, automated decision-making and artificial intelligence.

In the US, the Justice Department has sued Meta over allegations that the way its ad delivery algorithm distributed housing adverts discriminated against US Facebook users based on characteristics including race, sex, and disability. Meta settled that case under an an agreement to develop a new system to address the disparities caused by its algorithms in respect to housing ads; a system which will be subject to court oversight. The problem, however, is that the settlement only applies to housing ads, and only applies to users in the US.

In 2021, when we first noticed this discriminatory effect in the UK, we asked Facebook to explain the results. They didn’t. We then submitted complaints to regulators asking them to investigate our suspicion that the platform’s system for advertising jobs was discriminating on the basis of sex.

Now, with these new findings, we are joining forces with women’s rights organisations in the Netherlands and France to ask that the Dutch Institute of Human Rights and the French Défenseur des droits investigate Meta’s compliance with equality legislation and intervene should the company be found to be in violation of these important laws.

We’re also requesting that the Data Protection Authorities in both countries review the company’s compliance with rules which state that the company must process data transparently, legally, and fairly, in accordance with fundamental rights.

Algorithms fed by Meta’s assumptions about us dictate the content we see on our Facebook feeds and affect billions of people’s lives every day. We’ve uncovered how Facebook is profiting from ads which are delivered to users in a discriminatory way, and in a way that neither users nor advertisers have an opportunity to understand, let alone prevent.

Regulators must crack open the black box at the heart of Meta, investigate, and enforce our rights for a fairer society.

When approached for comment, a spokesperson from Meta said:

“We have applied targeting restrictions to advertisers when setting up campaigns for employment, as well as housing and credit ads, and we offer transparency about these ads in our Ad Library.

We do not allow advertisers to target these ads based on gender. We continue to work with stakeholders and experts across academia, human rights groups and other disciplines on the best ways to study and address algorithmic fairness.”





Notes: