By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Access your favorite topics in a personalized feed while you're on the go. download the app

Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview

Gig workers are doing the same jobs for different pay, and this model could come to your workplace someday.

That's according to new research from Veena Dubal, a law professor at University of California Hastings, who drew upon six years and thousands of hours of interviews and observations with hundreds of Uber and Lyft drivers, many of whom worked for more than one gig platform.

This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.

According to Dubal, companies like Amazon and Uber have "massive data sets" on the contract workers using their delivery or rideshare platforms, including when they work, for how long, and what kind of pay they've taken for past jobs. These companies are able to utilize this data to "calculate the exact wage rates necessary to incentivize desired behaviors," she told the Los Angeles Times, a practice she calls "algorithmic wage discrimination."

"From Amazon to Uber to the healthcare sector, workers are being paid different amounts for the same amount of work that is conducted for the same amount of time," said Dubal, whose research was published in the Social Science Research Network in January and will be included in a forthcoming Columbia Law Review.

Advertisement

Dubal said these instances could take the form of a food delivery driver being offered a lower rate than another driver would have been — because the AI algorithm predicted the first driver would be more likely to accept that rate. If a driver tends to work until they hit a certain daily mark, say $100, she said the algorithm might offer them lower rates to keep the driver working longer.

"It's basically variable pay that's personalized to individuals based on what is really, really a lot of data that's accumulated on those workers while they're working," Dubal said.

One Uber driver Dubal interviewed, Domingo, recalled being one ride of short of unlocking a $100 bonus one evening, but then said he experienced 45 minutes of "dead time" in a popular area before he was able to get another ride.

Related stories

"It feels like the algorithm is turned against you," he said, adding that it "literally feels like you're being punished by some unknown spiteful God."

Advertisement

Dubal described the alleged variable pay system as the "gamblification of work," a sentiment other gig workers shared.

"It's like gambling," said Ben, a rideshare driver. "The house always wins."

When reached for comment, an Uber spokesperson told Insider: "It's a good thing that Professor Dubal's paper is still a draft, because its central premise about how Uber presents Upfront Fares to drivers is simply wrong. We do not tailor individual fares for individual drivers "as little as the system determines that they may be willing to accept." Moreover, factors like a driver's race, ethnicity, Quest promotion status, acceptance rate, total earnings, or prior trip history are not considered in calculating fares and, where Upfront Fares is available, drivers see exactly what they will make and where they are going before deciding if it's worth their time or declining the request. Moving away from a rate card that only looks at time and distance while on a trip allows Uber's pricing technology to better account for things like long pick up times and whether a driver is going to a destination where there is typically low demand."

Amazon spokeswoman Simone Griffin told Insider, "We created the Amazon Flex program to give individuals the opportunity to set their own schedule and be their own boss, with competitive earnings that exceed $26 per scheduled hour on average. We hear from most of the Amazon Flex delivery partners that they love the program, and we're proud of the work they do on behalf of our customers every day."

Advertisement

Lyft did not respond to Insider's request for comment.

While the potential implications of artificial intelligence technologies have come under greater scrutiny ever since ChatGPT was rolled out in November, companies have been using AI tools for years to help set prices, make decisions, and even hire and fire workers. In her paper, Dubal cited algorithmic wage discrimination as among the reasons the California Labor Commission sued Uber and Lyft in 2020 — and claimed the companies owed drivers a combined $1.3 billion in payments for their hours worked. The lawsuits are still ongoing.

As companies incorporate AI technologies going forward, Dubal is concerned that algorithmic wage discrimination practices "have the great potential to seep into the firm practices of other sectors," which would mean more than just gig workers would be impacted.

Dubal said that there should be a ban on the use of algorithms and AI to set wages and called on the federal government to take a closer look at the issue.

Advertisement

"To address these problems, this Article invites lawmakers and regulators to direct their attention, not just to the problems of transparency and accuracy of automation technologies at work, but also to an evaluation of the social harms embedded in the logic of the algorithmic systems themselves," she wrote in the paper's concluding line.

Are you a gig worker willing to share your story about pay, schedule, and tipping? If so, reach out to this reporter at jzinkula@businessinsider.com.

Editor's note, April 13, 2023: This story was updated after publication to include an updated comment from Uber.. 55 Pages Posted: 23 Jan 2023 Last revised: 27 Apr 2023

Date Written: January 19, 2023

Abstract

Recent technological developments related to the extraction and processing of data have given rise to widespread concerns about a reduction of privacy in the workplace. For a growing number of low-income and subordinated racial minority work forces in the United States, however, on-the-job data collection and algorithmic decision-making systems are having a much more profound yet overlooked impact: these technologies are fundamentally altering the experience of labor and undermining the possibility of economic stability and mobility through work. Drawing on a multi-year, first-of-its-kind ethnographic study of organizing on-demand workers, this Article examines the historical rupture in wage calculation, coordination, and distribution arising from the logic of informational capitalism: the use of granular data to produce unpredictable, variable, and personalized hourly pay. Rooted in worker on-the-job experiences, I construct a novel framework to understand the ascent of digitalized variable pay practices, or the transferal of price discrimination from the consumer to the labor context, what I identify as algorithmic wage discrimination.



Across firms, the opaque practices that constitute algorithmic wage discrimination raise central questions about the changing nature of work and its regulation under informational capitalism. Most centrally, what makes payment for labor in platform work fair? How does algorithmic wage discrimination change and affect the experience of work? And, considering these questions, how should the law intervene in this moment of rupture?



To preface an assessment, Part I examines the rise of algorithmic wage discrimination and its historic legalization in California and Washington state as crucial occasions to understand how data from labor and algorithmic decision-making systems are changing wage practices in service and logistics sectors. The section also considers the extent to which these new laws comport with legal and cultural expectations about moral economies of work arising from and embedded in longstanding wage equalization statutes - namely, minimum wage and anti-discrimination laws. Part II uses findings and analysis from ethnographic research to assess how data from labor is used to produce algorithmic wage discrimination in ride-hail work and how workers subjectively experience and respond to the practice. I find that workers describe the variable payment structures as forms of gambling and trickery, and that these experiences, in turn, produce profoundly unsettling moral expectations about work and remuneration. Part III assesses both how workers’ groups have leveraged existing data privacy and business association laws to contest algorithmic wage discrimination and the limitations of these approaches. The Article concludes by proposing a non- waivable legal restriction on its practice, which will in turn also restrict harmful data extraction and deter firm fissuring practices.