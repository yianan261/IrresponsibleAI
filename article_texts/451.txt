Getty Images is suing Stability AI, creators of popular AI art tool Stable Diffusion, over alleged copyright violation.

In a press statement shared with The Verge, the stock photo company said it believes that Stability AI “unlawfully copied and processed millions of images protected by copyright” to train its software and that Getty Images has “commenced legal proceedings in the High Court of Justice in London” against the firm.

Getty Images CEO Craig Peters told The Verge in an interview that the company has issued Stability AI with a “letter before action” — a formal notification of impending litigation in the UK. (The company did not say whether legal proceedings would take place in the US, too.)

“We’re taking an action to protect our and our contributors’ intellectual property rights.”

“The driver of that [letter] is Stability AI’s use of intellectual property of others — absent permission or consideration — to build a commercial offering of their own financial benefit,” said Peters. “We don’t believe this specific deployment of Stability’s commercial offering is covered by fair dealing in the UK or fair use in the US. The company made no outreach to Getty Images to utilize our or our contributors’ material so we’re taking an action to protect our and our contributors’ intellectual property rights.”

When contacted by The Verge, a press representative for Stability AI, Angela Pontarolo, said the “Stability AI team has not received information about this lawsuit, so we cannot comment.”

The lawsuit marks an escalation in the developing legal battle between AI firms and content creators for credit, profit, and the future direction of the creative industries. AI art tools like Stable Diffusion rely on human-created images for training data, which companies scrape from the web, often without their creators’ knowledge or consent. AI firms claim this practice is covered by laws like the US fair use doctrine, but many rights holders disagree and say it constitutes copyright violation. Legal experts are divided on the issue but agree that such questions will have to be decided for certain in the courts. (This past weekend, a trio of artists launched the first major lawsuit against AI firms, including Stability AI itself.)

Related The scary truth about AI copyright is nobody knows what will happen next

Getty Images CEO Peters compares the current legal landscape in the generative AI scene to the early days of digital music, where companies like Napster offered popular but illegal services before new deals were struck with license holders like music labels.

“We think similarly these generative models need to address the intellectual property rights of others, that’s the crux of it,” said Peters. “And we’re taking this action to get clarity.”

Although the creators of some AI image tools (like OpenAI) refuse to disclose the data used to create their models, Stable Diffusion’s training dataset is open source. An independent analysis of the dataset found that Getty Images and other stock image sites constitute a large portion of its contents, and evidence of Getty Images’ presence can be seen in the AI software’s tendency to recreate the company’s watermark, as in the example image below:

Although companies like Stability AI deny any legal or ethical hazard in creating their systems, they have still begun making concessions to content creators. Stability AI says artists will be able to opt-out of the next version of Stable Diffusion, for example. In a recent tweet about the company’s training datasets, Stability AI CEO Emad Mostaque said “I believe they are ethically, morally and legally sourced and used,” before adding: “Some folks disagree so we are doing opt out and alternate datasets/models that are fully cc.”

The full details of Getty Images’ lawsuit have not yet been made public, but Peters said that charges include copyright violation and violation of the site’s terms of service (in particular, web scraping). Andres Guadamuz, an academic specializing in AI and intellectual property law at the UK’s University of Sussex, told The Verge it seemed like the case would have “more merit” than other existing AI lawsuits, but that “the devil will be in the details.”

When asked what remedies against Getty Images would be seeking from Stability AI, Peters said the company was not interested in financial damages or stopping the development of AI art tools, but in creating a new legal status quo (presumably one with favorable licensing terms for Getty Images).

“I don’t think it’s about damages and it’s not about stopping the distribution of this technology,” Peters told The Verge. “I think there are ways of building generative models that respect intellectual property. I equate [this to] Napster and Spotify. Spotify negotiated with intellectual property rights holders — labels and artists — to create a service. You can debate over whether they’re fairly compensated in that or not, but it’s a negotiation based of the rights of individuals and entities. And that’s what we’re looking for, rather than a singular entity benefiting of the backs of others. That’s the long term goal of this action.”

The full press statement from Getty Images is as follows:. We’ve filed a law­suit chal­leng­ing AI image gen­er­a­tors for using artists’ work with­out con­sent, credit, or com­pen­sa­tion.

Because AI needs to be fair & eth­i­cal for every­one.

This is Joseph Saveri and Matthew Butterick. In Novem­ber 2022, we teamed up to file a law­suit chal­leng­ing GitHub Copi­lot, an AI cod­ing assi­tant built on unprece­dented open-source soft­ware piracy. In July 2023, we filed law­suits on behalf of book authors chal­leng­ing Chat­GPT and LLaMA.

In Jan­u­ary 2023, on behalf of three won­der­ful artist plain­tiffs—Sarah Ander­sen, Kelly McK­er­nan, and Karla Ortiz, we filed an ini­tial com­plaint against Sta­bil­ity AI, DeviantArt, and Mid­jour­ney for their use of Sta­ble Dif­fu­sion, a 21st-cen­tury col­lage tool that remixes the copy­righted works of mil­lions of artists whose work was used as train­ing data. Lock­ridge Grindal Nauen P.L.L.P. joined us as co-coun­sel.

In Novem­ber 2023, we filed an amended com­plaint, adding seven new plain­tiffs and one new defen­dant, Run­way AI.

Case updates are posted reg­u­larly. You can also get updates by email.

Our plain­tiffs are won­der­ful, accom­plished artists who have stepped for­ward to rep­re­sent a class of thou­sands—pos­si­bly mil­lions—of fel­low artists affected by gen­er­a­tive AI.

Sarah Ander­sen is a car­toon­ist and illus­tra­tor. She grad­u­ated from the Mary­land Insti­tute Col­lege of Art in 2014. She cur­rently lives in Port­land, Ore­gon. Her semi-auto­bi­o­graph­i­cal comic strip, Sarah’s Scrib­bles, finds the humor in liv­ing as an intro­vert. Her graphic novel FANGS was nom­i­nated for an Eis­ner Award. Sarah also wrote The Alt-Right Manip­u­lated My Comic. Then A.I. Claimed It for the New York Times.

Kelly McK­er­nan is an inde­pen­dent artist based in Nashville. They grad­u­ated from Ken­ne­saw State Uni­ver­sity in 2009 and have been a full-time artist since 2012. Kelly cre­ates orig­i­nal water­color and acryla gouache paint­ings for gal­leries, pri­vate com­mis­sions, and their online store. In addi­tion to main­tain­ing a large social-media fol­low­ing, Kelly shares tuto­ri­als and teaches work­shops, trav­els across the US for events and comic-cons, and also cre­ates illus­tra­tions for books, comics, games, and more.

Karla Ortiz is a Puerto Rican, inter­na­tion­ally rec­og­nized, award-win­ning artist. With her excep­tional design sense, real­is­tic ren­ders, and char­ac­ter-dri­ven nar­ra­tives, Karla has con­tributed to many big-bud­get projects in the film, tele­vi­sion and video-game indus­tries. Karla is also a reg­u­lar illus­tra­tor for major pub­lish­ing and role-play­ing game com­pa­nies. Karla’s fig­u­ra­tive and mys­te­ri­ous art has been show­cased in notable gal­leries such as Spoke Art and Hashimoto Con­tem­po­rary in San Fran­cisco; Nucleus Gallery, Think­space, and Maxwell Alexan­der Gallery in Los Ange­les; and Galerie Arludik in Paris. She cur­rently lives in San Fran­cisco with her cat Bady.

Hawke South­worth is an illus­tra­tion and 3D artist who has been active in the online art com­mu­nity since 2006. He attended Laguna Col­lege of Art and Design in 2014. Since then, his focus has ranged from char­ac­ter and crea­ture designs, to world­build­ing, ARPG com­mu­nity build­ing, and game devel­op­ment. He cur­rently works as a free­lance designer and runs an up-and-com­ing Art Role­play­ing Game web­site, fea­tur­ing his own crea­ture designs and an eclec­tic fan­tasy world that users can inter­act with.

Grze­gorz Rutkowski is a Pol­ish fine artist, dig­i­tal painter, illus­tra­tor, and con­cept artist. He started his pro­fes­sional career in 2009. He has worked for com­pa­nies like Wiz­ards of the Coast, Ubisoft, Bliz­zard, Dis­ney, CD Pro­jekt RED, Games Work­shop and many more. He lives in Poland with his wife and two daugh­ters.

Gre­gory Manchess has cre­ated art­work for National Geo­graphic Mag­a­zine, Time, Atlantic Monthly, and The Smith­son­ian. His large por­trait of Abra­ham Lin­coln and seven other paint­ings are high­lighted in the Abra­ham Lin­coln Pres­i­den­tial Library and Museum. Manchess wrote and illus­trated his first ‘widescreen novel’ Above the Tim­ber­line, released in 2017 to stel­lar reviews. The Soci­ety of Illus­tra­tors pre­sented him with their high­est honor, the Hamil­ton King Award, in 1999. Today, Gre­gory lec­tures at uni­ver­si­ties and col­leges nation­wide and gives work­shops in paint­ing at the Nor­man Rock­well Museum in Stock­bridge MA, and The Ate­lier in Min­neapo­lis. He teaches at the Illus­tra­tion Mas­ter Class in Savan­nah GA and online with SmArt School.

Artist and author Ger­ald Brom has been con­tribut­ing his macabre and often bizarre visions to all facets of the cre­ative indus­tries for forty years, includ­ing major motion pic­tures, top-tier video games, comics, and books. He has also writ­ten and illus­trated six hor­ror nov­els, includ­ing such pop­u­lar titles as The Child Thief, Kram­pus the Yule Lord, Lost Gods, and Slew­foot.

Jingna Zhang is a Bei­jing-born, US-based Sin­ga­porean pho­tog­ra­pher whose award-win­ning works have appeared in Vogue, Time, and Harper’s Bazaar. Inspired by the Pre-Raphaelites and anime, her roman­tic images inter­weave Asian influ­ences with painterly art styles, and fea­ture col­lab­o­ra­tors such as Coco Rocha, Sug­izo, and Michelle Yeoh. Prior to pho­tog­ra­phy, Jingna was an agent and con­sul­tant for con­cept artists and illus­tra­tors with clients span­ning LucasArts, Ama­zon Pub­lish­ing, and Sony Music Japan. Jingna is cur­rently the founder of Cara, a plat­form for dis­cov­er­ing human artists.

Julia Kaye is an LA-based sto­ry­board artist & revi­sion­ist with over six years of indus­try expe­ri­ence, and the award-win­ning author of two crit­i­cally acclaimed graphic nov­els: Super Late Bloomer and My Life in Tran­si­tion. Her com­mit­ment to activism has led to col­lab­o­ra­tions with non-profit orga­ni­za­tions such as The Trevor Pro­ject and Trans Life­line. Her work has appeared on Webtoon, GoComics, Buz­zfeed, and the Dis­ney ani­mated show Big City Greens.

Adam Ellis is a comic artist and illus­tra­tor who lives in New York City. When he’s not draw­ing he’s watch­ing doc­u­men­taries about cults and dream­ing about one day own­ing a back­yard big enough to keep chick­ens.

Sta­bil­ity AI, founded by Emad Mostaque, is based in Lon­don.

Sta­bil­ity AI funded LAION, a Ger­man orga­ni­za­tion that is cre­at­ing ever-larger image datasets—with­out con­sent, credit, or com­pen­sa­tion to the orig­i­nal artists—for use by AI com­pa­nies.

Sta­bil­ity AI is the devel­oper of Sta­ble Dif­fu­sion. Sta­bil­ity AI trained Sta­ble Dif­fu­sion using the LAION dataset.

Sta­bil­ity AI also released Dream­Stu­dio, a paid app that pack­ages Sta­ble Dif­fu­sion in a web inter­face.

DeviantArt was founded in 2000 and has long been one of the largest artist com­mu­ni­ties on the web.

As shown by Simon Willi­son and Andy Baio, thou­sands—and prob­a­bly closer to mil­lions—of images in LAION were copied from DeviantArt and used to train Sta­ble Dif­fu­sion.

Rather than stand up for its com­mu­nity of artists by pro­tect­ing them against AI train­ing, DeviantArt instead chose to release DreamUp, a paid app built around Sta­ble Dif­fu­sion. In turn, a flood of AI-gen­er­ated art has inun­dated DeviantArt, crowd­ing out human artists.

Mid­jour­ney was founded in 2021 by David Holz in San Fran­cisco. Mid­jour­ney offers a text-to-image gen­er­a­tor through Dis­cord and a web app.

Though hold­ing itself out as a “research lab”, Mid­jour­ney has cul­ti­vated a large audi­ence of pay­ing cus­tomers who use Mid­jour­ney’s image gen­er­a­tor pro­fes­sion­ally. Holz has said he wants Mid­jour­ney to be “focused toward mak­ing every­thing beau­ti­ful and artis­tic look­ing.”

To that end, Holz has admit­ted that Mid­jour­ney is trained on “a big scrape of the inter­net”. Though when asked about the ethics of mas­sive copy­ing of train­ing images, he said “There are no laws specif­i­cally about that.”

Run­way was founded in New York in 2018 by Anas­ta­sis Ger­mani­dis, Ale­jan­dro Mata­mala-Ortiz and Cristóbal Valen­zuela. Run­way also employs Patrick Esser, for­merly a mem­ber of the Com­pVis research group at Lud­wig Max­i­m­il­ian Uni­ver­sity in Munich, where he was a prin­ci­pal devel­oper of the tech­nol­ogy under­ly­ing Sta­ble Dif­fu­sion.

If you’re a mem­ber of the press or the pub­lic with other ques­tions about this case or related top­ics, con­tact stablediffusion_inquiries@saverilawfirm.com. (Though please don’t send con­fi­den­tial or priv­i­leged infor­ma­tion.)

If you’d like to receive occa­sional email updates on the progress of the case, click here to sign up.. GenAI

AI-art lawsuits could set copyright precedents for titans like Microsoft and Stability AI

Thursday, January 19, 2023 by Snacks

Michelangelo would never (GraphicaArtis/Getty Images)

The AI suits are coming… Generative AI has blown up in the past year, with tools like ChatGPT and Stable Diffusion garnering mainstream headlines. Image generators including OpenAI’s DALL-E and Stability AI’s Stable Diffusion “create” images from text prompts (think: “a neon banana in the style of Vincent van Gogh”). But those AI-art tools are trained on billions of images scraped from the internet, many of which are copyrighted by the artists who created them.

Artists sue: This week a group of artists filed a class-action suit against AI-art generators Stability AI , Midjourney , and DeviantArt , arguing that the companies “violated the rights of millions of artists” and profited by using copyrighted images to train their AI models. A similar suit was recently filed against Microsoft , GitHub , and OpenAI .

This week a group of artists filed a class-action suit against AI-art generators , , and , arguing that the companies “violated the rights of millions of artists” and profited by using copyrighted images to train their AI models. A similar suit was recently filed against , , and . Companies too: Also this week, Getty Images sued Stability AI, alleging it “unlawfully copied and processed millions of images protected by copyright” without a Getty license. A study conducted last year concluded that a sizable chunk of Stable Diffusion's data was likely pulled from Getty’s site (partly evidenced by the tool's habit of including the Getty watermark).

It’s a legal gray area… So far there aren’t clear rules around the use of genAI because it’s such a new thing. But it’s growing at lightning speed and is top of mind for companies and artists. In September, Getty Images banned the inclusion of AI-generated images in its database over copyright concerns. But Adobe announced that it would sell images generated by AI tools like DALL-E and Stable Diffusion (so did Shutterstock).. This week Getty Images commenced legal proceedings in the High Court of Justice in London against Stability AI claiming Stability AI infringed intellectual property rights including copyright in content owned or represented by Getty Images. It is Getty Images’ position that Stability AI unlawfully copied and processed millions of images protected by copyright and the associated metadata owned or represented by Getty Images absent a license to benefit Stability AI’s commercial interests and to the detriment of the content creators.



Getty Images believes artificial intelligence has the potential to stimulate creative endeavors. Accordingly, Getty Images provided licenses to leading technology innovators for purposes related to training artificial intelligence systems in a manner that respects personal and intellectual property rights. Stability AI did not seek any such license from Getty Images and instead, we believe, chose to ignore viable licensing options and long‑standing legal protections in pursuit of their stand‑alone commercial interests.



Image credit: Artur Debat

. 