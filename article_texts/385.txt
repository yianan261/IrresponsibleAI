ROBO COP Cops forced to apologize over AI that created ‘racist’ suspect image from DNA

ARTIFICIAL intelligence used by police to create a suspect image from a DNA sample has sparked a backlash over racism.

Alberta, Canada's Edmonton Police Section (EPS) shared the AI-generated image on Twitter and revealed how sci-fi-like "DNA phenotyping" can be used to predict what a suspect looks like.

1 Police had to remove the controversial AI-generated image Credit: Getty

However, the police department had to quickly remove the image when it sparked uproar online.

It later released a statement and apologized for the offense caused.

The AI-generated image was slammed for being inaccurate and was even labeled as racist by some angry Twitter users.

Genetics lecturer at University College London, Dr. Adam Rutherford, responded by tweeting: "Geneticist here. You can’t make facial profiles or accurate pigmentation predictions from DNA, and this is dangerous snake oil."

Another person tweeted: "This is why we want the police defunded. You're wasting money on racist astrology for cops."

Lots of other tweets suggested that the AI was racist as it created an image of a black male.

The AI was also slammed for not being able to accurately determine basic things like age, facial hair, and skin tone based on the DNA sample alone.

The original tweet also sparked debate over whether archeological interpretations of DNA samples are correct.

The police press release stated: "My name is Enyinnah Okere and as Chief Operating Officer for the Community Safety and Well-being Bureau of EPS, I am responsible for overseeing our sexual assault section - it was my team that put out a release two days ago about the unsolved sexual assault of a young woman in 2019.

"This was a horrific sexual assault, one that very nearly caused the death of the young woman who was left unconscious and almost fully unclothed on a minus 27-degree morning in March."

No one was ever prosecuted in this case so the police department turned to Snapshot AI software for help.

The suspect was described as "Black and about 5'4" but little else was known about them other than a DNA sample.

The statement continued: "To move this stalled case forward, our team members sought the advice of colleagues in other jurisdictions who had previously used DNA phenotyping and saw the potential for it here. They commissioned a profile which we released on Tuesday."

And added: "But we were not and are not oblivious to the legitimate questions raised about the suitability of this type of technology.

"The potential that a visual profile can provide far too broad a characterization from within a racialized community and in this case, Edmonton's Black community, was not something I adequately considered.

"There is an important need to balance the potential investigative value of a practice with the all too real risks and unintended consequences to marginalized communities."

The statement concludes that all the AI images have been removed and that other means will be used to try and find justice for the victim.. Police departments are using a new high-tech tool for catching criminals and identifying victims: realistic portraits generated from DNA data. The technology is astounding in its results, but it has attracted its fair share of criticism and controversy.



Last week, the Edmonton Police Service (EPS) — the municipal police force for the City of Edmonton, Alberta in Canada — announced that, for the first time in its history, it was using DNA phenotyping in the hopes of identifying a suspect in a 2019 sexual assault case.

The EPS shared a computer-generated image of a Black male suspect that they created with DNA phenotyping and encouraged anyone who may have information about the assault to come forward. However, the police’s use of technology has since been mired in controversy.

The Case

On March 10, 2019, at approximately 5:45 a.m., police received a call that a female was found yelling for help in the area of 103 Street and 114 Avenue in Edmonton. The woman had been the victim of a violent sexual assault and she had sustained serious injuries.

Following a long investigation into the case where no witnesses, CCTV, public tips, or DNA matches were found, detectives took the step of enlisting Parabon NanoLabs, a DNA technology company in Virginia that specializes in advanced DNA analysis services. The service used in this case was DNA phenotyping, the process of predicting physical appearance and ancestry from unidentified DNA evidence.

Using DNA evidence from this investigation, Parabon produced trait predictions for the suspect of the 2019 sexual assault case. Individual predictions were made for the subject’s ancestry, eye color, hair color, skin color, freckling, and face shape.

By combining these attributes of appearance, a “Snapshot” composite was produced depicting what the POI may have looked like at 25 years old and with an average body-mass index (BMI) of 22. These default values were used because age and BMI cannot be determined from DNA.

On October 4, the EPS shared a press release along with a computer-generated image of a young Black male suspect that they had created with DNA phenotyping. The police force released the portrait to the public, both on its website and its social media platforms with an accompanying message from Detective Colleen Maynes who works for the EPS Sexual Assault Section.

“This is essentially a last resort after all other investigative avenues have been exhausted,” says Maynes. “It is by no means an immediate path to accusing a suspect. What it does is potentially give us leads in a cold case, and we can follow up with DNA testing from there.”

Controversial Technology

The EPS’ decision to produce and share this image was immediately met with questions about the privacy violations of DNA databases that investigators can search through as well as the racial biases in DNA phenotyping for forensic investigations.

Privacy and criminal justice experts dubbed the police force as irresponsible for disseminating the composite portrait of a young Black male suspect.

In response to the criticism regarding the publication of the image and the use of DNA phenotyping, Edmonton police released an apology on October 6 and removed the image from its website and social media.

The EPS has issued a statement on Tuesday’s DNA phenotyping media release. To read it, please visit our website. — Edmonton Police (@edmontonpolice) October 6, 2022

The EPS published an explanation for the decision to use DNA phenotyping two days after the image was released. The statement describes the brutality of the attack and the lack of leads, or evidence that could generate leads.

“[W]e were not and are not oblivious to the legitimate questions raised about the suitability of this type of technology,” writes EPS Chief Operating Officer Enyinnah Okere in the statement. “The potential that a visual profile can provide far too broad a characterization from within a racialized community and in this case, Edmonton’s Black community, was not something I adequately considered. There is an important need to balance the potential investigative value of a practice with the all too real risks and unintended consequences to marginalized communities.

“In our release, we did try to qualify the benefits and limits of the technique we used here. We felt we were clear on its limit. We indicated we saw it as a last resort. And we thank the media who attended our briefing for producing careful and balanced stories that similarly noted the intent of this work and the very fair criticisms that need to be considered.”

Eye-Opening Case Studies

According to Parabon, it has worked on hundreds of law enforcement investigations and successfully generated portraits of suspects from DNA data. On its site are a several case studies, with many showing the comparison between the DNA profile and actual photo of the suspect. As seen in the below images, there are some similarities between the DNA profile and the real photo of the suspect, in that they both reflect the same race, gender, eye, and hair color.

In addition to suggesting the physical appearance of crime suspects, the DNA portrait technology is also being used in attempts to identify the victims of crimes.

“We’re making predictions just from the DNA, so we have only so much information. And so when we make those predictions, it’s a description and these are standing in. If the police had a witness, then they wouldn’t need us,” Dr. Ellen Greytak, the director of bioinformatics and technical lead for the Snapshot division at Parabon NanoLabs, tells Vice. “We’re providing facts, like a genetic witness, providing this information that the detectives can’t get otherwise.”

“It’s just the same as if the police had gotten a description from someone who, maybe you know, didn’t see them up close enough to see if they had tattoos or scars, but described the person,” says Greytak. “What we find is that this can be extremely useful especially for narrowing down who it could be and eliminating people who really don’t match that prediction.”

She adds “In these cases, by definition, they always have DNA and so we don’t have to worry about the wrong person being picked up because they would always just match the DNA.”

According to Greytak, the technology creates the composite image by running the suspect’s DNA through machine-learning models that are built on thousands of people’s DNAs and their corresponding appearances.

“The data that we have on the people with known appearances are from a variety of sources, some of them are publicly available, you can request access for them. Some of them are from studies that we’ve run, where we’ve collected that information,” says Greytak.

Update on 10/14/22: This article previously said that Parabon uses GEDmatch and FamilyTree DNA as sources. Parabon tells us that this was incorrect. We apologize for the error.. An image of a suspect, created from a sample of his DNA? It sounds like dystopian sci-fi, but experts say it's even worse — it's tech that cops are already rolling out, even though it almost certainly doesn't work.

Alberta, Canada's Edmonton Police Section (EPS) took to Twitter on Tuesday to share an image created using DNA phenotyping, which the department claims can be used as a helpful tool to predict — not actually identify, just predict — what a criminal might look like.

The only problem? The tech is nowhere near mature, to the degree that it's unlikely that it's able to generate an accurate portrait, and it can't make any guess at all regarding key physical details ranging from age to facial hair.

The EPS alluded to those limitations in its press release, but decided to go ahead and release an image of the computer-generated suspect regardless. One key and loaded detail? The AI-generated suspect was Black — and experts were quick to raise the alarm.

"Geneticist here," tweeted Dr. Adam Rutherford, a genetics lecturer at University College London, in response to the announcement. "You can't make facial profiles or accurate pigmentation predictions from DNA, and this is dangerous snake oil."

Rutherford is almost certainly right. The EPS purchased the tech, dubbed Snapshot, from a company called Parabon NanoLabs, which on its website promises to help police departments "solve [their] cases — FAST!" You know, because that's what everyone wants cops to do — whip up a would-be "criminal" using what's essentially an Ancestry.com profile, so they can get'er done quick by... what? Investigating anyone who might match that "description?" Got it.

Again, the science just doesn't check out well enough for any of these generated description to be used in good faith. As Rutherford noted, it's impossible to accurately gauge most physical characteristics — skin color included — from a phenotype. It flat-out can't tell you someone's age or weight, and fully leaves out any physical changes wrought by environmental factors like pollution — which the EPS knows, because it had to use several default settings to generate their person of interest.

Bafflingly, the EPS did acknowledge many of those shortcomings in its announcement.

"Using DNA evidence from this investigation... a 'Snapshot' composite was produced depicting what the POI may have looked like at 25 years old and with an average body-mass index (BMI) of 22," reads the department's press release. "These default values were used because age and BMI cannot be determined from DNA."

In other words: this POI might have these characteristics, and though his age is unknown, this is what the maybe-person could have looked like at the age of 25 with a BMI of 22. There's a hole in the logic at every angle, here.

But they rolled it out anyway. On social media, critiques were searing.

"This is why we want the police defunded," wrote one Twitter user. "You're wasting money on racist astrology for cops."

"I like that you were somehow sold this product," responded another, "without anyone going 'wow, that's an obviously terrible idea' at any point."

That anger didn't fall on deaf ears. After a wave of criticism, the EPS removed the image from its press release and social media, and issued a moderately contrite new statement.

"The potential that a visual profile can provide far too broad a characterization from within a racialized community and in this case, Edmonton's Black community, was not something I adequately considered," wrote Enyinnah Okere, the chief operating officer for the Community Safety and Well-Being Bureau of EPS. "There is an important need to balance the potential investigative value of a practice with the all too real risks and unintended consequences to marginalized communities."

"Any time we use a new technology — especially one that does raise concerns about profiling of a marginalized group — we cannot be careful enough in how we validate these efforts and fully, transparently consider the risks," he continued. "We have heard legitimate external criticism and we have done our own gut checks internally to determine whether we got the balance right — and, as a leader, I don't think I did."

For now, the tech seems like a dead end generator, not to mention a pseudoscientific dragnet that get innocent people caught in the crossfire.

More on cop tech: Man Sues City of Chicago, Claiming Its AI Wrongly Imprisoned Him