By Aiden Pink October 26, 2017

A Palestinian man was mistakenly arrested in Israel after Facebook’s translation software turned his “good morning” photo caption into a threat.

The man, who works in a West Bank settlement, posted a photo of himself next to a bulldozer with the message “good morning” in Arabic. But Facebook’s proprietary translation algorithm translated it into Hebrew as “attack them.”

Local police officers were notified of the post and arrested the man. They were especially concerned that he was posing next to a bulldozer, which has been used by Palestinians in hit-and-run terror attacks.

Forwarding the News Thoughtful, balanced reporting from the Forward and around the web, bringing you updated news and analysis of the crisis each day. Terms (Required) I agree to the Forward's Terms of Service and Privacy Policy Email (Required)

Israeli security frequently monitors Palestinians’ social media accounts to detect possible terror threats.

No Arabic-speaking officer read the post before the man’s arrest, Haaretz reported. The man was soon freed after the police admitted a mistake was made.

“Unfortunately, our translation systems made an error last week that misinterpreted what this individual posted,” a Facebook spokesperson told Gizmodo. “Even though our translations are getting better each day, mistakes like these might happen from time to time and we’ve taken steps to address this particular issue. We apologize to him and his family for the mistake and the disruption this caused.”

Contact Aiden Pink at [email protected] or on Twitter, @aidenpink. Facebook has apologized after a Palestinian man was arrested by Israeli police for a post saying “good morning” that its automatic-translation service erroneously translated as “attack them” in Hebrew and “hurt them” in English, reports Israeli newspaper Haaretz. The man is a construction worker near Jerusalem, reports The Guardian. He posted a photo of himself last week leaning against a bulldozer with the caption “يصبحهم”, or “yusbihuhum,” which translates as “good morning.”

Police arrested the man after they were notified of the post and were suspicious he was planning a vehicle attack using the bulldozer. He was released hours later after police realized the mistake. Haaretz reports that before his arrest, no Arabic-speaking officer had read the man’s Facebook post.

Facebook is currently investigating the issue and Necip Fazil Ayan, an engineering manager in Facebook’s language technologies group, said in a statement to Gizmodo that though mistakes might happen, the company’s translations are getting better each day. “Unfortunately, our translation systems made an error last week that misinterpreted what this individual posted. We apologize to him and his family for the mistake and the disruption this caused.”. A construction worker was arrested after he posted ‘Good morning’ on Facebook, because the automatic translation got it wrong.

The Palestinian man had posted a photo at work with a cigarette and a coffee, adding a greeting to his followers in Arabic.

But the online translator misread what he said, translating it as ‘Hurt them’.

Israeli police arrested him on suspicion of inciting violence, believing he was urging people to use a bulldozer to attack people, the Times of Israel reports.

Nobody who spoke Arabic had read the post before he was interrogated.

Israeli security forces arrested him (File picture: Getty)

The automatic translator got mixed up because there is only one letter different in the phrases ‘good morning to you all’ and ‘hurt them’ in Arabic.

Bulldozers have been used in terror attacks in the past, so police thought he was promoting violence.

In fact it was a totally innocent and good natured photo from Beitar Illit settlement on October 15.

The man has since deleted his Facebook post and did not want to be identified, the Times reported.

MORE : Nursery worker died after accidentally overdosing on medication for mystery pain

MORE : Couple find huge stash of marijuana hidden inside their Amazon order. Facebook has apologised after an error in its machine-translation service saw Israeli police arrest a Palestinian man for posting “good morning” on his social media profile.

The man, a construction worker in the West Bank settlement of Beitar Illit, near Jerusalem, posted a picture of himself leaning against a bulldozer with the caption “يصبحهم”, or “yusbihuhum”, which translates as “good morning”.

But Facebook’s artificial intelligence-powered translation service, which it built after parting ways with Microsoft’s Bing translation in 2016, instead translated the word into “hurt them” in English or “attack them” in Hebrew.

Police officers arrested the man later that day, according to Israeli newspaper Haaretz, after they were notified of the post. They questioned him for several hours, suspicious he was planning to use the pictured bulldozer in a vehicle attack, before realising their mistake. At no point before his arrest did any Arabic-speaking officer read the actual post.

Facebook said it is looking into the issue, and in a statement to Gizmodo, added: “Unfortunately, our translation systems made an error last week that misinterpreted what this individual posted.

“Even though our translations are getting better each day, mistakes like these might happen from time to time and we’ve taken steps to address this particular issue. We apologise to him and his family for the mistake and the disruption this caused.”

Arabic is considered particularly difficult for many machine translation services due to the large number of different dialects in use around the world, on top of Modern Standard Arabic, the international form of the language.

The Israeli Defence Force has been open about monitoring the social media accounts of Palestinians, looking for “lone-wolf” attackers who might otherwise slip through the net. It reportedly does so automatically, using algorithms to look for terms such as “sword of Allah”.

Machine translation mistakes are a regular occurrence for anyone using AI to translate languages, particularly ones with little relationship. Earlier this month, Chinese social network WeChat apologised after its own machine translation system translated a neutral phrase meaning “black foreigner” as the n-word.

“When I ran the translator, the n-word came up and I was gobsmacked,” said Ann James, who had been texting back and forth with a friend when the faulty translation appeared.