ARTICLE TITLE: Sexist and Racist Google Adsense Advertisements
In a research paper recently submitted for publication, Sweeney ran more than 2,100 names of real people through Google searches. She found that names that sounded black were 25 percent more likely to trigger ads for criminal records than names that sounded white — even if, like Sweeney, the person had no criminal record.

That little display triggered a much larger research project in which Sweeney, a computer scientist and specialist in data privacy, concluded that Google searches of names more likely associated with black people often yielded advertisements for a criminal records search in that person’s name.

Latanya Sweeney , a professor of government at Harvard University, is a law-abiding citizen. So she was startled when a colleague showed her what happened when he ran her name through a Google search: an advertisement on the results page headlined ­“Latanya Sweeney, Arrested?”

Advertisement

Sweeney did not offer conclusions about exactly how this happens, or why, but said she planned further research to determine the causes.

Get Trendlines A business newsletter from Globe Columnist Larry Edelman covering the trends shaping business and the economy in Boston and beyond. Enter Email Sign Up

But the frequency with which the ads are paired to black-sounding names, said Sweeney, has real consequences.

“You could be in competition for an award, a scholarship, a new job,” she said. “You could be in a position of trust, like a professor, a judge. Having ads that show up suggestive of arrest, may actually discount your ability to function.”

For her study, Sweeney compiled lists of traditionally “black” names, such as Travon, Rasheed, Ebony, and Tamika, as well as “white” names such as Brad, Cody, Amy, and Jill.

The ads show up both on searches done on Google’s home page and on other websites that have built-in search functions and allow ads from Google to appear alongside the results. In all cases, Sweeney found the ads were from the same firm: Instant Checkmate LLC, a Las Vegas company that provides online background checks.

Advertisement

Instant Checkmate did not respond to repeated phone calls and e-mails seeking comment.

Google, meanwhile, issued a statement denying its AdWords business discriminates. AdWords is Google’s highly profitable service in which businesses pay to have their ads appear in the results when users search particular keywords or phrases.

“AdWords does not conduct any racial profiling,” said Google, adding the company’s policies prohibit advertisements “that advocate against an organization, person or group of people. It is up to individual advertisers to decide which keywords they want to choose to trigger their ads.”

Sweeney, a former professor at Carnegie Mellon University in Pittsburgh, did her undergraduate work at Harvard and was the first black woman to earn a doctorate in computer science from MIT. She founded Harvard’s Data Privacy Lab, which studies ways to share personal information over computer networks without compromising privacy.

For her study, Sweeney received funding from Google.

Sweeney said executives at Instant Checkmate told her they had bought search results from Google on the names of 100 million Americans. When one of these names is searched, Google displays an ad for Instant Checkmate, and gets a small fee if the searcher clicks on its ad. The more clicks an ad receives from searchers, the more likely it will appear on the page for that search term.

Not every search of the same name yields the same result; sometimes the advertisement from Instant Checkmate is neutral, simply offering to do a background check on the person whose name is searched. Other times, the ads from Instant Checkmate were more explicit, offering to provide an arrest record or criminal history.

Advertisement

Sweeney’s results dovetail somewhat with other research on “black” names, most notably a 2004 study that found employers were less likely to respond to resumes sent by people with black-sounding names.

For her research, Sweeney compiled a list of names from the 2004 study, and from a chapter in the book “Freakonomics” on distinctively black names. She then identified 2,184 people with either distinctively white or black names and confirmed the race of about 1,400 of them by looking up their photos in Google’s image database.

She found that first names were reliable predictors of a person’s race. Someone named Brad was almost always white, while someone named DeAndre was nearly always black.

Sweeney ran the names though Internet searches in two places — the main Google website, and the news site Reuters.com, which uses Google to search its story archive. Both sites display ads generated by Google’s advertising service.

Sweeney found that searches on Google’s own website produced Instant Checkmate ads just 16 percent of the time, but 84 percent of the time when searched on Reuters.com. And at the Reuters site, searches of black-sounding names were 25 percent more likely to yield ads with offers to view the person’s arrest or criminal record.

Other websites that use a Google search window and display Google ads yielded similar results. For example, entering “Latanya Sweeney” in the search box on one of the Globe’s websites, Boston.com, generated an ad from Instant Checkmate that reads in part, “Criminal records, phone, address, & more on Latanya Sweeney.”

Advertisement

Meanwhile, plugging “Jill Sweeney” into Boston.com’s search box yielded an Instant Checkmate ad that read: “Jill Sweeney found in database,” but no mention of an arrest or criminal record.

Sweeney said she has no idea why Google searches seem to single out black-sounding names. There could be myriad issues at play, some associated with the software, some with the people searching Google. For example, the more often searchers click on a particular ad, the more frequently it is displayed subsequently.

“Since we don’t know the reason for it,” she said, “it’s hard to say what you need to do.”

But Danny Sullivan, editor of SearchEngineLand.com, an online trade publication that tracks the Internet search and advertising business, said Sweeney’s research has stirred a tempest in a teapot. “It looks like this fairly isolated thing that involves one advertiser.”

He also said that the results could be caused by black Google users clicking on those ads as much as white users.

“It could be that black people themselves could be causing the stuff that causes the negative copy to be selected more,” said Sullivan. “If most of the searches for black names are done by black people . . . is that racially biased?”

On the other hand, Sullivan said Sweeney has uncovered a problem with online searching — the casual display of information that might put someone in a bad light. Rather than focusing on potential instances of racism, he said, search services such as Google might want to put more restrictions on displaying negative information about anyone, black or white.

Advertisement

For instance, Sullivan said Google could require advertisers to remove the words “arrest record” from all their ads.

Sweeney has submitted her study to an academic journal for publication, but is not allowed to identify it. She has posted the study online at the Social Science Research Network, and at Arkiv.org, a repository of research papers maintained by Cornell University.

Hiawatha Bray can be reached at bray@globe.com.. April 2, 2013

Volume 11, issue 3

PDF

Discrimination in Online Ad Delivery

Google ads, black names and white names, racial discrimination, and click advertising

Latanya Sweeney

Do online ads suggestive of arrest records appear more often with searches of black-sounding names than white-sounding names? What is a black-sounding name or white-sounding name, anyway? How many more times would an ad have to appear adversely affecting one racial group for it to be considered discrimination? Is online activity so ubiquitous that computer scientists have to think about societal consequences such as structural racism in technology design? If so, how is this technology to be built? Let's take a scientific dive into online ad delivery to find answers.

"Have you ever been arrested?" Imagine this question appearing whenever someone enters your name in a search engine. Perhaps you are in competition for an award, a scholarship, an appointment, a promotion, or a new job, or maybe you are in a position of trust, such as a professor, a physician, a banker, a judge, a manager, or a volunteer. Perhaps you are completing a rental application, selling goods, applying for a loan, joining a social club, making new friends, dating, or engaged in any one of hundreds of circumstances for which someone wants to learn more about you online. Appearing alongside your list of accomplishments is an advertisement implying you may have a criminal record, whether you actually have one or not. Worse, the ads may not appear for your competitors.

Job applications frequently include questions such as: Have you ever been arrested? Have you ever been charged with a crime? Other than a traffic ticket, have you been convicted of a crime? Employers ask these questions to establish trustworthiness. Because others often equate a criminal record with not being reliable or honest, protections exist for those having criminal records.

If an employer disqualifies a job applicant based solely upon information indicating an arrest record, the company may face legal consequences. The U.S. EEOC (Equal Employment Opportunity Commission) is the federal agency charged with enforcing Title VII of the Civil Rights Act of 1964, a law that applies to most employers, prohibiting employment discrimination based on race, color, religion, sex, or national origin. Guidance issued in 1973 extended protections to people with criminal records.5,11 Title VII does not prohibit employers from obtaining criminal background information. Certain uses of criminal information, however, such as a blanket policy or practice of excluding applicants or disqualifying employees based solely upon information indicating an arrest record, can result in a charge of discrimination.

To make a determination, the EEOC uses an adverse impact test that measures whether certain practices, intentional or not, have a disproportionate effect on a group of people whose defining characteristics are covered by Title VII. To decide, you calculate the percentage of people affected in each group and then divide the smaller value by the larger to get the ratio and compare the result to 80. For example, suppose a company laid off comparable black and white workers at the same rate—25 percent of blacks and 25 percent of whites—then the ratio, 25 divided by 25, would be 100 percent. If the ratio is less than 80 percent, then the EEOC considers the effect disproportionate and may hold the employer responsible for discrimination.6

What about online ads suggesting someone with your name has an arrest record, even when no one with your name has been arrested? Title VII does not apply unless you have an arrest record and can prove the potential employer routinely uses ads or information from the company sponsoring the ads, and the result has an inappropriate chilling effect on hiring applicants with criminal records.

The advertiser may argue the ads are commercial free speech—a constitutional right to display the ad associated with your name. The First Amendment of the U.S. Constitution protects advertising. In a landmark decision, the U.S. Supreme Court set out a test for assessing government restrictions on commercial speech, which begins by determining whether the speech is misleading.3 Are online ads suggesting the existence of an arrest record misleading if no one by that name has an arrest record?

Assume the ads are free speech: what happens when these ads appear more often for one racial group than another? Not everyone is being equally affected by the free speech. Is that free speech or racial discrimination?

Racism, as defined by the U.S. Commission on Civil Rights, is "any attitude, action, or institutional structure which subordinates a person or group because of their color . . . Racism is not just a matter of attitudes; actions and institutional structures can also be a form of racism."16 Racial discrimination results when a person or group of people is treated differently based on their racial origins, according to the Panel on Methods for Assessing Discrimination of the National Research Council.12 Power is a necessary precondition, because discrimination depends on the ability to give or withhold benefits, facilities, services, opportunities, etc., from someone who should be entitled to them and is denied on the basis of race. Institutional or structural racism, as defined in The Social Work Dictionary, is a system of procedures/patterns whose effect is to foster discriminatory outcomes or give preferences to members of one group over another.1

Racism can result, even if not intentional, and online activity now may be so ubiquitous that computer scientists have to think about societal consequences such as structural racism in the technology they design. These considerations frame the big picture, the relevant legal, societal, and technical landscape in which this exploration resides. Now we turn to the exploration itself: whether online ads suggestive of arrest records appear more often for one racial group than another among a sample of racially associated names. Then, we examine the role technology might play in combating this problem if evidence of the pattern exists.
