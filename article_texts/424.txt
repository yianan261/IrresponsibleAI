ARTICLE TITLE: Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent
24 Pages Posted: 22 Sep 2022

Date Written: August 31, 2022

Abstract

Academic surveillance can be considered as an emerging field of “capitalism surveillance” (Zuboff) pertaining to the dominance of a few companies in the surveillance field. Online proctoring software represent a variety of tools often based on artificial intelligence, such as Respondus Monitor, Proctorio, ProctorU, ProctorExam, Examity, ProctorTrack. While these tools generate legal issues of socio-economic discrimination and privacy, most of Canadian universities have used them during the pandemic and sometimes before that.



This paper considers the risks generated by AI tools for exam monitoring and the Canadian legal framework on data protection legislation, as well as on Artificial Intelligence (Bill C-27 – part 3: Artificial Intelligence and Data Act) in comparison with the European Commission’s proposal of regulation on AI (AI act). We make recommendations for the Canadian legislator to improve Bill C-27.. Organization

University of Ottawa

Published

2022

Project leader(s)

Céline Castets-Renard, Professor, Faculty of Law – Civil Law Section, University of Ottawa

Summary

This project examines how, during the COVID-19 pandemic, many universities used exam proctoring tools to compensate for the inability to conduct in-person exams.

The researchers found that while many surveillance processes and companies are operating in the industry, most tools use artificial intelligence techniques such as data mining and facial recognition to detect suspicious behaviour that could constitute cheating.

These companies use the personal information collected as part of their mission to monitor university exams. They also use it for secondary purposes of improving artificial intelligence tools. To do this, they obtain consent from students, but the conditions under which it is collected are not conducive to the expression of free, clear and individual consent. In addition, the separation of public and private sector privacy laws makes it difficult to characterize these outsourcing companies. Enforcing their potential liability as a principal under the Personal Information Protection and Electronic Documents Act ( PIPEDA ) is difficult in the context of enforcing provincial public sector laws.

Furthermore, this project demonstrates that control over the conditions of data collection and retention is made more difficult by the fact that many technology companies are U.S. -based and subject to U.S. law, and even require the transfer of data to the United States.

The researchers make five recommendations to address these issues, which can be found in the conclusion of the research report.

Project deliverables are available in the following language(s)

French

English

OPC -funded project

This project received funding support through the Office of the Privacy Commissioner of Canada’s Contributions Program. The opinions expressed in the summary and report(s) are those of the authors and do not necessarily reflect those of the Office of the Privacy Commissioner of Canada. Summaries have been provided by the project authors. Please note that the projects appear in their language of origin.

Contact information