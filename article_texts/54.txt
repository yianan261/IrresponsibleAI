Algorithms have taken hold over our lives whether we appreciate it or not.

When Facebook delivers us clickbait and conspiracy theories, it's an algorithm deciding what you're interested in.

When Uber ratchets up rush-hour prices, it's the service's algorithm kicking in to maximize profits.

When ads for shoes you can't afford follow you around the internet until you give in, it's an algorithm tracking your course.

This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.

Natalie Behring/Getty

Algorithms are also taking over policing. In cities like Los Angeles, Atlanta and Philadelphia, "predictive policing" algorithms comb through past crime data to tell officers which people and places are most at risk for future crimes.

Advertisement

The most popular is PredPol, an algorithm developed by the Los Angeles Police Department in collaboration with local universities that takes in hard data about where and when crimes happened and then makes a "hotspot" map of where crime will likely happen next.

But according to a study to be published later this month in the academic journal Significance, PredPol may merely be reinforcing bad police habits. When researchers from the Human Rights Data Analysis Group — a nonprofit dedicated to using science to analyze human-rights violations around the world — applied the tool to crime data in Oakland, the algorithm recommended that police deploy officers to neighborhoods with mostly black residents. As it happens, police in Oakland were already sending officers into these areas.

"These models are supposed to give you some unseen insight into where crime is supposed to be," William Isaac, one of the report's co-authors, said in an interview. "But it's just common-sense stuff, and we make a case that these software suites are basically used as a tool to validate police decisions."

Using a publicly-available version of PredPol's algorithm, researchers Isaac and Kristian Lum used 2010 arrest data from Oakland to predict where crimes would occur in 2011. To compare that map with what's actually going down in Oakland, researchers used data from the Census and the National Crime Victimization Survey to create a heat map showing where drug use in the city was most prevalent in 2011.

Advertisement

But according to a study to be published later this month in the academic journal Significance, PredPol may merely be reinforcing bad police habits. When researchers from the Human Rights Data Analysis Group — a nonprofit dedicated to using science to analyze human-rights violations around the world — applied the tool to crime data in Oakland, the algorithm recommended that police deploy officers to neighborhoods with mostly black residents. As it happens, police in Oakland were already sending officers into these areas.

"These models are supposed to give you some unseen insight into where crime is supposed to be," William Isaac, one of the report's co-authors, said in an interview. "But it's just common-sense stuff, and we make a case that these software suites are basically used as a tool to validate police decisions."

Using a publicly-available version of PredPol's algorithm, researchers Isaac and Kristian Lum used 2010 arrest data from Oakland to predict where crimes would occur in 2011. To compare that map with what's actually going down in Oakland, researchers used data from the Census and the National Crime Victimization Survey to create a heat map showing where drug use in the city was most prevalent in 2011.

A CU Boulder student is arrested for trespassing on the University of Colorado campus after authorities tried to squelch a huge marijuana smoke-in in Boulder, Colorado April 20, 2012 REUTERS/Rick Wilking

In an ideal world, the maps would be similar. But in fact, PredPol directed police to black neighborhoods like West Oakland and International Boulevard instead of zeroing in on where drug crime actually occurred. Predominantly white neighborhoods like Rockridge and Piedmont got a pass, even though white people use illicit drugs at higher rates than minorities.

Advertisement

To see how actual police practices in Oakland matched up with PredPol's recommendations, researchers also compared PredPol's map to a map of where Oakland Police arrested people for drug crimes. The maps were strikingly similar. Regardless of where crime is happening, predominantly black neighborhoods have about 200 times more drug arrests than other Oakland neighborhoods. In other words, police in Oakland are already doing what PredPol's map suggested — over-policing black neighborhoods — rather than zeroing in on where drug crime is happening.

Related stories

"If you were to look at the data and where they're finding drug crime, it's not the same thing as where the drug crime actually is," Lum said in an interview. "Drug crime is everywhere, but police only find it where they're looking."

PredPol did not respond to Mic's request for comment.

To be clear, Oakland does not currently use PredPol — researchers merely used Oakland as an example of what happens when you apply PredPol to a major metropolitan area. Dozens of other U.S. cities, however, do. It is a stapleof policing in Los Angeles, which has the second-largest department in the country after New York City. Across the nation, PredPol is deciding what neighborhoods and city blocks officers prioritize when they make their rounds.

Advertisement

Because PredPol's algorithm uses reported crime and arrests to generate a heat map — as opposed to where crime actually occurs — its recommendations can become a self-fulfilling prophecy. When officers are dispatched to neighborhoods where police already make a lot of arrests, they make even more, creating a feedback loop.

In a second experiment, Isaac and Lum hypothesized that sending police to neighborhoods chosen by the algorithm would lead to a jump in reported crime by 20%. The researchers fed that 20% increase in arrests back into the algorithm. The algorithm became orders of magnitude more confident that its predictions were correct.

"If police go there and find more crime, it creates a feedback loop, and the algorithm becomes more certain about these places that are over-policed," Lum said.

Predictive policing is still an exciting tool for departments under pressure from their city hall to modernize the police force. But many departments are giving up on crime mapping entirely for precisely the reason Isaac and Lum discovered in the course of their research: The new wave of predictive policing programs end up telling police what they already know. One criminologist Micspoke with last year referred to it as "old wine in new bottles."

Advertisement

Jeff Brantingham, anthropology professor at the University of California Los Angeles, displays a computer generated "predictive policing," zones at the Los Angeles Police Department Unified Command Post (UCP) in Los Angeles. Brantingham's research has helped lay the foundation for the field. AP Photo/Damian Dovarganes

Police in Richmond, California, decided not to renew their three-year PredPol contract after they couldn't find evidence it was working, citing double-digit increases in crime. In Burbank, police stopped relying on PredPol after a department-wide survey found that 75% of all officers had "low or extremely low" morale, in part due to new predictive policing directives.

"Officers on the street were told that this predictive model will tell you where to go and affect our crime rates positively — just do it," Sergeant Claudio Losacco of the Burbank Police Department said in a phone interview. "It's like telling a fisherman of 20 years that we're going to tell you how to fish."

To evaluate the fairness and efficacy of predictive crime algorithms, they would need to be audited by outside parties. But most predictive police technology exists in a black box of private sector trade secrets; systems that should be up for public scrutiny are outsourced to private companies like PredPol that don't have to disclose their algorithms for a public audit. The only way researchers were able to use the software in this case was to pull a version of the algorithm from one of PredPol's own, published studies.

"If predictive policing means some individuals are going to have more police involvement in their life, there needs to be a minimum of transparency," Adam Schwartz, a senior staff attorney with the Electronic Frontier Foundation, said in an interview "Until they do that, the public should have no confidence that the inputs and algorithms are a sound basis to predict anything."

Advertisement

Schwartz pointed out that in some states, such as Illinois, there are legal prohibitions on adopting systems that have a racially-disparate impact. Without being able to evaluate predictive policing systems, and strong laws in place to prevent police technology from amplifying the worst biases in police work, he says predictive policing isn't ready for actual police use.

"What we want for police to do is not to be putting in place new systems of predictive policing until a lot more study is done and safeguards are put in place," Schwartz said. "Frequently these systems shouldn't be adopted at all."

As for Oakland, they may not have PredPol yet, but Mayor Libby Schaaf has repeatedly sought over $150,000 to purchase PredPol for the Oakland Police Department. Malkia Cyril, executive director of the Oakland-based Center for Media Justice, says Oakland's legislators don't care that PredPol hasn't proven to be effective.

"Predictive policing is clearly not a solution, and it'll transfer existing bias and existing iniquities in the current policing system into a predictive approach," Cyril said. "It's not technology that makes the place a city more efficient and a better place to live. For us, it'll make the city unlivable.". 



Introduction



The expansion of digital record-keeping by police departments across the U.S. in the 1990s ushered in the era of data-driven policing. Huge metropolises like New York City crunched reams of crime and arrest data to find and target “hot spots” for extra policing. Researchers at the time found that this reduced crime without necessarily displacing it to other parts of the city—although some of the tactics used, such as stop-and-frisk, were ultimately criticized by a federal judge, among others, as civil rights abuses.

Advertisement

The next development in data-informed policing was ripped from the pages of science fiction: software that promised to take a jumble of local crime data and spit out accurate forecasts of where criminals are likely to strike next, promising to stop crime in its tracks. One of the first, and reportedly most widely used, is PredPol, its name an amalgamation of the words “predictive policing.” The software was derived from an algorithm used to predict earthquake aftershocks that was developed by professors at UCLA and released in 2011. By sending officers to patrol these algorithmically predicted hot spots, these programs promise they will deter illegal behavior.

But law enforcement critics had their own prediction: that the algorithms would send cops to patrol the same neighborhoods they say police always have, those populated by people of color. Because the software relies on past crime data, they said, it would reproduce police departments’ ingrained patterns and perpetuate racial injustice, covering it with a veneer of objective, data-driven science.

PredPol has repeatedly said those criticisms are off-base. The algorithm doesn’t incorporate race data, which, the company says, “eliminates the possibility for privacy or civil rights violations seen with other intelligence-led or predictive policing models.”

There have been few independent, empirical reviews of predictive policing software because the companies that make these programs have not publicly released their raw data.

Advertisement

A seminal, data-driven study about PredPol published in 2016 did not involve actual predictions. Rather the researchers, Kristian Lum and William Isaac, fed drug crime data from Oakland, California, into PredPol’s open-source algorithm to see what it would predict. They found that it would have disproportionately targeted Black and Latino neighborhoods, despite survey data that shows people of all races use drugs at similar rates.

PredPol’s founders conducted their own research two years later using Los Angeles data and said they found the overall rate of arrests for people of color was about the same whether PredPol software or human police analysts made the crime hot spot predictions. Their point was that their software was not worse in terms of arrests for people of color than nonalgorithmic policing.

However, a study published in 2018 by a team of researchers led by one of PredPol’s founders showed that Indianapolis’s Latino population would have endured “from 200% to 400% the amount of patrol as white populations” had it been deployed there, and its Black population would have been subjected to “150% to 250% the amount of patrol compared to white populations.” The researchers said they found a way to tweak the algorithm to reduce that disproportion but that it would result in less accurate predictions—though they said it would still be “potentially more accurate” than human predictions.



In written responses to our questions, the company’s CEO said the company did not change its algorithm in response to that research because the alternate version would “reduce the protection provided to vulnerable neighborhoods with the highest victimization rates.” He also said the company did not provide the study to its law enforcement clients because it “was an academic study conducted independently of PredPol.”

Advertisement

Other predictive police programs have also come under scrutiny. In 2017, the Chicago Sun-Times obtained a database of the city’s Strategic Subject List, which used an algorithm to identify people at risk of becoming victims or perpetrators of violent, gun-related crime. The newspaper reported that 85% of people that the algorithm saddled with the highest risk scores were Black men—some with no violent criminal record whatsoever.

Last year, the Tampa Bay Times published an investigation analyzing the list of people that were forecast to commit future crimes by the Pasco Sheriff’s Office’s predictive tools. Deputies were dispatched to check on people on the list more than 12,500 times. The newspaper reported that at least one in 10 of the people on the list were minors, and many of those young people had only one or two prior arrests yet were subjected to thousands of checks.

For our analysis, we obtained a trove of PredPol crime prediction data that has never before been released by PredPol for unaffiliated academic or journalistic analysis. Gizmodo found it exposed on the open web (the portal is now secured) and downloaded more than 7 million PredPol crime predictions for dozens of American cities and some overseas locations between 2018 and 2021.

This makes our investigation the first independent effort to examine actual PredPol crime predictions in cities around the country, bringing quantitative facts to the debate about predictive policing and whether it eliminates or perpetuates racial and ethnic bias.

Advertisement

We examined predictions in 38 cities and counties crisscrossing the country, from Fresno, California, to Niles, Illinois, to Orange County, Florida, to Piscataway, New Jersey. We supplemented our inquiry with Census data, including racial and ethnic identities and household incomes of people living in each jurisdiction—both in areas that the algorithm targeted for enforcement and those it did not target.

Overall, we found that PredPol’s algorithm relentlessly targeted the Census block groups in each jurisdiction that were the most heavily populated by people of color and the poor, particularly those containing public and subsidized housing. The algorithm generated far fewer predictions for block groups with more White residents.

Analyzing entire jurisdictions, we observed that the proportion of Black and Latino residents was higher in the most-targeted block groups and lower in the least-targeted block groups (about 10% of which had zero predictions) compared to the overall jurisdiction. We also observed the opposite trend for the White population: The least-targeted block groups contained a higher proportion of White residents than the jurisdiction overall, and the most-targeted block groups contained a lower proportion.

For more than half (20) of the jurisdictions in our data, the majority of White residents lived in block groups that were targeted less than the median or not at all. The same could only be said for the Black population in four jurisdictions and for the Latino population in seven.

Advertisement

When we ran a statistical analysis, it showed that as the number of crime predictions for block groups increased, the proportion of the Black and Latino populations also increased and the White population decreased.

We also found that PredPol’s predictions often fell disproportionately in places where the poorest residents live. For the majority of jurisdictions (27) in our data set, a higher proportion of the jurisdiction’s low-income households live in the block groups that were targeted the most. In some jurisdictions, all of its subsidized and public housing is located in block groups PredPol targeted more than the median.

We focused on census block groups, clusters of blocks that generally have a population of between 600 to 3,000 people because these were the smallest geographic units for which recent race and income data was available at the time of our analysis (2018 American Community Survey).

Block groups are larger than the 500-by-500-square-foot prediction squares that PredPol’s algorithm produces. As a result, the populations in the larger block groups could be different from the prediction squares. To measure the potential impact, we conducted a secondary analysis at the block level using 2010 Census data for blocks whose populations remained relatively stable. (See Limitations for how we define stable.)

Advertisement

We found that in nearly 66% of the 131 stable block groups, predictions clustered on the blocks with the most Black or Latino residents inside of those block groups. Zooming in on blocks showed that predictions that appeared to target majority-White block groups had in fact targeted the blocks nestled inside of them where more Black and Latino people lived. This was true for 78% of the 46 stable, majority-White block groups in our sample.

To try to determine the effects of PredPol predictions on crime and policing, we filed more than 100 public records requests and compiled a database of more than 600,000 arrests, police stops, and use-of-force incidents. But most agencies refused to give us any data. Only 11 provided at least some of the necessary data.

For the 11 departments that provided arrest data, we found that rates of arrest in predicted areas remained the same whether PredPol predicted a crime that day or not. In other words, we did not find a strong correlation between arrests and predictions. (See the Limitations section for more information about this analysis.)

We do not definitively know how police acted on any individual crime prediction because we were refused that data by nearly every police department. Only one department provided more than a few days’ worth of concurrent data extracted from PredPol that reports when police responded to the predictions, and that data was so sparse as to raise questions about its accuracy.

Advertisement

To determine whether the algorithm’s targeting mirrored existing arrest patterns for each department, we analyzed arrest statistics by race for 29 of the agencies in our data using data from the FBI’s Uniform Crime Reporting (UCR) project. We found that the socioeconomic characteristics of the neighborhoods that the algorithm targeted mirrored existing patterns of disproportionate arrests of people of color.

In 90% of the jurisdictions, per capita arrests were higher for Black people than White people—or any other racial group included in the dataset. This is in line with national trends. (See Limitations for more information about UCR data.)

Overall, our analysis suggests that the algorithm, at best, reproduced how officers have been policing, and at worst, would reinforce those patterns if its policing recommendations were followed.

Data Gathering and Preparation

We discovered access to PredPol prediction data through a page on the Los Angeles Police Department’s public-facing website that contained a list of PredPol reporting areas with links. Those links led to an unsecured cloud storage space on Amazon Web Services belonging to PredPol that contained tens of thousands of documents, including PDFs, geospatial data, and HTML files for dozens of departments, not just the LAPD. The data was left open and available, without asking for a password to access it. (Access has since been locked down.)

Advertisement

We first downloaded all the available data to our own database on June 8, 2020, using a cloud storage management tool developed by Amazon. We downloaded the data again and updated our analysis on Jan. 31, 2021. This captured a total of 7.8 million individual predictions for 70 different jurisdictions. These took the form of single-page maps indicating addresses, each marking the center of 500-by-500-foot boxes that the software recommended officers patrol during specific shifts to deter crime. Each report’s HTML code was formatted with the prediction’s date, time, and location. That allowed us to investigate patterns in PredPol predictions over time.

Of the 70 agencies in our dataset, we had less than six months of predictions for 10 of them and six others were empty folders. Not all the agencies were U.S.-based or even policing agencies—some were private security firms. One was using PredPol to predict oil theft and other crimes in Venezuela’s Boscán oil field, while another was using PredPol to predict protests in Bahrain. While these uses raise interesting questions, they fell outside the scope of our current investigation.

We limited our analysis to U.S. city and county law enforcement agencies for which we had at least six months’ worth of data. We confirmed with the law enforcement agency, other media reports, and/or signed contracts that they had used PredPol in the time period for which we had reports and the stop and start dates for each city. This reduced the list to 38 agencies.

Advertisement

For 20 of these 38 departments, some predictions in our data fell outside the stop/start dates provided by law enforcement, so we removed these predictions from the final data used for our analysis, in an abundance of caution. The final dataset we used for analysis contained more than 5.9 million predictions.

To determine which communities were singled out for additional patrol by the software, we collected demographic information from the Census Bureau for each department’s entire jurisdiction, not only the prediction locations.

For police departments, we assumed their jurisdictions included every block group in the city, an official boundary the Census calls a “census-designated place.” (See more in the Limitations section.) Sheriff’s departments were more complicated because in some cases their home county includes cities they do not patrol. For those, we obtained the sheriff departments’ patrol maps and used an online tool called Census Reporter to compile a list of every block group within the disclosed jurisdiction.

We looked up the census tracts and block groups for the coordinates of every prediction in our database using the Census’s geocoding API. The census tracts and block groups used in our analysis were drawn during the 2010 Census. We gathered demographic data for these areas from the five-year population estimates in the 2018 American Community Survey (ACS), the most recent survey available when we began our investigation.

Advertisement

The ACS only provides demographic information down to the block-group level—subdivisions of a census tract that generally include between 600 and 3,000 people and take up an average of 39 blocks. These are significantly larger than the prediction boxes, which are just shy of six acres or about the size of a square city block, but we had no good alternative. Smaller, block-level demographic data from the Census Bureau for 2020 is not scheduled to be released until 2022. The block-level data available during our investigation is more than 10 years old, and we found that the demographic changes since then in the majority of block groups in our data were significant (30% or more for the block groups’ Black, Latino, or White populations). (See more in the Limitations section.)

Layering on the Census ACS data from 2018 allowed us to carry out a disparate impact analysis about the people who lived in areas the PredPol software targeted at that time—and those who lived in areas that were not targeted.

Prediction Analysis and Findings

Methods

Given the quantity and various types of data we gathered, we used various methods of analysis for this investigation, each of which will be described in detail in subsequent sections.



We carried out several disparate impact analyses seeking to discern whether predictions fell more heavily on communities of color, low-income communities, and blocks containing public housing.



For the race/ethnicity and income analyses, we merged 2018 American Community Survey data and prediction data and observed the makeup of block groups that were targeted above and below the median; those targeted the most; and those targeted the least. (We also analyzed the data in a continuous manner to confirm that our findings were due to an underlying trend, not spurious observations.)



We also conducted a limited disparate impact analysis at the smaller, block-level scale using 2010 Census data.

Advertisement

For the public housing disparate impact analysis, we gathered data released by the federal Department of Housing and Urban Development on the location of subsidized and public housing in all of the jurisdictions in our data, mapped them out, and observed the frequency of PredPol predictions for those locations.

To examine possible relationships between predictions and law enforcement actions, we analyzed more than 270,000 arrest records from 11 agencies, 333,000 pedestrian or traffic stops from eight agencies, and 300 use-of-force records from five agencies, all of which were released under public records laws. (Most agencies did not provide records.)

We also examined arrest rates by race/ethnicity for 29 of the 38 jurisdictions in our final dataset using data from the FBI’s Uniform Crime Reporting program.

Lastly, six agencies provided disaggregated arrest data that included race, and we examined this data to discern arrest rates across racial groups for some crime types, such as cannabis possession.

Advertisement

Disparate Impact Analysis

Frequent police contact, like frequent exposure to a pollutant, can have an adverse effect on individuals and result in consequences that extend across entire communities. A 2019 study published in the American Sociological Review found that increased policing in targeted hot spots in New York City under Operation Impact lowered the educational performance of Black boys from those neighborhoods. Another 2019 study found that the more times young boys are stopped by police, the more likely they are to report engaging in delinquent behavior six, 12, and 18 months later.

We carried out a disparate impact analysis to assess which, if any, demographic groups would be disproportionately exposed to potential police interactions if the agencies had acted on recommendations provided by PredPol’s software. We analyzed the distribution of PredPol predictions for each jurisdiction at the geographic level of a census block group, which is a cluster of blocks with a population of between 600 to 3,000 people, generally.

Block groups in our data were made up of 28 blocks, on average, and contained an average of 1,600 residents. As stated earlier, these were much larger than PredPol’s 500-by-500-foot prediction squares but are the smallest geographic unit for which recent government information about the race, ethnicity, and household income of its inhabitants was available at the time of our investigation.

There was significant variation in the length of time each of the 38 jurisdictions in our analysis used the software during our window of access, and which crimes they used it to predict. There was also a huge difference in the average number of predictions on block groups among jurisdictions, which varied from eight to 7,967.

Advertisement

The 38 jurisdictions were of varying sizes; Jacksonville, Texas, was the smallest, with 13 block groups, and Los Angeles the largest, with 2,515 block groups.

We calculated the total number of predictions per block group in each jurisdiction. We then sorted the block groups in each jurisdiction by their prediction counts and created three categories for analysis.

We defined the “most-targeted block groups” as those in each jurisdiction that encompassed the highest 5% of predictions, which corresponded to between one and 125 block groups. We defined the “median-targeted block groups” as the 5% of each jurisdiction’s block groups straddling the median block group for predictions. And we defined the “least-targeted block groups” as each jurisdiction’s block groups with the bottom 5% of predictions.

We also calculated whether the majority (more than 50%) of a jurisdiction’s demographic group lived in the block groups targeted more or less than the median.

Advertisement

We chose to define the most-targeted and least-targeted groups using the 5% metric rather than using alternative methods, such as the Interquartile Range (IQR).

With the IQR method, we would consider block groups below the 25th percentile to be the least targeted and block groups above the 75th percentile to be the most targeted, but this did not fit our requirements because of the large volume of zero-prediction block groups (10%). Using the IQR method, the average percentage of a jurisdiction’s block groups in the most-targeted group would have been 7% of the jurisdiction’s block groups, whereas the average in the least-targeted group would have made up 71% of the jurisdiction’s block groups. This difference is too large to make a meaningful comparison of the demographic composition of the least- and most-targeted block groups. This is why we chose to use 5% for the least- and most-targeted groups.

In some of the larger jurisdictions, more than 5% of block groups received zero predictions. In those cases, we chose the most-populated block groups with no predictions for the 5%. We also ran an analysis in which we counted every block group with zero predictions as the least-targeted block groups, and the findings did not change significantly. (See Limitations for more.)

The analysis consisted of the following steps:

Advertisement

1. Sort the list of block groups from most targeted to least targeted and label the most targeted, median targeted or least targeted as defined above.

2. Get ACS population data at the block-group-level for the following demographic populations:



a) Race: African American, Asian, Latino, and White.



b) Household Income: Less than $45,000, $75,000–$100,000, $125,000–$150,000, Greater than $200,000

3. Calculate the proportion for each demographic group d in a jurisdiction’s most-targeted, median-targeted, and least-targeted block groups. Hence we calculate 3×38 values of dt:

Advertisement

4. Calculate the proportion for each demographic group d, in all the block groups in the jurisdiction j. This gives us 38 values for dj:

5. To determine if a demographic group’s proportion in the most-, median-, or least-targeted blocks is greater than it is in the jurisdiction overall, we simply compare the values. For each jurisdiction, we compare the three values of dt to dj. We present the results aggregated across all jurisdictions:

Advertisement

6. We also calculated what proportion of a jurisdiction’s demographic group d lived in the block groups targeted more and less than the median:

7. Using these values we can calculate the number of jurisdictions where the demographic majority lives in the most- and least-targeted blocks. After carrying out the comparisons individually for each jurisdiction, we present the aggregated results.



Advertisement

We acquired block group demographic data from the Census Bureau’s 2018 American Community Survey. We conducted our analysis for race/ethnicity and household income. Not every jurisdiction had reliable estimates at the block group level for each racial or income group because some populations were too small.

For our main analysis, we focused on the demographic composition of the most- and least-targeted blocks as well as those targeted more than the median and less than the median. Doing so allowed us to measure the disparate impact in a way that is clear yet simple to understand. In order to ensure we weren’t cherry-picking statistics, we also carried out an analysis that preserved the continuous nature of the data.

For each of our 38 jurisdictions, we looked at the relationship between the following variable pairs at the level of the census block group:

Prediction count and population of Race (Asian, African American, Latino, and White)

Prediction count and number of Households at different income ranges (Greater than $200,000, Between $125,000 and $150,000, Between $75,000 and $100,000, and Less than $45,000).

We calculated the Spearman correlation coefficient and used a box plot to visualize the distribution of correlation coefficients for each pair of variables and calculated the median coefficient values across all 38 jurisdictions. This analysis allowed us to measure if, for a given jurisdiction, the prediction count that a block group received is correlated to the race/ethnicity or income of the people living in it.

Advertisement

We chose to calculate individual coefficients for each jurisdiction, rather than collapsing all the block groups across jurisdictions into one analysis since they are independent distributions. There could be meaningful differences between jurisdictions’ policing practices, and there are definitely significant variations in the number of block groups and the racial and household income composition of the people living in each of them, as well as the total number of predictions they received. For this reason, we analyzed each jurisdiction individually and examined the distribution of those correlation coefficients to see if a pattern emerged.

For our final analysis, we looked at the demographic composition of the 38 jurisdictions individually by binning the block groups into discrete buckets based on the number of predictions they received. We made 10 equal-sized bins based on the percentile score of a block group in a given jurisdiction. The first bin had block groups that had between 0 predictions and the 10th percentile, and the last bin had block groups that were between the 90th and 100th percentile. We then calculated the demographic composition of the collection of block groups in each of these bins. Doing this allowed us to observe if there was any relationship between the composition of the racial/ethnic or income groups in each of these bins and the predictions it received. Unlike our previous analysis, this method includes all the block groups in each jurisdiction. We present the averaged results across all jurisdictions in the following two sections and provide the results for individual jurisdictions in our GitHub.

In order to measure the accuracy of our findings, we used the margin of errors for population estimates present in the 2018 ACS data to run our analysis on the lower and upper bounds of each block group’s population estimates. This allowed us to measure how much our findings varied due to ACS data inaccuracies. There wasn’t a significant change in our findings for African American, Asian, Latino, or White populations, or for different median household income ranges, no matter which population estimate we used.

To err on the side of caution throughout this methodology, we state our findings with the lowest of the three values we calculated (e.g., “at least 63% of jurisdictions”).

Advertisement

The only demographic group for which the findings varied significantly was Native Americans, so we didn’t use those findings in our analysis.

To determine whether focusing on a smaller geography would affect our findings, we completed a secondary analysis at the block level using 2010 data and found even greater disparities (more in the next section and Limitations).

Race and Ethnicity Analysis

Most- and Least-Targeted Block Groups

For the majority of jurisdictions we analyzed, the most-targeted block groups had a higher Black or Latino population while block groups that were never or infrequently targeted tended to have a higher White population when compared to the jurisdiction as a whole.

In a majority of 38 jurisdictions, more Blacks and Latinos lived in block groups that were most targeted, while more Whites lived in those that were least targeted.



Advertisement

In at least 84% of departments (32), a higher proportion of Black or Latino residents lived in the most-targeted block groups compared to the jurisdiction overall. Looking only at Black residents, a higher proportion lived in the most-targeted block groups in 66% of jurisdictions (25), and for Latinos alone, it’s 55% of jurisdictions (21).

This same phenomenon was less common for Asian residents. In at least 34% of jurisdictions (13), Asian populations in the most-targeted block groups exceed the jurisdiction’s median Asian population. It was the least common for White people. In at least 21% of jurisdictions (8) a higher proportion of White residents live in the block groups most targeted by PredPol’s software than the jurisdiction overall.

Conversely, when we looked at the block groups least targeted by PredPol’s software, their demographics were reversed. For at least 74% of the policing agencies in our data (28 jurisdictions) the proportion of White residents in the least-targeted block groups was higher than the jurisdiction overall. This was true for Blacks and Latinos much less often, in at least 16% (6) and 18% (7) of jurisdictions, respectively.

Analyzing the most-targeted blocks from all 38 jurisdictions, we found the African American and Latino proportion increased by 28% and 16% on average, and the average White population decreased by 17%. The opposite trend was true for the least-targeted blocks.

Advertisement

As predictions increased, the proportion of Blacks and Latinos in block groups increased. The opposite was true for Whites.

In Salisbury, Maryland, at least 26% of residents in the jurisdiction’s median block group are Black, according to the Census Bureau. However, the Black population jumped to at least 5%, on average, for block groups that were most targeted by PredPol.

In Portage, Michigan, the most-targeted block groups contained at least nine times as many Black residents as the median-targeted block groups in the city and at least seven times as many Black residents as the city overall.

And the number of predictions in these most-targeted areas was often overwhelming.

Advertisement

In one block group in Jacksonville, Texas (block group 1 of the 950500 census tract), PredPol predicted that either an assault or a vehicle burglary would occur at one of various locations in that block group 12,187 times over nearly two years. That’s 19 predictions each and every day in an area with a population o​​f 1,810 people. This block group’s population is at least 62% Black and Latino and between 15% and 21% White.

In fact, at least 83% of Jacksonville’s Black population lived in block groups that were targeted more than 7,500 times in two years. This was many times more than the percentage of the city’s White population that lived in those block groups (at least 23%).

When we asked PredPol about it, the company said Jacksonville was misusing the software for some of the time, using too many daily shifts, which resulted in extra predictions per day. (See more in the Company Response section.) The Jacksonville police did not respond to requests for comment.

Block Groups Above and Below the Median

We also found that for at least 76% of the jurisdictions in our data (29), a majority of a jurisdiction’s Black or Latino population lived in the block groups PredPol targeted more than the median. A majority of Asian residents lived in these block groups for at least 55% of jurisdictions in our data.

Advertisement

The algorithm largely spared White residents from the same level of scrutiny it recommended for Black and Latino residents.

For more than half (20) of the jurisdictions in our data, the majority of White residents lived in block groups that were targeted less than the median or not at all. The same could only be said for the Black population in four jurisdictions and for the Latino population in seven.

Block-Level Race Analysis

Advocates for hot spot policing stress that the small size of the prediction area is crucial. To determine whether focusing on a smaller geography would affect our findings, we completed a secondary analysis at the block level using 2010 Census data. To reduce the effects of population shifts over the ensuing decade, we limited this analysis to block groups with at least one prediction in our dataset where Black, Latino, and White populations did not change more than 20% between the 2010 Census and the 2018 ACS. Asian and Native American populations were too small for this secondary analysis. For our dataset, 20% proved to be a good threshold for selecting block groups where the demographic population shifts were small.

In the resulting 135 reasonably stable block groups (2% of the block groups in our data), we found that 89 of the targeted blocks within them had even higher concentrations of Black and Latino residents than the overall block group. (See more in the Limitations section.)

Advertisement

In some cases, zooming in on blocks showed that predictions that appeared to target majority White block groups had in fact targeted the blocks within them where people of color lived. For example, every single prediction in a majority White block group in Los Angeles’s Northridge neighborhood (block group 2 of the 115401 census tract) occurred on a block whose residents were almost all Latino. The most-targeted block in a majority White block group in Elgin, Illinois. (block group 1 of the 851000 Census tract), had seven times more Black residents than the rest of the block group.

For 36 (78%) of the 46 stable, majority-White block groups, predictions most frequently targeted the blocks inside of them that had higher percentages of Black or Latino residents. In only 18 (36%) of the 50 stable, majority-Black and -Hispanic block groups did the most-targeted blocks have higher percentages of White people than the block group overall.

Correlation Between Predictions and Race

We analyzed the relationship between the volume of predictions a block group received and its race and ethnic makeup using the Spearman correlation coefficient. We calculated the correlation coefficient for all 38 jurisdictions individually. For each jurisdiction, we calculated four coefficients, one for each race/ethnicity in our analysis. Thus, we had 38 × 4 coefficients. We visualized the distribution to surface the underlying trend.

The data suggests that as the number of predictions in a block group increases, the Black and Latino proportion of the population increases and the White and Asian proportion of the population decreases. While the median correlation is low, there is a lot of variation. This may be the result of the algorithm echoing existing policing practices or because some jurisdictions in the data are much more segregated than others.

Advertisement

As mentioned previously, PredPol’s prediction boxes are much smaller than a block group. Since the correlation coefficients are calculated at the level of the block group, they would not pick up the sort of targeting that we describe in the previous section, where even within some White-majority block groups, the most-targeted blocks were the ones where people of color lived. Thus these correlation coefficients are more conservative than the one carried out at the level of a census block.

We were not able to carry out this analysis at that more granular level due to the limitations of the block-level Census demographic data available to us.

As the number of predictions in a block group increased, the Black and Latino proportion of the population increased



Advertisement

Race/Ethnicity Composition of Deciles

To observe how the compositions of different race/ethnicity groups changed across block groups as a property of predictions, we binned the block groups into discrete buckets based on the number of predictions they received and calculated the proportion of the race/ethnicity and income groups in our analysis that lived in the collection of block groups in each bin.

After calculating these values for each of our 38 jurisdictions individually, we calculated the mean value for each bucket across all jurisdictions. This is shown in the chart below. The figure shows that, on average, as the number of predictions a block group received increases, the proportion of the Black and Latino populations increases and the White population decreases.

Neighborhoods with the most predictions had the lowest share of White residents.

Our analysis showed that the most-targeted block groups had a higher Black or Latino population than the jurisdiction as a whole, while block groups that were never or infrequently targeted tended to have a higher percentage of White residents than the jurisdiction as a whole.

Advertisement

To see how the demographic composition changed for any individual jurisdiction, see our GitHub here.

Wealth and Poverty Analysis

Joining prediction data with the Census Bureau’s 2018 American Community Survey data also gave us insight into the financial strata of those living in areas targeted by PredPol.

The federal poverty line, at $26,200 a year income for a family of four, is widely criticized as too low a measure to provide an accurate picture of all the people experiencing financial and food insecurity in America. To capture a broader swath of lower-income families than the poverty line allows, we chose a different federal metric: the income threshold for public school students to qualify for the federal free and reduced lunch program, which is $48,000 annually for a family of four. We rounded down to $45,000 because that was as close as the Census data could get us.

In our 38 jurisdictions, we observed significant variation in the upper income range. Some had almost no households that made more than $200,000, while for others they made up 15% of the jurisdiction. To account for the variation, we used three different higher income ranges to try to capture wealthier neighborhoods in different municipalities. These ranges were chosen using what was available in the Census’s table for household Income in the past 12 months.

Advertisement

We counted the number of households in each Census block group with an annual income of $45,000 or less as well as the following groupings: $75,000 to $100,00, $125,000 to $150,000, and more than $200,000. We then calculated what percentage of each jurisdiction’s portion of these income groups was located in block groups in the most-, median- and least-targeted areas for PredPol predictions, as we had for the racial and ethnic analysis.

Most- and Least-Targeted Block Groups

Our analysis found that, compared to the jurisdiction as a whole, a higher proportion of a jurisdiction’s low-income households lived in the block groups PredPol’s software targeted the most, and a higher proportion of middle-class and wealthy households lived in the block groups it targeted the least.

In at least 71% of jurisdictions (27) in our data set, a higher proportion of low-income households (annual income $45,000 or less) lived in the block groups most targeted by PredPol’s software compared to the jurisdiction overall. This was true for households that made more than $200,000 in at least 21% of jurisdictions (8).

In 30 jurisdictions, the most-targeted block groups had poorer households.

Advertisement

Looking at the most-targeted blocks in all 38 jurisdictions in our dataset, the proportion of households that earned less than $45,000 on average increased by 18%, and the average proportion of households that earned more than $200,000 decreased by 26%. The opposite trend was true for the least-targeted blocks.

As predictions increased, poorer households increased and wealthy ones decreased.

In some places, the disparity was even more dramatic. In Haverhill, Massachusetts, for instance, at least 21% of the jurisdiction’s 4,503 low-income households were located in the most-targeted block groups. In Decatur, Georgia, at least one in three (34%) of the jurisdiction’s low-income households lived in two block groups that PredPol targeted constantly—more than 11,000 predictions each over almost three years.

We also looked at the distribution of wealthier households in jurisdictions and compared those to PredPol predictions. We found that block groups that were never targeted tended to be wealthier. For a majority of the jurisdictions in our data, Census block groups that PredPol targeted the least were composed of more households that earned at least $200,000 a year than in the jurisdiction overall.

Advertisement

In Merced, California, for instance, the least-targeted block groups had at least 10 wealthy households on average. The median-targeted block groups had none. And in Birmingham, Alabama, the median block group didn’t have a single wealthy household. But block groups where PredPol never made predictions had at least 34 wealthier households on average.

To see how the demographic composition of the neighborhoods changed in an individual jurisdiction based on the software’s targeting, see our GitHub here.

Block Groups Above and Below the Median

We also found that for 33 jurisdictions (87%), the majority of the jurisdiction’s low-income households were located in the block groups targeted more than the median. In only 13 jurisdictions (34%) did a majority of households earning $200,000 or more live in block groups targeted more than the median.

Correlation Between Predictions and Income

We analyzed the relationship between the volume of predictions a block group received and the income range of the people living there. For each jurisdiction, we calculated four coefficients, one for each income range in our analysis. Thus, we had 38 × 4 coefficients. We visualized the distribution to surface the underlying trend.

Advertisement

We found a weak positive correlation between the proportion of households that make less than $45,000 a year and the number of predictions a block group receives and a weak negative correlation for the rest of the income levels. This means the data suggests that as the prediction count increases, the proportion of households that make less than $45,000 a year increases.

The proportion of households earning less than $45,000 a year positively correlated with predictions

Income Composition of Deciles

To observe how the composition of household income ranges changed across block groups as a function of predictions, we binned the block groups into discrete buckets based on the number of predictions they received and calculated the proportion of people of each income range in our analysis that lived there.

Advertisement

After calculating the distribution for each of our 38 jurisdictions individually, we calculated the mean value for each bucket across all block groups. This is shown in the figure below. The figure shows the same trend we observed in our previous analysis: Looking at the data for all 38 jurisdictions together, on average, as the number of predictions a block group received increases, the proportion of households that make less than $45,000 a year increases.

As predictions increased, average household income decreased

Our analysis found that, compared to the jurisdiction as a whole, a higher proportion of a jurisdiction’s low-income households lived in the block groups PredPol’s software targeted the most, and a higher proportion of wealthy households lived in the block groups it targeted the least. We also found that across the entire distribution as the predictions a block group received increased, the proportion of households making $45,000 a year or less also increased. To see how the composition changed for individual jurisdictions, see our Github here.

Public Housing Analysis

As we continued to explore these most-predicted areas, we noticed a large number were in and around public housing complexes, home to some of the nation’s poorest residents.

Advertisement

Using HUD’s online housing lookup tool, we gathered the locations of 4,001 public or private subsidized housing communities, homeless shelters, and elderly and special needs housing in the jurisdictions in our data. We then looked at the frequency with which PredPol predicted a crime would occur there.

For 22 jurisdictions in our data (57%), more than three-quarters of their public housing facilities were located in block groups that PredPol targeted more than the median. For some jurisdictions, a majority of public housing was located in the most-targeted block groups:

In Jacksonville, 63% of public housing was located in the block groups PredPol targeted the most.

In Elgin, 58% of public housing was located in the block groups PredPol targeted the most.

In Portage; Livermore, California; Cocoa, Florida; South Jordan, Utah; Gloucester, New Jersey; and Piscataway, every single public housing facility was located in block groups that were targeted the most.

In 10 jurisdictions, PredPol predicted crimes in blocks with public housing communities nearly every single day the program was in use there. (Since this analysis did not require Census demographic data, we counted the number of predictions for their locations.)

We were able to get arrest data for some of these departments, but when we compared it to the rate and type of predictions made, they could be miles apart.

Advertisement

For example, PredPol predicted that assault would occur an average of five times a day at the Sweet Union Apartments, a public housing community in Jacksonville—3,276 predictions over the 614 days that the Jacksonville Police Department used the software during the period we analyzed. PredPol said Jacksonville had at some point created too many shifts, so it was receiving repeat predictions. The police department did not respond to requests for comment.

It is unknown whether police increased patrols in those areas as a result (see more in Limitations). Arrest data provided by the Jacksonville police showed that officers made 31 arrests there over that time. Only four were for domestic violence or assault. The majority of the other 27 violations were outstanding warrants or drug possession.

Stops, Arrests, and Use of Force

We sought to determine the effect of PredPol predictions on commonly collected law enforcement data: stops, arrests, and use of force.

To do that, we made more than 100 public records requests to 43 agencies in our data for their use-of-force, crime, stop, and arrest data from 2018 through 2020. We focused on jurisdictions where PredPol predictions disproportionately targeted Black, Latino, or low-income neighborhoods and where the software predicted nonproperty crime types.

Advertisement

We also requested “dosage” data, which is PredPol’s term for data the software provides agencies that track when officers visit each prediction box and how much time they spent there—but the requests were roundly denied by nearly every agency, many on the grounds that the agency has stopped using PredPol and could no longer access the information.

Some agencies refused to give us any data at all; others gave us some data. Only two—Plainfield, New Jersey, and Portage—gave us all the types of data we requested.

We obtained data for pedestrian or traffic stops from eight agencies, arrest data from 11 agencies, and officer use-of-force incidents from five agencies. Some of the use-of-force records were provided as written reports rather than data, so we pulled out the metadata to build spreadsheets. Each set of new data was then checked against the original records by another journalist on the project.

We geolocated each arrest, stop, or use of force incident to a latitude/longitude coordinate. This allowed us to check whether the incident occurred on the same day as a PredPol prediction and within 250 feet of the center of the 500-by-500-foot box suggested for patrol (called “inside the box” by PredPol).

Advertisement

When an agency did not provide us with any data, we gathered jurisdiction-level arrest statistics from the FBI’s Uniform Crime Reporting program.

Stop, Arrest, and Use of Force Analysis

PredPol claims that using its software is likely to lead to fewer arrests because sending officers to the company’s prediction boxes creates a deterrent effect. However, we did not observe PredPol having a measurable impact on arrest rates, in either direction. (See Limitations for more about this analysis.)

While these findings are limited, a closer examination of the block groups that PredPol targeted most frequently suggests that the software recommended that police return to the same majority Black and Latino blocks where they had already been making arrests.



When we compared per capita arrests in the block groups that PredPol targeted most frequently—those in the top 5% for predictions—with the rest of the jurisdiction, we found they had higher arrests per capita than both the least-targeted block groups and the jurisdiction overall. These areas of high arrests also have higher concentrations of Black and Latino residents than the overall jurisdiction, according to Census data.

Advertisement

For example, data provided by Salisbury, Georgia, from 2018 to 2020 shows per capita arrests on the most-targeted block groups, those in the top 5% for predictions, were nearly seven times the arrest rate of the jurisdiction as a whole. The proportion of Black and Latino residents living in these most-targeted block groups is twice that of the jurisdiction as a whole, according to Census figures.

Neighborhoods with the most crime predictions had higher arrest rates.

This same pattern repeated for all 11 departments that provided us with disaggregated arrest data: The block groups most targeted by PredPol had both higher percentages of Black or Latino residents and higher arrests per capita than the jurisdiction overall.

We found a similar pattern for the agencies that provided us with data about use-of-force incidents. For three out of the five of them, per capita use-of-force rates were higher in the most-targeted block groups than the overall jurisdiction.

Advertisement

In Plainfield, per capita use-of-force rates in the jurisdiction’s most-targeted block groups were nearly two times the entire jurisdiction’s rate. In Niles, Illinois, per capita use-of-force in the most-targeted block groups was more than two times the jurisdiction’s rate. In Piscataway., it was more than 10 times the jurisdiction’s rate.

Arrests and use-of-force incidents are influenced by far too many variables to attribute statistical changes or any particular contact directly to PredPol predictions without further evidence.

We reviewed police reports we were able to obtain and, in some neighborhoods, arrests in prediction areas seemed to be mostly in response to calls for service while in others, many of the arrests were of the “curious cop” variety, where the officer initiated the contact without a crime report while on patrol. Even in those latter instances, we do not have direct confirmation that the PredPol prediction is what brought the police officer there that day.

While we cannot make any claims about causality, our findings show that both arrests of and police use of force on people of color were much more prevalent in the areas that PredPol targeted most frequently.

Advertisement

Overall Policing Patterns

Patterns of officers overpolicing people of color have been documented by researchers, civil rights activists, and the U.S. Department of Justice’s Civil Rights Division for decades.

We sought to examine whether the disproportionate pattern that we observed in PredPol’s predictions —targeting neighborhoods where people of color live—mirrored the agencies’ existing policing patterns. To do that, we analyzed the most widely available public data: arrests of people of color.

We gathered jurisdiction-level arrest statistics these agencies voluntarily report to the FBI’s Uniform Crime Reporting program (UCR). Three agencies in our dataset did not report crime statistics and, for six others, the UCR data was not disaggregated by race. Our analysis is based on the 29 remaining agencies.

We found that per capita arrest rates were higher for Black people than White people in 26 (90%) of the jurisdictions with usable statistics in our dataset. Officers in more than a third of these departments arrested Black people at more than three times the rate of White people. Officers in Decatur, for example, arrested Black people at a rate nine times that of White people.

Advertisement

These rates are somewhat understated, as no agency reported Latino arrest rates but rather reported arrests of people of that ethnicity as either White or Black. So part of the White arrest rate would include arrests of Latinos. (Only 18% of U.S. Latinos identify their race as Black, according to the Pew Research Center.)

Arrest rates tended to be higher for Black people than White people

For some types of charges, the differences in arrest rates between Black and White people in the jurisdictions we examined were breathtaking.

In Piscataway, New Jersey, a jurisdiction where PredPol made nearly 9,600 predictions for drug-related offenses, Black people were arrested for cannabis possession at a rate two times that of White people, proportionate to population. In Homewood, Alabama, the rate of cannabis arrests for Black people was 50 times that of White people. The National Survey on Drug Use and Health shows people of all races use drugs at similar rates.

Advertisement

When we analyzed individual arrest data for the six cities in our dataset that provided information about the arrestee’s race, we found that in each one Black people either were stopped, searched, arrested, or had force used against them by police at higher rates than any other racial group.

In Salisbury, for example, our analysis showed that Black people were stopped by officers at a rate twice as high as that of White people. During these stops, they were almost three times as likely to be searched and four times as likely to be arrested as White people.

There is a considerable body of academic and journalistic research supporting the idea that, across the country, people of color are disproportionately targeted by police for stops, arrests, and use-of-force. A study of millions of traffic stops in North Carolina found that Black and Latino people are more likely to be pulled over and searched than Whites, even though Whites were more likely to have illegal contraband on them. An analysis of police stops in Cincinnati, Ohio, showed that Black drivers constituted about three-quarters of arrests following a traffic stop but only made up 43% of the city’s population. A New York Times investigation found that police in Minneapolis, Minnesota, used force against Blacks seven times as frequently as against Whites.

Limitations

Prediction Data



Advertisement

Because of the way we obtained the data, we cannot be certain we’ve captured predictions for every jurisdiction using PredPol during the time period in our data: from Feb. 15, 2018, until Jan. 30, 2021. Public contracting records suggest that at least one department that is not in our dataset used PredPol between 2018 and 2020: Lakewood, Washington.

Since every coordinate in our dataset needed to be tied to corresponding Census data for the analysis, we disregarded any data that could not be geographically located by the Census API. This resulted in dropping 780 prediction locations out of 110,814, or 0.7%.

We were unable to investigate the “accuracy” of PredPol predictions—whether predicted crimes occurred on predicted days in predicted locations—nor do we know how each agency chose to respond to each prediction. As mentioned earlier, we asked every department to provide data about officer responses to PredPol predictions, which PredPol calls “dosage,” but only Plainfield and Portage provided any of that data. It is possible that some officers ignore PredPol reports entirely. Records for Plainfield showed officers responding to less than 2% of the total predictions that PredPol made for the department. How much of this is due to incomplete reporting by the department is impossible to know.

The Los Angeles Police Commission’s Office of the Inspector General found that LAPD officers’ response to PredPol predictions there varied wildly: Logs showed officers spent under a minute at most locations but in some cases stayed for more than an hour.

Advertisement

Classifying Least-Targeted Block Groups

In our analysis, we used 5% of a jurisdiction’s block groups as the window of analysis to classify the most-targeted, median-targeted, and least-targeted block groups. We chose 5% as it ensured non-overlapping block groups for small jurisdictions and still provided a reasonable sample size for comparison in the larger jurisdictions.

For 10 of the 38 jurisdictions, however, more than 5% of each of their block groups had no predictions. In those cases, we chose the most populous 5% of block groups with no predictions for analysis. To ensure this didn’t have a significant effect on our findings, we also ran our analysis by classifying all block groups with no predictions as the least-targeted block groups. If there were a significant difference in the demographic composition of those block groups, this analysis would allow us to observe that.

Running the analysis with all zero block groups classified as the least-targeted did not significantly change our analysis.

The number of departments showing racial or ethnic disparities in predictions changed by one or two, at most, depending on the group being examined. For the household income analysis, we saw no change in the distribution of households qualifying for free and reduced lunch. Three additional jurisdictions contained a higher percentage of households making more than $200,000 in the least-targeted group under the broader definition, and we saw a similar increase for households making $125,000–$150,000 and $75,000–$100,000 as well.

Advertisement

Given these small differences, we chose to keep the sample size consistent, since the analysis seemed easier to understand this way.

Jurisdictions That Didn’t Follow the Trend

For a handful of jurisdictions, the analysis did not show the same income and race/ethnicity trends as the other departments: Livermore, California; Calcasieu Parish, Louisiana; Forsyth County, Georgia; Boone County, Indiana; Temple Terrace, Florida; West Springfield Town, Massachusetts; South Jordan, Utah; Piscataway; Ocoee, Florida; and Farmers Branch, Texas. So we looked a bit deeper into their prediction locations.

In some of the jurisdictions, such as Farmers Branch, a significant number of predictions corresponded to parking lots for shopping centers, sports fields, and other commercial businesses located in more affluent, White neighborhoods. In our analysis, these predictions were counted toward the residents of the surrounding residential neighborhood even though the predictions were really targeting a commercial structure. Parking lots are widely known as common locations for car thefts and burglaries.

In other jurisdictions, such as Piscataway, a significant number of the predictions were labeled “DUI/DWI/Traffic.” These also targeted major roads and were near commercial areas. In our analysis, these were counted toward the residential, richer block groups surrounding them, which had high concentrations of White people, even though the predictions didn’t target those homes.

Advertisement

2018 American Community Survey Data

Our community exposure analysis relies on ACS five-year population estimates for race and poverty of residents at the census block group level, leaving us vulnerable to the margin of errors in the Census’s demographic data. Since margins of error can be quite high at the block group level, we used the lowest value of population estimate in this analysis. This is reflected throughout this methodology by the use of the term at least when talking about a particular demographic population.

We did not include individuals who identify as multiracial in our analysis.

Agency Jurisdictions

Census geographies do not necessarily map cleanly to law enforcement jurisdictions. As such, our jurisdiction maps may be slightly different from each agency’s actual patrol areas. For police departments, we assumed their jurisdiction included every block group in the city, an official boundary the Census calls a “census-designated place.”

We used Census Reporter to determine the block groups inside each “census-designated place” in our data. It is possible these miss some areas an agency patrols or include areas it does not patrol. For example, a local police department may contract its services to a transit authority or another government agency, potentially extending its patrol area beyond city limits.

Advertisement

We made the decision to limit our analysis to block groups in a jurisdiction’s census-designated place because we felt that, even if a given police department’s jurisdiction extends farther than these block groups, our findings within the city limits would still be accurate.

We do not expect that these unknown variables would change our findings significantly.

Sheriff departments were more complicated because in some cases, their county includes cities they do not patrol. For these agencies, we obtained their patrol maps and used Census Reporter to compile a list of every block group within the disclosed jurisdiction.

Block-Group-Level Data

In order to analyze the demographics of people living in the areas targeted by PredPol’s algorithm, we had to do our main analysis at the block group level, the smallest area available from the 2018 American Community Survey, which covered the time period in our dataset. The Census Bureau says it will not release block-level data from the 2020 Census until 2022.

Advertisement

Because of this, our main analysis does not perfectly calculate the racial, ethnic, and wealth characteristics of the residents “inside the box” for each prediction. The prediction boxes are 500 feet by 500 feet, or about the size of a city block. It is possible the micro-populations in those prediction boxes are slightly different from the overall block-group population. And sometimes the boxes encompass entirely commercial areas, where no one lives but which the surrounding community would frequent.

To test how using larger geographic locations may affect our findings, we conducted a secondary, block-level analysis using Census data from 2010, the most current available block-level data. Because those figures are stale and neighborhoods can change drastically in a decade, we limited the analysis to the most stable block groups.

We defined a stable block group as one whose Black, Latino, and White populations did not change more than 20% between the 2010 Census and the 2018 ACS. There are 154 block groups across 24 jurisdictions in our dataset that satisfy this definition. We looked specifically at the 135 stable block groups that received at least one prediction. From 2010 to 2018, these stable block groups on average lost 20 White and three Black residents and gained four Latino residents. These block groups average 2,163 residents.

Inside these 135 block groups were 4,710 blocks that were targeted by PredPol predictions. We found that even within a block group, the blocks most targeted by PredPol tended to have the highest concentration of Black or Latino residents. For 66% of the stable block groups in our analysis, the most-targeted block had a higher percentage of Black or Latino residents than the median block in the block group.

Advertisement

Measuring Arrest Rates

Arrest rates are dependent on a multitude of factors. We could not ascertain the direct effects of predictions on arrest or use-of-force rates overall because nearly every department denied our requests for data on whether and how officers responded to PredPol predictions. And for the two that did provide us with data on officer responses, it was either insufficient or unreliable. The Portage Police Department in Michigan provided us data for only two days out of the nearly three years we requested. Records provided by Plainfield showed officers responding to only 1% of the total predictions that PredPol made for the department. How much of this is due to incomplete reporting is impossible to know.

In the absence of this data, we examined possible linkages between arrests and PredPol predictions by comparing the average number of arrests and average number of predictions per block per week for the 10 jurisdictions we had data for. We calculated the correlation between the average number of arrests and average number of predictions per week. Given the limited data available to us, we were unable to find a strong correlation between predictions and arrests for any of the 10 departments in our dataset.

Correlations between predictions and arrests were weak

UCR, Arrest, and Use of Force Data

Data from local law enforcement arrived in many different forms, and often with redactions. Many agencies excluded certain arrests, such as arrests of juvenile offenders, and thus we can assume police arrested more people in predicted locations than we were able to document.

Advertisement

No agency in our dataset reported Latino arrest rates to the FBI’s UCR program but rather reported those arrested as either White or Black.

In our arrest-rate analysis, when calculating the arrest rates for days with predictions on a given block, we were unable to identify whether an arrest occurred due to patrol officers being directed to the area by PredPol’s algorithm, due to unrelated patrols, from a crime report from a member of the community, or for some other reason.

PredPol Response

We sent our methodology as well as the underlying data to PredPol, which renamed itself Geolitica earlier this year. The company confirmed that the reports “appeared to be” generated by its software.

Brian MacDonald, CEO of the company, stated that the analysis was based on “erroneous” and “incomplete” data. When asked to explain how it was incomplete, he did not respond.

Advertisement

The errors, he said, were that one department (Jacksonville, Texas) inadvertently doubled up on some shifts, resulting in additional predictions, and that the data for at least 20 departments in the cache included “zombie reports,” which the company generated for internal testing purposes after a department stopped using the software. We kept the Jacksonville data because they were actual predictions delivered to departments.



We also explained to the company that we had confirmed the dates of usage with the departments in our data directly, through contracts and/or through other media reports and discarded predictions that fell outside of it. We offered to provide those usage dates to MacDonald. Instead, he offered to allow us to use the software for free on publicly available crime data instead of reporting on the data we had gathered. After we declined, he did not respond to further emails from us.



In response to questions regarding the software’s disproportionate targeting of Black, Latino, and low-income neighborhoods, MacDonald said that the software doesn’t have any information on the underlying demographic of the areas under patrol. “If those areas received a greater number of patrol boxes, it is because the people who lived in those locations were reporting crimes at a higher rate than in other parts of the jurisdictions.’’ He also referenced a study concluding that there is a direct relationship between poverty and crime rates in a given area.

When we pointed out that we found some jurisdictions using the software to predict drug crimes, something the company has stated the software should not be used for, since these can be selectively enforced in different neighborhoods, he said policing agencies make their own decisions on how to use the software. “We provide guidance to agencies at the time we set them up and tell them not to include event types without clear victimization that can include officer discretion, such as drug-related offenses.”

Advertisement

Law Enforcement Agency Responses

We reached out to every law enforcement agency whose predictions were included in our analysis with a list of questions. Only 13 agencies responded at all, despite multiple attempts, and 11 of those said they were no longer using the software.

“When I took over as chief, I knew this was a useless tool,” Thomas Mosier, the police chief in Piscataway, said in a telephone interview. “As I remember this system, it was clunky. The ends didn’t justify the means.”

“As time went on, we realized that PredPol was not the program that we thought it was when we had first started using it,” Sgt. Craig Kootstra, chief of staff of the Tracy, California, police department, said in an email.

Sgt. Joseph LaFrance, a public information officer at the West Springfield Police Department in Massachusetts, said the agency never shared predictions with individual officers. “We passed on renewing the contract, finding we didn’t need to spend money on a system to tell us what we already knew, [like] we have a shoplifting problem in the Riverdale Plaza,” he wrote in an email.

Alexandria, Louisiana, and Temple Terrace still have contracts with PredPol, but say they are no longer using it.

The sheriff’s office in Boone County, Indiana, and the police department in Decatur were the only two agencies actively using the software who responded to us. Maj. Brian Stevenson, operations commander in Boone County, said his department currently uses PredPol to get a general sense of where crime is occurring, not to inform daily missions but said they could start using it to direct daily patrols in the future.

Sgt. John Bender of the Decatur Police Department said the agency likes PredPol. He said the software helps guide the department’s decisions on where to patrol. “The program as well as the officers’ own knowledge of where crime is occurring assists our department in utilizing our patrol resources more efficiently and effectively,” he wrote in an email.

Advertisement

The only agency whose officials directly expressed concern about the racial and socioeconomic disparities in our findings was the Elgin Police Department in Illinois.

Among the questions we asked were whether the departments made any arrests due to an officer being in a location for a PredPol prediction. Most ignored the question and those that did write said either no or they didn’t know of any.

Conclusion

We found that PredPol’s algorithm as used by dozens of law enforcement agencies disproportionately targeted vulnerable populations, including low-income communities and residents of public housing. We also found that its predictions disproportionately targeted neighborhoods with proportionately more Black and Latino residents.

In at least 74% of the jurisdictions in our data, the least-targeted block groups (many of which had no predictions at all) also had the highest proportion of White residents in the jurisdiction. In at least 84% of departments, a higher proportion of Black or Latino residents lived in the most-targeted block groups compared to the jurisdiction overall.

Advertisement

The poor were also disproportionately targeted. For the majority of jurisdictions in our data, a higher proportion of the jurisdiction’s low-income households lived in the block groups that were targeted the most. In some, nearly all of the jurisdiction’s subsidized and public housing was located in block groups that were targeted the most.

Some block groups were the subject of crime predictions every day and in multiple locations within the same block group. The people most likely to be affected by daily PredPol predictions were residents of public and subsidized housing, among the poorest residents. Our data showed that for 10 jurisdictions (26%), the algorithm predicted crimes would occur in these communities at least once nearly every day the software was used for the agency.

The cascading consequences as a result of a police contact for residents of public and subsidized housing can be severe: In cities with crime-free-housing ordinances like Elgin, police contact, even for low-level offenses and even by the residents’ guests, can lead to eviction.

We also found that PredPol’s predictions mirrored existing arrest patterns. For the 11 jurisdictions that provided us granular arrest data, we found that the blocks most targeted by PredPol were also more likely to be scenes of arrests overall. Our analysis of arrests by race as reported to the FBI Uniform Crime Reporting project by 29 departments in our data (90%) showed Black people were more likely to be arrested than White people in all but three of the jurisdictions.

Advertisement

Acknowledgments

We thank Kristian Lum (formerly of the University of Pennsylvania, now with Twitter), William Isaac (research affiliate at Oxford University and Google Deepmind), Brian Root (Human Rights Watch), Stats.org, Kristin Lynn Sainani (Stanford University), David Weisburd (George Mason University), Laura Kurgan (Columbia University Graduate School of Architecture, Planning and Preservation), and Dare Anne S. Brawley (Columbia University Graduate School of Architecture, Planning and Preservation) for reviewing an earlier draft of this methodology.. This article is co-reported with The Markup.



Between 2018 and 2021, more than one in 33 U.S. residents were potentially subject to police patrol decisions directed by crime-prediction software called PredPol.

Advertisement

The company that makes it sent more than 5.9 million of these crime predictions to law enforcement agencies across the country—from California to Florida, Texas to New Jersey—and we found those reports on an unsecured server.

Gizmodo and The Markup analyzed them and found persistent patterns.

Residents of neighborhoods where PredPol suggested few patrols tended to be Whiter and more middle- to upper-income. Many of these areas went years without a single crime prediction.

By contrast, neighborhoods the software targeted for increased patrols were more likely to be home to Blacks, Latinos, and families that would qualify for the federal free and reduced lunch program.

Advertisement

These communities weren’t just targeted more—in some cases, they were targeted relentlessly. Crimes were predicted every day, sometimes multiple times a day, sometimes in multiple locations in the same neighborhood: thousands upon thousands of crime predictions over years. A few neighborhoods in our data were the subject of more than 11,000 predictions.

The software often recommended daily patrols in and around public and subsidized housing, targeting the poorest of the poor.

“Communities with troubled relationships with police—this is not what they need,” said Jay Stanley, a senior policy analyst at the ACLU Speech, Privacy, and Technology Project. “They need resources to fill basic social needs.”

Yet the pattern repeated nearly everywhere we looked:

Advertisement

Neighborhoods in Portage, Michigan, where PredPol recommended police focus patrols have nine times the proportion of Black residents as the city average. Looking at predictions on a map, local activist Quinton Bryant said, “It’s just giving them a reason to patrol these areas that are predominantly Black and Brown and poor folks.”

In Birmingham, Alabama, where about half the residents are Black, the areas with the fewest crime predictions are overwhelmingly White. The neighborhoods with the most have about double the city’s average Latino population. “This higher density of police presence,” Birmingham-based anti-hunger advocate Celida Soto Garcia said, “reopens generational trauma and contributes to how these communities are hurting.”

the city’s average Latino population. “This higher density of police presence,” Birmingham-based anti-hunger advocate Celida Soto Garcia said, “reopens generational trauma and contributes to how these communities are hurting.” In Los Angeles, even when crime predictions seemed to target a majority White neighborhood, like the Northridge area, they were clustered on the blocks that are almost 100% Latino. The neighborhoods in the city where the software recommended police spend the most time were disproportionately poor and more heavily Latino than the city overall. “These are the areas of L.A. that have had the greatest issues of biased policing,” said Thomas A. Saenz, president and general counsel of the LA-based Latino civil rights group MALDEF.

100% Latino. The neighborhoods in the city where the software recommended police spend the most time were disproportionately poor and more heavily Latino than the city overall. “These are the areas of L.A. that have had the greatest issues of biased policing,” said Thomas A. Saenz, president and general counsel of the LA-based Latino civil rights group MALDEF. About 35 miles outside of Boston, in Haverhill, Massachusetts, PredPol recommended police focus patrols in neighborhoods that had three times the Latino population and twice the low-income population as the city average. “These are the communities that we serve,” said Bill Spirdione, associate pastor of the Newlife Christian Assembly of God and executive director of the Common Ground food pantry.

In the Chicago suburb of Elgin, Illinois, neighborhoods with the fewest crime predictions were richer, with a higher proportion than the city average of families earning $200,000 a year or more. The neighborhoods with the most predictions didn’t have a single one; instead, they had twice as many low-income residents and more than double the percentage of Latino residents as the city average. “I would liken it to policing bias-by-proxy,” Elgin Police Department deputy chief Adam Schuessler said in an interview. The department has stopped using the software.

Overall, we found that the fewer White residents lived in an area—and the more Black and Latino residents lived there—the more likely PredPol would predict a crime there. The same disparity existed between richer and poorer communities.

In neighborhoods most targeted by Prediction software, Black and Latino populations were higher



“No one has done the work you guys are doing, which is looking at the data,” said Andrew Ferguson, a law professor at American University, who is a national expert on predictive policing. “This isn’t a continuation of research. This is actually the first time anyone has done this, which is striking because people have been paying hundreds of thousands of dollars for this technology for a decade.”

It’s impossible for us to know with certainty whether officers spent their free time in prediction areas, as PredPol recommends, and whether this led to any particular stop, arrest, or use of force. The few police departments that answered that question either said they couldn’t recall or that it didn’t result in any arrests, and the National Association of Criminal Defense Lawyers said its members are not informed when crime prediction software leads to charges.

Advertisement

Jumana Musa, director of that group’s Fourth Amendment Center, called the lack of information a “fundamental hurdle” to providing a fair defense.

“It’s like trying to diagnose a patient without anyone fully telling you the symptoms,” Musa said. “The prosecution doesn’t say, ‘The tool that we purchased from this company said we should patrol here.’”

That’s because they don’t know either, according to the National District Attorneys Association, which polled a smattering of members and found that none had heard of it being part of a case.

Only one of 38 law enforcement agencies in our analysis, the Plainfield Police Department in New Jersey, provided us with more than a few days of PredPol-produced data indicating when officers were in prediction boxes—and that data was sparse. None of it matched perfectly with arrest reports during that period, which were also provided by the agency.

Advertisement

We found the crime predictions for our analysis through a link on the Los Angeles Police Department’s public website, which led to an open cloud storage bucket containing PredPol predictions for not just the LAPD but also for dozens of other departments. When we downloaded the data on Jan. 31, 2021, it held 7.4 million predictions dating back to Feb. 15, 2018. Public access to that page is now blocked.

We limited our analysis to U.S. law enforcement agencies with at least six months of predictions and removed predictions generated outside of contract dates, which were likely testing or trial periods. That left 5.9 million predictions provided to 38 agencies over nearly three years.

Who uses PredPol



PredPol, which renamed itself Geolitica in March, criticized our analysis as based on reports “found on the internet.” But the company did not dispute the authenticity of the prediction reports, which we provided, acknowledging that they “appeared to be generated by PredPol.”

Advertisement

Company CEO Brian MacDonald said our data was “incomplete,” without further explanation, and “erroneous.” The errors, he said, were that one department inadvertently doubled up on some shifts, resulting in additional predictions, and that the data for at least 20 departments in the cache included predictions that were made after the contract period and not delivered to the agencies.

We explained that we had already discovered date discrepancies for exactly 20 departments and were not using that data in our final analysis and volunteered to share the analysis dates with him for confirmation. He instead offered to allow us to use the software for free on publicly available crime data instead of reporting on the data we had gathered. After we declined, he did not respond to further emails.



Only 13 out of 38 departments responded to requests for comment about our findings and related questions, most with a written statement indicating they no longer use PredPol.

One exception was the Decatur Police Department in Georgia. “The program as well as the officers’ own knowledge of where crime is occurring assists our department in utilizing our patrol resources more efficiently and effectively,” public information officer Sgt. John Bender said in an emailed statement. A third of Decatur’s low-income households were in a pair of neighborhoods that were each the subject of more than 11,000 crime predictions in two years.

Advertisement

As predictions increased, average household income decreased

Except for Elgin, Illinois, whose deputy chief called the software “bias by proxy,” none of the 38 agencies that used PredPol during our analysis period expressed concern about the stark demographic differences between the neighborhoods that received the most and least predictions.

We asked MacDonald whether he was concerned about the race and income disparities. He didn’t address those questions directly, but rather said the software mirrored reported crime rates, “to help direct scarce police resources to protect the neighborhoods most at risk of victimization.” The company has long held a position that because the software doesn’t include race or other demographic information in its analysis, that “eliminates the possibility for privacy or civil rights violations seen with other intelligence-led or predictive policing models.”

Yet according to a research paper, PredPol co-founders determined in 2018 that the algorithm would have targeted Black and Latino neighborhoods up to 400% more than White residents in Indianapolis had it been used there.



Advertisement

MacDonald said in his email that the company did not provide the study to its law enforcement clients because it “was an academic study conducted independently of PredPol.” The authors presented the paper at an engineering conference that’s not part of the usual police circuit, the 2018 IEEE International Conference on Systems, Man and Cybernetics.



The study authors developed a potential tweak to the algorithm that they said resulted in a more even distribution of crime predictions, but they found the predictions were less in line with later crime reports, making it less accurate than the original, although still “potentially more accurate” than human predictions.

MacDonald said the company didn’t adjust its algorithm in response.

“Such a change would reduce the protection provided to vulnerable neighborhoods with the highest victimization rates,” he said.



Advertisement

While MacDonald responded to some written questions by email, none of the company’s leaders would agree to an interview for this story.

To use PredPol’s algorithm, police departments set up an automatic feed of crime reports, which experts and police said include incidents reported by both the public and by officers, and choose which crimes they want to be predicted. The algorithm uses three variables to come up with future crime predictions: the date and time, the location, and the type of past crime reports.

The predictions consist of 500-by-500-foot boxes marked on a map listing the police shift during which the crimes are most likely to occur. PredPol advises officers to “get in the box” during free time. Officials in some cities said officers frequently drove to prediction locations and completed paperwork there.

How predictive policing works

Advertisement

In his email to Gizmodo and The Markup, MacDonald said the company’s choice of input data ensures the softare’s predictions are unbiased.

“We use crime data as reported to the police by the victims themselves,” he said. “If your house is burglarized or your car stolen, you are likely to file a police report.”

But that’s not always true, according to the federal Bureau of Justice Statistics (BJS). The agency found that only 40% of violent crimes and less than a third of property crimes were reported to police in 2020, which is in line with prior years.

The agency has found repeatedly that White crime victims are less likely to report violent crime to police than Black or Hispanic victims.



Advertisement

In a special report looking at five years of data, BJS found an income pattern as well. People earning $50,000 or more a year reported crimes to the police 12% less often than those earning $25,000 a year or less.

Wealthy and White victims of violent crime are less likely to report to police

This disparity in crime reporting would naturally be reflected in predictions.

“There’s no such thing as crime data,” said Phillip Goff, co-founder of the nonprofit Center for Policing Equity, which focuses on bias in policing. “There is only reported crime data. And the difference between the two is huge.”

Advertisement

MacDonald didn’t respond to questions about these studies and their implications, but PredPol’s founders acknowledged in their 2018 research paper that place-based crime prediction algorithms can focus on areas that are already receiving police attention, creating a feedback loop that leads to even more arrests and more predictions there.

We examined more than 270,000 arrests in 11 cities using PredPol that provided those records to us (most refused) and found that locations with lots of predictions tended to have high arrest rates in general, suggesting the software was largely recommending officers patrol areas they already frequented.

Five cities provided us with data on officer use of force, and we found a similar pattern. In Plainfield, per capita use-of-force rates were nearly double the city average in the neighborhoods with the most predictions. In Niles, Illinois, per capita use of force was more than double the city average in high-prediction neighborhoods. In Piscataway, New Jersey, the arrest rate was more than 10 times the city average in those neighborhoods.

Arrests per capita relative to jurisdiction average



Advertisement

“It’s a reason to keep doing what they’re already doing,” said Soto Garcia, the Birmingham-based activist, “which is saying, ‘This area sucks.’ And now they have the data to prove it.”

Take the 111-unit Buena Vista low-income housing complex in Elgin. Six times as many Black people live in the neighborhood where Buena Vista is located than the city average.

Police made 121 arrests at the complex between Jan. 1, 2018, and Oct. 15, 2020, according to records provided by the city, many for domestic abuse, several for outstanding warrants, and some for minor offenses, including a handful for trespassing by people excluded from the complex.

Those incidents, along with 911 calls, fed the algorithm, according to Schuessler, the Elgin Police Department’s deputy chief.

Advertisement

As a result, PredPol’s software predicted that burglaries, vehicle crimes, robberies, and violent crimes would occur there every day, sometimes multiple times a day—2,900 crime predictions over 29 months.

By comparison, the software only predicted about 5% as many crimes, 154, in an area about four miles north of Buena Vista where White residents are the majority.

Neighborhoods with the most predictions had the lowest share of White residents



Schuessler said police spent a lot of time at Buena Vista because of a couple of police programs, not software predictions.



Advertisement

Frequent police presence at Buena Vista, whatever led them there, had steep consequences for one family.

Brianna Hernandez had spent two years on a waiting list to get into Buena Vista. When she found an intent-to-evict notice on her door last year, she said she broke down in tears in the kitchen that would no longer be hers. It was November 2020. Daily covid-19 infection rates in Illinois had spiked to an all-time high, and hospitals were stuffed to capacity with the sick and the dying.

A few months earlier, Hernandez’s longtime boyfriend Jonathan King had stopped by Buena Vista to drop off cash for expenses for her and their three small children.



He was sitting on her car in the parking lot, waiting, when officer Josh Miller of the police department’s Crime Free Housing Unit rolled by in an unmarked car.

Advertisement

“You know you’re not supposed to be here, right?” King remembers Miller asking him.

The city’s crime-free housing ordinance requires all leases to allow eviction if the renters, their relatives, or guests are involved in criminal activity, even nearby, and allows the city to punish landlords that don’t deal with it.

King, now 31, said Buena Vista had banned him years before when he was on parole for a robbery he committed as a minor in Chicago 14 years earlier.

“They told him that once you got off probation you would be able to come back,” Hernandez said. “Apparently, that didn’t happen.”

Advertisement

It was King’s third arrest for trespassing at Buena Vista. He ran for it, and when officers caught up to King, they said they found a gun nearby, which King denies belongs to him. Miller arrested him for trespassing and weapons possession. The arrest came at the time of a PredPol prediction, but Schuessler said that’s not what led to it. That case is still pending.

“I know he’s banned, but what can a man do?” Hernandez asked. “He has kids.”

She said the arrest led to the eviction notice from Buena Vista. (Buena Vista wouldn’t confirm or deny it.) Hernandez remembers her 4-year-old and 5-year-old children asking, “Why are we going to a hotel?” and struggling for an answer. “They want to know why we’re moving stuff out. Why this and why that…. I wanted to sit down and cry.”

Advertisement

Robert Cheetham, the creator of a PredPol competitor, HunchLab, said he wrestled with the vicious cycle crime prediction algorithms could create.

“We felt like these kinds of design decisions mattered,” he said. “We wanted to avoid a situation where people are using the patrol area maps as an excuse for being around too much and in a way that wouldn’t necessarily be helpful.” He said his company tried to solve the problem by evening out the number of predictions delivered to each neighborhood.

Advocates in at least six cities we spoke to were unaware the software was being used locally. Even those involved in government-organized social justice committees said they didn’t have a clue about it.

“It did not come up in our meetings,” said Kenneth Brown, the pastor of Haverhill’s predominantly Black and Latino Calvary Baptist Church, who chaired a citywide task force on diversity and inclusion last year.

Advertisement

Calcasieu Parish, La., which started receiving predictions on April 9, 2019, refused to confirm it was using the software. Robert McCorquodale, an attorney with the sheriff’s office who handles public records requests, cited “public safety and officer safety” as the reasons and said that, hypothetically, he wouldn’t want would-be criminals to outwit the software.

“I don’t confess to be an expert in this area,” he said, “but I feel like this is not a public record.”

We kept Calcasieu in our data because its predictions began in the middle of our analysis period and continued until the end, suggesting it is a legitimate new client. Calcasieu’s predictions were not among the most disparate in our data, and removing them would not meaningfully alter the results of our analysis.

Gizmodo and The Markup also found that some policing agencies were using the software to predict crimes PredPol advises against. These include drug crimes, which research has shown are not equally enforced, and sex crimes, both of which MacDonald said the company advises clients against trying to predict.

Advertisement

However, we found four municipalities used PredPol to predict drug crimes between 2018 and 2021: Boone County, Indiana; Niles, Illinois; Piscataway, New Jersey; and Clovis, California. Clovis was also one of three departments using the software to predict sexual assaults. The other two were Birmingham and Fort Myers, Florida.

When we asked MacDonald about it, he said policing agencies make their own decisions on how to use the software.

“We provide guidance to agencies at the time we set them up and tell them not to include event types without clear victimization that can include officer discretion, such as drug-related offenses,” he wrote. “If they decide to add other event types later that is up to them.”

Thomas Mosier, the police chief in Piscataway, said in an interview that he doesn’t recall receiving any instructions about not predicting certain crime types. The other agencies declined to comment about it or ignored our questions altogether.

Advertisement

Nearly every agency also combined fundamentally different crime types into a single prediction. For instance, authorities in Grass Valley, California, mixed assaults and weapons crimes with commercial burglaries and car accidents.

MacDonald said, “research and data support the fact that multiple crime types can be concentrated in specific crime hotspots.”

Christopher Herrmann, a criminologist at the John Jay College of Criminal Justice, disagreed.

“Crime is very specific,” Herrmann said. “A serial murderer is not going to wake up one day and start robbing people or start stealing cars or selling drugs. The serial shoplifter isn’t going to start stealing cars. A serial rapist isn’t going to start robbing people.”

Advertisement

A study looking at crime patterns in Philadelphia found that “hot spots of different crime types were not found to overlap much,” and a 2013 book about predictive policing published by the RAND Corporation recommended against mixing crimes for predictions.

When we asked police departments that made arrests at the time and locations of PredPol predictions whether the software had brought them to the locations, they generally wouldn’t comment.

Corey Moses, for instance, was stopped by the LAPD on Feb. 11, 2019, for smoking a Newport cigarette in a nonsmoking area by a train station in MacArthur Park during the time of a crime prediction period there. The officer ran Moses’s name and discovered he had a warrant for an unpaid fine for fare evasion. Moses was cuffed, searched, and thrown in jail for the night.

“Sometimes you gotta really be doing some stupid stuff for the police to bother you, and then sometimes you don’t,” said Moses, who is Black and 41 years old. “You can just be at the wrong place at the wrong time.”

Advertisement

The LAPD didn’t respond to questions about whether the officer was responding to a PredPol prediction.

We did not try to determine how accurately PredPol predicted crime patterns. Its main promise is that officers responding to predictions prevent crimes by their presence.

But several police departments have dropped PredPol’s software in recent years, saying they didn’t find it useful or couldn’t judge its effectiveness. These include Piscataway; West Springfield, Massachusetts; and Los Angeles, Milpitas, and Tracy, California.

“As time went on, we realized that PredPol was not the program that we thought it was when we had first started using it,” Tracy Police Department chief of staff Sgt. Craig Koostra said in a written statement. He did not respond to a request to elaborate.

Advertisement

Some agencies soured on the software quickly. In 2014, a year after signing up, Milpitas Police Department lieutenant Greg Mack wrote in an evaluation that the software was “time consuming and impractical” and found no evidence that using it significantly lowered crime rates.

In his email, MacDonald declined to provide the number of clients the company has now or had during the analysis period but stated that the number of U.S. law enforcement agencies in our data set was not an accurate count of its clients since 2018. Of the 38 U.S. law enforcement agencies in our analysis, only 15 are still PredPol customers—and two of those said they aren’t using the software anymore, despite paying for it.

Even PredPol’s original partner, the LAPD, stopped using it last year.

The department said it was a financial decision. But it came after the LAPD’s inspector general said it couldn’t determine if the software was effective and members of the Stop LAPD Spying Coalition protested at a police commission meeting, waving signs reading “Data Driven Evidence Based Policing = Pseudoscience” and “Crime Data Is Racist.”

Advertisement

The result was an end to a relationship begun under former police chief, Bill Bratton, who had sent one of his lieutenants to UCLA to find interesting research that could be applied to crime-fighting. He ran across P. Jeffrey Brantingham, an anthropologist whose early work involved devising models for how ancient people first settled the Tibetan plateau.

“Each time mathematics interfaces itself with a new discipline, it is invigorated and renewed,” Brantingham and PredPol co-founder George Mohler, now a computer scientist at Indiana University–Purdue University Indianapolis wrote in a National Science Foundation grant application in 2009. Brantingham’s parents were academics who pioneered the field of environmental criminology, the study of the intersection of geography and crime. And he said he learned a lot at their feet.

“I didn’t realize it, but I was accumulating knowledge by osmosis, hearing about crime and criminal behavior while spending time with my parents,” Brantingham said in a 2013 profile in UCLA’s student newspaper.

“Criminals are effectively foragers,” he added. “Choosing what car to steal is like choosing which animal to hunt.”

Advertisement

Collaborating with LAPD burglary detectives, Brantingham and Mohler developed an algorithm to predict property crime and tested it out. It was credited with lowering property crimes by 9% in the division using it, while these crimes rose 0.2% in the rest of the city.

The academic research that led to PredPol was funded by more than $1.7 million in grants from the National Science Foundation. UCLA Ventures and a pair of executives from telephone headset manufacturer Plantronics invested $3.7 million between 2012 and 2014 to fund the nascent commercial venture.

Around the same time, the U.S. Department of Justice began encouraging law enforcement agencies to experiment with predictive policing. It has awarded grants to at least 11 cities since March 2009, including PredPol clients in Newark, New Jersey; Temple Terrace, Florida; Carlsbad and Alhambra, California; and the LAPD, which received $3 million for various projects.

But PredPol has now lost luster in academic circles: Last year, more than 1,400 mathematicians signed an open letter begging their colleagues not to collaborate on research with law enforcement, specifically singling out PredPol. Among the signatories were 13 professors, researchers, and graduate students at UCLA.

Advertisement

MacDonald in turn criticized the critics. “It seems irresponsible for an entire profession to say they will not cooperate in any way to help protect vulnerable communities,” he wrote in his email to Gizmodo and The Markup.

Ferguson, the American University professor, said that whatever PredPol’s future, crime predictions made by software are here to stay—though not necessarily as a standalone product. Rather, he said, it’s becoming part of a buffet of police data offerings from larger tech firms, including Oracle, Microsoft, Accenture, and ShotSpotter, which uses sound detection to report gunshots and bought the crime prediction software HunchLab.

When we reached out to those companies for comment all except for Oracle, which declined comment, distanced themselves with predictive policing—even though in the past all of them had pitched or publicized their products being used for it and HunchLab was a PredPol competitor.

PredPol’s original name was formed from the words predictive and policing, but even it is now distancing itself from the term—MacDonald called it a “misnomer”—and is branching out into other data services, shifting its focus to patrol-officer monitoring during its rebranding this year as Geolitica.

Advertisement

And that, too, was Ferguson’s point.

“These big companies that are going to hold the contracts for police [data platforms] are going to do predictive analytics,” Ferguson said.

“They’re just not going to call it predictive policing,” he added. “And it’s going to be harder to pull apart for journalists and academics.”



Read the full peer-reviewed analysis on which this report is based here.

. Gabriel Dance Mark Hansen



Additional production by Andy Rossback Graphics byandAdditional production by

Just over a year after Michael Brown’s death became a focal point for a national debate about policing and race, Ferguson and nearby St. Louis suburbs have returned to what looks, from the outside, like a kind of normalcy. Near the Canfield Green apartments, where Brown was shot by police officer Darren Wilson, a sign reading “Hands Up Don’t Shoot” and a mountain of teddy bears have been cleared away. The McDonald’s on West Florissant Avenue, where protesters nursed rubber bullet wounds and escaped tear gas, is now just another McDonald’s.

This story was produced in collaboration with

Half a mile down the road in the city of Jennings, between the China King restaurant and a Cricket cell phone outlet, sits an empty room that the St. Louis County Police Department keeps as a substation. During the protests, it was a war room, where law enforcement leaders planned their responses to the chaos outside.

One day last December, a few Jennings police officers flicked on the substation’s fluorescent lights and gathered around a big table to eat sandwiches. The conversation drifted between the afternoon shift’s mundane roll of stops, searches, and arrests, and the day’s main excitement: the officers were trying out a new software program called HunchLab, which crunches vast amounts of data to help predict where crime will happen next.

The conversation also turned to the grand anxieties of post-Ferguson policing. “Nobody wants to be the next Darren Wilson,” Officer Trevor Voss told me. They didn’t personally know Wilson. Police jurisdiction in St. Louis is notoriously labyrinthine and includes dozens of small, local municipal agencies like the Ferguson Police Department, where Wilson worked — munis, the officers call them — and the St. Louis County Police Department, which patrols areas not covered by the munis and helps with “resource intense events,” like the protests in Ferguson. The munis have been the targets of severe criticism; in the aftermath 2014's protests, Ferguson police were accused by the federal Department of Justice of being racially discriminatory and poorly trained, more concerned with handing out tickets to fund municipal coffers than with public safety.

The officers in Jennings work for the St. Louis County Police Department; in 2014, their colleagues appeared on national TV, pointing sniper rifles at protesters from armored trucks. Since then, the agency has also been called out by the Justice Department for, among other things, its lack of engagement with the community.

ST. LOUIS COUNTY HUNCHLAB CRIME MAP ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD FLORISSANT St. Louis 70 ST CHARLES BALLWIN KIRKWOOD 270 FERGUSON FENTON JENNINGS MEHLVILLE Mississippi River MARYLAND HEIGHTS 64 St. Louis CHESTERFIELD 5 miles CREVE COEUR CLAYTON ST. LOUIS COUNTY POLICE DEPARTMENT JURISIDICTION BALLWIN WILDWOOD ST CHARLES KIRKWOOD FLORISSANT 55 FERGUSON JENNINGS FENTON Mississippi River CHESTERFIELD 255 St. Louis MEHLVILLE 44 BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles 5 miles ST. LOUIS COUNTY POLICE JURISIDICTION ST. LOUIS COUNTY ST CHARLES FLORISSANT FLORISSANT FERGUSON FERGUSON JENNINGS JENNINGS Mississippi River Mississippi River CHESTERFIELD CHESTERFIELD St. Louis St. Louis BALLWIN BALLWIN FENTON FENTON MEHLVILLE MEHLVILLE 5 miles 5 miles HUNCHLAB CRIME MAP ST CHARLES FLORISSANT 70 FERGUSON 270 JENNINGS 64 Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD 55 255 FENTON MEHLVILLE 44 5 miles ST. LOUIS COUNTY ST CHARLES FLORISSANT 70 FERGUSON 270 JENNINGS 64 Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD 55 255 FENTON MEHLVILLE 44 5 miles ST. LOUIS COUNTY POLICE JURISIDICTION ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles HUNCHLAB CRIME MAP ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles

Still, the county police enjoy a better local reputation than the munis. Over the last five years, Jennings precinct commander Jeff Fuesting has tried to improve relations between officers — nearly all white — and residents — nearly all black — by going door to door for “Walk and Talks.” Fuesting had expressed interest in predictive policing years before, so when the department heads brought in HunchLab, they asked his precinct to roll it out first. They believed that data could help their officers police better and more objectively. By identifying and aggressively patrolling “hot spots,” as determined by the software, the police wanted to deter crime before it ever happened.

HunchLab, produced by Philadelphia-based startup Azavea, represents the newest iteration of predictive policing, a method of analyzing crime data and identifying patterns that may repeat into the future. HunchLab primarily surveys past crimes, but also digs into dozens of other factors like population density; census data; the locations of bars, churches, schools, and transportation hubs; schedules for home games — even moon phases. Some of the correlations it uncovers are obvious, like less crime on cold days. Others are more mysterious: rates of aggravated assault in Chicago have decreased on windier days, while cars in Philadelphia were stolen more often when parked near schools.

What Is Predictive Policing?

At the same time, a growing chorus of activists and academics worry that the reliance on data is a sign that police departments have not adequately heeded the lessons of Ferguson. Kade Crockford, the director of the Technology for Liberty program at the Massachusetts ACLU, says that predictive policing is based on “data from a society that has not reckoned with its past,” adding “a veneer of technological authority” to policing practices that still disproportionately target young black men. In other cities, some police departments are even moving toward predicting which people, rather than which places, are most crime-prone.

“At a time when communities are crying out for justice,” Crockford told me, “I never heard anyone in one of these communities say, ‘I think police need to use more computers!’”

Predicting crime has always been part of police work; any beat cop can tell you that a particularly dark street corner is vulnerable to carjackers, or a large parking lot offers anonymity for drug dealers. Scholars have been mapping crime since the 1800s, but during New York City’s crime spike in the 1990s, police officers started doing so systematically. Most notable among them was Jack Maple, a quick-talking, up-from-the-bottom transit cop who wore double-breasted suits, homburg hats, and two-tone shoes and has become a near-mythic figure in police circles. At the NYPD’s Manhattan headquarters, Maple would stretch out butcher paper across 55 feet of wall space. "I called them the Charts of the Future," he once told an interviewer. “I mapped every train station in New York City and every train. Then I used crayons to mark every violent crime, robbery, and grand larceny that occurred.”

Maple’s boss, Police Commissioner Bill Bratton, sent officers to patrol the areas Maple marked up. The process evolved into an entire system of police management called CompStat, which uses data to hold individual precinct commanders accountable for the crime levels in their areas. In varying forms, “hot-spot policing” has spread throughout the nation’s police departments. Bratton calls it “computerized fishing.”

Homicide Aggravated Assault GUN CRIME R0bbery ST CHARLES ST CHARLES FLORISSANT FLORISSANT SIMPLE ASSAULT FERGUSON FERGUSON JENNINGS JENNINGS GUN CRIMES Mississippi River Mississippi River CHESTERFIELD CHESTERFIELD aggrAvated assault St. Louis St. Louis Drunk driving BALLWIN BALLWIN KIRKWOOD KIRKWOOD VEHICLE ACCIDENT FENTON FENTON MEHLVILLE MEHLVILLE TRESPASSING burglary 5 miles 5 miles larceny Time Location Last Occurrence Aggravated assault (assault with a dangerous weapon) makes up 18.5 percent of the overall risk score assigned to a cell. The darkest regions on this map represent cells with a 1 in 320 chance of at least one aggravated assault taking place there during the shift. Gun crime (all homicides, robberies, and aggravated assaults with a firearm) makes up about 16.5 percent of the overall risk score. The darkest regions represent a 1 in 850 chance of at least one gun crime taking place. DRIVING WHILE INTOXICATED TRESPASSING HOMICIDE ST CHARLES ST CHARLES FLORISSANT FLORISSANT FLORISSANT ST CHARLES FERGUSON FERGUSON FERGUSON JENNINGS JENNINGS JENNINGS Mississippi River Mississippi River Mississippi River CHESTERFIELD CHESTERFIELD CHESTERFIELD St. Louis St. Louis St. Louis BALLWIN BALLWIN BALLWIN KIRKWOOD KIRKWOOD KIRKWOOD FENTON FENTON FENTON MEHLVILLE MEHLVILLE MEHLVILLE 5 miles 5 miles 5 miles Driving while intoxicated makes up 10 percent of the total risk score. The darkest regions represent a 1 in 1,300 chance of at least one DWI taking place. Trespassing makes up about 10 percent of the total risk score. The darkest regions represent cells a 1.7 percent chance of at least one act of trespassing taking place. Homicides make up 0.66 percent of the total risk score assigned to a cell. The two darkest cells on this map present a 3 percent chance of at least one homicide taking place. Homicide R0bbery SIMPLE ASSAULT GUN CRIMES aggrAvated assault Drunk driving VEHICLE ACCIDENT TRESPASSING burglary larceny Time Location Last Occurrence Aggravated Assault ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Aggravated assault (assault with a dangerous weapon) makes up 18.5 percent of the overall risk score assigned to a cell. The darkest regions on this map represent cells with a 1 in 320 chance of at least one aggravated assault taking place there during the shift. GUN CRIME ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Gun crime (all homicides, robberies, and aggravated assaults with a firearm) makes up about 16.5 percent of the overall risk score. The darkest regions represent a 1 in 850 chance of at least one gun crime taking place. DRIVING WHILE INTOXICATED FLORISSANT ST CHARLES FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Driving while intoxicated makes up 10 percent of the total risk score. The darkest regions represent a 1 in 1,300 chance of at least one DWI taking place. TRESPASSING ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Trespassing makes up about 10 percent of the total risk score. The darkest regions represent cells a 1.7 percent chance of at least one act of trespassing taking place. HOMICIDE ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Homicides make up 0.66 percent of the total risk score assigned to a cell. The two darkest cells on this map present a 3 percent chance of at least one homicide taking place. Homicide R0bbery SIMPLE ASSAULT GUN CRIMES aggrAvated assault Drunk driving VEHICLE ACCIDENT TRESPASSING burglary larceny Time Location Last Occurrence Aggravated Assault ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Aggravated assault (assault with a dangerous weapon) makes up 18.5 percent of the overall risk score assigned to a cell. The darkest regions on this map represent cells with a 1 in 320 chance of at least one aggravated assault taking place there during the shift. GUN CRIME ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Gun crime (all homicides, robberies, and aggravated assaults with a firearm) makes up about 16.5 percent of the overall risk score. The darkest regions represent a 1 in 850 chance of at least one gun crime taking place. DRIVING WHILE INTOXICATED FLORISSANT ST CHARLES FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Driving while intoxicated makes up 10 percent of the total risk score. The darkest regions represent a 1 in 1,300 chance of at least one DWI taking place. TRESPASSING ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Trespassing makes up about 10 percent of the total risk score. The darkest regions represent cells a 1.7 percent chance of at least one act of trespassing taking place. HOMICIDE ST CHARLES FLORISSANT FERGUSON JENNINGS Mississippi River CHESTERFIELD St. Louis BALLWIN KIRKWOOD FENTON MEHLVILLE 5 miles Homicides make up 0.66 percent of the total risk score assigned to a cell. The two darkest cells on this map present a 3 percent chance of at least one homicide taking place.

“Cops-on-dots,” as it’s sometimes known, has often been associated with Bratton’s other major legacy, “Broken Windows,” in which police target low-level offenses like graffiti and public drinking, creating a sense of public order that is believed to deter more serious crimes. Such tactics have been credited with helping bring down crime rates, but they have also contributed to the aggressive targeting — and stopping and searching — of black people, fostering resentment of police in many communities.

St. Louis officials had been using data to send police to patrol hot spots since 2009; today the city holds weekly meetings for commanders to discuss why certain crimes keep hitting certain places, and how to address it. When one precinct captain noticed a lot of robberies of appliances from houses under construction, officers were instructed to keep track of building schedules. In agencies across the country, the more commanders looked at the data, the more timely their responses to that data could be, and crime analysis started edging toward real time. The dream was to go beyond the present.

Throughout the criminal justice system, a faith in data’s ability to improve upon human judgment has led judges, prosecutors, and other officials in recent years to embrace tools that address the future; many use “risk assessments” of defendants — which involve questionnaires about demographics, family, and personal history — in sentencing decisions. The White House has asked Silicon Valley companies if they can develop algorithms to predict which people are likely to become “radicalized.”

In the summer of 2014, a couple of months before Ferguson erupted, St. Louis County Police Chief Jon Belmar returned from a conference of police leaders in Boston, where he had been impressed by presentations from mathematicians and data analysts. He told his aide, Sgt. Colby Dolly, that he wanted their department to join dozens of cities already using predictive policing software.

As Dolly studied the predictive policing market, he found it was crowded with competitors. Since 2009, the National Institute of Justice had been funding research into crime prediction, transforming the field into big business. IBM, Hitachi, and Lexis had all begun to offer ways to predict crime through data.

The leader in the field is PredPol, a company that grew out of a team of researchers and officers working under Bratton during the chief’s mid-2000s stint in Los Angeles. PredPol’s algorithms digest years of data on crime locations, times, and types, spitting out the spots most likely to be hit by crime again. After using PredPol for four months, police in the Foothill Division in the San Fernando Valley claimed that property crime dropped 13 percent, while in the rest of the city, it rose by 0.4 percent. PredPol has received millions in venture capital funding and is now used by more than 50 police agencies in the US and UK.

But Dolly was attracted by Azavea’s ability to analyze the impact of businesses, churches, and weather patterns on criminal activity. It was also cheaper: Azavea quoted around $50,000 for a year of HunchLab, where PredPol was asking for roughly $200,000.

Azavea’s employees have a Silicon Valley ebullience — their website mentions “ping pong tournaments, team runs, hackathons,” and “chess matches over lunch” — but they do not share the tech industry’s talk of “disruption.” Their rhetoric is civic-minded; the company’s other projects include tools to analyze legislative districts, as well as an app that helps city residents map the locations of trees in order to study their environmental impact.

As predictive policing has spread, researchers and police officers have begun exploring how it might contribute to a version of policing that downplays patrolling — as well as stopping, questioning, and frisking — and focuses more on root causes of particular crimes. Rutgers University researchers specializing in “risk terrain modeling” have been using analysis similar to HunchLab to work with police on “intervention strategies.” In one Northeast city, they have enlisted city officials to board up vacant properties linked to higher rates of violent crime, and to advertise after-school programming to kids who tend to gather near bodegas in high-risk areas.

A Day of Potential Robberies The shifting risk of robberies over the course of 24 hours in December. The darkest regions on this map represent areas with the highest risk of a robbery taking place. Source: HunchLab

Dolly was not opposed to examining and addressing the causes of crime, but the department was still focused on patrolling. He hoped using HunchLab might improve relations with the community by reducing the frequency with which police had to aggressively sweep an area in the wake of a crime. “You can only go so far in enforcing or arresting your way out of crime issues,” he said. “This is a way to combat crime that should have minimal impact on the community.”

In order to sidestep concerns about racially disproportionate policing, Dolly asked HunchLab to only predict the kinds of serious felonies that result in 911 calls, and not low-level crimes like drug possession. He asked the analysts to produce two boxes for every patrol area — no matter how wealthy or poor, black or white — showing two areas at the highest risk of crime for every 8-hour shift. But Dolly also recognized the fundamental limitation of the tool — it was “telling you where to go,” he said. “It’s not telling you what to do.”

A few hours before police officers in Jennings started their afternoon patrol, Dolly sat down at his computer at police headquarters. He logged into the HunchLab website and pulled up a map. The sprawling metropolis was covered in little bright dots. He clicked to zoom in, and the dots grew into transparent boxes, each covering a space roughly half the size of a city block, and each tinted green, orange, red, purple, blue, pink, or yellow. The colors indicated which type of crime was most likely to hit that box: green for larceny, orange for gun crimes, red for aggravated assault.

As Dolly zoomed in on Jennings, he saw two boxes tinted green to indicate a high risk of larceny. He knew this area was one of Jennings’ only commercial districts, so of course there would be a lot of shoplifting. As he panned toward the residential neighborhoods nearby, however, he saw red and orange boxes in areas that looked fairly random. “I’ve been doing police work 16 years,” he said, “and I don’t think you’d be able to isolate locations like this.”

Where Crime Might Strike Jennings, divided into HunchLab squares on the morning of December 15, 2015. The darker the square , the greater the risk that a crime will occur. FERGUSON JENNINGS POPULATION 14,737 MEDIAN HOUSEHOLD INCOME $27,785 POLICE STATION RACIAL MAKEUP BLACK 89.8% WHITE 8.5% HISPANIC 0.6% 1 mile FERGUSON JENNINGS POPULATION 14,737 MEDIAN HOUSEHOLD INCOME $27,785 POLICE STATION RACIAL MAKEUP BLACK 89.8% WHITE 8.5% HISPANIC 0.6% 1 mile FERGUSON JENNINGS POP 14,737 MEDIAN HOUSEHOLD INCOME $27,785 POLICE STATION RACIAL MAKEUP BLACK 89.8% WHITE 8.5% HISPANIC 0.6% 1 mile

Source: U.S. Census Note: HunchLab does not make predictions for squares containing police stations or hospitals as the incidents reported at these places may include inaccurate locations.Source: HunchLab

A few hours later, Thomas Keener arrived for his afternoon shift, checked his gun, got into his squad car, and pulled up the same map. Ten hours a day, four days a week, Keener’s primary job is to answer 911 calls and provide backup to other officers. When calls don’t come in, he patrols. Keener, 27, grew up in southern Missouri and graduated from the police academy six years ago. He is unfailingly polite. While his peers wear short sleeves, he chooses a long-sleeve khaki uniform and a dark brown tie, a formal get-up that, coupled with his buzzed hair, accentuates his boyishness.

When Keener began his shift, he headed toward the boxes HunchLab deemed to be high-risk. Like Dolly, he immediately registered that a green larceny box was over an area that contained a couple of dollar stores where he has caught people running out with stolen goods. He pointed out common escape routes. “See how it’s easy to disappear over there?” Even without HunchLab, he would have probably gone to the area. In other cities where HunchLab has been used, police officers are often unsurprised by the locations of the boxes — police in Lincoln, Nebraska, started experimenting with the software in 2014 but have found it mostly tells them what they already know. “When I look at the HunchLab maps,” said former police chief Tom Casady, “I say, 'Yep, it got that right!’”

The shift rolled on, and Keener got a series of calls: to help a man who had overdosed, to assist with an arrest at the police station, to help look for some young men in hoodies suspected of a burglary. The day was proving to be a safe one. “I’m going to choose to credit the patrols with that,” Keener said.

Driving through Jennings, it was clear Keener already had a predictive map stored in his brain. He pointed out non-descript yards and houses where he had been called to the scene of homicides, burglaries, and gang shootings.

He continued through particular blocks of residential neighborhoods where HunchLab had placed red and orange boxes to indicate a risk of aggravated assault and gun crime. The streets were lined with crumbling little brick houses. In a few yards, signs reading “We Must Stop Killing Each Other” had been stuck into the dirt.

As Keener drove through the bottom left corner of a HunchLab box — red to indicate a high risk of aggravated assaults — he noticed a white Chevy Impala with a dark window tint, dark enough to merit a traffic ticket.

Keener gunned his motor and flashed his lights. The car slowed to a stop, and Keener walked up to the window. Leaning down, he caught a whiff of marijuana. The young man was black and looked to be in his 20s, with a baseball cap, grey sweatpants, and a tattoo that crept out of his shirt. Keener said, politely but firmly, “I smell what smells like weed to me.”

The man said he smoked earlier, but that there was “nothing in the car.”

Keener decided the smell gave him probable cause for a search. He told the young man to step out, frisked him, and asked him if he had anything “I should know about.” The man said he had a gun. Keener found a black Glock 23 pistol, .40 caliber, under the seat. He took it back to his car, noticing it had no magazine — just a bullet in the pipe. “Pretty big,” Keener said, turning the gun in his hands.

Another police car rolled up behind Keener — a standard call for backup had gone out. Standing between his own car and Keener’s car, the young man stared at the ground, clearly annoyed but also trying not to appear annoyed. When Keener asked about the smell again, he said, “You ask me if I smoke. I smoke, man!”

LOCATION OF STOP ASSIGNED PATROL SQUARE TOP CRIME RISKS 1 AGGRAVATED ASSAULT 2 GUN CRIME 3 BURGLARY 4 LARCENY 5 SIMPLE ASSAULT 250 feet An area in southwest Jennings that HunchLab has identified as having a high risk of aggravated assault. Keener checks the registration of a Glock 23 pistol he found while searching a car near this square. LOCATION OF STOP ASSIGNED PATROL SQUARE TOP CRIME RISKS 1 AGGRAVATED ASSAULT 2 GUN CRIME 3 BURGLARY 4 LARCENY 5 SIMPLE ASSAULT 250 feet An area in southwest Jennings that HunchLab has identified as having a high risk of aggravated assault. Keener checks the registration of a Glock 23 pistol he found while searching a car. LOCATION OF STOP ASSIGNED PATROL SQUARE 250 feet An area in southwest Jennings that HunchLab has identified as having a high risk of aggravated assault. Keener checks the registration of a Glock 23 pistol he found while searching a car.

While the man paced, Keener looked up his name and the gun’s ID number. It didn’t turn up as stolen. It is legal to have a gun in your car in Missouri if you’re over 18 and not a convicted felon. The man had been arrested, but never convicted, for stealing a gun. Keener let him go with a ticket for the window tint.

The Record The best criminal justice reporting from around the web, organized by subject

As the Impala drove off, Keener looked back at the HunchLab map. The stop itself had gone down just outside the aggravated assault square. “He could have been going to shoot somebody,” he said, shrugging. “Or not.”

That HunchLab had sent him to a location where he may or may not have averted illegal activity was, for the moment, tangential; it would not be clear for months whether crime rates in Jennings might be affected by the program.

Research on the impact of predictive policing programs is still in its infancy. Last year, PredPol researchers published a study finding that sending patrol officers to several areas of Los Angeles predicted by their algorithm led to a reduction, on average, of more than four crimes per week in these neighborhoods — twice as efficient as human crime analysts. The researchers said the savings — resulting from not having to investigate and prosecute crimes that otherwise may have happened — could reach $9 million per year.

Jeremy Heffner, the product manager for HunchLab, is careful about making promises; he argues the results will vary based on how a particular police agency uses their analysis. “By having more accurate locations, we amplify the effect a meaningful tactic may have,” Heffner told me, “but you still need a meaningful tactic.” Studies of HunchLab’s effectiveness are underway in several cities, and researchers in Philadelphia are comparing patrolling in marked police cars to sending unmarked cars, which could quickly respond to crime, but might not deter it.

Even with data-driven tools, on-the-ground police work is full of ambiguity and discretion, which makes measuring their impact difficult. Would Keener have stopped the car at all had it not been in a HunchLab box? “It’s all relative,” Keener said. “Probably.” He was careful to point out that being in the box alone was not a good enough reason to stop someone. “Does the data give me grounds to stop just because they’re walking around? No.”

“My son don’t have anything positive to say, so he’d rather not say anything at all,” said the mother of the man whom Keener had stopped. It was a few weeks later, and we were talking by phone — her son had not wanted to be interviewed, and she was too suspicious of the police to put her name in print. “Believe it or not, if you say anything to the press,” she said, the police “will make sure to pull you over and treat you worse.”

The mother and her son have been pulled over a lot, she said, and it often feels as though they are targeted because they’re black. “They give you a reason” — the tinted windows, the marijuana smell — “but then they get to asking you to get out [of the car]. Well, why do I have to get out? Because you said so? All I can go on is it’s because I’m black.”

There are widespread fears among civil liberties advocates that predictive policing will actually worsen relations between police departments and black communities. “It’s a vicious cycle,” said John Chasnoff, program director of the ACLU chapter for Eastern Missouri. “The police say, ‘We’ve gotta send more guys to North County,’ [where Jennings is located] because there have been more arrests there, and then you end up with even more arrests, compounding the racial problem.”

Dolly had tried to mitigate this issue by having HunchLab identify two boxes for every beat, no matter how “high-crime” the area. But to Chasnoff, the entire emphasis on patrolling was misplaced. “I don’t think anyone, in the abstract, has a problem with figuring out where crime is and responding to it,” he said. “But what’s the appropriate response? The assumption is: we predicted crime here, and you send in police. But what if you used that data and sent in resources?”

Many at the top of the county police agree with Chasnoff, and are interested in finding ways to use predictive policing software to address crime through other government resources. “We can’t just have the criminal justice system solve our problems,” Belmar, the St. Louis County police chief, said the morning before Keener’s shift.

Late last year, the department began sending lists of high-crime areas to a nonprofit called Better Family Life, which deploys outreach workers to connect residents with drug treatment and educational programs. In theory, HunchLab could provide even more targeted areas for this organization and others to apply their model of what James Clark, the nonprofit’s vice president, calls “hot-spot resources.”

This has not happened yet. For those who would like to see police change their methods in the wake of Ferguson — and shift toward problem-solving and community relationships rather than patrolling — HunchLab looks like one method of data analysis being swapped for another. It may be more objective and may lead well-meaning police commanders to be more thoughtful about what’s driving crime, but that’s little comfort to the young black men stopped and searched. “It’s another example of the county police selling themselves as more professional,” Chasnoff said, “but maybe it’s just a more professional use of the same bad ideas.”

Throughout his shift, Officer Keener witnessed hints of simmering distrust. At one point, several children danced in the street, which he said was locally understood to be an insult to police. Later on, just outside one of the HunchLab boxes, he drove by a house where, he said, a drug dealer lived. A suspicious-looking rental car was parked outside. As he slowed down and peered out, the car door opened and a woman — black, maybe mid-30s — emerged. She pointed at the police vehicle to someone in the car and scrunched up her face in disgust. Keener turned back toward the dashboard screen and rolled away.