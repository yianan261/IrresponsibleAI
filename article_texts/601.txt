An audio clip posted to social media on Sunday, purporting to show Britain’s opposition leader Keir Starmer verbally abusing his staff, has been debunked as being AI-generated by private-sector and British government analysis.

The audio of Keir Starmer was posted on X (formerly Twitter) by a pseudonymous account on Sunday morning, the opening day of the Labour Party conference in Liverpool. The account asserted that the clip, which has now been viewed more than 1.4 million times, was genuine, and that its authenticity had been corroborated by a sound engineer.

Ben Colman, the co-founder and CEO of Reality Defender — a deepfake detection business — disputed this assessment when contacted by Recorded Future News: “We found the audio to be 75% likely manipulated based on a copy of a copy that's been going around (a transcoding).

“As we don't have the ground truth, we give a probability score (in this case 75%) and never a definitive score (‘this is fake’ or ‘this is real’), leaning much more towards ‘this is likely manipulated’ than not,” said Colman.

“It is also our opinion that the creator of this file added background noise to attempt evasion of detection, but our system accounts for this as well,” he said.

The audio was criticized on a bipartisan basis, despite the highly contested political environment in the United Kingdom — with polls generally showing the Labour Party 17 points ahead of the incumbent Conservatives.

Simon Clarke, a Conservative Party MP, warned on social media: “There is a deep fake audio circulating this morning of Keir Starmer - ignore it.” The security minister Tom Tugendhat, also a Conservative MP, also warned of the “fake audio recording” and implored Twitter users not to “forward to amplify it.”

“Deepfakes threaten our freedom. That’s why the Defending Democracy Taskforce and the work the PM is doing on AI are critical for protecting us all,” added Tugendhat. The word “deepfake” is used colloquially to refer to any kind of synthetic media generated by AI technologies.

The Defending Democracy Taskforce was established in November 2022 with the mission of reducing “the risk of foreign interference to the U.K.’s democratic processes, institutions, and society, and ensure that these are secure and resilient to threats of foreign interference,” accordion to a parliamentary question previously answered by Tugendhat.

Recorded Future News understands an analysis of the audio file by the British government confirmed it to be fake.

Screenshot of the social media post featuring the audio file.



Authorities in the U.K. are bracing for this kind of interference ahead of the country’s general election next year, in the wake of similar attempts to influence the recent elections in Slovakia.

Two days before the polls opened there on September 30, faked audio clips were published on social media attempting to incriminate an opposition party leader and a journalist with rigging the election by plotting to purchase votes.

Publicly debunking the audio was a challenge because of the country's election laws, which strictly ban both the media and politicians making campaigning announcements in the two days before the polls open.

As reported by Wired, as an audio post the fake also “exploited a loophole in Meta’s manipulated-media policy, which dictates only faked videos — where a person has been edited to say words they never said — go against its rules.”

It is not clear who produced the fake audio in either the Slovakian or British cases.

The account which posted the Keir Starmer smear had previously tweeted: “Let me be clear. I am unequivocally PRO smear tactics against those who engage in smear tactics themselves. People lie about Keir Starmer? Good. And I'm one of them.”

That tweet has now been deleted, although the fake audio remains available.. A YouGov survey in May of more than 100 U.K. MPs showed the rise of AI-generated content was their top concern surrounding AI applications. It's easy to see why.

Labour Shadow Digital Minister Alex Davies-Jones told a fringe event at the party’s conference in Liverpool on Monday that Hansard recordings of parliamentary proceedings offered bad actors an “on demand” library of MPs saying “almost any word” — something which will massively assist the training of AI models to make even more realistic fakes of politicians ahead of the 2024 election.

“The challenge is to explain to people that there is a whole other order of risks with generative AI,” explained Andrew Dudfield, head of AI at fact-checking group Full Fact.

But despite years of warnings about electoral disinformation, no regulator is responsible for stopping it and the government’s response to fake content, through the Online Safety Bill, barely begins to tackle the problem, experts warn.

'Missed opportunity'

Publishing disinformation to undermine political opponents is nothing new, but what is keeping experts awake at night is the ease and scale with which the leap in generative AI tools allows fake material to spread.

Some had hoped that the Online Safety Bill could be used to combat the rise of deepfakes ahead of the U.K.’s election next year.. Deepfake videos of Sir Keir Starmer have been posted on the first day of Labour Party conference in a move that underlines the threat posed by deepfake technology and AI in UK politics.

The fake video of the Labour leader emerged on X, formerly known as Twitter, on Sunday morning as senior figures and party activists gathered in Liverpool.

A deepfake usually involves an image or video in which a person or object is visually or audibly manipulated to say and do something that is fabricated.

Read more: Heckler removed from stage before Rayner speech - conference latest

The first fake audio, posted by an account with less than 3,000 followers, purports to capture the Labour leader abusing party staffers - but the audio is not real and the incident did not happen.

The second makes out that Sir Keir is criticising the city of Liverpool.

The emergence of the audio is reminiscent of the recent elections in Slovakia, where a fake audio recording emerged of Michal Simecka, the leader of the Progressive Slovakia Party, apparently engaged in a conversation with a leading journalist from a daily newspaper discussing how to rig the election.

The pair immediately confirmed that the audio was fake and that the conversation did not happen.

Analysis by the AFP news agency found that the audio showed signs of being manipulated with AI.

Advertisement

Former populist prime minster Robert Fico ultimately won the election on a ticket to withdraw his country's military support for Ukraine.

It is unclear what impact, if any, the false video had on the outcome of the election, but the journalist featured in it, Monika Todova, later told The Times she was "disgusted" by it.

Please use Chrome browser for a more accessible video player 2:30 Is AI an existential threat?

"It's my words, but not my sentences," she told the newspaper.

"My friends and our readers realise it's a deepfake, but people who voted for Smer-SD or Republic [a far-right party] think it's real."

Back home there have been similar warnings about the threat AI poses to UK democracy.

Dame Wendy Hall, one of the world's leading computer scientists, issued a stark warning in an interview with Sky's Beth Rigby in which she said AI will threaten UK democracy ahead of upcoming elections here and the United States.

Spreaker Spreaker , which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enable Spreaker cookies or to allow those cookies just once. You can change your settings at any time via the This content is provided by, which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enablecookies or to allow those cookies just once. You can change your settings at any time via the Privacy Options Unfortunately we have been unable to verify if you have consented to Spreaker cookies. To view this content you can use the button below to allow Spreaker cookies for this session only. Enable Cookies Allow Cookies Once

Click to subscribe to Politics at Jack and Sam's wherever you get your podcasts

Speaking on Beth Rigby Interviews... Dame Wendy Hall said AI's ability to damage democracy should be more of an immediate concern than any existential threat posed by the technology.

"Next year we will see a growth in disinformation, the deep fakes of this world, because AI makes it very easy to do that," she said.

"You can just get the tools off the internet and it's getting harder and harder to detect that a video, or a photo, or a piece of text has been faked."

Dame Wendy sits on the government's AI Council, an "independent expert committee" providing "advice to government and high-level leadership of the AI ecosystem".

She is also the regius professor of computer science at the University of Southampton where one of her specialties is AI.

Please use Chrome browser for a more accessible video player 30:00 Beth Rigby Interviews... Dame Wendy Hall

"We've got two major elections coming up next year - the US, UK - and the EU have got elections as well," she said.

"I see this as a threat to democracy. In the sense that we've got to help people understand where they're getting the messages from.

"I think that's more important than worrying about an existential threat in 100 years' time, but, I'm not saying the existential threat isn't there," she added.

Read more:

'Sickening rise' in AI-generated child sex abuse images

ChatGPT creator expresses concern about 'under-regulation'

"So we have to prepare for the fact that we are keeping the AI under our control, so that we don't become the slaves to that master, which is where the regulation comes in."

The government is due to hold a global AI summit on 1 and 2 November, where Dame Wendy wants the government to focus on deep fakes.

"We need people to quite quickly pull together the technology that's used to detect fakes and to ensure that something is coming from a trusted source," she said.

It is not just the world of politics that has been threatened by AI.

Actor Tom Hanks recently spoke out after a fake advert appeared to use his face to promote a dental plan but which Mr Hanks said had used an artificial AI version of him without his authorisation.. As members of the UK’s largest opposition party gathered in Liverpool for their party conference—probably their last before the UK holds a general election—a potentially explosive audio file started circulating on X, formerly known as Twitter.

The 25-second recording was posted by an X account with the handle “@Leo_Hutz” that was set up in January 2023. In the clip, Sir Keir Starmer, the Labour Party leader, is apparently heard swearing repeatedly at a staffer. “I have obtained audio of Keir Starmer verbally abusing his staffers at [the Labour Party] conference,” the X account posted. “This disgusting bully is about to become our next PM.”

It’s unclear whether the audio recording is real, AI-generated, or recorded using an impersonator. British fact-checking organization Full Fact said it is still investigating. “As we’re talking now, it can’t be validated one way or the other. But there are characteristics of it that point to it being a fake,” says Glen Tarman, Full Fact’s head of advocacy and policy. “There’s a phrase which appears to be repeated, rather than [using] a different intonation the second time it’s used, and there’s a few glitches in the background noise.”

Audio deepfakes are emerging as a major risk to the democratic process, as the UK—and more than 50 other countries—move toward elections in 2024. Manipulating audio content is becoming cheaper and easier, while fact-checkers say it’s difficult to quickly and definitively identify a recording as fake. These recordings could spend hours or days floating around social media before they’re debunked, and researchers worry that this type of deepfake content could create a political atmosphere in which voters don’t know what information they can trust.

“If you are listening to a sound bite or a video online with this seed of doubt about whether this is genuinely real, it risks undermining the foundation of how debate happens and people’s capacity to feel informed,” says Kate Dommett, professor of digital politics at Sheffield University.

X’s manipulated media policy states that videos or audios that have been deceptively altered or manipulated should be labeled or removed. Neither has happened to the post, and X did not reply to WIRED’s request for comment on whether the platform has investigated the recording’s authenticity.. While the recording was quickly identified as a fake MPs said they were growing increasingly concerned about the dangers AI could pose to an election campaign.. The Emerging Threat of Political Deepfakes

A recent incident has thrust the dangers of deepfake technology into the spotlight again. An audio clip surfaced on Twitter last week allegedly capturing British opposition leader Sir Keir Starmer swearing at staffers. But evidence suggests the recording was an AI-generated deepfake, not an authentic leak. This event highlights the growing threat that deepfakes pose to the political world, and society more broadly.

What Are Deepfakes?

Deepfakes leverage AI techniques like machine learning and neural networks to fabricate audio or video that falsely depict people saying or doing things they never actually did. During the machine learning process (ML), the AI model trains on hours of authentic audio data of the target person to learn their facial animation, speech patterns, and vocal nuances. It then uses this data to generate new synthetic media that realistically impersonate the target person.

How Audio Deepfakes Are Created Using Text to Speech

Now that we have a general understanding of how machine learning is the foundation of deepfake creation, we’ll focus in on how audio deepfakes of Keir Starmer were likely created. The accessibility to voice AI generators, and AI voice changers has given individuals access to voice cloning. Users can scrape the Labour Party leader’s audio data from the internet and upload that data into a voice AI generator where they can clone his voice. Once the voice cloning is complete, the user is able to generate AI voice content through text to speech (TTS) or speech to speech (STS) conversion. Below is a diagram of text to speech synthesis.. The Starmer deepfake affair – letter to the editor

Photo by Emily Morter on Unsplash

Share EmailTwitterFacebook

Dear Editor,

An element of doubt is insidious, I thought, having read about the ‘recording’ posted on X (formerly twitter), purporting to be a tirade from Sir Keir Starmer, effing and blinding at his staff because they forgot to bring his tablet (as in iPad, not paracetamol).

Labour staffers were taken somewhat by surprise, it would seem, at being asked to address its veracity, (by which time it had received over 700,000 views), but they categorically denied that the ‘recording’ is genuine, and even the current Tory minister responsible for online safety – Tom Tugendhat – and former minister Sir Simon Clarke have enjoined people to ignore it as a fake. Some people, however, will undoubtedly not see – or will dismiss – these denials.

“This afternoon top Tory Sir Simon Clarke came to Sir Keir Starmer’s rescue, telling his followers to “ignore” the deep fake video. He added that it’s a “reminder why the upcoming AI summit organised by the Prime Minister is so important”. He said: “From the Slovakian elections a few days ago to today’s incident, this is a new threat to democracy.” The Express

It is hard, I think, to imagine Starmer losing his rag in this way: he and the shadow cabinet seem increasingly unable to say anything remotely controversial; but this year’s Labour Party Conference will probably be the last before the general election, and Starmer and his cohort must be under a degree of stress. So it’s not inconceivable, perhaps, that such an incident might actually have taken place. If genuine, it is not especially damaging (particularly compared with the behaviour of other politicians), but it is slight enough to be feasible, which is where the element of doubt creeps in.

Although many news outlets have dismissed it as a ‘deepfake’, there will be people who take it at face value. (“It was in the Daily Mail so it must be true” is a family joke: my late in-laws used to believe every word.) Additionally, many young people apparently never look at news media at all, but rely on TikTok, Facebook and the like instead: so we must accept that manipulated online material could have a potentially-huge impact upon people’s views – and their voting choices.

This, and the infinite life and reach of anything online, must be invaluable to anyone wishing to subvert the truth, for whatever reason. We have all heard of conspiracy theories: perhaps this is where many ‘deepfakes’ lead. Many of these theories are ridiculous, but, for example, it seems that at least 12 per cent (mostly Trump supporters!) of Americans still believe the moon landings didn’t really happen but were staged, and filmed by – of course – Stanley Kubrick. Perhaps this was the first deepfake?!

The misuse of artificial intelligence could have huge impacts on democracy, and whilst the EU is obviously alarmed enough to have been preparing counter-measures for some time, here in Brexit Britain – despite many warnings from AI experts – the government appears only now to be catching up. The technology is moving so fast that I fear it will be left up to individuals to decide whether or not something we see or hear online is real.

I hope we reach the correct conclusions.

Anna Andrews

East Devon. Bogus clips of the Labour leader were posted online on Sunday, sparking alarm over the impact of artificial intelligence in politics as the general election approaches

"Deepfake" clips of Keir Starmer released during Labour conference have sparked warnings over the threat to democracy from artificial intelligence (AI).

An AI-generated audio clip of the Labour leader appearing to berate a staff member has already been viewed at least 1.4million times online. But the incident didn't take place and the audio is not real. Another bogus clip suggested Mr Starmer was criticising Liverpool, where the party's annual conference is being held.

Deepfakes are videos, pictures and audio that have been digitally manipulated to make it look like someone is saying or doing something that they haven't. The technology has become more sophisticated with the rapid development of AI, making it sometimes difficult to tell spot.

Computer scientist Dame Wendy Hall, sits on the government's AI Council, told Sky News: "The technology to manipulate the video and the audio has been around for a long time. The point is now that it's easy to use, it's become mature enough so it's downloadable from a number of websites."

The doctored video were posted on Twitter on Sunday as Labour began its annual conference, in a sign of the threat politics faces from AI. It comes after a recent election in Slovakia, where a fake audio recording emerged of Michal Simecka, the leader of the Progressive Slovakia Party, appearing to discuss rigging the election with a top journalist. The conversation never happened but the audio was widely heard online.

Labour activists will get training in spotting deepfakes and other potential threats as the party ramps up digital campaigning skills ahead of the election. Rishi Sunak will host a global summit next month on AI at Bletchley Park, the home of British codebreakers during the Second World War.

If you can't see the poll, click here

A string of senior Tories ditched party lines to warn people against posting or amplifying the footage. Security Minister Tom Tugendhat expressed alarm at the clips, saying: "Deepfakes threaten our freedom. That’s why the Defending Democracy Taskforce and the work the PM is doing on AI are critical for protecting us all".

Ex-Cabinet Minister Simon Clarke told Twitter users to "ignore it". He added: "It’s a reminder why the upcoming AI summit organised by the Prime Minister is so important. From the Slovakian elections a few days ago to today’s incident, this is a new threat to democracy."

Another top Tory Matt Warman said: "The last 30 years of public life has seen a catastrophic undermining of faith in institutions, for good & bad reasons. But today’s Sir Keir Starmer deepfake is a new low, supercharged by AI & social media. Democracy is under real threat - technology to verify content is essential.". 11 October 2023

There is no evidence that the clip is genuine. Labour sources and Conservative MPs both say the clip was faked, while the X account which shared it has previously published other unevidenced claims about Mr Starmer. The clip may have been generated by artificial intelligence, but we don’t know that for sure.

There is no evidence that an audio clip which has gone viral on X (formerly Twitter), allegedly of Labour leader Sir Keir Starmer swearing at a member of his staff, is genuine.

The clip, which has over 1.5 million views at the time of writing and has also been shared on Facebook, was posted as the Labour party conference got underway in Liverpool on Sunday.

Definitively proving that a non-specific and unattributed audio clip has been faked is difficult. The emergence of this clip has exposed the increased challenges of verification posed by new technology and the challenge of ensuring an effective and proportionate response by social media platforms on such content.

We’ve not been able to determine whether the clip was generated with artificial intelligence, edited in some other way or is of an impersonator, but we’ve not seen any evidence to suggest it is real.

There are no specific clues in the clip itself, such as identifiable background noise or names used, which would enable it to be verified. Sources within the Labour party have said the clip is fake, as have the security minister Tom Tugendhat and Simon Clarke MP, both Conservatives.

Mr Tugendhat and Mr Clarke suggested the clip is an audio version of a deepfake and referred to ongoing work to deal with the challenges of artificial intelligence. When we asked Mr Tugendhat what that assessment was based on however, we did not receive a response.

The X account which claimed to have received the audio clip and said it was of Mr Starmer “verbally abusing his staffers at conference” currently operates under the name “El Borto”, and has previously published other unevidenced claims about Mr Starmer. It is not clear who runs the account, which was set up in January 2023 and now has around 3,600 followers. We’ve attempted to contact the owner of the account but haven’t received a response.

Honesty in public debate matters You can help us take action – and get our regular free email Sign up

Unevidenced claims

On 21 August, while operating under the name “UK Politics”, the account in question claimed to have conducted an interview with Mr Starmer. The account said: “NEW: Labour Leader Keir Starmer has said he would be supportive of the death penalty “for the most heinous of crimes”.”

We’ve not seen any evidence to support such a claim, or evidence Mr Starmer did such an interview. In fact, Mr Starmer has repeatedly made clear his opposition to capital punishment and won an award for his work on death penalty cases.

Asked to provide the source by other X users, the account holder replied: “We are the source. He was speaking to us.” The account holder then claimed to have footage of Mr Starmer speaking those words but said they were unable to upload it as: “I don’t have permission to post the video. I could get sued.”

The following day the account uploaded what appeared to be a photo of a television tuned to an item on the BBC News channel with the caption: “Keir Starmer death penalty comments”. Replying to other users, the X account owner seemed to imply that the quotes they had published the previous day were now being reported by the broadcaster.

We’ve not seen any evidence that this is an image of a real BBC News report. We’ve not found any mention of this report elsewhere online, and close scrutiny of the image appears to show inconsistencies with the text in the caption, which suggest it may have been digitally altered. In addition, when Full Fact checked what was being reported on BBC News at 1.28pm on 22 August—the time stamp featured in the photo—there was no mention of Mr Starmer and the presenters were instead discussing the growing popularity of chess.

‘Difficult to confirm deepfakes with total certainty’

We’ve seen analysis of the audio clip from a number of different audio experts, but without any definite overall conclusion.

Mike Russell, founder of the audio production firm Music Radio Creative and a certified audio professional with more than 25 years of experience, conducted extensive analysis for a podcast, which at the time of writing has yet to be published. He told Full Fact it was "impossible to confirm 100%" whether or not the clip was a deepfake.

"Unfortunately there is no definitive yes/no,” he said. ”It remains very difficult to confirm deepfakes with total certainty… we're rapidly approaching a point where audio can no longer be trusted as factual evidence with the rise of AI synthesis.”

Although his analysis failed to find any AI "glitches" and some tests suggested the audio was real, Mr Russell was also able to use AI voice cloning tools to recreate extremely realistic fake samples of Sir Keir's voice.

A recent study by researchers from University College London found that the technology required to produce fake audio clips is now widely accessible and easy to use. “While early deepfake speech algorithms may have required thousands of samples of a person’s voice to be able to generate original audio, the latest pre-trained algorithms can recreate a person’s voice using just a three-second clip of them speaking,” it said.

“Open-source algorithms are freely available and while some expertise would be beneficial, it would be feasible for an individual to train them within a few days.”

The same study included an experiment which found that humans are only able to detect altered audio 73% of the time.

Concerns about the potential for manipulated audio to generate misinformation was highlighted recently when, shortly before elections in Slovakia, an audio recording was posted to Facebook allegedly featuring the head of a political party and prominent journalist discussing how to rig the vote.

Both men denied any such conversation had ever taken place and fact checkers from AFP said the audio showed signs of having been manipulated using AI.. Keir Starmer appeared in a totally doctored AI clip going viral on Twitter this morning

Politicians were dealt a warning this morning about the potential disruptive power of AI in the next general election. Labour aides were forced to deny that Sir Keir Starmer had been recorded losing his temper in a sweary outburst as a video went viral that sounded exactly like him. In the video posted on X, over a din "Keir Starmer" could be heard ranting: “That f***ing tablet. F***s sake, I literally told you didn’t I? F***s sake. “Bloody moron. No, I’m sick of it, I’m sick of it, I’m f***ing sick of it. Every single time! “Just shut your f***ing mouth. F***ing idiot.” Click here to join our Whatsapp community to be the first to receive the latest politics news

I have obtained audio of Keir Starmer verbally abusing his staffers at conference.



This disgusting bully is about to become our next PM. pic.twitter.com/T9Rxv2KDdp — El Borto ������������������ (@leo_hutz) October 8, 2023

At first, Labour aides appeared indignant at having to issue a denial that the recording was genuine. However, as it has accrued more than 764,000 views on the Elon Musk-owned platform at the time of writing, they eventually issued a categorical denial. Former Labour MP George Galloway was one X user seemingly sucked into believing that the recording was real. This afternoon top Tory Sir Simon Clarke came to Sir Keir Starmer’s rescue, telling his followers to “ignore” the deep fake video. He added that it’s a “reminder why the upcoming AI summit organised by the Prime Minister is so important”. He said: “From the Slovakian elections a few days ago to today’s incident, this is a new threat to democracy.”

Sir Simon said the scary video is precisely why the PM's forthcoming AI summit is so important

SUBSCRIBE Invalid email We use your sign-up to provide content in ways you've consented to and to improve our understanding of you. This may include adverts from us and 3rd parties based on our understanding. You can unsubscribe at any time. More info

Sir Simon referenced a scandal in Slovakia earlier this week, an audio recording was posted to Facebook, supposedly of the Liberal party leader discussing with a journalist how to rig the election. Cabinet minister Tom Tugendhat backed Sir Simon's words, saying "Deepfakes threaten our freedom. That’s why the Defending Democracy Taskforce and the work the PM is doing on AI are critical for protecting us all". Politicians across the world are concerned about the impact deepfake videos can and will have in upcoming elections. Senior Fellow at the Brookings Institution’s Centre for Technology Innovation, Darrel West, has warned that voters in the US will find it “very difficult… to distinguish the real from the fake”. He said: “You could just imagine how either Trump supporters or Biden supporters could use this technology to make the opponent look bad. "There could be things that drop right before the election that nobody has a chance to take down."

Trending