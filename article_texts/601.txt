Deepfake videos of Sir Keir Starmer have been posted on the first day of Labour Party conference in a move that underlines the threat posed by deepfake technology and AI in UK politics.

The fake video of the Labour leader emerged on X, formerly known as Twitter, on Sunday morning as senior figures and party activists gathered in Liverpool.

A deepfake usually involves an image or video in which a person or object is visually or audibly manipulated to say and do something that is fabricated.

Read more: Heckler removed from stage before Rayner speech - conference latest

The first fake audio, posted by an account with less than 3,000 followers, purports to capture the Labour leader abusing party staffers - but the audio is not real and the incident did not happen.

The second makes out that Sir Keir is criticising the city of Liverpool.

The emergence of the audio is reminiscent of the recent elections in Slovakia, where a fake audio recording emerged of Michal Simecka, the leader of the Progressive Slovakia Party, apparently engaged in a conversation with a leading journalist from a daily newspaper discussing how to rig the election.

The pair immediately confirmed that the audio was fake and that the conversation did not happen.

Analysis by the AFP news agency found that the audio showed signs of being manipulated with AI.

Advertisement

Former populist prime minster Robert Fico ultimately won the election on a ticket to withdraw his country's military support for Ukraine.

It is unclear what impact, if any, the false video had on the outcome of the election, but the journalist featured in it, Monika Todova, later told The Times she was "disgusted" by it.

Please use Chrome browser for a more accessible video player 2:30 Is AI an existential threat?

"It's my words, but not my sentences," she told the newspaper.

"My friends and our readers realise it's a deepfake, but people who voted for Smer-SD or Republic [a far-right party] think it's real."

Back home there have been similar warnings about the threat AI poses to UK democracy.

Dame Wendy Hall, one of the world's leading computer scientists, issued a stark warning in an interview with Sky's Beth Rigby in which she said AI will threaten UK democracy ahead of upcoming elections here and the United States.

Spreaker Spreaker , which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enable Spreaker cookies or to allow those cookies just once. You can change your settings at any time via the This content is provided by, which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enablecookies or to allow those cookies just once. You can change your settings at any time via the Privacy Options Unfortunately we have been unable to verify if you have consented to Spreaker cookies. To view this content you can use the button below to allow Spreaker cookies for this session only. Enable Cookies Allow Cookies Once

Click to subscribe to Politics at Jack and Sam's wherever you get your podcasts

Speaking on Beth Rigby Interviews... Dame Wendy Hall said AI's ability to damage democracy should be more of an immediate concern than any existential threat posed by the technology.

"Next year we will see a growth in disinformation, the deep fakes of this world, because AI makes it very easy to do that," she said.

"You can just get the tools off the internet and it's getting harder and harder to detect that a video, or a photo, or a piece of text has been faked."

Dame Wendy sits on the government's AI Council, an "independent expert committee" providing "advice to government and high-level leadership of the AI ecosystem".

She is also the regius professor of computer science at the University of Southampton where one of her specialties is AI.

Please use Chrome browser for a more accessible video player 30:00 Beth Rigby Interviews... Dame Wendy Hall

"We've got two major elections coming up next year - the US, UK - and the EU have got elections as well," she said.

"I see this as a threat to democracy. In the sense that we've got to help people understand where they're getting the messages from.

"I think that's more important than worrying about an existential threat in 100 years' time, but, I'm not saying the existential threat isn't there," she added.

Read more:

'Sickening rise' in AI-generated child sex abuse images

ChatGPT creator expresses concern about 'under-regulation'

"So we have to prepare for the fact that we are keeping the AI under our control, so that we don't become the slaves to that master, which is where the regulation comes in."

The government is due to hold a global AI summit on 1 and 2 November, where Dame Wendy wants the government to focus on deep fakes.

"We need people to quite quickly pull together the technology that's used to detect fakes and to ensure that something is coming from a trusted source," she said.

It is not just the world of politics that has been threatened by AI.

Actor Tom Hanks recently spoke out after a fake advert appeared to use his face to promote a dental plan but which Mr Hanks said had used an artificial AI version of him without his authorisation.. A YouGov survey in May of more than 100 U.K. MPs showed the rise of AI-generated content was their top concern surrounding AI applications. It's easy to see why.

Labour Shadow Digital Minister Alex Davies-Jones told a fringe event at the party’s conference in Liverpool on Monday that Hansard recordings of parliamentary proceedings offered bad actors an “on demand” library of MPs saying “almost any word” — something which will massively assist the training of AI models to make even more realistic fakes of politicians ahead of the 2024 election.

“The challenge is to explain to people that there is a whole other order of risks with generative AI,” explained Andrew Dudfield, head of AI at fact-checking group Full Fact.

But despite years of warnings about electoral disinformation, no regulator is responsible for stopping it and the government’s response to fake content, through the Online Safety Bill, barely begins to tackle the problem, experts warn.

'Missed opportunity'

Publishing disinformation to undermine political opponents is nothing new, but what is keeping experts awake at night is the ease and scale with which the leap in generative AI tools allows fake material to spread.

Some had hoped that the Online Safety Bill could be used to combat the rise of deepfakes ahead of the U.K.’s election next year.. While the recording was quickly identified as a fake MPs said they were growing increasingly concerned about the dangers AI could pose to an election campaign.. 11 October 2023

There is no evidence that the clip is genuine. Labour sources and Conservative MPs both say the clip was faked, while the X account which shared it has previously published other unevidenced claims about Mr Starmer. The clip may have been generated by artificial intelligence, but we don’t know that for sure.

There is no evidence that an audio clip which has gone viral on X (formerly Twitter), allegedly of Labour leader Sir Keir Starmer swearing at a member of his staff, is genuine.

The clip, which has over 1.5 million views at the time of writing and has also been shared on Facebook, was posted as the Labour party conference got underway in Liverpool on Sunday.

Definitively proving that a non-specific and unattributed audio clip has been faked is difficult. The emergence of this clip has exposed the increased challenges of verification posed by new technology and the challenge of ensuring an effective and proportionate response by social media platforms on such content.

We’ve not been able to determine whether the clip was generated with artificial intelligence, edited in some other way or is of an impersonator, but we’ve not seen any evidence to suggest it is real.

There are no specific clues in the clip itself, such as identifiable background noise or names used, which would enable it to be verified. Sources within the Labour party have said the clip is fake, as have the security minister Tom Tugendhat and Simon Clarke MP, both Conservatives.

Mr Tugendhat and Mr Clarke suggested the clip is an audio version of a deepfake and referred to ongoing work to deal with the challenges of artificial intelligence. When we asked Mr Tugendhat what that assessment was based on however, we did not receive a response.

The X account which claimed to have received the audio clip and said it was of Mr Starmer “verbally abusing his staffers at conference” currently operates under the name “El Borto”, and has previously published other unevidenced claims about Mr Starmer. It is not clear who runs the account, which was set up in January 2023 and now has around 3,600 followers. We’ve attempted to contact the owner of the account but haven’t received a response.

Honesty in public debate matters You can help us take action – and get our regular free email Sign up

Unevidenced claims

On 21 August, while operating under the name “UK Politics”, the account in question claimed to have conducted an interview with Mr Starmer. The account said: “NEW: Labour Leader Keir Starmer has said he would be supportive of the death penalty “for the most heinous of crimes”.”

We’ve not seen any evidence to support such a claim, or evidence Mr Starmer did such an interview. In fact, Mr Starmer has repeatedly made clear his opposition to capital punishment and won an award for his work on death penalty cases.

Asked to provide the source by other X users, the account holder replied: “We are the source. He was speaking to us.” The account holder then claimed to have footage of Mr Starmer speaking those words but said they were unable to upload it as: “I don’t have permission to post the video. I could get sued.”

The following day the account uploaded what appeared to be a photo of a television tuned to an item on the BBC News channel with the caption: “Keir Starmer death penalty comments”. Replying to other users, the X account owner seemed to imply that the quotes they had published the previous day were now being reported by the broadcaster.

We’ve not seen any evidence that this is an image of a real BBC News report. We’ve not found any mention of this report elsewhere online, and close scrutiny of the image appears to show inconsistencies with the text in the caption, which suggest it may have been digitally altered. In addition, when Full Fact checked what was being reported on BBC News at 1.28pm on 22 August—the time stamp featured in the photo—there was no mention of Mr Starmer and the presenters were instead discussing the growing popularity of chess.

‘Difficult to confirm deepfakes with total certainty’

We’ve seen analysis of the audio clip from a number of different audio experts, but without any definite overall conclusion.

Mike Russell, founder of the audio production firm Music Radio Creative and a certified audio professional with more than 25 years of experience, conducted extensive analysis for a podcast, which at the time of writing has yet to be published. He told Full Fact it was "impossible to confirm 100%" whether or not the clip was a deepfake.

"Unfortunately there is no definitive yes/no,” he said. ”It remains very difficult to confirm deepfakes with total certainty… we're rapidly approaching a point where audio can no longer be trusted as factual evidence with the rise of AI synthesis.”

Although his analysis failed to find any AI "glitches" and some tests suggested the audio was real, Mr Russell was also able to use AI voice cloning tools to recreate extremely realistic fake samples of Sir Keir's voice.

A recent study by researchers from University College London found that the technology required to produce fake audio clips is now widely accessible and easy to use. “While early deepfake speech algorithms may have required thousands of samples of a person’s voice to be able to generate original audio, the latest pre-trained algorithms can recreate a person’s voice using just a three-second clip of them speaking,” it said.

“Open-source algorithms are freely available and while some expertise would be beneficial, it would be feasible for an individual to train them within a few days.”

The same study included an experiment which found that humans are only able to detect altered audio 73% of the time.

Concerns about the potential for manipulated audio to generate misinformation was highlighted recently when, shortly before elections in Slovakia, an audio recording was posted to Facebook allegedly featuring the head of a political party and prominent journalist discussing how to rig the vote.

Both men denied any such conversation had ever taken place and fact checkers from AFP said the audio showed signs of having been manipulated using AI.