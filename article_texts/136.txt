ARTICLE TITLE: Brand Safety Tech Firms Falsely Claimed Use of AI, Blocking Ads Using Simple Keyword Lists
We’ve Known Brand Safety Tech Was Bad—Here’s How Badly It Defunds The News
We’ve known for a long time that brand safety detection technologies were blunt instruments [1], [2], [3], [4], [5]. Despite their claims of advanced AI (artificial intelligence) and ML (machine learning) in their sales materials, it was painfully clear the brand safety technology was blocking ads based on simple keyword lists. This is not a new phenomenon, just more easily observable at the start of the pandemic when ads on the front pages of New York Times and Wall Street Journal were blocked and replaced by “cloud ads” just because the page contained the word “covid-19” or “coronavirus.” So while these brand safety technologies were being paid for by advertisers, hoping that would help keep ads off of not-brand-safe sites, they were instead blocking advertisers’ ads on legitimate mainstream news sites. The result of this blocking is that more ads and dollars flow to lower quality sites in programmatic channels - the exact opposite effect to what advertisers thought would happen. 
Getting Brand Safety Right is Hard
Don’t get me wrong. Getting brand safety right is hard. That’s because words have meaning, phrases may have different meanings, the English language has many puns and idioms, and context matters. For example, the word “blood” may be undesirable or “not-brand-safe” when appearing on a consumer site; but the same word “blood” is fine and needed on a medical site. Others have documented that keyword blocking is a very common practice. But often it is humorously flawed. "For example, “shooting” is one of the most common blacklist terms. While it may identify some content about violence, that term will also block content by astronomy buffs (shooting stars), sports fans (shooting hoops), technology users (troubleshooting), photographers (shooting a photo) and card players (shooting the moon)." (Source: AdAge) 
Getting brand safety right at scale is even harder. Brand safety technology either has a few milliseconds to determine if a page is brand safe or unsafe when their detection tag is in the ad iframe, or the tech has to do mass crawling to index billions of webpages and millions of sites. These crawlers are software programs that load the webpages and collect all the text content on the page for brand safety analysis. The challenge is that modern webpages change often or have dynamic content loaded by javascript (e.g. weather, sports scores, news, slideshows, etc.). The content can change after the brand safety crawler makes a “brand safety” determination for the page. This means a page that was marked “safe” may no longer be safe, or a site marked “unsafe” may no longer be “unsafe.” Furthermore, fraudsters operating fake sites meticulously avoid keywords most often marked as “brand_unsafe” and thus get all the ads and ad dollars that were blocked from going to mainstream legitimate publishers like New York Times, Wall Street Journal, etc.
In the tables above are examples of “content classifiers” seen in the largest ad network. Look closely at the domains and how they were classified. Some categories are clearly wrong while others may simply be incomplete and imprecise — and the entire site cannot be easily categorized into one category, just like songs may not fit neatly into only one genre of music. We have reviewed cases in the past where entire sites get blocked or blacklisted due to not brand-safe content on a few pages. CBSnews.com being marked as “weapons” is likely that there was a news item that contained the word “weapons.” 


