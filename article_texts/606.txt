Company named Artipet used an AI version of King to sell weight loss services

Gayle King has hit out at an AI generated advert that manipulated a video of her to advertise its weight loss services.

The CBS host, 68, warned fans not to be fooled by the deepfake video, which has appeared across Instagram.

The post, apparently from a company named Artipet, uses King's likeness and voice to try and sell weight loss products.

In a statement to her almost one million followers King said: 'People keep sending me this video and asking about this product and I have nothing to do with this company.

'I posted this video promoting my radio show on August 31 (swipe to see the original), and they’ve manipulated my voice and video to make it seem like I’m promoting it.

Gayle King warned Instagram followers her voice has been spoofed on a weight loss company's post

I’ve never heard of this product or used it! Please don’t be fooled by these AI video.'

The fake video features a genuine clip of King that appears to have been dubbed with an AI generated voice.

She can be heard saying: 'Ladies honestly I did not expect my weight loss to spark so many questions. My direct messages on Instagram are overflowing.

'Instead of replying to each one individually I decided to make a post about it. Follow the link right now and learn more about my secret.'

A flashing link at the bottom of the page encourages viewers to click through.

It comes just a day after Tom Hanks warned that an 'AI version' of his image was being used to sell a dental plan.

He told his 9.5 million followers to 'beware' of the scam and added, 'I have nothing to do with it'.

The incidents are just the latest example of celebrities taking issue with AI usages of their work.

The AI generated add took elements from King's original post on Instagram promoting her radio show

In July it emerged that Sarah Silverman hopes to sue Meta and Chat GPT's parent company Open AI over claims their AI language models were trained on her copyrighted material.

And earlier this month, several high profile authors including George R.R. Martin and Jodi Picoult partnered with The Authors Guild and announced they are suing Open AI for the same reason.

The Guild organized the class action lawsuit amid fears it could 'decimate' the writing professions.

Memory Man author David Baldacci, who is among the authors suing, also warned the use of AI in this way poses an 'existential threat' to the industry.. . In a Facebook video viewed by thousands, CNN’s Wolf Blitzer appears to hawk a diabetes drug. In another, “CBS Mornings” host Gayle King seems to endorse weight loss products.

But the clips are doctored — the latest in a rash of deepfakes that hijack images of trusted news personalities in spurious ads, undermining confidence in the news media.

Similar social media posts in recent months have targeted Fox News personality Jesse Watters, CBC host Ian Hanomansing and BBC stars Matthew Amroliwala and Sally Bundock.

In some cases, the journalists have used their own accounts to push back.

“I’ve never heard of this product or used it! Please don’t be fooled by these AI videos,” King said on Instagram in October.

After seeing clips of himself supposedly promoting cannabis products, CNN medical correspondent Sanjay Gupta also posted a warning: “These scams have nothing to do with me… my primary concern is for your health, and I do worry you could be harmed if you take these products.”

The manipulated videos push everything from unproven treatments to investment schemes — many promising “guaranteed income” or access to coveted shares. Some also use altered footage of billionaire Elon Musk, founder of Tesla and SpaceX.

Some include links to investment schemes, unapproved products or unrelated e-commerce websites that disappear after several days.

Meta, the parent company of Facebook and Instagram, has banned deepfakes since early 2020, with some exceptions for parody and satire. Other platforms have similar policies.

But such clips — many of which AFP has fact-checked — are still spreading online.

Voice cloning

“I have seen a rise in these types of videos where a person’s voice is cloned from as little as two minutes of their voice, and then any other video of them is modified so that the mouth is consistent with the new audio,” Hany Farid, a professor at the University of California-Berkeley specializing in digital forensics, previously told AFP.

Some deepfakes are easy to detect due to their poor quality. However, experts warn the technology is improving — and TV personalities are easy targets because there is ample footage available to train AI programs.

The trend is worrisome because “people have grown to trust a newscaster like their friend,” according to Andrea Hickerson, dean of journalism at the University of Mississippi.

“It’s really dangerous because people aren’t expecting misinformation and disinformation to come in that way,” she said. “It looks like a traditional news outlet.”

‘Crisis of trust’

AI-manipulated content has become a growing part of investment fraud in particular, which cost Americans some $3.8 billion in 2022, according to the Federal Trade Commission.

Such schemes have reportedly targeted victims in Canada, Australia and other countries. In some cases, they cost individuals tens or hundreds of thousands of dollars.

“The schemes are becoming increasingly complex as criminals fuse traditional tactics with online scams involving cryptocurrencies and artificial intelligence,” said attorney Chase Carlson in a blog post earlier this year.

Americans are increasingly worried about the use of AI online — particularly when it comes to politics.

More than 50 percent expect such falsehoods to affect the outcome of the 2024 election, according to a September poll from Axios and business intelligence firm Morning Consult.

AFP has previously debunked deepfake videos of US President Joe Biden announcing a military draft and former secretary of state Hillary Clinton endorsing Florida Governor Ron DeSantis for president.

Rebekah Tromble, director of the Institute for Data, Democracy and Politics at The George Washington University, said this kind of misinformation “plays into larger concerns about trust in information and trust in institutions.”

Only about a third of Americans have a “great deal” or “fair amount” of confidence in the news media, according to an October Gallup poll, matching a low recorded in 2016.

Many of the manipulated clips circulating online are low-quality “cheapfakes,” Tromble noted, but they still contribute to “a crisis of trust.” She urged news consumers to use caution before sharing such posts on social media.

“There’s still a lot of good information out there, and with a healthy dose of skepticism we can snuff out the things that are disinformation,” she said.. An advertiser reportedly used a deepfake of Tom Hanks to promote dental plans without the actor’s permission. Hanks shared a warning on Instagram on Sunday alerting his followers about the AI-generated video, which he wrote he had “nothing to do with.” Hanks has been outspoken about the challenges AI poses for the industry, and the use of actors’ digital likenesses is one of the major points of concern voiced by striking SAG-AFTRA workers.

Just last spring, Hanks said in an appearance on The Adam Buxton Podcast that AI and deepfakes present both artistic and legal challenges. “I could be hit by a bus tomorrow and that’s it,” Hanks said, “but my performances can go on and on and on and on and on, and outside of the understanding that it’s been done with AI or deepfake, there’ll be nothing to tell you that it’s not me.” He also spoke of a hypothetical scenario in which an entire movie series could be made using an AI version of him that’s “32 years old from now until kingdom come.” Perhaps in confirmation of what's to come, the offending dental plan ad depicts a significantly younger Hanks.

The use of AI to capitalize on celebrities’ legacies has already become an ethical issue. Roadrunner: A Film About Anthony Bourdain sparked widespread debate upon its release after it was revealed the documentary contained AI-generated voice overs of the beloved chef and storyteller. Just this weekend, Robin Williams’ daughter, Zelda Williams, posted in support of “SAG’s fight against AI,” writing on Instagram that she’d seen firsthand how the technology is used to capture the likeness of people “who cannot consent,” like her father.

“These recreations are, at their very best, a poor facsimile of greater people,” Williams wrote, “but at their worst, a horrendous Frankensteinian monster, cobbled together from the worst bits of everything this industry is, instead of what it should stand for.”

Hanks said in the April interview that the issue has been on his radar since filming The Polar Express in the early 2000s, which starred a CGI version of the actor. It was “the first time that we did a movie that had a huge amount of our own data locked in a computer,” Hanks told Buxton, adding, “We saw this coming.”