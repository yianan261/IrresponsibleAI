Tom Hanks and Gayle King, a co-host of “CBS Mornings,” have separately warned their followers on social media that videos using artificial intelligence likenesses of them were being used for fraudulent advertisements.

“People keep sending me this video and asking about this product and I have NOTHING to do with this company,” Ms. King wrote on Instagram on Monday, attaching a video that she said had been manipulated from a legitimate post promoting her radio show on Aug. 31.

The doctored footage, which she shared with the words “Fake Video” stamped across it, showed Ms. King saying that her direct messages were “overflowing” and that people should “follow the link” to learn more about her weight loss “secret.”

“I’ve never heard of this product or used it!” she wrote. “Please don’t be fooled by these AI videos.”. Videos circulating of Tom Hanks promoting a dental plan or MrBeast giving out $2 iPhones are about as legit as that email from a foreign royal begging you to spot them $5K 🙏.

The Forrest Gump star and the YouTube philanthropist warned their fans this week that clips making the rounds on social media are AI deepfakes created without their consent. And that’s just a tiny taste of how the nascent tech that can animate celebrity faces and put words in their mouths has been roiling showbiz.

Tom Brady, who probably wishes his FTX ad was a deepfake, threatened to sue the creators of a crass standup special made with an AI-generated version of his voice and likeness earlier this year.

Robin Williams’s daughter, Zelda Williams, posted on Instagram over the weekend that she’s disturbed by attempts to “recreate actors who cannot consent,” like her late father.

AI makes waves in Hollywood

The issue of restricting the use of deepfakes has also been a central sticking point in the negotiation between the SAG-AFTRA union and Hollywood studios amid the ongoing actors strike. Background actors worry their employers could replace them with animated versions of their avatars. Performers also say that without proper AI guardrails, studios could use their work to train artificial intelligence without consent or cast an actor’s likeness in a role that they might find objectionable. (Williams said she’s rooting for SAG in its “fight against AI.”)

AI was also an issue in the recently negotiated contract (not yet finalized) that ended the strike by TV and film writers. The agreement limits the extent to which producers can use AI-generated content to replace the work of human pros.

Deepfakes aren’t just entertainment bogeymen. Doctored content is also disrupting politics. A few days before this weekend’s parliamentary election in Slovakia, AI-made audio clips featuring what sounded like one of the front-runners discussing plans to buy votes and double the price of beer circulated on social media, and…he lost his bid to become prime minister.. Tom Hanks has warned fans that an ad for a dental plan that appears to use his image is in fact fake and was created using artificial intelligence.

In a message posted to his 9.5 million Instagram followers, the actor said his image was used without his permission. “BEWARE!! There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it,” Hanks wrote over a screenshot of a computer-generated image of himself from the clip.

The Oscar winner has expressed concerns in the past about the use of AI in film and TV, although he has not shied away from approving digitally altered versions of himself in film.

The 2004 computer-animated Christmas fantasy The Polar Express featured a CGI version of Hanks. He was also de-aged in scenes in 2022 film A Man Called Otto.

Speaking with British comedian Adam Buxton on his podcast on 18 April, just days before the start of the Hollywood writers’ strike, Hanks said of AI: “We saw this coming. We saw that there was going to be this ability to take zeros and ones inside a computer and turn it into a face and a character. Now that has only grown a billionfold since then, and we see it everywhere.

“I can tell you that there [are] discussions going on in all of the guilds, all of the agencies, and all of the legal firms to come up with the legal ramifications of my face and my voice – and everybody else’s – being our intellectual property.

“Right now if I wanted to, I could get together and pitch a series of seven movies that would star me in them in which I would be 32 years old from now until kingdom come. Anybody can now recreate themselves at any age they are by way of AI or deepfake technology.”

Hanks told Buxton that AI could allow a fake version of him to continue acting in perpetuity.

“I could be hit by a bus tomorrow, and that’s it, but performances can go on and on and on and on. And outside of the understanding that it’s been done with AI or deepfake, there’ll be nothing to tell you that it’s not me and me alone. And it’s going to have some degree of lifelike quality. That’s certainly an artistic challenge, but it’s also a legal one.”

The US writers’ strike ended last week, with one of the major sticking points being concerns that unchecked AI could undermine the work of creatives. The Writers Guild of America approved an agreement with the Alliance of Motion Picture and Television that features restrictions on how AI can be used in film and TV.

However Sag-Aftra – the union representing Hollywood actors – remains on strike, meaning most productions cannot resume. The actors’ strike began a few months after the writers’ strike, with pay, as well as concern over the use of AI in generating unapproved likenesses of actors, at the heart of the dispute. There are hopes the writers’ deal could help usher in a resolution to the Hollywood actors’ strike.

In the Robert Zemeckis-directed film Here, set for release next year, Tom Hanks will play younger versions of his character using a tool from Metaphysic. The AI company said it can create “high-resolution photorealistic faceswaps and de-ageing effects on top of actors’ performances live and in real time without the need for further compositing or VFX work”.. Will the real Tom Hanks please stand up?

The "Elvis" actor, 67, claimed on Instagram Sunday that a dental company used a computer-generated video of him without his permission.

"BEWARE!! There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it," Hanks wrote over a screenshot of the advertisement.

He did not reveal which company used his likeness for their advertisement.

USA TODAY reached out to reps for Hanks for comment.

The latest use of the Oscar-winning actor comes five months after he discussed the morality of AI and the possibility of his likeness being used for acting after he dies.

"Anybody can now recreate themselves at any age they are by way of AI or deep fake technology," he said on "The Adam Buxton" podcast in May. "I could be hit by a bus tomorrow and that’s it, but my performances can go on and on and on."

Hanks elaborated that aside from a project labeling a posthumous movie with him as AI, "there'll be nothing to tell you that it's not me and me alone and it's going to have some degree of lifelike quality."

He added: "That's certainly an artistic challenge, but also a legal one."

Podcast host Adam Buxton insisted that audiences would be able to tell the difference, especially in some stylistic choices that Hanks makes that AI would not pick up.

"Without a doubt people will be able to tell, but the question is, will they care?" Hanks responded. "There are some people that won't care, that won't make that delineation."

The morality of AI in the entertainment industry is sparking "discussions going on in all of the guilds, all of the agencies, and all of the legal firms in order to come up with the legal ramifications of my face and my voice and everybody else’s being our intellectual property," the actor added.

Tom Hanks reacts to AI:Actor says some people 'won't care' if an computer-generated version of him continues acting after death

AI has been an ongoing concern in Hollywood for both actors and screenwriters.

The Writers Guild of America board unanimously voted to affirm the strike-ending deal on Wednesday with the Alliance of Motion Picture and Television Producers, the group that represents studios, streaming services and production companies in negotiations.

According to a WGA statement, writers earned increased pay, health and pension contributions with the contract extension as well as new foreign streaming residuals, and viewership-based streaming bonuses. There are also assurances against AI, a particular point of contention in the negotiations.

Contributing: Bryan Alexander

Hollywood writers' strike to endas union leadership OKs deal. An advertiser reportedly used a deepfake of Tom Hanks to promote dental plans without the actor’s permission. Hanks shared a warning on Instagram on Sunday alerting his followers about the AI-generated video, which he wrote he had “nothing to do with.” Hanks has been outspoken about the challenges AI poses for the industry, and the use of actors’ digital likenesses is one of the major points of concern voiced by striking SAG-AFTRA workers.

Just last spring, Hanks said in an appearance on The Adam Buxton Podcast that AI and deepfakes present both artistic and legal challenges. “I could be hit by a bus tomorrow and that’s it,” Hanks said, “but my performances can go on and on and on and on and on, and outside of the understanding that it’s been done with AI or deepfake, there’ll be nothing to tell you that it’s not me.” He also spoke of a hypothetical scenario in which an entire movie series could be made using an AI version of him that’s “32 years old from now until kingdom come.” Perhaps in confirmation of what's to come, the offending dental plan ad depicts a significantly younger Hanks.

The use of AI to capitalize on celebrities’ legacies has already become an ethical issue. Roadrunner: A Film About Anthony Bourdain sparked widespread debate upon its release after it was revealed the documentary contained AI-generated voice overs of the beloved chef and storyteller. Just this weekend, Robin Williams’ daughter, Zelda Williams, posted in support of “SAG’s fight against AI,” writing on Instagram that she’d seen firsthand how the technology is used to capture the likeness of people “who cannot consent,” like her father.

“These recreations are, at their very best, a poor facsimile of greater people,” Williams wrote, “but at their worst, a horrendous Frankensteinian monster, cobbled together from the worst bits of everything this industry is, instead of what it should stand for.”

Hanks said in the April interview that the issue has been on his radar since filming The Polar Express in the early 2000s, which starred a CGI version of the actor. It was “the first time that we did a movie that had a huge amount of our own data locked in a computer,” Hanks told Buxton, adding, “We saw this coming.”. . Tom Hanks is pretty recognizable, whether he's holding a box of chocolates in Forrest Gump or wearing a space suit in Apollo 13. But should you see a dental insurance ad with his picture, look twice. It's not really the Oscar-winning actor.

"Beware!" Hanks wrote on Instagram this weekend. "There's a video out there promoting some dental plan with an AI version of me. I have nothing to do with it."

Hanks shared an image, which The New York Times reports to be an apparent screenshot from the ad, though he declined to answer the newspaper's questions about what company ran the ad or whether he is planning legal action. The Times reported being unable to find the ad online.

Hanks isn't the only celebrity complaining about doctored footage of themselves being used in ads. CBS Mornings host Gayle King made a similar post on Instagram on Monday.

"People keep sending me this video and asking about this product and I have NOTHING to do with this company," King wrote. "I posted this video promoting my radio show on August 31 (swipe to see the original), and they've manipulated my voice and video to make it seem like I'm promoting it ... I've never heard of this product or used it! Please don't be fooled by these AI videos."

The stars' faked images don't seem to be helping make unknown brands famous, however. The King video is paired with an apparent company name, Artipet. But the Times reports that, as with the Hanks video, reporters couldn't figure out what product was being promoted or what company was involved.

King's fans seemed thankful that the host pointed out the footage.

"I knew it was fake the second I saw it yesterday," one Instagram commenter wrote. "So frustrating! People fall for these scams all the time. Ugh! Thanks for pointing it out to everyone!"

How to protect yourself from celebrity deepfakes

Both the Hanks and King posts appear to reference "deepfakes," images or videos that use artificial intelligence to make it look as if a person is doing or saying things he or she actually isn't. As CNET noted in this article, the technology entered the mainstream in 2019 and since has evolved and improved.

The European Union has strengthened its rules around how tech companies must deal with deepfakes with a revised Code of Practice on Disinformation, and in March, video-sharing app TikTok required that synthetic or manipulated media depicting realistic scenes must be clearly labeled as fake. TikTok's changes continue to allow synthetic media featuring public figures under some circumstances, though abuse, political misinformation and commercial endorsements are now prohibited there.

To avoid being fooled, there are practical things you can do when trying to determine whether something is generated by AI. Look for odd phrasing and facial movements, research if the source is reputable and Google the content to see if others are questioning its validity.

Editors' note: CNET is using an AI engine to help create some stories. For more, see this post.. American television personality Gayle King has warned her followers about the dangers of artificial intelligence (AI) after she became the victim of a manipulated video.

A video of King has circulated on Instagram in which she appeared to promote various weight loss products from a company known as Artipet. The sponsored post appeared on the feed of many of the "CBS Mornings'" host's one million followers.

"Ladies, honestly, I did not expect my weight loss to spark so many questions. My direct messages on Instagram are overflowing," King can be heard saying in the video. "Instead of replying to each one individually, I decided to make a post about it. Follow the link right now and learn more about my secret."

While the video appeared legitimate to many, some eagle-eyed Instagram users noticed that some of King's words did not match up with her lips and her voice seemed to lack proper emotion.

OPENAI UPDATES CHATGPT TO LET AI TOOL 'SEE, HEAR AND SPEAK'

The video eventually came to the attention of King, who explained the video was manipulating an authentic video of her to promote a slew of weight loss services falsely.

"People keep sending me this video and asking about this product and I have NOTHING to do with this company," she wrote in an Instagram post.

King revealed that the fabricated content used an August 31 promotional video for her radio show to mislead viewers.

"I've never heard of this product or used it! Please don't be fooled by these AI videos," she added.

Representatives for King have requested that the fake video be taken down several times.

WHAT IS ARTIFICIAL INTELLIGENCE (AI)?

She is not the first celebrity to fall victim to AI.

A day earlier, actor Tom Hanks warned that someone used the technology to create a video of him touting the benefits of a dental plan.

The video showed the 67-year-old Oscar winner at a younger age dressed in a black shirt and matching suit jacket.

"BEWARE!! There's a video out there promoting some dental plan with an AI version of me. I have nothing to do with it," Hanks told his 9.5 million Instagram followers.

Hanks has previously expressed concern about the dangers of AI, telling podcast host Adam Buxton that he could pitch movies that could show him at any age "from now until kingdom come."

WHAT ARE THE DANGERS OF AI? FIND OUT WHY PEOPLE ARE AFRAID OF ARTIFICIAL INTELLIGENCE

"I could be hit by a bus tomorrow, and that's it, but performances can go on and on and on and on. And outside of the understanding that it's been done with AI or deepfake, there'll be nothing to tell you that it's not me," Hanks said. "That's certainly an artistic challenge, but it's also a legal one."

On Sunday, YouTube personality MrBeast slammed a TikTok video that seemed to show him offering 2$ iPhones to fortunate viewers, calling it a "deepfake scam ad."

"If you're watching this video, you're one of the 10,000 lucky people who will get an iPhone 15 Pro for just $2," the fake advertisement told viewers. "I'm MrBeast and I'm doing the world's largest iPhone 15 giveaway. Click the link below to claim yours now."

MrBeast, who has 188 million YouTube followers, questioned how AI technology could be used and spread on social media.

"Are social media platforms ready to handle the rise of AI deepfakes? This is a serious problem," he said.

CLICK HERE TO GET THE FOX NEWS APP. Company named Artipet used an AI version of King to sell weight loss services

Gayle King has hit out at an AI generated advert that manipulated a video of her to advertise its weight loss services.

The CBS host, 68, warned fans not to be fooled by the deepfake video, which has appeared across Instagram.

The post, apparently from a company named Artipet, uses King's likeness and voice to try and sell weight loss products.

In a statement to her almost one million followers King said: 'People keep sending me this video and asking about this product and I have nothing to do with this company.

'I posted this video promoting my radio show on August 31 (swipe to see the original), and they’ve manipulated my voice and video to make it seem like I’m promoting it.

Gayle King warned Instagram followers her voice has been spoofed on a weight loss company's post

I’ve never heard of this product or used it! Please don’t be fooled by these AI video.'

The fake video features a genuine clip of King that appears to have been dubbed with an AI generated voice.

She can be heard saying: 'Ladies honestly I did not expect my weight loss to spark so many questions. My direct messages on Instagram are overflowing.

'Instead of replying to each one individually I decided to make a post about it. Follow the link right now and learn more about my secret.'

A flashing link at the bottom of the page encourages viewers to click through.

It comes just a day after Tom Hanks warned that an 'AI version' of his image was being used to sell a dental plan.

He told his 9.5 million followers to 'beware' of the scam and added, 'I have nothing to do with it'.

The incidents are just the latest example of celebrities taking issue with AI usages of their work.

The AI generated add took elements from King's original post on Instagram promoting her radio show

In July it emerged that Sarah Silverman hopes to sue Meta and Chat GPT's parent company Open AI over claims their AI language models were trained on her copyrighted material.

And earlier this month, several high profile authors including George R.R. Martin and Jodi Picoult partnered with The Authors Guild and announced they are suing Open AI for the same reason.

The Guild organized the class action lawsuit amid fears it could 'decimate' the writing professions.

Memory Man author David Baldacci, who is among the authors suing, also warned the use of AI in this way poses an 'existential threat' to the industry.. On Monday, a “CBS Mornings” co-host warned thousands of social media followers that an AI-rendered image of her was falsely promoting a product that she has no connection with. A day earlier, an Oscar-winning actor told people to “beware” of an AI image of himself floating around on the internet. The same day, a YouTube star with 188 million followers said AI-doctored content was trying to shill for a “scam” using his likeness.

The three celebrities — with large followings in their respective realms — started a week of high-profile reactions to AI-altered images that underscore the increasing contention regarding the use of artificial intelligence and its ability to reproduce people’s likenesses regardless of their consent.

Gayle King of CBS News posted a warning to Instagram on Monday, sharing a snippet of a video that used her likeness for a purported weight loss product.

Advertisement

“People keep sending me this video and asking about this product and I have NOTHING to do with this company,” King wrote, stamping the words “fake video” across her AI depiction. “I’ve never heard of this product or used it! Please don’t be fooled by these AI videos.”

Representatives of King “have requested that the fake video be taken down several times,” said Samantha Graham, a CBS News spokesperson. “Gayle was made aware of this by friends who reached out to her about it.”

Academy Award winner Tom Hanks warned his 9.5 million followers of a similar scam Sunday.

“There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it,” Hanks posted to Instagram.

It is unclear what entities were behind the deepfakes, or false images purporting to be real, that featured King’s and Hanks’s doctored footage. Hanks’s representatives declined to respond to The Washington Post’s questions. His post did not name the alleged dental company that depicted his likeness, and he didn’t share the video. King’s post showed a logo for “Artipet,” for which a web search showed little online presence Tuesday evening.

Advertisement

The conversations, legal recourse and regulations around the technology remain murky, with few concrete laws in the United States or around the world targeting unauthorized AI-generated content.

Many companies are rethinking or reducing ethical AI research, often as part of broader cost-cutting, even as new applications of the technology are booming. Some schools have banned access to ChatGPT, an AI bot that can churn out responses or answers to students’ schoolwork in mere moments. AI images such as the ones Hanks and King called out are becoming harder to distinguish from real ones as tech companies improve their AI products, giving way to misinformation — in the case of these celebrities, false advertisements. The technology may take jobs from already disadvantaged groups as well.

It’s a sticking point in Hollywood, too. The use of AI is among the issues on the bargaining table between the Screen Actors Guild-American Federation of Television and Radio Artists (SAG-AFTRA) and major Hollywood studios. The actors union remains on a months-long strike against studios, even after the Writers Guild of America recently ended its strike.

Advertisement

SAG-AFTRA seeks protections for its members from having their likeness, voice or performances used without their consent or without compensation. In an FAQ about the strike authorization, the union said AI’s ability to mimic these creative expressions is a “real and immediate threat to the work of our members.” The guild also wants to prevent studios from being able to train AI to create performances from an actor’s existing work.

Hanks has expressed worry about the technology, too. In an interview with the Adam Buxton Podcast this year, the actor said AI allows fake versions of actors to proliferate — and, if allowed, the public may not know or care.

“Right now if I wanted to, I could get together and pitch a series of seven movies that would star me in them in which I would be 32 years old, from now until kingdom come. Anybody can now re-create themselves at any age they are by way of AI or deepfake technology,” Hanks told Buxton.

Advertisement

“I could be hit by a bus tomorrow, and that’s it, but performances can go on and on and on and on. And outside of the understanding that it’s been done with AI or deepfake, there’ll be nothing to tell you that it’s not me,” he said. “That’s certainly an artistic challenge, but it’s also a legal one.”

“We saw this coming. We saw that there was going to be this ability to take zeros and ones inside a computer and turn it into a face and a character. Now that has only grown a billionfold since then, and we see it everywhere,” Hanks added. “I can tell you that there [are] discussions going on in all of the guilds, all of the agencies, and all of the legal firms to come up with the legal ramifications of my face and my voice — and everybody else’s — being our intellectual property.”

Skip to end of carousel The Style section Style is where The Washington Post covers happenings on the front lines of culture and what it all means, including the arts, media, social trends, politics and yes, fashion, all told with personality and deep reporting. For more Style stories, click here End of carousel

Beyond Hollywood, social media stars are calling out the technology for its dubious impacts.

Advertisement

YouTube star MrBeast, whose real name is Jimmy Donaldson, shared an AI-generated video of himself Sunday. Like the ones of King and Hanks, the video depicted a false Donaldson, who has 188 million YouTube followers, making claims that the real Donaldson doesn’t endorse.

He called it a “deepfake scam ad.”

“If you’re watching this video, you’re one of the 10,000 lucky people who will get an iPhone 15 Pro for just $2,” the video advertisement told viewers. “I’m MrBeast and I’m doing the world’s largest iPhone 15 giveaway. Click the link below to claim yours now.”

Donaldson criticized the TikTok-based video on X, one of several sites that have struggled over the years to contain such misinformation. “Are social media platforms ready to handle the rise of AI deepfakes?” he asked. “This is a serious problem.”. A number of TikTok deepfakes have been called out by the celebrities whose likenesses have been stolen. These include MrBeast, Tom Hanks, and Gayle King.

The fake video of MrBeast claimed that viewers had been selected to receive an iPhone 15 Pro for just $2, leaving the YouTube star to question whether social media networks are prepared for deepfake scams …

What is a deepfake?

A deepfake is a video in which generative AI is used to fake footage of an individual, usually a celebrity, politician, or other public figure.

The better ones can look extremely convincing, usually combining real video footage of the person with AI-generated mouth movements to match the fake speech. The audio either splices together actual words and phrases from many hours of source footage, or generates realistic impersonations of the voice from the same training data.

Deepfakes obviously have huge potential for harm, from scamming people out of money through lending credibility to hoaxes to political disinformation intended to influence election results.

TikTok deepfakes

NBC reports on the MrBeast example.

YouTube star MrBeast, whose real name is Jimmy Donaldson, is asking if social media platforms are prepared to deal with fake AI ads after a scam advertisement on TikTok featured a deepfake of him offering $2 iPhones. “Lots of people are getting this deepfake scam ad of me … are social media platforms ready to handle the rise of AI deepfakes? This is a serious problem,” Donaldson posted on X, formerly known as Twitter. When asked for comment, a spokesperson for Donaldson directed NBC News to the post.

TikTok said that it had removed the video, and pointed to its policy requiring the disclosure of synthetic or manipulated media.

CNET reports that Tom Hanks is another victim, with his likeness used to promote a dental plan.

Tom Hanks is pretty recognizable, whether he’s holding a box of chocolates in Forrest Gump or wearing a space suit in Apollo 13. But should you see a dental insurance ad with his picture, look twice. It’s not really the Oscar-winning actor. “Beware!” Hanks wrote on Instagram this weekend. “There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it.”

CBS Mornings host Gayle King likewise.

King made a similar post on Instagram on Monday. “People keep sending me this video and asking about this product and I have NOTHING to do with this company,” King wrote. “I posted this video promoting my radio show on August 31 (swipe to see the original), and they’ve manipulated my voice and video to make it seem like I’m promoting it … I’ve never heard of this product or used it! Please don’t be fooled by these AI videos.”

NYU professor calls for TikTok ban

The broader controversy over the Chinese-run short video app continues, with many fearing that the algorithmically generated feeds can be used to feed pro-Chinese and anti-Western content to users.

TNW reports NYU professor Scott Galloway telling a conference in Helsinki that the app was a threat to national security.

Galloway described TikTok as probably “the most ascendant technology company in history” — and “a national defence threat” […] “They have implanted a neural jack into the web matter of our youth,” Galloway said […] Galloway fears this audience is being brainwashed by the CCP. “If I were them, I would put my thumb delicately, insidiously, covertly, elegantly, on the scale of anti-Western content and on the scale of pro-China content,” he said.

Photo: Jakob Owens/Unsplash. Artificial intelligence (AI) has been a major talking point in Hollywood throughout 2023 and continues to be so as multiple celebrities have come forth denouncing the use of the likeness in AI deep fakes.

Actor Tom Hanks, YouTube personality MrBeast and American broadcast journalist Gayle King have all recently tried to put an end to deep fakes of themselves.

Hanks was the first of the three to identify the AI deep fake of himself after he posted a screenshot of the video on his Instagram page on Oct. 1, saying “beware” and that he had nothing to do with it.

The AI version of Hanks was created to promote what he called “some dental plan.”

A day later, on Oct. 2, King posted a similar video on her Instagram. An AI deep fake of her surfaced, which used a video she recently made to promote her radio show.

The fake also promoted a product the journalist said she neither knew of nor endorsed. She wrote, “...they’ve manipulated my voice and video to make it seem like I’m promoting it” and warned her community “not to be fooled.”

King received many comments in her support and voicing concerns over the “scariness” of AI deep fakes.

On Oct. 3, YouTube personality James Donaldson, known as MrBeast, took to social media platform X (formerly Twitter) to denounce an AI-generated deep fake of himself. In this instance, MrBeast is seen promoting a scam for winning an iPhone 15 pro.

The YouTube personality’s posts made a plea to social media platforms, saying: “Are social media platforms ready to handle the rise of AI deep fakes? This is a serious problem.”

Lots of people are getting this deepfake scam ad of me… are social media platforms ready to handle the rise of AI deepfakes? This is a serious problem pic.twitter.com/llkhxswQSw — MrBeast (@MrBeast) October 3, 2023

One X user commented on MrBeast’s post, saying they had received the ad on their TikTok, while another also raised concerns over the widespread emergence of AI deep fakes.

While there has been no official legislation created or implemented regarding AI deep fakes in the United States, lawmakers are considering regulating political deep fakes in the lead-up to the 2024 presidential election.

Related: AI deepfakes are getting better at spoofing KYC verification — Binance exec

However, Hollywood entertainment studios and actors have been negotiating the use of AI in future productions. Members of the Screen Actors Guild-American Federation of Television and Radio Artists have included AI as an issue in their strike, which has been ongoing since the summer.

The proposal from studios suggested that background performers should be scanned, receiving only a single day’s worth of pay, and then hand over complete ownership of the scan, image and likeness to the companies.

Meanwhile, the Writer’s Guild strike has finally ended, with negotiated terms for AI use in written material in the entertainment industry.

Magazine: ‘AI has killed the industry’: EasyTranslate boss on adapting to change. Credit: tomhanks/Instagram, gayleking/Instagram, MrBeast/X

As long as the web has existed, this advice has rung true: “Don’t believe everything you see on the internet.” Whether it’s a personal blog, a tweet, a YouTube video, or a TikTok, anyone can say anything on here, and it’s tough to know whether or not they’re right (or even telling the truth).



But we’re at an inflection point in internet literacy: Generative AI has reached a scary place, with tech good enough to mimic the likeness of celebrities and make these “clones” say whatever they want. To those in the know, these deepfakes might not be convincing yet, but what about the average social media user? It seems we’re rapidly approaching a point where the general public will start to believe these fraudulent videos are real, and that’s a frightening thought.

There are three high-profile examples of this just from the past week or so. The first is Tom Hanks: The actor posted a screenshot on his Instagram from a video promoting a “dental plan,” with a spokesperson that looks like Tom Hanks if he had his teeth reinstalled. The video itself doesn’t appear to be public, and Hanks didn’t share it or the name of the company promoting it. But the assumption is some company or person made a deepfake of Tom Hanks to sell a dental product. As I mentioned, taking a good look at the image, you can already tell there’s something “off” about his face, and had we been able to see the video, it’s likely that the motion would have the stiff, uncanny valley look that so many AI deepfakes have.

But Mr. Hanks was far from the only celebrity this week to deal with a deepfake issue. Gayle King, one of the anchors of CBS Mornings, posted a deepfake to her Instagram account, stating that people keep sending her the video and that she has nothing to do with it. This time, she shared the original video the deepfake is based on, an innocent video of King discussing having Bruce Springsteen on her show:

Keen observers will be able to tell the first video is fake: The lip movements don’t match up with the audio, and while the audio resembles King’s voice, it’s too stiff, as if she was pretending to be a bad actor while reading a script. I’m sure any of us attuned to these limitations of deepfakes and generative AI will notice the telltale signs right away, but I’m not convinced everyone will see this as immediately fake.

Third, internet sensation Mr. Beast is currently going viral for a deepfake advertisement that’s being shown to TikTok users, myself included. In it, “Mr. Beast” congratulates the viewer for being among 10,000 users selected to win an iPhone 15 Pro for just two dollars. Lucky you!

The video in question is one of the better ones I’ve seen, although it also has its obvious issues. Whoever made this one took care to make Mr. Beast seem more expressive as he spoke, in an attempt to make the whole interaction seem more natural. I think that could be effective for some, but, again, it’s not 100%. Watching the video knowing its fake brings all the imperfections to the surface.

Even if you think it’s obvious these examples are fake, as Marques Brownlee says, this is the worst this tech is going to be. Deepfakes are only going to keep improving, aiming for the ultimate goal of being indistinguishable from real video.

If you’ve enjoyed any of the AI song covers that are blowing up all over the internet, you know how good the tech is getting. The voice actor for Plankton from Spongebob should rightly be concerned about how excellent these covers are, such as Plankton’s cover of Beggin’. Frank Sinatra might have died when Dua Lipa was two, but this AI cover of him singing Levitating is a bop.

This tech can even translate your speech and dub over it in real time, in your voice. While there are a host of apps out there with this ability, even Spotify is testing it to translate podcasts in the hosts’ voices.

At this point, the best deepfakes are audio-only, and even then they still have their accuracy problems. But what happens when a bad actor can make a fake Mr. Beast ad that most people fall for? Imagine a truly convincing Mr. Beast saying directly to young and impressionable fans, “All you have to do to enter my giveaway is enter your banking information, so I can wire you the winnings directly.” Maybe the “contest” will be held inside a “Mr. Beast app,” which actually installs malware on your device.

Of course, there are more frightening scenarios to consider. We’re approaching a presidential election next year. How good will deepfake technology get by November 2024? Will someone open TikTok before heading to the polls to watch a deepfake of Joe Biden saying it’s his ultimate goal to imprison his political enemies? Or maybe one of Donald Trump telling his supporters to show up armed to the polls?

Be diligent when watching videos online

Social media companies need to be more proactive about attacking these fake videos before they spread to others, but we also have a part to play in all this. We need to be careful, now more than ever, when casually scrolling and clicking around this great big internet of ours. Just because you see a video of a “celebrity” saying something, or endorsing a product, doesn’t make it real—not anymore. Check the account it’s posted to diligently: If it’s supposedly the real personality, their account should be verified (unless we’re talking about a useless platform like X, in which case all posts should be treated as false unless unequivocally proven otherwise).

While we wait for deepfakes to get really good, there are still plenty of red flags that tell you when something is illegitimate. Eye and mouth movements will appear strange, for one. Look at that Mr. Beast video: While they tried their best to make him expressive, his eyes are pretty vacant for this first half of the clip. And while they matched the lip movements well, many deepfakes aren’t good at that yet.

Many of these videos appear in very poor quality as well. That’s because increasing the resolution reveals how janky the video is. Deepfakes rely on a real video of a person, whether its the celebrity or not, then overlay the celebrity’s face on top of that video and manipulate it to their liking. It’s pretty hard to do this in high resolution without blending issues, so you see layers clipping in and out of each other.

A healthy dose of skepticism goes a long way on the internet. Now that generative AI is taking over, dial up the skepticism as much as you can.. Ver esta publicación en Instagram Una publicación compartida por Tom Hanks (@tomhanks)

AI is everywhere. Many artists use AI-powered tools to create mind-blowing works or enhance some interesting concepts. Unfortunately, these resources have also had some questionable uses, including the creation of deepfakes. These altered videos show people doing or saying something that they actually didn't. They're computer-generated clips that look entirely real due its repurposing of existing footage. And while celebrities seem to be the most common target for this, AI presents risings concerns that everyone who consumes digital media should be aware of.

Two of the latest figures to deal with an unauthorized AI-generated version of themselves are actor Tom Hanks and broadcast journalist Gayle King. Hanks first posted a warning to Instagram, letting his followers know that there was an AI scam going around that features his face. “BEWARE!! There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it,” the actor wrote over a screenshot of the video.

King also alerted her Instagram followers about an AI-generated video showing her advertising a weight-loss product. “I’ve never heard of this product or used it! Please don’t be fooled by these AI videos,” she wrote. King also shared the original clip the altered version was based on. “I posted this video promoting my radio show on August 31, and they’ve manipulated my voice and video to make it seem like I’m promoting it.”

While this misuse of AI tools seems to come from fraudulent companies, there have also been concerns of its application in more established companies. One of the grievances SAG-AFTRA, the union representing Hollywood actors, has raised during its current strike regards how AI could be used by studios to create digital replicas of actors without proper compensation or approval. When an AI-generated collaboration between Drake and The Weekend hit streaming services earlier this year, music labels raised concerns about how this seemingly harmless bit could become a serious worry for artists in a frail music industry.

To keep harmful AI-generated content at bay, a concerted effort between all parts would be needed—purveyors of these tools could offer ways of tracking the origins of the content, while social media platforms could patch their algorithms to deter its reach, as well as acting quickly in the face of content that has been flagged by users. Should it be needed, even international law could get involved and set some parameters regarding the use of these tools.

AI tools and creations appear to be here to stay, and while a framework of rules set by the key players would be a big step toward protecting the public, platforms that bypass them could always pop up. The days of a video or a picture being proof or something could long be gone, eroding public trust and changing the digital landscape as we know it.

AI presents rising concerns that everyone who consumes digital media should be aware of. Recently, actor Tom Hanks and broadcast journalist Gayle King warned about unauthorized AI-generated versions of themselves being used to promote products they never endorsed.

Ver esta publicación en Instagram Una publicación compartida por Gayle King (@gayleking)

h/t: [Ars Technica]

Related Articles:

People Can’t Believe This Photo of a Bird Isn’t Photoshopped or AI-Generated

Photographer Admits His Award-Winning Photo Is AI-Generated and Rejects Prize

Artist Fuses Her Paintings With AI-Generated Art in Unique Collaboration of Human and Computer

Photo of Pope Francis Wearing a Stylish Puffer Jacket Is Actually an AI-Generated Image. In a Facebook video viewed by thousands, CNN’s Wolf Blitzer appears to hawk a diabetes drug. In another, “CBS Mornings” host Gayle King seems to endorse weight loss products.

But the clips are doctored — the latest in a rash of deepfakes that hijack images of trusted news personalities in spurious ads, undermining confidence in the news media.

Similar social media posts in recent months have targeted Fox News personality Jesse Watters, CBC host Ian Hanomansing and BBC stars Matthew Amroliwala and Sally Bundock.

In some cases, the journalists have used their own accounts to push back.

“I’ve never heard of this product or used it! Please don’t be fooled by these AI videos,” King said on Instagram in October.

After seeing clips of himself supposedly promoting cannabis products, CNN medical correspondent Sanjay Gupta also posted a warning: “These scams have nothing to do with me… my primary concern is for your health, and I do worry you could be harmed if you take these products.”

The manipulated videos push everything from unproven treatments to investment schemes — many promising “guaranteed income” or access to coveted shares. Some also use altered footage of billionaire Elon Musk, founder of Tesla and SpaceX.

Some include links to investment schemes, unapproved products or unrelated e-commerce websites that disappear after several days.

Meta, the parent company of Facebook and Instagram, has banned deepfakes since early 2020, with some exceptions for parody and satire. Other platforms have similar policies.

But such clips — many of which AFP has fact-checked — are still spreading online.

Voice cloning

“I have seen a rise in these types of videos where a person’s voice is cloned from as little as two minutes of their voice, and then any other video of them is modified so that the mouth is consistent with the new audio,” Hany Farid, a professor at the University of California-Berkeley specializing in digital forensics, previously told AFP.

Some deepfakes are easy to detect due to their poor quality. However, experts warn the technology is improving — and TV personalities are easy targets because there is ample footage available to train AI programs.

The trend is worrisome because “people have grown to trust a newscaster like their friend,” according to Andrea Hickerson, dean of journalism at the University of Mississippi.

“It’s really dangerous because people aren’t expecting misinformation and disinformation to come in that way,” she said. “It looks like a traditional news outlet.”

‘Crisis of trust’

AI-manipulated content has become a growing part of investment fraud in particular, which cost Americans some $3.8 billion in 2022, according to the Federal Trade Commission.

Such schemes have reportedly targeted victims in Canada, Australia and other countries. In some cases, they cost individuals tens or hundreds of thousands of dollars.

“The schemes are becoming increasingly complex as criminals fuse traditional tactics with online scams involving cryptocurrencies and artificial intelligence,” said attorney Chase Carlson in a blog post earlier this year.

Americans are increasingly worried about the use of AI online — particularly when it comes to politics.

More than 50 percent expect such falsehoods to affect the outcome of the 2024 election, according to a September poll from Axios and business intelligence firm Morning Consult.

AFP has previously debunked deepfake videos of US President Joe Biden announcing a military draft and former secretary of state Hillary Clinton endorsing Florida Governor Ron DeSantis for president.

Rebekah Tromble, director of the Institute for Data, Democracy and Politics at The George Washington University, said this kind of misinformation “plays into larger concerns about trust in information and trust in institutions.”

Only about a third of Americans have a “great deal” or “fair amount” of confidence in the news media, according to an October Gallup poll, matching a low recorded in 2016.

Many of the manipulated clips circulating online are low-quality “cheapfakes,” Tromble noted, but they still contribute to “a crisis of trust.” She urged news consumers to use caution before sharing such posts on social media.

“There’s still a lot of good information out there, and with a healthy dose of skepticism we can snuff out the things that are disinformation,” she said.