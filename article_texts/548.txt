n May 24th, @opera, a tech company based in #Oslo, Norway and owned by Chinese billionaire Zhou Yahui, released a new browser that integrates an AI chatbot called Aria. According to the company's press release, it is based on "OpenAI’s GPT technology" and "enhanced by additional capabilities such as adding live results from the web."

Like other AI products that have recently been unleashed on society, this one has serious flaws. It answered one of my questions by slandering acclaimed and highly respected photographers. It falsely accused Lynsey Addario, James Nachtwey, Ron Haviv, Lee Miller and Larry Towell of committing war crimes. These photographers have documented conflict at great peril for the public record, not committed war crimes. Raymond D’Addario and Ronald L. Haeberle are not a war criminals either. They were U.S. military photographers. Opera and Open AI's product is defective and dangerous.

AI is an extremely powerful technology that its own creators don't seem to fully understand. We don't allow drug companies to dump powerful new medicines on society without testing or safeguards. Why are we allowing the tech giants to shove their defective products on us? Do we want to live in a world where machines that have perfected the art of persuasion—yet completely lack the ability to fact check—flood the information space? AI chatbots have hacked human language and generated a blackbox of obscure correlations between words and phrases. Everything is put together by algorithms based on shifting probabilities. These assemblages may seem like human communication, but they are not based on common sense, nor on ethics, nor on morals, nor on transparent editorial policies, nor on scientific rigor. Without regulation or responsible use, AI chatbots can undermine our relationship with knowledge and drive us towards an epistemological crisis.
