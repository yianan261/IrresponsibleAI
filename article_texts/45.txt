. . Google has lost a case in Italy over the defamatory nature of autocomplete suggestions, according to a lawyer for the complainant.

Google has lost a case in Italy over the defamatory nature of autocomplete suggestions. Credit: Google

On Tuesday, lead counsel Carlo Piana wrote on his blog that the Court of Milan has upheld its earlier decision to order Google to filter out libellous search suggestions. These are the suggestions that pop up in Google's search input bar, proposing what the user might be wanting to search for.

People searching via Google for Piana's client, who remains publicly unnamed, were apparently presented with autocomplete suggestions including truffatore ("con man") and truffa ("fraud").

The order (PDF, in Italian) is dated 31 March, although Piana only made its contents public on Tuesday. Google lost its bid to claim the protection of the E-Commerce Directive's safe harbour provisions, which partly shields hosting and ISPs from liability for content held on or transmitted over their systems. However, the court viewed the autocomplete suggestions as being produced by Google itself.

Content filter

"Google argued that it could not be held liable because it is a hosting provider, but we showed that this is content produced by them (and by the way, they do filter out certain content, including terms that are known to be used to distribute copyright-infringing material), although through automated means," Piana wrote.

The lawyer said the suit is "by no means an endorsement to censorship", as the allegations had been fully discussed with Google before the court action was even considered and only two phrases were put forward to be filtered out of autocomplete.

"All cases are different, therefore there is no assurance that similar cases would see the same outcome," Piana said. He added that this case had "caused a lot of trouble to the client, who has a public image both as an entrepreneur and provider of educational services in the field of personal finance".

In a statement on Tuesday, Google said it was "disappointed" by the Court of Milan's decision.

"We believe that Google should not be held liable for terms that appear in autocomplete as these are predicted by computer algorithms based on searches from previous users, not by Google itself," the company said. "We are currently reviewing our options."

This is not the first time Google has fallen foul of Italy's authorities. In February 2010, three Google executives were convicted in absentia over a video uploaded to the site, in which an autistic child was shown being bullied. In January this year, Italian authorities also forced Google to make concessions regarding Google News and AdSense, in order to close an antitrust investigation in the country.. A popular Irish hotel has sued Google for defamation because Google’s autocomplete feature suggests to searchers that the hotel is in receivership.

Searchers looking for the Ballymascanlon Hotel — a four-star property that’s reportedly one of the most popular wedding venues in northeast Ireland and is not in financial trouble — see “ballymascanlon hotel receivership” as an autocomplete suggestion as soon as they’ve typed only eight letters of the hotel name. According to a recent Sunday Times article (quoted here by TJ McIntyre), some brides have contacted the hotel “in tears” after seeing the autocomplete suggestion, no doubt fearing that their wedding plans would have to be scrapped.

As Mark Collier writes, the hotel isn’t seeking punitive damages from Google; the suit only asks for an injunction to stop Google from showing the autocomplete suggestion about receivership, and for Google to pay the hotel’s legal fees.

Collier also details how the hotel made multiple attempts to contact Google about the issue and resolve it away from court – beginning with online channels and eventually escalating to attorney’s letters and even including the autocomplete problem in a DMCA complaint filed in March.

Previous Autocomplete Cases

Google has already faced similar complaints in other countries, and hasn’t fared well in the courts. The company lost two cases last year in France; see our articles Google Loses French Lawsuit Over Google Suggest and Google Convicted Again In France Over Google Suggest.

Earlier this year, Google also lost cases in Italy and Argentina.

How Autocomplete Works

Google has explained many time that autocomplete suggestions come from actual search activity. In Danny Sullivan’s article, How Google Instant’s Autocomplete Suggestions Work, the company commented on the Italian case I mentioned above:

We believe that Google should not be held liable for terms that appear in Autocomplete as these are predicted by computer algorithms based on searches from previous users, not by Google itself.

But Google’s argument that autocomplete suggestions are algorithmic doesn’t seem to stand up to legal scrutiny, perhaps because the company has manually removed piracy-related terms in the past, and its help pages list other cases — pornography, violence, hate speech, etc. — where suggestions will be removed.

I’m certainly not a lawyer, nor do I play one on Search Engine Land. So, whether that happens again in Ireland is anyone’s guess at this point.

(Thanks to Mark Collier for tipping us to this story. If you have news tips to share, please contact us.). Yeung wants a court to order Google to remove the "defamatory" suggestions and to pay him compensation.

When users type "Albert Yeung Sau-shing" in English or Chinese into the search engine, Google automatically suggests related search terms such as "triad", "Sun Yee On" and "14K" - the names of triad gangs.

Yeung, founder of a company that manages some of Hong Kong's most famous celebrities, wants to sue the US technology giant because the "autocomplete" function of its search engine links him to triad gangs.

A High Court judge's ruling that entertainment tycoon Albert Yeung Sau-shing can go ahead with his defamation lawsuit against Google is a decision that could have far-reaching consequences for the future of its search engine.

Google argues the suggestions are generated by a computer algorithm or process based on the most frequent combinations of terms that people search for.

But the High Court ruled Google "recombines and aggregates" data through its algorithm and therefore can be legally regarded as a "publisher", meaning it may be sued for defamation.

The decision is a major blow to Google, three months after it lost a landmark case in the European Court of Justice, when it was ordered to erase links to content about individuals on request under the "right to be forgotten".

In her judgment on Tuesday, Madam Justice Marlene Ng May-ling said a jury "may consider" a substantial award for Yeung given Google's search features.

"The advantages of having easy access to a rich store of information ... [come] at a price; any risk of misinformation can spread easily as users forage in the web. The art is to find the comfortable equilibrium," Ng said.

Google's lawyer, Gerard McCoy SC, warned that "the entire basis of the internet will be compromised" if search engines were required to "audit" what could be accessed.

He said Google used "an algorithmic-based approach that requires no human input, operation and/or manipulation in the search processes" and was "a mere passive facilitator".

The judge, however, was unimpressed, saying that Google's algorithms "are synthesising and reconstituting" inputted query data and web content before publishing them as suggestions.

Information thus provided was "distilled pursuant to artificial intelligence set up by Google Inc themselves", Ng said. "This raises a question as to whether or not Google Inc is a neutral tool, and whether [autocomplete search] results are merely [a] machine-generated and non-meaningful jumble of keywords."

Google would not comment on the judgment.

Francis Fong Po-kiu, chairman of the Hong Kong Association of Interactive Marketing, cast doubt on the usefulness of asking Google to remove the associations, as media materials could not be taken down.

"Even if the court was to eventually rule in favour of any individual, the ruling should bind the search engine only so far as that person is concerned," Fong said.

This is not the first time Google has been sued over its autocomplete function. Last year, a German court ordered it to remove offensive or defamatory search suggestions. In that case, the court said Google would only have to remove certain terms when it was notified of an unlawful violation of a person's rights.

This article appeared in the South China Morning Post print edition as: Tycoon's suit risks big impact for Google. CANBERRA, Australia -- An Australian man who alleges Google defamed him on Wednesday won a court battle to sue the search engine giant. Milorad "Michael" Trkulja was shot in the back in 2004 in a restaurant in Melbourne, Australia's second largest city.

The Australian High Court unanimously ruled in favor of Trkulja, supporting his allegation that a Google search of his name could indicate to an ordinary person he was "somehow associated with the Melbourne criminal underworld."

Trkulja had successfully argued in the Victoria state Supreme Court in 2012 that Google defamed him by publishing photos of him linked to hardened criminals of Melbourne's underworld.

Four years later, the Victorian Court of Appeal overturned the decision, finding the case had no prospect of successfully proving defamation. The High Court disputed that ruling and ordered Google to pay Trkulja's legal costs.

Google searches for "Melbourne criminal underworld photos" bring up images of Trkulja alongside gangland figures, his lawyer Guy Reynolds told the High Court in March.

However, Google's lawyers argued it would be "irrational" for someone to assume photos in a Google image search for underworld figures are all of criminals, because the same search would also bring up the Google logo, movie posters, images of crime victims and photos of actor Marlon Brando.

Trkulja is also claiming defamation around Google's "autocomplete" options for his name, which have included phrases like "is a former hit man," ''criminal" and "underworld."

However, the court heard autocomplete is an automatic function and that previous searches influence future suggestions.

The defamation suit is expected to go back to the Victoria Supreme Court for trial.

Trkulja said he would continue the legal action until he gets the result he wants, fearful someone will see the images and tell his grandchildren he's a hardened criminal.

"I will sue Google ... and I will sue them till they stop. I want them to block my pictures," he said. "I'm not a criminal, I've never been involved and I will make sure these people are not going to ruin my family - I have grandchildren," he added.

Google said in a statement: "We will continue to defend the claim. We decline to comment further on ongoing legal matters.". Google’s autocomplete feature has earned meme status for the hilarious and sometimes disturbing search terms it suggests. For example, if you type “why are” into Google search right now, the number one suggested search is: “Why are manhole covers round?” But autocomplete isn’t all fun and games. When Hong Kong business tycoon Albert Yeung Sau-shing Googled his name, the autocomplete feature suggested the word “triad,” a term that, in Asia, is associated with organized crime.

Now Yeung is suing Google for libel.

Yeung is the founder and chairman of Emperor Group, a sprawling business empire that includes property development, entertainment and financial services. He has been found guilty of crimes including illegal bookmaking and perverting the course of public justice, and has been fined for insider trading.

However, he has tried to rehabilitate his image through charity work. He is not one to tolerate even a minor blemish to his reputation — or his tablecloth for that matter: “If any sauce drops on the dining table, I would be very unhappy, as though my business had failed,” he once said, according to the South China Morning Post.

Advertisement

Google tried to have the case dismissed, but Tuesday a judge in Hong Kong said it could go to trial. The decision follows a trend in overseas courts sympathetic to those who want to hold Google responsible for what the Internet says about them. Deputy High Court Judge Marlene Ng cited Europe’s recent “right to be forgotten” ruling requiring Google to remove embarrassing or outdated search results upon request.

Share this article Share

To prove libel in Hong Kong — and the United States — you have to show the accused published a defamatory statement about you. At issue in this case is whether Google can be regarded as the “publisher” of terms suggested by its search algorithm.

Autocomplete uses predictive search, which makes suggestions based on past Googling. For Yeung, “triad” appeared in autosearch because others were searching for his name and the word — or because those words appeared together in pages indexed by Google. Google, however, says it can’t “publish” libelous search results like a newspaper might publish a libelous article because it uses automated search algorithms without human input.

Autosearch in action.

Advertisement

Yeung doesn’t dispute the search process is automated. However, he argues Google has control over suggested search terms because it designed the search algorithm. Therefore, he says, Google is the “publisher” of search results.

The court acknowledges that “to influence or change what the autocomplete instant results show will require a large number of users with unique internet protocol (IP) addresses to type the desired search query into Google Search on an ongoing basis.”

Nonetheless, the judge ruled that Yeung has a “good arguable case” and cleared it to move forward.

Writing for Gigaom, Jeff John Roberts said the ruling is worrisome because it “may give prominent figures like Yeung a new tool to silence public opinion they disagree with. At the same time, the decision cites — and builds on — a worrying worldwide rush to censor Google.”. How We Perceive the World

Google increasingly influences how we perceive the world. What are we more afraid of? That behind the computing processes stands a merciless machine, or the opaque and arbitrary decisions of a large US corporation?

Both are to be feared and, in the case of Google, both come into play. Contrary to what the Google spokesman suggests, the displayed search terms are by no means solely based on objective calculations. And even if that were the case, just because the search engine means no harm, it doesn't mean that it does no harm. The Autocomplete function, the usefulness of which Google so guilelessly praises as a means of giving one's fingers a rest, undeniably helps spread rumors. Assuming that someone unsuspectingly begins to look for information on "Bettina Wulff" and is offered "prostitute," "Hanover" and "dress" as additional search terms -- where, independent of their actual interests, will users most likely click?. A recent High Court decision has opened the door to defamation proceedings that could affect search engine providers, as well as other businesses using search engine optimisation to improve their online profile.

Search engines have, without question, made access to information much easier and faster. Indeed, without search engines, it would be very difficult to navigate the trillions of internet pages and find meaningful results expeditiously. The algorithms behind search engines like Google are also now so developed that they are able to predict what you are looking for through their auto-complete function. What happens though, if those functions return results that are claimed to be untrue and potentially defamatory?

In the recent decision of Trkulja v Google Inc [2018] HCA 25, the High Court of Australia allowed an action to continue in which Google Inc. (a US company) is alleged to be liable in defamation for publishing search results that include images of Mr Trkulja mixed with images of convicted Melbourne criminals, as well as text referring to him and predictions generated by Google's autocomplete functionality. The decision holds the door open to defamation proceedings. While it clearly affects search engines like Google, it may also have implications for businesses using search engine optimisation to increase their online profile (eg media providers where key words could be lumped together in an unintentional manner).

Relevant defamation law

The law of defamation provides a remedy where a person's reputation is damaged by the publication of unjustifiable derogatory information.

In order to sue, it is necessary to prove that the defamatory material that is complained of was in fact published by the party being sued. In order to prove that fact, it must be shown that the alleged publisher:

was in some degree an accessory to the communication of the material in issue; and

intentionally participated in the communication of the allegedly defamatory material.

As to whether something is actually defamatory depends on what ordinary reasonable people would understand by the matter complained of, and whether it would cause them to think less of the person in question.

The events leading up to the Google defamation case

Milorad "Michael" Trkulja is an Australian resident who was shot in the back during a shooting in a Melbourne restaurant in 2004. This incident led to several articles in which there were references to certain Melbourne crime figures and investigations.

Mr Trkulja alleges that when Google image searches were performed during 2012 - 2014 of "Melbourne criminal underworld photos" and "Melbourne underworld criminals", images of him were mixed with images of convicted Melbourne criminals, and the pages contained various phrases such as "melbourne criminals", "melbourne criminal underworld figure", "melbourne criminal underworld photos", "Melbourne underworld crime" etc. It was also alleged that searches of Michael Trkulja's name associated him through the autocomplete function with terms like "is a former hit man", "criminal" and "underworld".

When Mr Trkulja issued proceedings in the Victorian Supreme Court, Google responded by applying to have the proceeding summarily dismissed on three bases:

first, that it did not publish the images;

second, that the matters in issue were not defamatory of Mr Trkulja; and

third, that Google was entitled to immunity from suit as a matter of public interest.

The Supreme Court dismissed Google's application, finding that:

by intentionally participating in the communication of the allegedly defamatory search results, there was a basis for alleging that Google was the publisher of the images;

the fact that the images were often returned alongside well-known underworld figures meant that it was arguable that the material was defamatory as it suggested that Mr Trkulja was a convicted criminal; and

the immunity proposed by Google was not in the public interest.

Google appealed the Court's decision on all three bases. The Court of Appeal did not decide the first ground (but noted its view that the innocent dissemination defence would likely be available), and rejected the third ground. However, it upheld Google's contention that Mr Trkulja would have no prospect of success in claiming that the matters in issue were capable of being defamatory.

Mr Trkulja disagreed and appealed to the High Court.

Appealing to the High Court

The primary issue before the High Court was whether or not the defamation proceedings should have been summarily dismissed by the Court of Appeal.

In a joint judgment, the High Court upheld Mr Trkulja's appeal, finding that:

it was strongly arguable that Google's intentional participation in the communication of the allegedly defamatory results to Google search engine users supports a finding that Google 'published' the allegedly defamatory results; and

some of the search results complained of had the capacity to convey to any ordinary reasonable person viewing the results that Mr Trkulja was somehow associated with the Melbourne criminal underworld and those search results could accordingly be defamatory.

The High Court said that there could be no certainty as to the nature and extent of Google's involvement in the compilation and publication of its search engine results until after discovery. This adversely impacts a court's ability to make a summary determination on publication and innocent dissemination contentions.

As to whether the published material was defamatory, the High Court noted that the test for whether a published matter is capable of being defamatory is what ordinary reasonable people would understand by the matter complained of, and whether that would cause them to think less of a person. The test is not, as stated by the Court of Appeal, whether "any of the defamatory imputations which are pleaded [are] arguably conveyed". It is not what the Court thinks the allegedly defamatory words or images say or depict, but rather what they could convey to the ordinary reasonable person who is a member of the jury. This also must be considered in light of each search and response being, in effect, a different publication.

Further, while the High Court was prepared to accept the assumption that the ordinary reasonable person who has used the Google search engine contemplates that their search results bear some connection to the search terms, it cautioned that in the absence of tested, accepted evidence to the contrary, there could be a significant variance of experience and understanding among the range of persons taken to be representative of the hypothetical ordinary reasonable person

In short, the High Court held that the Court of Appeal had applied the wrong test in considering whether any of the pleaded defamatory imputations were arguably conveyed, and whether the case should be summarily dismissed. In those circumstances, the Court allowed Mr Trkulja's appeal and his case can continue before the Victorian Supreme Court.

Key takeaways from the Google defamation case

This case illustrates that search results (eg images that place a person in an incorrect context or allow false or improper connections to be drawn) have the capacity to convey defamatory imputations. Whether this case proceeds to create significant implications for search engines like Google, will depend upon whether the defamatory imputations are upheld and more importantly, whether Google is subsequently found to be the primary publisher or has a defence as an innocent disseminator under section 32 of the Defamation Act (Vic). No doubt, there will be many interested persons watching the progress of this case because of the impact it may have on how businesses use search engines.

It must be kept in mind, however, that the primary relevance of the High Court's decision focuses upon Google's application for summary dismissal of the claim and the standards and tests that must be applied. It demonstrates that the courts apply great caution when asked on an interlocutory basis to find that a defamation pleading is incapable of bearing a defamatory imputation.. This morning, the Federal Supreme Court (Bundesgerichtshof) has held Google liable for a functionality of its search engine, the autocomplete function. The claimants had requested that Google ceased the publication of autocomplete results that suggested “fraud” or “Scientology” as additional search terms when the claimants’ names were searched. Google will now have to stop the publication of such “predictions” if and when it has become aware that automatically created predictions infringe the rights of third parties.

The predictions of additional search terms are generated automatically by a Google algorithm, based inter alia on the search terms entered by Google users. Google has been using the function since April 2009.

Google has been taken to court across the globe on this issue, winning in Italy in March 2013, and loosing in Japan in April 2013, for example. Today’s ruling appears to be the first one from a court of last instance. And if Google were not enough to get the matter into the headlines: Germany’s former first lady, Bettina Wulff, had commenced a similar action, which had been stayed, pending the outcome in today’s case. Bettina Wulff is seeking to stop the publication of autocomplete results linking her to search words such as “escort” or ” red light”. Her case had triggered a broad debate about the legal limits on the publication of search results.

The Court of Appeals (Oberlandesgericht) Köln had found, in the previous instance, in favour of Google. It did not attribute the “statements” generated by the autocomplete function to Google (“Den […] Ergänzungssuchbegriffen ist nicht der Charakter eigenständiger inhaltlicher Aussagen der Suchmaschine bzw. deren Betreibers […] beizumessen.”)

The Federal Supreme Court did not agree. Its line of arguments is as follows: The publication of predictions as a result of the autocomplete function constitutes a violation of personality rights (Persönlichkeitsrecht), if they imply a statement that is untrue. On the other hand, not every violation of personality rights by the search engine triggers Google’s liability. The autocomplete function per se is perfectly legal. The issue is the missing safeguard against the publication of results of a defamatory nature (“… dass sie keine hinreichenden Vorkehrungen getroffen hat, dass die von der Software generierten Suchvorschläge Rechte Dritter verletzen.”)

The Federal Supreme Court also does not find that there is a general duty to scrutinize the search results for potential infringements of third party rights prio to publication (“Der Betreiber einer Suchmaschine ist regelmäßig nicht verpflichtet, die […] Suchergänzungsvorschläge vorab auf etwaige Rechtsverletzungen zu überprüfen.”)

This duty is only triggered if and when Google becomes aware of a violation of third party rights. In practice, Google will now have to investigate the defamatory or slanderous nature of suggested search terms if a cease and desist letter comes in, and will then have to take appropriate action.

Technically, the claimants’ right to request Google to cease and desist is based on Sec. 823, 1004 German Civil Code (BGB) and Art. 1, 2, Basic Law (Grundgesetz), that is, on a combination of civil law tort concepts, and the fundamental rights of human dignity and personal freedom. The Federal Supreme Court does weight the respective rights of claimants on the one hand and Google’s rights, which also enjoy constitutional protection, and on balance, finds in favour of the claimants. I refrain from a personal comment on the matter, since my firm acts for one of the parties involved.. Google Found Liable For Autocomplete Suggestions In Italy

from the oh-come-on dept

Here’s yet another ridiculously bad ruling for search engines in Italy. Glyn Moody points us to the news of a blog post by a lawyer involved in the case (against Google) who is happy that his side prevailed and that Google is liable for search autocomplete suggestions. The case involved someone who was upset that doing a Google search on his name popped up “con man” (“truffatore”) and “fraud” (“truffa”) as autocomplete Google search suggestions. We’ve seen similar cases elsewhere, and France has (most of the time) also ruled against Google.

Of course, this is ridiculous for a variety of reasons. Google is not “creating” this content. It’s accurately suggesting results based on what users are searching. Clearly, people are searching on this particular individual along with the two terms. That’s not Google’s fault. Yet Google is liable for it?

One interesting footnote: a part of the reason why the court ruled the way it did was because the court noted that Google already edited autocomplete suggestions for issues related to copyright infringement. Funny. That’s exactly the issue we warned about when Google made the silly decision (following pressure from the US government) to start blocking certain keywords from autocomplete. The court seems to see this as proof that Google can and should be responsible for the content in that autocomplete box… Once again, it looks like the company would have been better off not meddling.

Filed Under: autocomplete, defamation, italy, liability, search

Companies: google. The South Australian Supreme Court has found that Google published defamatory statements that appeared in autocomplete and related search terms on its search engine, after it received notice of the defamatory material and failed it remove it.

His Honour Justice Blue reasoned that the defamatory phrase was 'generated by Google programs as a result of Google's programming' and that 'the mere fact that the words are programmed to be generated because the user or others have previously searched for those words makes no difference' to the question of publication. His Honour decided that there was no reason why Google should not be held accountable for these 'publications' after it was put on notice by the plaintiff. It is worth noting that the plaintiff did not seek to argue that Google should be liable for the period prior to notification.

In his judgment, his Honour referred to the 'only authority' on this point as supporting this conclusion, being the decision of the High Court of Hong Kong in Dr Yeung Sau Shing Albert v Google Inc. In that case, the High Court dismissed an application by Google to have the proceeding stayed or dismissed on the basis that, among other things, the plaintiff had 'a good arguable case' that Google was the publisher of defamatory statements that appeared in Google Autocomplete and Related Search results.

His Honour Justice Blue also followed the reasoning of the Victorian Supreme Court in Trkulja v Google Inc LLC (No 5) and held that Google was the publisher of defamatory search results (comprising of the title, snippet and URL) after it received notification and failed to remove the defamatory results within a reasonable time.

A further hearing is scheduled to decide the remaining issues of the defences of triviality and time limitation, the application for an extension of time, causation and quantum of damages.

You can read the judgment in full here.. Such a ruling would mean that Google would not be liable if information displayed via its 'autocomplete' function was defamatory, said media law specialist Ian Birdsey of Pinsent Masons, the law firm behind Out-Law.com.

Autocomplete suggests words or characters for completing a partial search on Google.

Last week a court in Australia ruled that Google should have to pay damages to Milorad Trkulja, a TV presenter who had complained that the internet giant had defamed him, according to a report by the BBC.

Trkulja was shot in a Melbourne restaurant in 2004 by a gunman wearing a balaclava. He claimed that, following the shooting and subsequent reporting of the incident, his name had become associated with the images of alleged criminals when users typed his name into the 'Google Images' search function.

Trkulja sued Google claiming that the company had failed to remove the defamatory link between him and the alleged criminals when he requested such action. The Supreme Court of Victoria accepted Google's argument that it had innocently disseminated the material but said that that defence was only applicable up to the point at which the company received Trkulja's complaint and held Google to be liable for defaming the man as a result of its inaction, according to the BBC's report.

This Australian case follows a similar ruling in Japan after a court there ordered Google to stop its search engine technology from suggesting "specific terms" that have linked a man's name to crimes he did not commit.

The unnamed man sued Google after claiming that the terms the company's autocomplete software suggests in association with his name caused him to lose his job and has subsequently put off potential new employers, according to a report at the time by Kyodo news agency on the Japan Times website.

In a similar ruling in France Google was fined $65,000 by a court after its search engine suggested the French word for 'crook' when users typed-in the name of an insurance company.

However, in the UK in 2009 the High Court ruled that Google is not the publisher of defamatory words that appear in its search results. Mr Justice Eady ruled that even when notified that its results contained libellous words Google was not liable as a publisher.

Google's liability for defamatory words that appear via its 'autocomplete' suggestions is as yet untested in the UK. However, Ian Birdsey said that it is unlikely that a UK court would come to a different conclusion from the one arrived at by the High Court in 2009.

"Although the issue of whether Google’s liability for its ‘autocomplete’ search function has yet to be dealt with by UK courts, the High Court in 2009 did determine that Google was a mere facilitator of the information displayed on its search results because it did not authorised the appearance of the information on users’ screens in a ‘meaningful sense’,” Birdsey said. “If the UK courts were to assess whether Google was liable for defamation as a result of the way its ‘autocomplete’ system suggests terms to users I think the courts would draw similar conclusions and find that Google is not a publisher."

"There has to be recognition that Google search terms are the product of input by its users. It is unfair to view Google as a traditional publisher of suggested search terms as a result of this," he added.

“In his judgement Mr Justice Eady said that there was a ‘degree of international recognition that the operators of search engines should put in place [a take-down policy] (which could obviously either be on a voluntary basis or put upon a statutory footing) to take account of legitimate complaints about legally objectionable material’,” Birdsey said. "The European Commission is currently looking to reform 'notice and takedown' rules that govern illegal material posted on the internet and has asked whether search engines, among other intermediaries, should be deemed to be ‘hosts’ of content. It is to be hoped that the Commission’s plans make clear whether search engines do have responsibility for removing illegal content and what that process should be."

To be considered libellous under common law in the UK comments must be published, communicated to someone other than the person being defamed and not be justified by a range of defences, including that the comments are true or were expressed as an opinion.

In the UK laws on defamation are also written into legislation. Under the Defamation Act a person can claim a defence against allegations of defamation if they can show that they were neither the author, editor or publisher of the comments, "took reasonable care in relation to its publication" and "did not know, and had no reason to believe, that what he did caused or contributed to the publication of a defamatory statement". The Act defines 'publisher' as meaning "a commercial publisher, that is, a person whose business is issuing material to the public, or a section of the public, who issues material containing the statement in the course of that business".

Under the E-Commerce Regulations it is possible for "secondary publishers" to be found responsible for defamatory comments posted using their service. However, they can avoid liability for defamation under the terms of the Regulations if they are viewed as acting only as a mere conduit or caches or hosts of the material.

In order to avoid any liability for unlawful material, the service provider must, upon gaining 'actual knowledge' that the initial source has been removed or access to it has been disabled, act 'expeditiously' to ensure that the information is deleted or access to it disabled.. In May 2013, the German Federal Court of Justice stated that Google's predictions within the autocomplete function of its web search engine can violate the right of personality.[1] The right of personality ensures that a person's (or even a company's[2]) personality (reputation) is respected and can be freely developed.[3] Only the individual shall, in principle, decide how he/she wants to present himself/herself to third parties and the public.[4]

[5] Facts of the case [ edit ]

A stock corporation, which sold food supplements and cosmetics online, and its chairman filed an action for an injunction and financial compensation against Google based on a violation of their right of personality.[6] Google runs a web search engine under the domain "www.google.de" (among others), which allows Internet users to search for information online and access third party content through a list of search results.

In 2009, Google implemented a so-called "autocomplete" function which shows word combinations as predictions for the search of the user in a new window while typing in a search term into the search mask. These predictions are based on an algorithm which evaluates the number of searches on specific terms of other users. If users typed the full name of the chairman into the search engine in May 2010 the autocomplete function showed the predictions "Betrug" (fraud) or "Scientology". The claimants stated that the chairman would have no connection to Scientology and that he was under no investigation for fraud. Furthermore, they argued that no search result would show a connection between the chairman and fraud or Scientology. Therefore, they saw these predictions as a violation of their right of personality.

The Regional Court Cologne decided in favour of Google and dismissed the case as unfounded.[7] The Higher Regional Court Cologne uphold this judgement.[8] The claimants filed an appeal to the German Federal Court of Justice.

[9] The decision [ edit ]

The German Federal Court of Justice set aside the judgement of the Higher Regional Court Cologne and referred the case back to this court.[10]

The Federal Court of Justice held that

the predictions ("Betrug"/"Scientology") expressed the existence of a factual connection between the chairman and these negatively connoted terms and violated the right of personality [11] (the Higher Regional Court Cologne had taken a different view previously and had held that the predictions only expressed that other users typed in these word combinations for their search or that the terms could be found in linked third party content)

(the Higher Regional Court Cologne had taken a different view previously and had held that the predictions only expressed that other users typed in these word combinations for their search or that the terms could be found in linked third party content) the claimant's right of personality outweighed Google's freedom of expression [12] and commercial freedom [13] in a trade-off because false expressions do not need to be accepted

and commercial freedom in a trade-off because false expressions do not need to be accepted the violation was directly assignable to Google because they designed the software, exploited the user's behaviour, and suggested the predictions to the users

the national implementation [14] of the provisions of the Electronic Commerce Directive, [15] which grant intermediaries (access, caching, and host provider) immunity from liability to a certain extent, [16] were not applicable in this case because the predictions were not third party content that Google only made accessible or presented, but Google's own content

of the provisions of the Electronic Commerce Directive, which grant intermediaries (access, caching, and host provider) immunity from liability to a certain extent, were not applicable in this case because the predictions were not third party content that Google only made accessible or presented, but Google's own content the basis for a liability of the search engine provider is not the fact that he developed and used the software because these actions are protected by the provider's commercial freedom [17]

the liability can only be based on the fact that the provider did not take the necessary precautions to prevent the violation of a right of personality as part of a so-called "Stoererhaftung" (the "Stoererhaftung" (interferer's liability) is a liability of a person (the "Stoerer") who is not a perpetrator or participant himself, but contributed willingly and adequately causally to the infringement of a protected legal interest in any way and requires a breach of a reasonable duty of care [18] )

) the search engine provider has, in principle, no obligation to monitor the predictions generated by a software beforehand and is only responsible if he becomes aware of the violation by the predictions

if the provider is notified of a violation by the victim he is also required to prevent future violations.[19]

In April 2014, the Higher Regional Court Cologne then decided in favour of the claimants insofar as they objected to the additional term "Scientology" which Google initially refused to remove.[20] A financial compensation was not awarded because Google removed the entry later (about one and a half after the objection) and therefore limited the infringement.[21] Due to the fact that Google removed the additional term "Betrug" (fraud) immediately after the claimant's first objection, this part of the claim was unfounded.[22]

Criticism [ edit ]

Some legal scholars argued that the judgement established a reasonable balance between the protection of the right of personality (by Google's obligation to remove and prevent infringing predictions after a notice), Google's interest to still provide the autocomplete function (without the need to monitor all predictions) and the Internet user's interest to make use of the search's improvement.[23]

The court's decision that the search engine provider has no obligation to monitor the predictions generated by a software beforehand and is only responsible if he becomes aware of the violation by the predictions corresponds with previous judgements[24] of the court on the "Stoererhaftung" (interferer's liability) of a host provider for content that third parties posted on the host provider's website.[25] However, due to the fact that these previous judgements discussed the liability for third party content, others stated that the fact that the court's autocomplete judgement is based on Google being an interferer ("Störer") within the "Stoererhaftung" (interferer's liability) – and not a perpetrator – contradicts the court's statement that the predictions have to be seen as Google's own content.[26]

Moreover, the judgement raises the question which result a trade-off between Google's freedom of expression and commercial freedom and another person's right of personality would have in other scenarios.[27] Depending on the specific circumstances, it could be more complicated to assess if a prediction is false or (even) true, but not worthier of protection than the right of personality (e.g. in a case in which an investigation for a crime – like fraud – already started or in which a person is actually the victim of a crime).[28]

Another interesting issue is the question to what extent Google is capable of legally evaluating and processing notifications by alleged victims of an infringement.[29] The current legal situation could be an incentive for Google to just remove the prediction after a complaint in order to avoid any liability.[30]

Background information [ edit ]

This judgement was not the only time a possible defamation by Google's autocomplete function was discussed in a courtroom. In Germany, Bettina Wulff, the wife of the former President of the Federal Republic of Germany Christian Wulff, filed for an action for an injunction regarding 43 predictions against Google at the Regional Court Hamburg based on a violation of her right of personality.[31] The word combinations included the words "Escort" (escort) and "Prostituierte" (prostitute).[32] However, in January 2015, Google deleted these predictions and the parties settled the lawsuit.[33] By taking legal actions against Google, Bettina Wulff probably also caused a so-called "Streisand effect" because many people learned about the predictions by the created media attention for the first time.[34]

In France, in 2010, the Superior Court of Paris ordered Google to cease suggesting certain predictions, including "rapist", "satanist", "rape", and "prison", to Internet users who search for a man's name.[35] The man, convicted for a "corruption of a minor" at the time, was still appealing his conviction.[36] In Italy, a businessman filed a defamation suit because of the terms "truffatore" (conman) and "truffa" (fraud) that were added to his name by the autocomplete function.[37] The Milan court ordered Google to remove these predictions in 2011.[38] Furthermore, in 2012, the Supreme Court of Victoria in Melbourne, Australia held Google liable for defamation by wrongly linking a private person to crimes he in fact was a victim of and awarded $200,000 in damages.[39][40] Moreover, in 2013, the Tokyo District Court in Japan also ordered Google to modify its predictions and pay 300,000 yen ($3,100) as damages to a man which was linked to crimes he did not commit.[41]

However, Google's autocomplete function was not only subject of defamation suits. In another case, French human rights organisations (including SOS Racisme) sued Google for adding the word "juif" (Jewish) to the names of celebrities within its predictions.[42] The human rights organisations argued that Google provided "ethnic files" by suggesting these predictions, which is forbidden in France.[43] The parties settled in 2012 without revealing the details of the settlement.[44]

Today, Google provides an online form that allows Internet users to report an (allegedly) infringing prediction within the autocomplete function.[45]

Relevance [ edit ]

The relevance of this judgement goes beyond the mere autocomplete function because it can be seen as a precedent on the question if algorithms can make defamatory statements.[46] With artificial intelligence[47] and robots becoming more and more widespread in our society, future scenarios, in which the liability for their actions has to be discussed, seem to be likely.[48]. It has been a huge week for defamation law.

Last Thursday, the NSW Government announced a push to reform Australia’s uniform defamation laws. It is calling for a “cyber-age reboot”. That proposal was backed by a “statutory review” of the NSW Defamation Act. At a meeting of the Council of Attorneys-General, the states and territories agreed to reconvene a working party to consider reform of equivalent statutes around Australia.

The following Wednesday, the High Court delivered its most important defamation judgment in years. In a case that fits perfectly with the theme of the NSW proposals, Milorad “Michael” Trkulja succeeded in his appeal against Google. The Court found that Trkulja could sue the American company for defamation in respect of search results which potentially indicated that he had ties to Melbourne’s criminal underworld.

The next morning, the Victoria Court of Appeal allowed Bauer Media’s appeal from the judgment that awarded Rebel Wilson A$4.5 million in damages. The Court held that Wilson was entitled to A$600,000, and not to millions extra for lost opportunity to earn from roles that she may have been offered had the defendant not defamed her in its gossip magazines. The previous assessment of damages depended on the spread of the defamatory allegations on the internet via the “grapevine effect”.

The record for Australia’s largest defamation judgment is now barrister Lloyd Rayney’s A$2.6 million defamation win against the State of Western Australia, litigated by Perth firm Bennett + Co. If Rayney’s current appeal is successful, that figure may increase even further.

There’s a lot to think about.

The NSW proposal to allow large corporations to sue for defamation is particularly worrying. It would have a significant chilling effect on journalism.

But the issue that the NSW government chose to highlight from its statutory review was that defamation law is ill-equipped for the digital era. I agree that the way we communicate has completely changed in the 13 years since our Uniform Defamation Acts were introduced.

Read more: Defamation in the digital age has morphed into litigation between private individuals

Trkulja v Google shows it is time for reform

Trkulja was shot in the back in a Melbourne restaurant in 2004. As you’d expect, people wrote about it on the internet. Google provided access to that content through its search engine: web crawlers discovered web pages relevant to Trkulja, indexed them, and ranked them via its Google Search algorithms.

The result of those processes was that Trkulja was associated with some shady figures through Google search. A Google image search for his name would display Trkulja’s picture with those of Melbourne criminals. The results pages contained keywords like “melbourne criminals” and “melbourne underworld photos”.

Google’s autocomplete results would also cast him in a poor light, returning terms like “michael trkulja criminal” or “michael trkulja underworld”. The results page linked to content which described Trkulja as a “former hitman”.

Trkulja sued, claiming that this computer-generated material defamed him. Google argued that the claim was so weak that it should come to an end even before a trial. Victoria’s Supreme Court rejected Google’s argument.

Read more: Craig McLachlan, defamation and getting the balance right when sexual harassment goes to court

But the Victorian Court of Appeal allowed Google’s appeal, agreeing that the claim had no prospect of success. It found that the ordinary, reasonable person would not understand that the search results conveyed “imputations” which damaged Trkulja’s reputation. In their view, ordinary people would understand that there may be a disconnect between the words you type into Google and the results that follow.

On further appeal, the High Court unanimously decided that the Court of Appeal was wrong. At least some of the search results complained of had the capacity to convey the idea that Trkulja was associated with dodgy characters. Trkulja was given “the green light to sue” Google. Trkulja’s claim can now proceed.

Even before this case, you could sue Google for defamation

Like other foreign companies, Google is not immune to litigation because it is based overseas. On old principles, Google can be responsible for third party content which it “published” by sharing. It might have a defence of “innocent dissemination”, but perhaps not if the defamed person drew the problem to the company’s attention.

People have won against Google before. A few years ago, Janice Duffy succeeded in her claim that Google should be responsible for linking to defamatory websites. So in a sense, yesterday’s judgment is nothing really new.

It does provide some clarity on whether something like search results has the “capacity” to convey defamatory meaning. It is likely that Google will continue to be sued by all sorts of people who are aggrieved by search results that cast them in a poor light.

The case also demonstrates that our old laws are perhaps ill-suited to the digital era.

We should stop shooting the messenger

Reflecting on this case, it is worth considering whether we should cut internet intermediaries some slack when it comes to defamation law.

We could do so by giving effect to the “safe harbour” proposal flagged in the NSW statutory review. It would provide internet intermediaries with a shield from liability for third parties content. Telcos already enjoy something like this in Australia, which protects them from liability for copyright infringement.

Faced with cases like Trkulja, you would understand if Google simply acceded to every request to remove content from its search results. But what if Google did that for complaints by paedophiles, murderers or dictators?

Read more: Before you write that scathing online review, beware of defamation

Google provides a free public service which is indispensable to our way of life. Without Google’s assistance, many of us would be lost online. When access to the functionality of Google and other intermediaries is limited, our substantive access to information is limited.

Extending safe harbour to internet platforms is worth seriously considering – other countries, like the United States, are already doing this.

The NSW statutory review does not go into these difficult issues in enough depth. In light of the rapid developments in media and technology, the best way forward is for the Australian Law Reform Commission to consider this in detail. We need to make sure that we get the right balance between freedom of speech, free access to information, and protection of reputation.. ARTICLE

To print this article, all you need is to be registered or login on Mondaq.com.

Another day, another defamation case about Google search engine results. This time, it's the High Court which gave Google the thumbs down in the Michael Trkulja v Google saga. This decision isn't the end of the story though.

It started in 2009 when Google searches for "Michael Trkulja" started returning images of him and known criminals in the same results along with headings like "Melbourne Crime". Google tried to argue innocent dissemination, but Trkulja was successful in his defamation claim. Google didn't appeal.

The problematic search results continued though, with Google's autocomplete function now offering words like "criminal" and "underworld" after Trkulja's name and searches for "Melbourne criminal underworld" returning images of him. Google agreed to block the autocomplete predictions but wouldn't remove the images. Trkulja commenced a new defamation claim.

This time Google tried to have the case thrown out early, arguing (among other things) that it wasn't a "publisher" and that the search results weren't defamatory anyway. The trial court rejected all that and took Trkulja's earlier success into account, finding his case was arguable and should be allowed to continue.

Google appealed. The appeal court flipped and said Google's search results weren't capable of being defamatory, meaning Trkulja's case was bound to fail.

Trkulja took that to the High Court, which said the appeal court got it wrong. The High Court had some other stuff to say too.

Google was mistaken to argue that reasonable internet users were aware of the unpredictable results often generated in image searches. Ordinary Google users would likely contemplate that the results had at least some connection to the search terms they entered.

It didn't matter that some of the other images returned by the search were also of non-criminals (like Marlon Brando, a police commissioner and a tram). Trkulja wasn't well known and could still be mistaken for a criminal, whereas the other non-criminals were obvious (especially the tram).

The High Court agreed with the trial judge that it was strongly arguable that Google was a "publisher" and, where Google hadn't even filed a defence, it was premature of the appeal court to take the view that innocent dissemination would succeed.

What's next? It's back to the trial court again for Trkulja and Google to continue preparing the case for final hearing. The saga continues.

We do not disclaim anything about this article. We're quite proud of it really.. REUTERS/Stringer

BEIJING (Reuters) - A Hong Kong court has ruled that a local tycoon can sue Google Inc for defamation because searches for his name on Google suggest adding the word 'triad', Hong Kong's notorious organized crime groups.

Advertisement

Searches in both English and Chinese for Albert Yeung Sau-shing, the founder and chairman of Hong Kong-based conglomerate Emperor Group, will automatically suggest phrases related to organized crime using Google's 'autocomplete' function.

On Tuesday, the High Court of Hong Kong dismissed Google's argument that it was not responsible for the autocomplete suggestions related to Yeung and that the court did not have personal jurisdiction over the U.S. search giant.

Google frequently finds itself embroiled in legal issues over what results are shown by its search engine. The European Union's top court in May ruled that people have a right to request that years-old personal information that is no longer relevant be removed from Internet search results.

"There is a good arguable case that Google Inc is the publisher of the Words and liable for their publication," said Marlene Ng, the deputy high court judge, in her ruling.

Advertisement

Google declined to comment on the verdict.

Related stories

Yeung is seeking damages from Google for libel and wants the company to remove the defamatory search suggestions, court documents said.

Google argued that autocomplete works according to an automated algorithm and the company is not responsible for the resulting suggestions, which change depending on what a critical mass of users search for.

"The entire basis of the internet will be compromised if search engines are required to audit what can be assessed by users using their search tools," court documents attributed Gerard McCoy, Google's lawyer, as saying.

Advertisement

"It would be impossible for Google Inc to manually interfere with or monitor the search processes given the billions of searches conducted by Google Search," McCoy said according to the documents.

Because Google did not protest that the autocomplete suggestions were defamatory and they have criminal associations, Google may end up paying a large amount of money if Yeung sues successfully.

"In my view, it cannot be said at this stage that damages for reputational damage in Hong Kong are likely to be minimal if Yeung wins at trial," Ng said.

(Reporting by Paul Carsten; Additional reporting by Venus Wu in HONG KONG; Editing by Simon Cameron-Moore). A Milan judge has found Google Italy guilty of defamation because of the way its search engine linked the name of an Italian businessman to the word "fraud" and has ordered the company to modify the operation of its Autocomplete service.

The ruling by Judge Roberto Bichi was published March 24 and rejects a Google appeal against an earlier Milan court ruling that upheld the complaint of a businessman, identified in press reports Tuesday only as "AB." Bichi also ordered the company to pay a total of €3,800 ($5,550) in costs and damages.

AB, an entrepreneur in the financial services sector who uses the Internet to promote his business, complained that Google's Suggest search/Autocomplete function linked his name to the words "fraud" and "fraudster" (truffa and truffatore).

The connection was particularly unfortunate since he was a trader and clients might naturally search for his name in connection with the word "trading." AB complained that the word "fraud" came up as a suggestion after his name even without the user beginning to type a further term and that Google failed to take corrective action when the problem was drawn to its attention by his lawyer.

Bichi and a panel of two other judges ruled that the association of the plaintiff's name with the word "fraud" was liable to lead users "to doubt the moral integrity of the individual" and "to suspect him of illicit conduct."

The fact that the links did not actually lead to defamatory information about AB was not a valid excuse for Google's conduct, the judges said. Many users would not bother to click on the links and would come away with a negative impression of AB, while there was no evidence to support Google's contention that Internet users were capable of discriminating intelligently about the information they found online, the judges said.

In its appeal against the earlier ruling, Google argued that it provided a neutral hosting service and that the selection of information was carried out automatically by its proprietary software, with no active human intervention.

The company also argued that if it intervened to prevent its users from having access to information posted by third parties it could open itself to complaints and requests for compensation.

Writing in his blog, Carlo Piana, the lead counsel for AB, said there was no question of the court ruling opening the door to censorship. His client had discussed the case with Google before going to court, and was seeking the elimination of only two search terms, Piana wrote.

There was no question of the ruling creating a precedent, Piana said. "All cases are different."

"Google argued that it could not be held liable because it is a hosting provider, but we showed that this is content produced by them, although through automated means. Therefore in this case the search engine cannot avail itself of the safe harbor provision of the [European Union's] e-commerce directive," Piana wrote.

Technology expert Guido Scorza took a contrary view, arguing in his blog that there was nothing defamatory about Google's conduct.

The search engine had simply registered the fact that a number of users had combined AB's name with the words "fraud" and "fraudster," Scorza wrote. "The suggestions merely recounted the history of other people's searches and made them available to new users," he said.

The Milan ruling follows similar controversies in France, Sweden and Brazil, and comes just over a year after three Google executives were handed suspended six-month prison sentences in Milan for allowing a video showing the bullying of a handicapped boy to be posted on Google Video.

It also has elements in common with a ruling by a Rome court last month that ordered Yahoo to remove links from its search engine that led to pirated copies of an Iranian film.

Google was disappointed by the court's decision because it failed to take account of the fact that Autocomplete was based on the search behaviors of prior users, the company said in a written statement. "For the moment we are considering all our options," it said.. A MAN who claims Google has defamed him has won his High Court battle to sue the search engine giant.

The court ruled in favour of Milorad "Michael" Trkulja in a judgment on Wednesday, supporting his claim that search engine results could indicate to an ordinary person he was "somehow associated with the Melbourne criminal underworld".

Mr Trkulja, who was shot in the back in a Melbourne restaurant in 2004, successfully argued in the Victorian Supreme Court in 2012 that Google defamed him by publishing photos of him linked to hardened criminals of Melbourne's underworld.

Camera Icon Milorad Trkuja Credit: AAP

TheNightly Get in front of tomorrow's news for FREE Journalism for the curious Australian across politics, business, culture and opinion. READ NOW

Four years later the Victorian Court of Appeal overturned the decision, finding the case had no prospect of successfully proving defamation.

Google searches for "Melbourne criminal underworld photos" bring up images of Mr Trkulja alongside gangland figures Mick Gatto, Carl Williams, Chopper Reid, Mario Condello and Mark and Jason Moran, his lawyer Guy Reynolds told the High Court in March.

However, Google's lawyers argued it would be "irrational" for someone to assume photos in a Google image search for underworld figures are all of criminals, because the same search would also bring up the Google logo, movie posters, images of crime victims and photos of actor Marlon Brando.

Mr Trkulja also claimed defamation around Google's "autocomplete" options for his name, which have included phrases like "is a former hit man", "criminal" and underworld".

However the court heard autocomplete is an automatic function and that previous searches influence future suggestions.

In its decision, the High Court of Australia ruled the Google search results were capable of defaming Mr Trkulja.

“It would be open to a jury to conclude that an ordinary reasonable person using the Google search engine would infer that the persons pictured whose identities are unknown are persons, like the notorious criminals with whom they are pictured, in some fashion opprobriously connected with criminality and the Melbourne criminal underworld,” the judgment said. “So to conclude, as the Court of Appeal observed, might result in the list of persons potentially defamed being large and diverse. But contrary to the Court of Appeal's apparent reasoning, that does not mean that the conclusion is unsound. It means no more than that, in such cases, the liability of a search engine proprietor, like Google, may well turn more on whether the search engine proprietor is able to bring itself within the defence of innocent dissemination than on whether the content of what has been published has the capacity to defame.”

Google was also order to pay the costs of the appeal.

More to come.. . Entertainment promoter Milorad Trkulja claims Google has continued to disseminate content unfairly linking him to the Melbourne criminal underworld

A court cleared the way for a rare defamation action against Google on Wednesday after a man claimed the global internet giant published material linking him to Australia's criminal underworld.

Entertainment promoter Milorad Trkulja was shot in the back at a Melbourne restaurant in a 2004 crime that was never solved.

In 2012, Google was ordered to pay Aus$200,000 (US$150,000) in damages to Trkulja, who claimed he was defamed by material that implied he was a major crime figure and had been the target of a professional hit.

Trkulja then launched further proceedings against the online behemoth relating to images and text that he said continued to link him to underworld figures, according to the Australian Broadcasting Corporation.

A Victorian state court ruled in favour of Google, but Australia's High Court has now upheld an appeal by Trkulja, paving the way for his defamation action.

At least some search results for Trkulja "had the capacity to convey... that the appellant was somehow associated with the Melbourne criminal underworld", the court said.

Google has denied the claims, saying it had innocently disseminated material published by others.

In the 2012 decision, a jury ruled Google had failed to act when Trkulja's lawyers wrote to them demanding action over the "grossly defamatory" content.

The judge at the time likened the internet giant to a library or newsagent which has at times been considered a publisher in defamation cases.

Trkulja argued his reputation was critical to his work as a promoter and had been seriously damaged by the defamatory material.

There has been legal debate in Australia about whether search engines like Google can be considered "publishers" under Australian defamation law, even if they did not create the content.

Previous court rulings have given conflicting views.

© 2018 AFP. Is Google liable for defamation for not removing defamatory information in search results? Is Google liable for defamation as a secondary publisher by including hyperlinks to a website that contains defamatory materials when the hyperlink is included in search results? Finally, is Google liable for defamation when its Autocomplete and Related Search features produce suggested search inquires that are defamatory? According to the recent decision of an Australian Court in Duffy v Google Inc., [2015] SASC 170 (27 October 2015), yes to all, at least once Google has received notice of these activities and fails to stop them within a reasonable period of time.

The case contains a treasure trove of Commonwealth law summarizing decisions on the liability of Internet intermediaries and service providers for defamation committed or facilitated by their online activities. Sadly, the decision, and the cases against Google relied on in the decision, illustrate the plight of individuals who sought and were denied the help asked for from Google to stop publishing information that damaged their reputations. Invariably, after being forced to litigate against one of the world’s wealthiest companies, their claims were vindicated by the courts which made findings that Google has a corporate responsibility to act, at least once it is put on notice that its search results are alleged to be defamatory. See, for example, Trkulja v Google Inc LLC (No 5) [2012] VSC 533 (summarized here), Tamiz v Google Inc [2013] EWCA Civ 68 (summarized here), Dr Yeung Sau Shing Albert v Google Inc [2014] HKCFI 1404, A v Google New Zealand Ltd [2012] NZHC 2352, Rana v Google Australia Pty Ltd [2013] FCA 60, Bleyer v Google Inc LLC [2014] NSWSC 897.

The Duffy v Google case arose from six articles that were published on the Ripoff Report website about the plaintiff, Dr. Duffy, and later published on other sites ostensibly derived from the Ripoff Report articles. The plaintiff notified Google and asked that the offending text and hyperlinks be removed from its search indexes. After many attempts to get Google to change its search results it removed the material relating to the six Ripoff Report webpages but not the other webpages. The plaintiff also notified Google that searches for her name on its websites resulted in the display by it’s Autocomplete utility of defamatory alternative search term “Janice Duffy Psychic Stalker” and requested its removal. Google did not comply.

The first issue in the case was whether the paragraphs (title, snippet and URL) displayed by the Google websites to users in response to searches for Dr Duffy’s name were published by Google. An example of a search alleged to be defamatory is the following:

R1 Ripoff Report Janice Duffy – Psychic Stalker Psychics Beware Of… Dr Janice Duffy is truly an embarrassment to her profession as a Senior Researcher in Adelaide Australia #2 Consumer Comment. Respond to this report… www.ripoffreport.com/…Janice-Duffy…/janice-duffy-psychic-stalker-98d93.htm Cached

Google argued it could not be liable for defamatory information published in search results as the information was produced without human intervention through the use of its computer systems and processes. It contended that for it to be liable it would have to authorize or accept responsibility for the publication. The court rejected this defense finding that Google played a critical role in publishing the defamatory content, once it became aware of what its systems were disseminating. Google could not be likened to a passive telecommunications carrier given the active role its systems played in generating and transmitting the offending information to the public.

I reject Google’s contention that a defendant can only ever be a publisher if the defendant authorises or accepts responsibility for the publication… Google was the sole operator and controller of the Google website. The paragraphs resided on Google’s website. The paragraphs were communicated by Google to the user conducting a search. Google played a critical role in communicating the paragraphs to the user. The physical element of publication is present. Google did not play the passive role of a mere conduit such as an internet service provider who merely provides access to the internet or a telecommunications carrier who merely provides access to the telephone network. Google played an active role in generating the paragraphs and communicating them to the user. The mere fact that the words are programmed to be generated because they appear on third party webpages makes no difference to the physical element. It makes no difference to the physical element whether a person directly composes the words in question or programs a machine which does so as a result of the program. I agree with the analysis of Beach J in Trkulja v Google Inc LLC (No 5)[140] in this respect… The mere fact that the paragraphs were generated automatically by Google’s software programs does not prevent Google being a publisher of them after notification by Dr Duffy. If Google personnel were made aware of the existence of the paragraphs generated by Google’s own software programs and failed to remove them, their continuing existence thereafter was the direct result of human action or inaction rather than merely the result of machine operation. Approaching the question from first principles, Google was a secondary publisher of the paragraphs after notification and lapse of a reasonable time to allow for their removal (if that occurred). There is no case in which it has been held that a search engine operator does not publish such paragraphs after the operator has been notified of them and failed to remove them within a reasonable time. In Metropolitan International Schools Ltd (trading as SkillsTrain and/or Train2Game) v Designtechnica Corp (trading as Digital Trends) and others,[143] Eady J held that Google was not a publisher of such paragraphs before notification or while taking reasonable steps to remove them after notification. Eady J did not go so far as to hold that Google could not be a publisher if it refused to remove them after notification. McCallum J in Bleyer v Google Inc LLC[144] and Fenlon J in [the British Columbia case] Niemela v Malamas[145] each held that Google was not a publisher of such paragraphs before notification but explicitly said that the same conclusion did not necessarily apply after notification. The reasoning of Fenlon J strongly suggests that her Honour would have concluded that Google was a publisher of such paragraphs after notification. In particular, Fenlon J considered that the only real difference between the innocent dissemination test and the passive instrument test involves the burden of proof. I conclude that Google was a publisher of the paragraphs relating to Dr Duffy if and to the extent that Google failed to remove them after a reasonable time elapsed after effective notification by Dr Duffy.

The second issue in the case was whether the content of the external webpages was republished by Google when users clicked on hyperlinks displayed by the Google website when conducting searches for Dr Duffy’s name. An example is the search result below which contains the hyperlink to allegedly defamatory material.

R1 Ripoff Report Janice Duffy – Psychic Stalker Psychics Beware Of… Dr Janice Duffy is truly an embarrassment to her profession as a Senior Researcher in Adelaide Australia #2 Consumer Comment. Respond to this report… http://www.ripoffreport.com/…Janice-Duffy…/janice-duffy-psychic-stalker-98d93.htm Cached

The Court held that publishing a hyperlink to defamatory material along with search results information made Google a secondary publisher of the information. In reaching its conclusion, the court relied on, among others, the important decision of the Supreme Court of Canada in the Crookes case. According to the court:

In the case of the URL contained in the paragraph extracted at [214] above, it is necessary to have regard to the text of the title and the snippet in conjunction with the fact that the title functions also as a hyperlink. The text and the hyperlink comprise an integrated whole. The text says that Dr Duffy is a stalker of psychics of whom psychics should beware and offers by clicking on the title on the Google webpage to deliver to the user the Ripoff Report webpage that provides more detail. The user does not need to enter the URL into the user’s web browser; the Google website is programmed automatically to cause the browser to display the Ripoff Report webpage by clicking on the hyperlink. In these circumstances, Google is a secondary publisher of the Ripoff Report webpage if and to the extent that Google failed to remove the paragraph incorporating the hyperlink after a reasonable time elapsed after effective notification by Dr Duffy. This conclusion is supported by the judgment of Beach J in Trkulja v Google Inc LLC (No 5),[152] in which his Honour held that it was open to the jury to conclude that Google was a publisher of the snippets and hyperlink alike, treating the two as an integrated whole. In Crookes v Wikimedia Foundation Inc,[153] the Supreme Court of Canada considered that it was critical to take into account the text comprising or surrounding a hyperlink to determine whether the operator of the website upon which the hyperlink resided was a publisher of the material contained on the external webpage to which the hyperlink led. The Court held that merely creating a hyperlink without more did not amount to publication of the material on the external webpage. The Court held that the position might be different if some text from the external webpage were reproduced. Abella J (with whom Binnie, LeBel, Charron, Rothstein and Cromwell JJ agreed) gave as an example: This might be found to occur, for example, where a person places a reference in a text that repeats defamatory content from a secondary source.[154]

Another issue in the case was whether the generation by Google’s Autocomplete and Related Search features at the Google websites of the words “janice duffy psychic stalker” when a user entered the search term “Janice Duffy” was a publication by Google after notification and failure by Google to remove it within a reasonable time thereafter.

The court found Google liable for not ceasing to publish the defamatory search suggestions to users. It did so relying, in part, on a prior Hong Kong case, Dr Yeung Sau Shing Albert v Google Inc.[158], where Deputy Judge Marlene Ng held that there was a good arguable case that an operator whose search engine generates objectively defamatory materials by its automated processes is a “publisher” and that Google was more than a passive facilitator vis-à-vis its Autocomplete and Related Search utilities.. A Japanese court has ordered Google to modify its autocomplete function so that it does not suggest a connection to crimes when a Japanese man's name is entered, adding that the Web giant must pay 300,000 yen ($3,100) to the plaintiff.

The ruling by the Tokyo District Court comes after its injunction last year backing the plaintiff, a Tokyo man who has not been identified. Google did not follow the injunction.

The man claimed that when Google users begin typing his name, the search engine would automatically suggest criminal acts he did not commit. The links would produce articles slandering him, he said.

The plaintiff said that along with the autocomplete function slandering him, he unexpectedly lost his job and was repeatedly rejected when he applied for other work.

"A situation has been created by which illegally submitted documents can be easily viewed," chief judge Hisaki Kobayashi was quoted as saying by the Mainichi Shimbun newspaper.

The court did not rule that the search functions were directly responsible for the loss of the plaintiff's job.

But the decision marks the first time a Japanese court has ordered Google to change these search terms, according to the plaintiff's lawyer, Hiroyuki Tomita.

"This [autocomplete feature] can lead to irretrievable damage, such as job loss or bankruptcy, just by displaying search results that constitute defamation or violation of the privacy of an individual person or small and medium-size companies," Tomita was quoted as saying last year by Kyodo News.

Google runs data centers in Hong Kong, Singapore, and Taiwan, but not in Japan, and so the court can't compel it to make the changes.

Google told CNET it had no comment on the case, but is studying the matter carefully.

The decision follows Google's loss of a case in Italy and another in France over autocomplete results.

Earlier this year, an Australian surgeon sued Google in California over autocomplete suggestions that he was bankrupt. Google, meanwhile, has indicated that it is not responsible for autocomplete results because they are generated automatically.

(Via AFP). Google searches employ two features: autocomplete and Google instant. These work together to complete your search terms and to automatically load search results while you're typing. While you're probably thankful for the few seconds this saves, or the way it triggers a connection you couldn't recall, Bettina Wulff (wife of former German President Christian Wulff) would be unlikely to agree with you these days. Type Wulff's name into Google, and the first autocomplete suggestions you'll see are "Bettina Wulff escort," and "Bettina Wulff prostituierte." Wulff is now suing Google for defamation, along with German TV host Günther Jauch and over 30 bloggers and media outlets. Wulff's suit against Google focuses on the results of this autocomplete feature.

Years ago, rumors began that Bettina Wulff had a former career as a prostitute named "Lady Victoria," possibly intended to damage Christian Wulff's political career. Wulff denies these rumors in her new biography, and asserts that they have harmed her reputation and family life. Wulff has filed a defamation suit in the Hamburg District Court to force Google to remove these false, damaging terms from the results of its autocomplete function. So far, Google has not removed the result terms; according to Spiegel Online, the company denies responsibility and claims that the products of the autocomplete function are driven by an algorithm relying on, among other things, popular search terms selected by users.

Without going into too much detail about the search algorithms, suggested autocomplete searches are all real searches done by Google users. The algorithm considers popularity foremost, but also considers geography, relevance, and your prior search history, among other objective factors, when providing these results. In this manner, then, Google's autocomplete feature and Google instant consider more than popularity, and there are times in which Google's algorithms limit search results or alter their ranking to reflect policy considerations.

Thus, if Google chose to alter the results of a search for Bettina Wulff, it would not be the first time Google has censored or altered Autocomplete results for policy reasons. For example, pressure from the entertainment industry and government officials has impacted Google's searches. In an attempt to fight piracy, Google's search function will not complete words such as "bittorrent", "torrent" and "rapidshare." Similarly, up until recently, Google had blocked the term "bisexual" from autocomplete search results, only removing "bisexual" from its banned words after a campaign by BiNet and other advocacy groups. Should false speech, particularly that injurious to its subject, be its next consideration?

Bettina Wulff is not the first individual to sue Google over false autocomplete results, and there is some precedent for finding defamation arising out of search results. Earlier this year in Japan, a man sued Google after its autocomplete results linked him to a crime he had never committed, allegedly resulting in irretrievable damage. The Japanese court ordered Google to delete the identified "false" autocomplete terms. Google was also fined last year when autocomplete suggested "crook" after the name of a French insurance company, and an Italian court ordered Google to filter out libelous search results that falsely suggested fraud. It would not be surprising, then, if a case tried in Germany, where defamation is codified in the criminal code, follows the lead of these other nations.

As in many other situations involving liability for content, this case highlights American exceptionalism in the realm of free speech. The United States takes a very speech-protective approach to libel, particularly with respect to public figures like Wulff. While the specific elements of defamation vary slightly from state to state, to establish liability for defamation in the case of public figures, the injured party must prove that the speaker acted with actual malice -- i.e., knowledge of falsity or a high degree of awareness of probable falsity.

Under this rigorous standard, it seems unlikely that this case or a similar defamation case would succeed in a U.S. court. Google, in devising its algorithm, did not knowingly intend to publish false statements of fact. At most, a court might determine that Google failed to take adequate precautions against defamatory combinations of words popping up, but "actual malice" depends on knowledge of falsehood and not objective perceptions of negligence. Moreover, even under a negligence standard it might be unreasonable to expect Google to police for truthfulness every potential autocomplete suggestion resulting from an inquiry on its search engine.

In addition, popularity is the primary factor considered in producing search results, and with regards to this element, Google is not itself speaking in a traditional manner but rather collecting and presenting the speech of others. As such, Google would likely be immune in the U.S. under Section 230 of the Communications Decency Act, which prohibits online services from being treated as the publisher of user-generated defamatory content. Although Google's autocomplete function calls particular prior searches by other users to one's attention, it apparently does not modify those searches in a way that would transform Google into a content creator.

Just to see if the issue was specific to Google, I also ran a search for Bettina Wulff on Bing, which returned the same results (though in slightly altered order) as one on Google. As Bing uses a different search algorithm, this supports Google's assertion that the results are the product of popular searches and suggests that the factors other than popularity have a minimal, if not negligent, role in determining these results. If Google, then, relies on the popularity of searches to determine its results, and these searches reflect the speech of countless individuals as measured objectively, can Google possibly be found to have acted with subjective awareness of probable falsity? While Bettina Wulff's case as tried in Germany won't provide us with that answer, it's only a matter of time before a U.S. defamation case arising out of autocomplete results raises these questions directly.

Kristin Bergman is a 2L at William & Mary Law School. After using autocomplete and Google instant, she discovered a Kristin Bergman committed to yoga and massage. This isn't her.

(Image captured from Google search run using Google Chrome on September 26, 2012.). Melbourne man Milorad “Michael” Trkulja has won his high court battle to sue the search engine Google for defamation over images and search results that link him to the Melbourne criminal underworld.

Trkulja said he would continue legal action against Google until it removed his name and photos from the internet.

Sign up to receive the top stories in Australia every day at noon

Trkulja, who was shot in the back in a Melbourne restaurant in 2004, successfully argued in the Victorian supreme court in 2012 that Google defamed him by publishing photos of him linked to hardened criminals of Melbourne’s underworld.

Four years later the Victorian court of appeal overturned the decision, finding the case had no prospect of successfully proving defamation.

The high court disputed that ruling in a judgment on Wednesday and ordered Google to pay Trkulja’s legal costs.

Trkulja said he would continue the legal action until he got the result he wanted.

“I will sue Google … and I will sue them til they stop. I want them to block my pictures,” he said. “I’m not a criminal, I’ve never been involved and I will make sure these people are not going to ruin my family – I have grandchildren.”

Google searches for “Melbourne criminal underworld photos” bring up images of Trkulja alongside gangland figures Mick Gatto, Carl Williams, Chopper Reid, Mario Condello and Mark and Jason Moran, Trkulja’s lawyer Guy Reynolds told the high court in March.

However, Google’s lawyers argued it would be “irrational” for someone to assume photos in a Google image search for underworld figures all showed criminals, because the same search would also bring up the Google logo, movie posters, images of crime victims and photos of actor Marlon Brando.

In a unanimous judgment led by the chief justice, Susan Keifel, the court said it was to be assumed someone searching for members of the Melbourne criminal underworld would “rationally suppose” the people whose pictures or names appeared, or at least some of them, were members of such.

The court found while it was clear some of those pictured, such as Brando, were not criminals, it could be concluded someone who was relatively unknown, such as Trkulja, could be connected with criminality or the underworld.

Trkulja also claimed defamation around Google’s “autocomplete” options for his name, which have included phrases like “is a former hit man”, “criminal” and “underworld”.

However, the court heard autocomplete was an automated function and that previous searches influenced future suggestions.

Comment is being sought from Google.. . . A new lawsuit alleges that Google's search engine has an anti-Semitism problem.

French anti-discrimination organization SOS Racisme, in association with the Union of Jewish Students of France, the Movement Against Racism and for Friendship Among Peoples and other organizations, is suing Google because its autocomplete feature suggests the word "Jewish" in searches involving certain public figures, including News Corporation chairman Rupert Murdoch and actor Jon Hamm, reports The Times of Israel.

Indeed, querying the search engine for "Jon Hamm," for example, yields "Jon Hamm Jewish" as one of the top results.

Advertisement

LOOK:



According to Google's website, its algorithm for the Google Instant autocomplete feature "predicts and displays search queries based on other users' search activities and the contents of web pages indexed by Google." In addition, the search engine says it strives to "reflect the diversity of content on the web (some good, some objectionable)" and so has a narrow set of removal policies for pornography, violence, hate speech, etc. -- though not narrow enough for SOS Racisme, it seems.

A lawyer for SOS Racisme, Patrick Kulgman, told Agence France Presse (AFP) that Google's autocomplete algorithms have resulted in "the creation of what is probably the biggest Jewish file in history," according to The Times of Israel. As an "ethnic file," this compilation is outlawed in the country.

Local reports pointed out by The Hollywood Reporter explain that the plaintiffs contend users of Google in France and across the world are systematically confronted with the unsolicited association of the term "Jew" with prominent names in the world of politics, media, and business. A hearing for the lawsuit is scheduled for Wednesday.

The Hollywood Reporter also writes that the last lawsuit Google saw in France due to its autocomplete feature occurred in 2009, when two French companies sued the search engine because its autocomplete feature suggested the French word for "scam" in searches for said companies' names.

Advertisement. "It could lead to irretrievable damage such as a loss of job or bankruptcy just by showing search results that constitute defamation or a violation of the privacy of an individual person or small and medium-sized companies," Mr Tomita told Japanese news agency Kyodo.