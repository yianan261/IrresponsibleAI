It has come to light that the Home Office is using a secretive algorithm, which it describes as digital “streaming tool,” to sift visa applications. So far they have refused to disclose much information about how the algorithm works, hiding behind the “Immigration Exemption” to the Freedom of Information Act.

We do know that the algorithm scans applications and directs them into a fast lane (Green), a slow lane (Yellow), or a full digital pat-down (Red). It seems clear that people’s right to come to the UK to work, study, or see loved ones, is being affected by this shadowy and unaccountable use of software by the government.

We’re concerned that this algorithm could be yet another example of the “hostile environment” policy towards immigrants which brought us “Go Home” vans and led to the Windrush scandal.

As far as we can tell, the algorithm is using problematic and biased criteria, like nationality, to choose which “stream” you get in. People from rich white countries get “Speedy Boarding” – poorer people of colour get pushed to the back of the queue.

We are seeking a judicial review to fix this misuse of digital technology. We will use the law to find out exactly what the algorithm is and what it does.

So far we have served the Home Office with a “pre-action” letter, and are awaiting their response. We have also launched a crowd-funder to raise money for the legal challenge. Click the Donate box below to pitch in. You can also read more about the case in this Guardian article.. The growth of technology has brought a great deal of efficiency and security to almost all organisations and businesses. But such progress may have taken a slightly wrong turn as the reliance on artificial intelligence by the Home Office as a streaming tool for visa applications may actually be carrying out its functions on grounds of racial bias.

Last week the Guardian reported a legal action has been filed by the Joint Council for the Welfare of Immigrants (JCWI) against the Home Office over the use of an algorithm which filters visa applications on potentially unlawful grounds such as 'nationality'. This follows a report by the Financial Times in June this year that the Home Office was 'secretly' using the algorithm to process visa applications. The Home Office has since confirmed this technology is only used to allocate applications and not decide on them. But why the mystery?

I am among many who would consider the advancement of technology as a blessing to mankind as I, quite frankly cannot imagine a world without smartphones. On the other hand some would consider the advancement of technology as a disaster. Despite this being slightly dramatic I can see why one would come to this conclusion. We are increasingly dependent on technology for almost all everyday tasks. For example, to know directions to a location we would use GPS or for cab services we would resort to the numerous apps on our phones. We no longer memorise directions because Google maps does it for us. In many ways such levels of reliance on technology can be daunting.

The Home Office’s reliance on the algorithm to stream visa applications may have been implemented to better its efficiency and to finally improve on its service standards and visa processing times (which in itself is a topic for another blog). The Home Office is said to have been relying on an algorithm which uses nationality to stream applicants in the categories green, yellow and red. Regardless of the affirmation the Home Office has given to confirm the algorithm is only used to allocate applications and not make decisions, the basis on which these applicants are streamed and their applications allocated is crucial. We cannot be caught up celebrating the technological advancement of our time and ignore an unhealthy reliance on artificial intelligence in dealing with people’s lives, and in so doing discriminating against them on grounds of their race and nationality.

The process of allocating cases (by an algorithm) and alerting human caseworkers that an application has been streamed as red, simply on the basis of the applicant’s nationality (if this is indeed the case) already tells the caseworker the application is a potential refusal before the caseworker has fully considered it. By contrast an application which has been streamed as green by an algorithm tells the caseworker this case is worthy of an approval. This means two almost identical applications, based on the same grounds, are treated and processed differently. The case labelled as red is likely to be treated with more suspicion and subjected to intense and intrusive scrutiny. However, the case which has been given the green light receives less scrutiny and is more likely to be approved.

It doesn’t take a genius to know which nationalities/races are likely to get the red light and which are likely to get the green light. Some may accept the justification for this and say the reason for making such a distinction on the basis of nationality may be due to the fact that certain applicants from a select few countries may have previously breached immigration laws and thus are considered higher risk, therefore it’s okay for everyone with these nationalities to be painted with the same brush. This is embarrassing to write let alone say out loud. Why should an applicant who genuinely wishes to visit his or her family in the UK be subjected to a harsher scrutiny and treated differently because previous applicants from his or her country of nationality have overstayed or committed a crime? An applicant should only be held to this standard if he or she has personally breached an immigration law and/or committed a crime themselves in the past. Applying a harsh standard to a completely new applicant simply because their nationality matches that of previous offenders is both unfair and prejudicial. Applicants of all nationalities have the potential to breach immigration rules.

Aside from the increased scrutiny and chance of refusal, the streamlining alone means that the processing times of applications will vary according to, for example, the applicant’s nationality. It is nearly always the case that all applicants want and need their application to be dealt with as quickly as possible. They all pay the same high Home Office fees, including often for priority processing, and yet receive different service standards based on preconceived applicant characteristics. Treating applicants who have been streamed as red (based on their nationality alone) differently to applicants who have been streamed as green based also on their nationality alone for the same application is without question discriminatory.

Nationality is a protected characteristic under the Equalities Act 2010 and a public authority such as the Home Office “must when making decisions of a strategic nature about how to exercise its functions, have due regard to the desirability of exercising them in a way that is designed to reduce the inequalities of outcome...”

As mentioned above, if visa applicants are being treated differently because of having been streamed as red by an algorithm, not only does this explain why we have such a high number of UK visa refusals for African visitors to the UK but it also indicates that the Home Office may actually be in breach of the Equalities Act. Consequently, while the use of technology should be appreciated for the remarkable improvement it has brought to our lives, it should not be programmed to encourage racial bias as this is making an already bad situation worse.

In conclusion therefore, the Home Office must be transparent in how the algorithm works and the basis on which it has been designed to stream visa applications. It will be interesting to see if JCWI’s legal action reveals the full details and basis on which the algorithm works – which could for example stream against not only nationality but also sex and age.

Here at Kingsley Napley, we provide all types of immigration advice and assist with various visa applications including those previously refused. If you believe you have been wrongly denied entry to the UK and would like our assistance, please do not hesitate to contact us.. . Foxglove is supporting the Joint Council for the Welfare of Immigrants (JCWI) to challenge the Home Office’s use of a secret algorithm to sift visa applications, which it describes as a digital “streaming tool”.

We share JCWI’s concerns that this shadowy, computer-driven process has the power to affect someone’s chances of getting a visa and is likely to be doing so in a discriminatory way.

Papers have now been filed in this case seeking a judicial review. This is an important step. It moves us one stage closer to the case being heard by a judge. You can read more about this development in this article in the Guardian newspaper.

Since the case launched in October, we’ve engaged in pre-action correspondence with the Home Office. We still aren’t convinced that the algorithm doesn’t spit out bias or discriminatory decisions. We are still worried that a computer program is affecting people’s right to come here to work, study or see loved ones.

We also continue to be concerned it seems to be discriminating on the basis of crude characteristics like nationality – rather than assessing individual applicants fairly. People from rich white countries are getting Speedy Boarding. Poorer people of colour are getting pushed to the back of the queue.

Coronavirus is affecting the legal system and that may mean some delays in the case being heard in court. However, it definitely won’t be preventing JCWI, with our support, from pursuing this matter to its conclusion.

Families kept apart by this secretive visa algorithm may include key workers upon whom we are all relying during the current pandemic.

It’s more important than ever to challenge this injustice so that, once the pandemic is over and people are able to travel again, every visa application is assessed transparently and fairly.

JCWI have launched a crowdfunder to cover their legal costs in this case. Please donate by clicking the Donate button below if you can.