A group of civil liberties advocates and immigrant rights organizations on Tuesday sued Clearview AI in a Northern California court, alleging that the controversial facial recognition company illegally "scraped," or obtained, photos for its database and that its "mass surveillance technology disproportionately harms immigrants and communites of color."

"Thousands of local police officers and federal agents, including ICE agents, can pull up Clearview on their phones, take your photo, and know everything about you."

--Jacinta Gonzalez, Mijente

Mijente, NorCal Resist, and five activists filed the suit (pdf) in Alameda County Superior Court in an attempt to stop the New York-based company from collecting data in California and to compel it to delete personal images and data already scraped from social media sites and stored in its database of over three billion photos.

The lawsuit claims the company's artificial intelligence software is being used by federal and state law enforcement agencies to identify people, in contravention of state and local statutes. In 2019, California became the third state after Oregon and New Hampshire to prohibit law enforcement use of facial recognition and other biometric tracking technology in officer body cameras.

In recent years, several California municipalities including San Francisco, Oakland, and Berkeley have also passed laws banning or limiting police and other city agencies from using facial recognition technology. San Francisco's ban is being tested in a lawsuit filed by the Electronic Frontier Foundation, the ACLU of Northern California, and local activists, who allege they were illegally surveilled at last year's Black Lives Matter protests.

"Privacy is enshrined in the California constitution, ensuring all Californians can lead their lives without the fear of surveillance and monitoring," Sejal Zota, a lead attorney in the new suit, said in a statement. "Clearview AI upends this dynamic, making it impossible to walk down the street without fear your likeness can be captured, stored indefinitely by the company, and used against you any time in the future. There can be no meaningful privacy in a society with Clearview AI."

In an interview with CNN Business, Zota called Clearview AI's technology "a terrifying leap toward a mass surveillance state where people's movements are tracked the moment they leave their homes."

The plaintiffs argue that minorities are especially at risk of rights violations, with the lawsuit noting that "facial recognition algorithms have repeatedly been shown to perform poorly when examining the faces of people of color."

"Consequently, facial recognition technology has a far greater risk of misidentifying people of color," it states.

"Facial recognition technology has a far greater risk of misidentifying people of color."

--lawsuit

Jacinta Gonzalez, a senior organizer at Mijente, said in a statement that "thousands of local police officers and federal agents, including ICE [Immigration and Customs Enforcement] agents, can pull up Clearview on their phones, take your photo, and know everything about you--whether you're at a protest, on the subway, or on the side of the road. This is going to be used to surveil us, arrest us, and in some cases deport us."

Clearview AI has been denounced around the world, with the European Union last year asserting that the company likely violates its privacy laws and Canada's privacy commissioner last month condemning the firm's use of "scraped" biometric data.

In addition to privacy concerns, the company has also come under fire for ties to far-right individuals in the U.S.. France's privacy watchdog slapped a €20 million fine on US firm Clearview AI on Thursday, October 20, for breaching privacy laws, as pressure mounts on the controversial facial-recognition platform.

The firm collects images of faces from websites and social media feeds without seeking permission and sells access to its vast database – reportedly around 20 billion pictures – to clients including law enforcement agencies.

Privacy activists have raised objections to the business model around the world, already winning a case in the United States that has forced the firm to stop selling its main database to private clients.

The French complaint to privacy watchdog CNIL is one of a slew filed by activists across Europe that has already resulted in fines in Italy and Britain. CNIL ruled last year that Clearview was processing personal data unlawfully and ordered it to stop, but said on Thursday that the firm had not responded.

In addition to the 20-million-euro ($19.6 million) fine, CNIL once again ordered the firm to stop collecting data from people residing in France and delete the data it had already collected. The watchdog said there were "very serious risks to the fundamental rights of the data subjects".

Clearview AI has two months to comply with the order or begin incurring fines of €100,000 per day.

Clearview boss Hoan Ton-That said in statements emailed to Agence France-Presse that his company had no clients or premises in France and was not subject to EU privacy law, adding that his firm collected "public data from the open internet" and complied with all standards of privacy. "There is no way to determine if a person has French citizenship purely from a public photo from the internet, and therefore it is impossible to delete data from French residents," he added.

Clearview was formed five years ago and has since attracted almost $40 million in funding from investors including prominent Silicon Valley conservative Peter Thiel, according to the Crunchbase website.

More on this topic Subscribers only Internet users are 'poisoning' their personal data in the fight against online surveillance. CNN Business —

Clearview AI, the controversial firm behind facial-recognition software used by law enforcement, is being sued in California by two immigrants’ rights groups to stop the company’s surveillance technology from proliferating in the state.

The complaint, which was filed Tuesday in California Superior Court in Alameda County, alleges Clearview AI’s software is still used by state and federal law enforcement to identify individuals even though several California cities have banned government use of facial recognition technology.

The lawsuit was filed by Mijente, NorCal Resist, and four individuals who identify as political activists. The suit alleges Clearview AI’s database of images violates the privacy rights of people in California broadly and that the company’s “mass surveillance technology disproportionately harms immigrants and communities of color.”

Sejal Zota, a lawyer for the parties who brought the suit and the legal director at Just Futures Law, told CNN Business that the parties that brought the suit seek an injunction to prevent Clearview AI from being used in California, along with the deletion of face scans of Californians that the company has collected.

Hoan Ton-That, the chief executive of Clearview AI, uses the Clearview smart phone application in New York on Jan. 10, 2020. Amr Alfiky/The New York Times/Redux

Founded in 2017, Clearview AI compiles billions of photos into a database for its software, which can use these images to identify individual people. The company has claimed to have scraped over 3 billion photos from the internet, including photos from popular social media platforms like Facebook, Instagram, Twitter and YouTube. Major tech companies have sent the company cease-and-desist notices in the past, arguing its photo snagging practices violate their terms of service.

“Clearview AI complies with all applicable law and its conduct is fully protected by the First Amendment,” Floyd Abrams, a lawyer for the company, said in a statement to CNN Business on Tuesday.

Facial recognition technology has grown in prevalence — and controversy — in recent years, popping up everywhere from airport check-in lines to police departments and drugstores. And while it could add a sense of security and convenience for businesses that roll it out, the technology has been widely criticized by privacy advocates who are concerned that it may include racial biases and have the potential for misuse.

The lawsuit is the latest attempt by grassroots groups to clamp down on facial-recognition software, which is not widely regulated in the United States. In the absence of clear federal rules regarding the usage of the technology, a number of cities — such as San Francisco, Boston, and Portland, Oregon — have banned the technology in some capacity. A few states, including Illinois, California, and Washington, have related legislation that limits its use.

Zota said the parties that brought the lawsuit see Clearview’s technology “as a terrifying leap toward a mass surveillance state where people’s movements are tracked the moment they leave their homes.” The individual plaintiffs participated in political movements that are critical of the police and of US Immigration and Customs Enforcement, he said.

“The ability to control their likenesses and biometric identifiers — and to continue to engage in political speech critical of the police and immigration policy, free from the threat of clandestine and invasive surveillance — is vital to Plaintiffs, their members, and their missions,” the lawsuit states.

Clearview was sued last year in Illinois by the American Civil Liberties Union, which alleged in its complaint that the company’s technology violates that state’s 2008 Biometric Information Privacy Act. In a statement, the ACLU alleged Clearview participated in “unlawful, privacy-destroying surveillance activities.”

At the time, a lawyer for Clearview AI responded by saying the ACLU lawsuit was “absurd.”

That lawsuit is ongoing; Clearview filed a motion to dismiss the suit in December, which the ACLU replied to in a legal brief, an ACLU spokesperson told CNN Business.

More recently, Clearview AI has also been declared illegal in Canada. The company was told to remove Canadian faces from its database.. The growth of the surveillance industry is concerning for privacy advocates, who worry about the use of facial recognition.

Clearview AI has amassed a database of more than 3 billion photos of individuals by scraping sites such as Facebook, Twitter, Google and Venmo. It’s bigger than any other known facial-recognition database in the U.S., including the FBI’s. The New York company uses algorithms to map the pictures it stockpiles, determining, for example, the distance between an individual’s eyes to construct a “faceprint.”

This technology appeals to law enforcement agencies across the country, which can use it in real time to help determine people’s identities.

It also has caught the attention of civil liberties advocates and activists, who allege in a lawsuit filed Tuesday that the company’s automatic scraping of their images and its extraction of their unique biometric information violate privacy and chill protected political speech and activity.

Advertisement

The plaintiffs — four individual civil liberties activists and the groups Mijente and NorCal Resist — allege Clearview AI “engages in the widespread collection of California residents’ images and biometric information without notice or consent.”

This is especially consequential, the plaintiffs argue, for proponents of immigration or police reform, whose political speech may be critical of law enforcement and who may be members of communities that have been historically over-policed and targeted by surveillance tactics.

Clearview AI enhances law enforcement agencies’ efforts to monitor these activists, as well as immigrants, people of color and those perceived as “dissidents,” such as Black Lives Matter activists, and can potentially discourage their engagement in protected political speech as a result, the plaintiffs say.

The lawsuit, filed in Alameda County Superior Court, is part of a growing effort to restrict the use of facial-recognition technology. Bay Area cities — including San Francisco, Oakland, Berkeley and Alameda — have led that charge and were among the first in the U.S. to limit the use of facial recognition by local law enforcement in 2019.

Yet the push comes at a time when consumer expectations of privacy are low, as many have come to see the use and sale of personal information by companies such as Google and Facebook as an inevitability of the digital age.

Unlike other uses of personal information, facial recognition poses a unique danger, said Steven Renderos, executive director of MediaJustice and one of the individual plaintiffs in the lawsuit. “While I can leave my cellphone at home [and] I can leave my computer at home if I wanted to,” he said, “one of the things that I can’t really leave at home is my face.”

Advertisement

Clearview AI was “circumventing the will of a lot of people” in the Bay Area cities that banned or limited facial-recognition use, he said.

Enhancing law enforcement’s ability to instantaneously identify and track individuals is potentially chilling, the plaintiffs argue, and could inhibit the members of their groups or Californians broadly from exercising their constitutional right to protest.

“Imagine thousands of police officers and ICE agents across the country with the ability to instantaneously know your name and job, to see what you’ve posted online, to see every public photo of you on the internet,” said Jacinta Gonzalez, a senior campaign organizer at Mijente. “This is a surveillance nightmare for all of us, but it’s the biggest nightmare for immigrants, people of color, and everyone who’s already a target for law enforcement.”

The plaintiffs are seeking an injunction that would force the company to stop collecting biometric information in California. They are also seeking the permanent deletion of all images and biometric data or personal information in their databases, said Sejal R. Zota, a legal director at Just Futures Law and one of the attorneys representing the plaintiffs in the suit. The plaintiffs are also being represented by Braunhagey & Borden.

“Our plaintiffs and their members care deeply about the ability to control their biometric identifiers and to be able to continue to engage in political speech that is critical of the police and immigration policy free from the threat of clandestine and invasive surveillance,” Zota said. “And California has a Constitution and laws that protect these rights.”

In a statement Tuesday, Floyd Abrams, an attorney for Clearview AI, said the company “complies with all applicable law and its conduct is fully protected by the 1st Amendment.”

Advertisement

It’s not the first lawsuit of its kind — the American Civil Liberties Union is suing Clearview AI in Illinois for allegedly violating the state’s biometric privacy act. But it is one of the first lawsuits filed on behalf of activists and grass-roots organizations “for whom it is vital,” Zota said, “to be able to continue to engage in political speech that is critical of the police, critical of immigration policy.”

Clearview AI faces scrutiny internationally as well. In January, the European Union said Clearview AI’s data processing violates the General Data Protection Regulation. Last month, Canada’s privacy commissioner, Daniel Therrien, called the company’s services “illegal” and said they amounted to mass surveillance that put all of society “continually in a police lineup.” He demanded the company delete the images of all Canadians from its database.

Clearview AI has seen widespread adoption of its technology since its founding in 2017. Chief Executive Hoan Ton-That said in August that more than 2,400 law enforcement agencies were using Clearview‘s services. After the January riot at the U.S. Capitol, the company saw a 26% jump in law enforcement’s use of the tech, Ton-That said.

The company continues to sell its tech to police agencies across California as well as to Immigration and Customs Enforcement, according to the lawsuit, despite several local bans on the use of facial recognition.

The San Francisco ordinance that limits the use of facial recognition specifically cites the technology’s proclivity “to endanger civil rights and civil liberties” and “exacerbate racial injustice.”

Studies have shown that facial-recognition technology falls short in identifying people of color. A 2019 federal study concluded Black and Asian people were about 100 times more likely to be misidentified by facial recognition than white people. There are now at least two known cases of Black people being misidentified by facial-recognition technology, leading to their wrongful arrest.

Advertisement

Ton-That previously told The Times that an independent study showed Clearview AI had no racial biases and that there were no known instances of the technology leading to a wrongful arrest.

The ACLU, however, has previously called the study into question, specifically saying it is “highly misleading” and that its claim that the system is unbiased “demonstrates that Clearview simply does not understand the harms of its technology in law enforcement hands.”

Renderos said that making facial recognition more accurate doesn’t make it less harmful to communities of color or other marginalized groups.

“This isn’t a tool that exists in a vacuum,” he said. “You’re placing this tool into institutions that have a demonstrated ability to racially profile communities of color, Black people in particular.... The most neutral, the most accurate, the most effective tool — what it will just be more effective at doing is helping law enforcement continue to over-police and over-arrest and over-incarcerate Black people, Indigenous people and people of color.”