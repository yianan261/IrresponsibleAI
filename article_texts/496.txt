another-body-256658 - Credit: Courtesy of Another Body

Taylor Klein will remind you of someone you know. A math-whiz engineer from an engineering family, her Facebook feed is littered with photos of her eating ice cream, studying, and enjoying the great outdoors — the most innocent of pastimes. We are introduced to her via video diary, where she compliments her mother’s strong work ethic and extols the virtues of school. “I never once broke the rules, because I was too scared of what would happen if I did,” she explains. “I think my teachers were concerned because I was worried about college when I was in seventh grade. … I was, like, stressing out about getting into college when I was 12.”

One day, during her senior year of college, Taylor received a Facebook message from one of her friends. “I’m really sorry but I think you need to see this,” the message read, followed by a link to a Pornhub video. She clicked the link and her jaw hit the floor: It was of a woman who looked just like her having sex with a man. Only this never really happened. Taylor’s face was superimposed on another woman’s body. She’d been receiving strange messages from men on Instagram calling her “disgusting” and coming on to her more aggressively than normal. It suddenly clicked.

More from Rolling Stone

“Oh, my God … people were messaging me because they found me on a porn website. I was just … first of all shocked that my name and my face were on there. It didn’t even register that my school and my hometown were also on there,” she recalls. “And then just seeing, like, oh, my God, these videos had thousands of views on them.”

Taylor is the main subject of Another Body, an urgent documentary from filmmakers Sophie Compton and Reuben Hamlyn that premiered at SXSW. The film explores the dark, highly disturbing world of nonconsensual deepfake-porn of women, which experts estimate constitutes about 90 percent of all deepfake content online.

In Compton and Hamlyn’s doc, “Taylor Klein” is not the victim’s real name, and the woman’s face we see in video-diary testimonials isn’t hers but an actor’s face deepfaked over it — in order to preserve what’s left of her anonymity. Taylor soon discovered about “six or seven” deepfake porn videos of herself on Pornhub, along with ones tied to an xHamster account. They were covered in creepy comments, leading the youngster — who already had crippling anxiety and OCD — to wonder whether any of these people might come after her.

“I still just haven’t really processed it. It’s like one of those things that’s too upsetting to think about, so I just don’t,” she says, tearing up, adding, “I just wanted to be numb, basically.”

“I kept asking myself, ‘Why would someone want to do this? And who would do this?’” she says. “I felt like someone’s trying to punish me.”

So, she took action. Taylor called the local police, and we hear a recording of that call in the doc. The policeman on the other end of the line tells her he’s “not quite sure” what they could do, but says they’ll call back soon. A few weeks later, Taylor finally received that call. The cop told her that her tormentor was within their rights to do what they did, and there’s nothing else they can do given that there were no laws concerning nonconsensual deepfake porn in her state, and it doesn’t yet fall within the confines of nonconsensual porn laws, since it incorporates the victim’s face but not their body.

When more deepfake videos popped up — this time of her freshman-year roommate Julia (also a pseudonym) — she reached out to her classmate to warn her, and the two joined forces to try to figure out who was the person behind all this ugliness. Unfortunately, it wasn’t an easy task. They were female engineering students at a school where they estimated there were only four women for every hundred men. And they’d already been on the receiving end of plenty of harassment from their male classmates, a number of whom were, by all accounts, incels.

The duo initially suspected “Bobby” (a pseudonym), a classmate they remembered from freshman year who suddenly began posting a ton of hentai porn and “cultlike things” on main that suggested he believed he “was in some video-game world” with an “apocalyptic-god storyline,” where he was “talking down to humans.” (A real gem, this one.) They prowled 4chan and discovered that a single user had been posting photos of a number of their female classmates, and all of them knew “Mike” (another pseudonym) — a friend of theirs from freshman year. Both women had befriended Mike and grown close to him, with Taylor living in the same dorm as him her freshman and junior years, describing him as the person who initially “made her feel at home in college” — that is, until his demands became too much.

“It was just a really good friendship until it wasn’t. He basically tried to make me his personal therapist, and I couldn’t handle it,” remembers Taylor. Both women had the exact same experience, and ultimately distanced themselves from him. “He didn’t want to listen to what was going on with me. He just wanted to talk about his issues,” adds Julia.

Then came the smoking gun: Julia discovered that the same 4chan handle posted a photo she took with Mike her freshman year, while Taylor found deepfake porn of herself posted to 4chan that was made around the time of her falling-out with him.

“Maybe he felt like he was entitled to all the attention and all the support that he wanted from us, and when we set boundaries for ourselves, that’s what made him vengeful,” Taylor reasons, later adding, “I believe that in his mind, he’s getting back at us for ‘wronging’ him.”

They located a profile with the same handle as Mike’s 4chan one on a popular deepfake porn site, MrDeepFakes.com, whose logo is none other than Donald Trump. One of the women the account made a lot of deepfake porn of was Gibi ASMR — an ASMR YouTuber with 4.6 million subscribers. Mike’s deepfake porn profile had more than a million views, and had posted 132 deepfake-porn videos.

“Someone that knew me on a very, very, very personal level — it’s hard to believe he has this complete other world that none of us knew about,” offers Taylor.

Taylor and Julia reached out to Gibi ASMR and explained the situation to her, prompting the content creator to post a video to her social handles calling out this icky deepfake-porn trend and demanding more accountability. The post went viral.

Hey all – serious topic – and honestly just a tiny blip in the conversation. My experience is not unique in the slightest, which is why I feel compelled to speak out. It can and will truly happen to anyone. I hope you take a listen, and help me take some action against deepfakes. pic.twitter.com/pbH7kf0PI1 — Gibi 🐝 (@GibiOfficial) November 10, 2022

Meanwhile, the young women convinced police to place a call to Mike and, after some light prodding — and Mike neither confirming nor denying he did it, but apologizing and saying it would never happen again — they closed the case.

That certainly didn’t end things for Taylor.

“He’s still friends with all of my friends, and it’s tough because I can’t really tell them about it. I tried telling one of them, and he didn’t really believe me that it was him,” Taylor says, adding, “Because the police didn’t do anything, it feels like it’s kind of my word against his. … I definitely worry something would happen where people wouldn’t like me, or people would turn against me. It feels like I’ve had to deal with all of the consequences that he should have had to deal with.”

Taylor was the one who eventually had to leave their friend group. And her story echoes those of so many other women, including Twitch star QTCinderella, who came forward in February in a tear-filled video describing how she’d been terrorized by deepfake porn of herself online, calling out fellow streamer Atrioc for boasting that he’d “purchased two doctored clips featuring other famous female Twitch stars, prompting a spike in traffic to the deepfake porn site,” reported the New York Post. (Atrioc then released his own apology video.)

“Whoever is targeted is driven offline. It’s like the aperture of people’s lives closes,” explains Mary Anne Franks, a professor at the University of Miami School of Law, in Another Body. “The disciplinary effect of those deepfakes is: You shouldn’t be successful, you shouldn’t go into journalism, you shouldn’t go into politics. That is a massive chilling effect.” And the perpetrators of these crimes are almost never held accountable for their actions.

“I think because he essentially got away with this,” Taylor says, “Mike will certainly keep doing this to women in his life.”



Best of Rolling Stone

Click here to read the full article.