Sitting in the witness box of a small London courtroom this week, a Meta executive faced an uncomfortable question: Did her company contribute to the suicide of a 14-year-old named Molly Russell?

Videos and images of suicide, self-harm and depressive content that the teenager viewed in the months before she died in November 2017 appeared on a screen in the courtroom. The executive was read a post that Molly had liked or saved from Instagram, and heard how it was copied almost verbatim in a note filled with words of self-loathing later found by her parents.

“This is Instagram literally giving Molly ideas,” Oliver Sanders, a lawyer representing the family, said angrily during one moment of the exchange.

Leaning forward in the witness chair, the executive, Elizabeth Lagone, who leads the company’s health and well-being policy, responded: “I can’t speak to what was going on in Molly’s mind.”