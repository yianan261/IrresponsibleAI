The Guardian has accused Microsoft of damaging its journalistic reputation by publishing an AI-generated poll speculating on the cause of a woman’s death next to an article by the news publisher.

Microsoft’s news aggregation service published the automated poll next to a Guardian story about the death of Lilie James, a 21-year-old water polo coach who was found dead with serious head injuries at a school in Sydney last week.

The poll, created by an AI program, asked: “What do you think is the reason behind the woman’s death?” Readers were then asked to choose from three options: murder, accident or suicide.

Readers reacted angrily to the poll, which has subsequently been taken down – although highly critical reader comments on the deleted survey were still online as of Tuesday morning.

A reader said one of the Guardian reporters bylined on the adjacent story, who had nothing to do with the poll, should be sacked. Another wrote: “This has to be the most pathetic, disgusting poll I’ve ever seen.”

The chief executive of the Guardian Media Group, Anna Bateson, outlined her concerns about the AI-generated poll in a letter to Microsoft’s president, Brad Smith.

She said the incident was potentially distressing for James’s family and had caused “significant reputational damage” to the organisation as well as damaging the reputation of the journalists who wrote the story.

“This is clearly an inappropriate use of genAI [generative AI] by Microsoft on a potentially distressing public interest story, originally written and published by Guardian journalists,” she wrote.

Bateson added that it had demonstrated “the important role that a strong copyright framework plays in enabling publishers to be able to negotiate the terms on which our journalism is used”.

Microsoft has a licence with the Guardian to publish the news organisation’s journalism. The Guardian article and accompanying poll appeared on Microsoft Start, a news aggregation website and app.

Bateson asked for assurances from Smith that: Microsoft will not apply experimental AI technology on or alongside Guardian journalism without the news publisher’s approval; and Microsoft will always make it clear to users when AI tools are used to create additional units and features next to trusted news brands like the Guardian. Bateson said there was a “strong case” for Microsoft adding a note to the article taking responsibility for the poll.

The GMG chief executive added that while this week’s AI safety summit was looking at long-term safety, Microsoft and other platforms needed to outline how they would prioritise trusted information, fair reward for licensing journalism and more transparency and safeguards for consumers around use of AI.

A Microsoft spokesperson said: “We have deactivated Microsoft-generated polls for all news articles and we are investigating the cause of the inappropriate content. A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this kind of error from reoccurring in the future.”. On Tuesday, The Guardian accused Microsoft of damaging its journalistic reputation by publishing an AI-generated poll beside one of its articles on the Microsoft Start website. The poll, created by an AI model on Microsoft's news platform, speculated on the cause of a woman's death, reportedly triggering reader anger and leading to reputational concerns for the news organization.

"This has to be the most pathetic, disgusting poll I’ve ever seen," wrote one commenter on the story. The comment section has since been disabled.

The poll appeared beside a republished Guardian story about Lilie James, a 21-year-old water polo coach who was found dead with head injuries in Sydney. The AI-generated poll presented readers with three choices to speculate on the cause of James' death: murder, accident, or suicide. Following negative reactions, the poll was removed, but critical comments remained visible for a time before their removal.

Anna Bateson, the chief executive of the Guardian Media Group, voiced her concerns in a letter to Microsoft President Brad Smith. Bateson criticized Microsoft's use of generative AI for creating a poll on a sensitive issue without the news publisher's consent.

Advertisement

"This is clearly an inappropriate use of genAI [generative AI] by Microsoft on a potentially distressing public interest story, originally written and published by Guardian journalists," she wrote in the letter.

She argued that the poll was not only potentially distressing for the deceased woman's family but also harmful to the reputation of the journalists who wrote the original article, some of which had been angrily called out by name by commenters on the article. Bateson then emphasized the importance of a "strong copyright framework" for publishers to negotiate how their content is used by third-party platforms.

The Guardian has a licensing agreement with Microsoft that allows the tech company to publish the newspaper's articles on Microsoft Start, which serves as a news aggregation website and app. Bateson has requested that Microsoft commit to not using experimental AI technology alongside Guardian journalism without approval and to make it clear when AI tools are employed for generating additional content.

Bateson also called on Microsoft to take responsibility for the poll by attaching a note to the original article. As of press time, Microsoft had not yet commented to The Guardian on the matter.

This isn't the first time Microsoft's automated AI-generated news content has caused controversy. In September, MSN published an AI-generated article that declared deceased former NBA player Brandon Hunter "useless at 42." In August, MSN also published a list of can't-miss tourist destinations in Ottawa that included a food bank.. An auto-generated poll that Microsoft embedded on its news aggregating platform alongside a Guardian article was “crass” and caused significant damage to The Guardian’s reputation, the newspaper said on Thursday.

The poll, which was posted last week next to an article about a woman who was found dead in a school bathroom in Australia, asked readers to speculate on the cause of the woman’s death. It gave three choices: murder, accident or suicide. The Guardian said the poll was created using generative artificial intelligence, which can generate text, images and other media from prompts.

Anna Bateson, the chief executive of Guardian Media Group, wrote in a letter to Microsoft that the poll was “clearly an inappropriate use of genAI.”

“Not only is this sort of application potentially distressing for the family of the individual who is the subject of the story, it is also deeply damaging to the Guardian’s hard-won reputation for trusted, sensitive journalism, and to the reputation of the individual journalists who wrote the original story,” Ms. Bateson wrote in the letter, addressed to Brad Smith, Microsoft’s vice chairman and president, on Tuesday. Ms. Bateson said that The Guardian had already asked Microsoft not to apply its experimental technologies to Guardian news articles because of the risks it posed.. Screenshot of the poll, which was removed Monday, Oct. 31.

Microsoft has shut off all its AI-generated polls on news articles and launched an investigation after the Guardian Media Group blasted the tech giant for a poll that ran alongside a story about a woman's death. Driving the news: "A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this kind of error from reoccurring in the future," Microsoft said in a statement to Axios on Wednesday.

The Microsoft statement said the tech giant had "deactivated Microsoft-generated polls for all news articles" and is "investigating the cause of the inappropriate content."

Backstory: On Tuesday, The Guardian Media Group demanded that Microsoft take public responsibility for the poll, which ran next to an article about a woman found dead at a school in Australia, according to a letter obtained by Axios.

The poll, which ran within Microsoft's curated news aggregator platform Microsoft Start, asked the reader what they thought the cause was of the woman's death.

which ran within Microsoft's curated news aggregator platform Microsoft Start, asked the reader what they thought the cause was of the woman's death. "This is clearly an inappropriate use of genAI by Microsoft on a potentially distressing public interest story, originally written and published by Guardian journalists," Guardian CEO Anna Bateson wrote to Microsoft president Brad Smith.

Why it matters: While Microsoft did eventually remove the poll, the damage was already done.

Readers slammed The Guardian and the article author in the poll's comments section, whom they assumed were responsible for the blunder.

"This application of genAI by Microsoft is exactly the sort of instance that we have warned about in relation to news," Bateson's letter said, "and a key reason why we have previously requested to your teams that we do not want Microsoft's experimental genAI technologies applied to journalism licensed from the Guardian."

Details: Bateson urged Microsoft to add a note to the poll, arguing Microsoft should take "full responsibility for it."

She also asked for assurance from Microsoft that it will not apply "experimental technologies on or alongside Guardian licensed journalism" without its explicit approval.

In addition, she accused Microsoft of failing to "substantively respond" to the Guardian's request to discuss how Microsoft intends compensate news publishers for the use of their intellectual property "in the training and live deployment of AI technologies within your wider business ventures."

The big picture: Newsrooms have been grappling with ways to leverage artificial intelligence responsibly while ensuring they don't compromise their editorial content.

Many are currently pushing tech firms to pay them to use their content to train AI models.

What to watch: Following an embarrassing publishing experiment from CNET earlier this year, more media companies are including disclosures of the use of AI in their editorial products.

In her letter to Smith, Bateson asked that Microsoft always make it clear to users "wherever genAI is involved in creating additional units and features as they apply to third party journalism from trusted news brands like the Guardian."

Editor's note: This story has been updated to include a statement from Microsoft.. More than three years after Microsoft gutted its news divisions and replaced their work with AI and algorithmic automation, the content generated by its systems continues to contain grave errors that human involvement could, or should, have stopped. Today, The Guardian accused the company of damaging its reputation with a poll labeled “Insights from AI” that appeared in Microsoft Start next to a Guardian story about a woman’s death, asking readers to vote on how she died.

The Guardian wrote that though the poll was removed, the damage had already been done. The poll asked readers to vote on whether a woman took her own life, was murdered, or died by accident. Five-day-old comments on the story indicate readers were upset, and some clearly believe the story’s authors were responsible.

We asked Microsoft via email whether the poll was AI-generated and how it was missed by its moderation, and Microsoft general manager Kit Thambiratnam replied:

We have deactivated Microsoft-generated polls for all news articles and we are investigating the cause of the inappropriate content. A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this kind of error from reoccurring in the future.

The Verge obtained a screenshot of the poll from The Guardian.

A screenshot sent by The Guardian shows the poll, which is clearly labeled “Insights from AI.” Screenshot: The Guardian

In August, a seemingly AI-generated Microsoft Start travel guide recommended visiting the Ottawa Food Bank in Ottawa, Canada, “on an empty stomach.” Microsoft senior director Jeff Jones claimed the story wasn’t made with generative AI but “through a combination of algorithmic techniques with human review.”

The Guardian says that Anna Bateson, Guardian Media Group’s chief executive, wrote in a letter to Microsoft president Brad Smith that the “clearly inappropriate” AI-generated poll had caused “significant reputational damage” to both the outlet and its journalists. She added that it outlined “the important role that a strong copyright framework plays” in giving journalists the ability to determine how their work is presented. She asked that Microsoft make assurances that it will seek the outlet’s approval before using “experimental AI technology on or alongside” its journalism and that Microsoft will always make it clear when it’s used AI to do so.

The Guardian provided The Verge with a copy of the letter.

Update October 31st, 2023, 12:40PM ET: Embedded The Guardian’s letter to Microsoft.

Update October 31st, 2023, 6:35PM ET: Added a statement from Microsoft.. The Guardian has accused Microsoft of damaging its brand by adding an offensive AI-generated poll to one of its articles.

In a story reporting on the death of 21-year-old Lilie James, whose body was found with serious head injuries in Australia, the tech giant’s AI asked readers to vote on the cause of her passing, giving them the options of murder, accident or suicide.

Furious readers reacted by describing the poll as “disgusting” and calling for the instant dismissal of the journalist – who had nothing to do with the poll.

Why we care. Microsoft’s decision to use AI instead of human writers is causing problems again. This is a clear reminder of why businesses should utilize AI to support human efforts rather than replace them. Neglecting this approach could damage your brand’s reputation and adversely affect your search rankings.

How this happened. Microsoft has agreements with major news organizations around the world, such as The Guardian and CNN, under which it can republish their articles in return for a portion of ad revenue. However, when the tech giant republished this story, its AI technology automatically added the offensive poll.

What The Guardian is saying. Anna Bateson, chief executive of the Guardian Media Group, wrote to Microsoft’s president, Brad Smith, accusing the company of upsetting James’ family, as well as causing “significant reputational damage” to both the newspaper and the journalist. She said:

“This is clearly an inappropriate use of genAI [generative AI] by Microsoft on a potentially distressing public interest story, originally written and published by Guardian journalists.”

Bateson then asked Smith to reassure her that:

“Microsoft will not apply experimental AI technology on or alongside Guardian journalism without the news publisher’s approval; and Microsoft will always make it clear to users when AI tools are used to create additional units and features next to trusted news brands like the Guardian.”

What Microsoft is saying. A Microsoft spokesperson said:

“We have deactivated Microsoft-generated polls for all news articles and we are investigating the cause of the inappropriate content. A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this kind of error from reoccurring in the future.”

Get the daily newsletter search marketers rely on. Business email address Subscribe Processing... See terms.

History repeating itself. This isn’t the first time Microsoft’s generative AI has landed the tech giant in trouble. In September, the company was heavily criticized after publishing an AI-generated obituary for NBA star Brandon Hunter.

The former Boston Celtics and Orlando Magic player passed away suddenly this week, aged 42, after collapsing during a hot yoga class in Orlando, Fl. Shortly after his passing, fans were shocked to see the father of three described as “useless” in an obituary published on MSN. The headline read:

“Brandon Hunter useless at 42.”

Readers reacted by branding Microsoft “lazy” for leveraging AI to create articles and urged the company to rehire the editorial staff it replaced with AI.

Deep dive. Read the Guardian’s response in full for more information.. The Guardian accused Microsoft of causing "significant reputational damage" with an AI-generated poll.

A poll speculating how a woman died appeared next to a Guardian news story on Microsoft Start.

The poll on the aggregation platform highlights the risk of relying on automated processes.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Advertisement

A newspaper publisher accused Microsoft of damaging its reputation after an AI-generated poll appeared next to one of its articles on an aggregation platform.

The Guardian reported on Lilie James, a 21-year-old water polo coach who was found dead with serious head injuries at a high school in Sydney, Australia.

An AI-generated poll asking readers to vote on whether they thought the woman had died by murder, suicide or accident appeared next to the article on Microsoft Start.

This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now. Have an account? Log in .. Microsoft’s recent use of an AI-generated poll has sparked criticism from The Guardian, one of the UK’s leading news publishers. The tech giant’s news aggregation service displayed the automated poll alongside a Guardian article detailing the tragic death of Lilie James, a young water polo coach from Sydney.

Controversial AI poll raises eyebrows

The poll asked readers to speculate on James’s death, giving three choices: murder, accident, or suicide. Many readers found the poll insensitive. Some even demanded the firing of the Guardian reporter linked to the story, even though they didn’t create the poll.

Anna Bateson, Guardian Media Group’s Chief Executive, shared her concerns in a letter to Brad Smith, Microsoft’s president. She stressed the poll’s potential harm to James’s family and the damage to The Guardian’s reputation.

Guardian seeks assurances from Microsoft

In her letter, Bateson demanded two key assurances from Microsoft. Firstly, she insisted that Microsoft refrain from using experimental AI technology alongside Guardian journalism without explicit approval from the news publisher. Secondly, she called for clear indications to users when AI tools are employed to create additional content adjacent to trusted news brands.

Moreover, she suggested Microsoft should add a note to the article, accepting responsibility for the poll.

The role of AI in journalism

This incident underscores the broader debate about the role and limitations of AI in journalism. While AI can enhance news distribution, it can also cause issues when used insensitively. Bateson mentioned the need for a strong copyright system, allowing publishers to set terms for using their content.

Microsoft, licensed to share The Guardian’s content, showcased the article and poll on their platform, Microsoft Start.

As the industry grapples with the challenges and opportunities presented by AI, Bateson’s comments serve as a reminder of the need for transparency, safeguards, and a commitment to prioritizing trusted information.. How's AI in the media going? Well, Microsoft apparently ran a disgusting AI-generated poll next to a syndicated article about a woman who'd been found dead in Australia — and The Guardian, which published the original article in question, wants answers.

As The Guardian reports in its own recounting of the incident, the article that Microsoft re-published on its MSN news portal focused on the death of a young 20-something woman in Sydney, whose body was found at the school where she worked as a water polo coach.

Unsurprisingly, police are considering the case as a possible murder — but the classless poll still questioned whether readers thought the woman had died by suicide, murder, or accident. Beneath the question, a disclaimer that the poll was part of the company's "insights from AI" somehow made the tasteless poll even more egregious.

A screenshot of the offending poll in question. Image via Axios/screenshot.

In a letter sent to Microsoft president Brad Smith that the newspaper quoted, Guardian Media Group CEO Anna Bateson said the debacle was not only potentially upsetting to the family of the young woman, but that it also poses "significant reputational damage" to The Guardian and the journalists who wrote the article.

"This is clearly an inappropriate use of [generative AI] by Microsoft on a potentially distressing public interest story, originally written and published by Guardian journalists," Bateson wrote in her letter to Smith.

The CEO, per the entire text of the letter provided to The Verge, added that although Microsoft has a license to republish The Guardian on MSN, the publisher had previously asked the tech giant not to use its "experimental" AI alongside its licensed work without the company's approval.

Bateson also demanded Microsoft explain how it plans to compensate its news partners when it uses their intellectual property "in the training and live deployment of AI technologies within your wider business ventures."

Microsoft should, the CEO added, take "full responsibility" for the passé poll, which has since been removed from Microsoft's syndication of the story. In a statement provided to Futurism, a Microsoft spokesperson said that the company has deactivated its poll feature and is "investigating the cause of the inappropriate content."

"A poll should not have appeared alongside an article of this nature," the spokesperson continued, "and we are taking steps to help prevent this kind of error from reoccurring in the future."

Anyone who's kept up with Futurism's AI reporting this year knows that Microsoft's syndication service — which has had its own AI plagiarism issues — is just one of many platforms dabbling in AI-generated content.

From BuzzFeed to CNET, disastrous pivots to AI have made fools of numerous media CEOs who placed losing bets early on the burgeoning chatbot technology — and in spite of all those bungles, we have yet to see a single really impressive deployment of AI in media.

More on the AI of it all: LinkedIn Laying Off 700 as Microsoft Pivots to AI. When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works

In 2020, Microsoft announced huge layoffs across MSN and Azure organizations, among others, due to the company replacing its editor and curators with AI algorithms. Now, the algorithms seem to have caused an issue between Microsoft and The Guardian.

Today, The Guardian accused Microsoft of damaging its reputation after an inappropriate AI-generated poll appeared beside the tragic news of the death of 21-year-old Lilie James in Sydney.

Appearing right beside it, the distasteful poll asked users what the reason for the woman’s death was and gave readers the option to choose between murder, suicide, or accident. Naturally, the poll disturbed readers and was soon taken down from the website.

Nevertheless, the damage was already done as some highly critical comments from readers were still up until Tuesday morning on the article. Some of the Microsoft Start readers, according to The Guardian, were also unaware that it was Microsoft that created the poll. This affected The Guardian's reputation.

One of such comments called out The Guardian stating, “This has to be the most pathetic, disgusting poll I’ve ever seen,” while another wrote, “Tamsin [the Guardian journalist] should be sacked for that poll. No community guidelines at play here obviously??”

Following this, the chief executive of the Guardian Media Group, Anna Bateson, wrote a letter to Microsoft president, Brad Smith discussing the issue.

The two-page letter, as shared by The Guardian with The Verge, argues that the AI-generated poll makes it seem as if The Guardian had displayed it, hence, damaging its reputation. Moreover, the letter calls out Microsoft saying that there is a “strong case” for the company attaching a note with the article taking full responsibility for the incident.

The letter also adds:

“We would also like your assurance that a) Microsoft will not apply these experimental technologies on or alongside Guardian licensed journalism without our explicit prior approval; and b) that Microsoft will always make it clear to users of of your platforms wherever genAI is involved in creating additional units and features as they apply to third party journalism from trusted news brands like the Guardian.”

Bateson even went as far as to call this an “inappropriate use” of generative AI and an incident that emphasizes the “important role that a strong copyright framework plays” in helping journalists and publishers to discuss how their work is shared online.

The Guardian has asked Microsoft to comment, however, Microsoft has not sent a reply to the letter or shared a statement addressing the issue yet.. The Guardian is demanding compensation from Microsoft after the tech giant inserted a “crass” AI-generated poll into one of its articles that asked readers to speculate on the cause of someone’s death.

MSN, which has a licence to re-run some Guardian stories, published an article from Guardian Australia about a young woman who was found dead at a school in Sydney.

In the middle of the article it inserted an AI-generated poll that asked readers what they thought the cause of the woman’s death was. They were given three options: murder, accident and suicide.

Anna Bateson, chief executive of Guardian Media Group, said the use of AI was “deeply concerning” and called for discussions with a top Microsoft executive.

In a letter to Brad Smith, vice chairman and president of Microsoft, she wrote: “Not only is this sort of application potentially distressing for the family of the individual who is the subject of the story, it is also deeply damaging to the Guardian’s hard-won reputation for trusted, sensitive journalism, and to the reputation of the individual journalists who wrote the original story.”. Microsoft’s generative artificial intelligence tool inserted a “deeply concerning” poll into a Guardian news story asking readers to speculate on the cause of a woman’s death.

Tech giant Microsoft has a licence with The Guardian to publish its news stories on its Microsoft Start platform, a news aggregator website and app.

Last week a Guardian news story on the death of school water polo instructor Lilie James in Sydney was included on Microsoft Start along with an AI-generated poll asking: “What do you think is the reason behind the woman’s death?”

Readers were given three potential answers to the poll: murder, accident or suicide.

While the poll was generated entirely by Microsoft’s tools and not by The Guardian or its journalists, several readers commenting on the story did not make this distinction, with some calling for the writer to be fired.

Guardian Media Group chief executive Anna Bateson wrote a letter to Microsoft President Brad Smith about the incident, saying the organisation has previously warned about the risks of using generative AI around its news stories.



The poll was widely criticised. Photo: Supplied

“This application of genAI by Microsoft is exactly the sort of instance that we have warned about in relation to news, and a key reason why we have previously requested to your teams that we do not want Microsoft’s experimental genAI technologies applied to journalism licensed from The Guardian,” Bateson said in the letter.

“Not only is this sort of application potentially distressing for the family of the individual who is the subject of the story, it is also deeply damaging to the Guardian’s hard-won reputation for trusted, sensitive journalism, and to the reputation of the individual journalists who wrote the original story.”

The Guardian has called for reassurances that Microsoft will not use any experimental AI tools on its content, and will make it clear when AI has been used to create additional units and features.

“There is an almost complete absence of clear or transparent labelling of these genAI powered outputs, and certainly no disclaimer or explanation to users that these technologies are owned and operated by Microsoft, and to the inherent unreliability of them,” Bateson said.

“This has to change.”

In response, Microsoft took down the poll and launched an investigation into how it came to appear alongside the story.

“We have deactivated Microsoft-generated polls for all news articles and we are investigating the cause of the inappropriate content,” a Microsoft spokesperson said.

“A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this kind of error from reoccurring in the future.”

It comes more than three years after Microsoft laid off dozens of journalists and editorial staff at Microsoft News and its MSN organisations and replaced them with artificial intelligence tools, which will be used to pick the news and content to be presented on these platforms.

It’s not the first time these tools have gone wrong.

In August, an apparently AI-generated travel article recommended visiting a food bank in Ottawa, Canada “on an empty stomach”.

Microsoft later claimed this story was generated “through a combination of algorithmic techniques with human review”.

The Guardian has also called for a wider discussion on the use of news content to train generative AI tools.

The issue of copyright and generative AI is already a messy and complicated one.

The New York Times is also considering suing ChatGPT over the use of its articles to train its algorithm, over concerns it could become a direct competitor.

The news organisation has also updated its terms of service to stop AI companies using its content to train their models.. Credit: Microsoft

As AI begins to eat its way into our lives more each day, its limitations become more obvious as it encounters situations its creators might not have envisioned. The latest example comes from Microsoft, which used AI to insert polls next to news stories for its readers to take, theoretically increasing engagement. Recently, it inserted a poll about a woman in Sydney who was found dead, with the poll asking readers what they thought was the cause of death.

The news article was concerning a water polo coach in Sydney whose body was found in the school's gymnasium. The resulting poll asked readers what they thought the cause was, with the options including murder, an accident, or suicide. The article originated with The Guardian, which took Microsoft to task for including such a callous poll alongside its article in the company's news aggregator, Microsoft Start (MSN.com on the web). According to Axios, the errant poll has caused Microsoft to suspend its AI-powered poll generator until it can investigate the matter.

The poll was saved by Axios before Microsoft removed it from the story following reader outcry. Credit: Axios

The move by Microsoft was too little, too late, according to The Guardian, which received heavy flak from readers thinking it was responsible for the poll. Guardian CEO Anna Bateson wrote a fiery letter to Microsoft president Brad Smith about the situation, reiterating the paper's desire that it never wanted polls appearing alongside any syndicated content. "This application of genAI by Microsoft is exactly the sort of instance that we have warned about in relation to news," wrote Bateson. The CEO urged Microsoft to clarify to readers that AI, not The Guardian, had made the poll.

Microsoft has taken responsibility for the insensitive poll. In a statement to Axios, it wrote, "A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this kind of error from reoccurring in the future," Microsoft stated.

The whoopsie from Microsoft highlights the difficulty of using AI and algorithms to replace human judgment. According to CNN, Microsoft's news aggregator service has republished numerous false stories recently. It had previously employed over 800 editors globally to curate content but had reduced that number recently due to "automation," which many editors took to mean AI was now doing their jobs.

If anything, the incident only highlights the need for media companies to clarify when using AI-generated content. Whether Microsoft will take that route when its polls return online remains to be seen.. Microsoft is facing backlash after it used AI to create an insensitive poll speculating on the cause of a woman's death that was published alongside an article from The Guardian on Microsoft's news aggregation service, Microsoft Start.

The article covered the tragic death of a 21-year-old water polo coach in Sydney, Australia, who was discovered dead at her school with significant head injuries.

The poll that ran next to the article asked readers, "What do you think is the reason behind the woman's death?" Readers were given three options: murder, accident, or suicide.

Many readers associated the poll with The Guardian's journalist and demanded the firing of the reporter, who had no involvement with the poll. The Guardian says it has suffered "significant reputational damage" as a result.

From The Guardian:

The chief executive of the Guardian Media Group, Anna Bateson, outlined her concerns about the AI-generated poll in a letter to Microsoft's president, Brad Smith. She said the incident was potentially distressing for James's family and had caused "significant reputational damage" to the organisation as well as damaging the reputation of the journalists who wrote the story. "This is clearly an inappropriate use of genAI [generative AI] by Microsoft on a potentially distressing public interest story, originally written and published by Guardian journalists," she wrote.

In response to the backlash, Microsoft deactivated AI-generated polls for all news articles and promised to investigate the cause of the inappropriate content. They also pledged to prevent similar incidents from happening in the future.. . What if instead of being deviously calculating, robots just turned out to be blazingly insensitive? You know, not end the world – just make it...

For more crisp and insightful business and economic news, subscribe to The Daily Upside newsletter. It's completely free and we guarantee you'll learn something new every day.

What if instead of being deviously calculating, robots just turned out to be blazingly insensitive? You know, not end the world – just make it intolerable.

UK newspaper The Guardian submitted a complaint to Microsoft on Tuesday after the Microsoft Start aggregated news service featured a grotesquely inappropriate AI-generated poll next to a Guardian article about a suspected murder. Among other things, it seems the bots weren't trained on ad placement.

Error in Judgment (Day)

While the full effects of generative AI on the news business are still rippling their way through the industry, The Guardian's complaint against Microsoft gives a clue to the current state of play. For all its technological advances, AI is still devoid of editorial judgment, human decency, or plain common sense.

That didn't stop Microsoft from adding a feature to Microsoft Start that uses AI to generate little polls. They pop up next to news articles, providing readers with a little extra content alongside the journalism it's pulled in. The poll in question asked readers to vote on exactly what they thought led to the death of 21-year-old Lilie James, who was found dead with severe head wounds at a school in Australia. Anna Bateson, CEO of The Guardian's parent company Guardian Media Group, wrote in a letter to Microsoft President Brad Smith that the AI-generated poll significantly harmed The Guardian's reputation:

In her letter, Bateson said the incident highlighted: "the important role that a strong copyright framework plays in enabling publishers to be able to negotiate the terms on which our journalism is used." Microsoft did not immediately respond when contacted by The Daily Upside for comment on Bateson's letter.

The Guardian is one of the first outlets to openly attack a mainstream Big Tech company currently riding the AI-hype train, although Semafor reported in July that a collection of major publishers were forming an alliance to mount legal action against platforms whose large language models gulp up their news copy.

Rishi'll Be Back: The Guardian's letter comes the same week that UK Prime Minister Rishi Sunak is hosting an "AI Safety Summit," an event that will culminate with Sunak sitting down for a livestream on X/Twitter with always reassuring CEO Elon Musk. Chris Stokel-Walker, a journalist with an upcoming book on the impact of AI, said the summit's agenda goes: "heavy on the existential risks of a Terminator-style AI gaining super-intelligent sentience" rather than more immediate risks that, you know, exist.. What you need to know

An article by The Guardian covering the unfortunate passing of a young woman was featured in Microsoft Start, and alongside it was an AI-generated poll asking readers to vote on how she died.

Readers were outraged with the intensive poll shifting blame to the outlet and author.

The Guardian fears that the poll will negatively impact its reputation.

The chief executive has since reached out to Microsoft's President seeking clarification, stressing the importance of a strong copyright framework that gives publishers control over their content.

Microsoft issued a statement indicating that it is investigating the matter and putting elaborate measures in place to prevent such an occurrence.

With generative AI now more widespread than ever, the importance of human intervention is becoming more apparent. It's barely been three months since Microsoft published an AI-generated article recommending Ottawa Food Bank as a top tourist attraction in Canada (though it has since been pulled down), and yet another bizarre and insensitive incident has occurred.

The Guardian accuses Microsoft of tarnishing its reputation by incorporating a poll marked "Insights from AI" next to an article from the outlet talking about the unfortunate passing of a woman, according to a spot by The Verge. The poll insensitively featured several options, including murder, accident, or suicide, which readers were supposed to pick from to guess how the woman lost her life.

The insensitive poll has since been pulled down, but The Guardian indicates that the damage has already been done, not to mention the emotional turmoil caused to the bereaved family. Going by the comments left on the article, it's obvious that the readers weren't too happy about it. In fact, some readers believe that the insensitive poll was the author's own doing and that the outlet was pointing fingers at AI to cover up its tracks.

A screenshot of the insensitive AI-generated poll on The Guardian's story covering the tragic death of a young woman, as well as comments from readers enraged by the poll. (Image credit: The Guardian)

The Guardian Media Group's chief executive, Anna Bateson, has already penned a letter to Microsoft's President, Brad Smith, raising concerns over the AI-generated poll featured in their story and further expressing the potential negative impact it could or might have on the outlet.

This is clearly an inappropriate use of genAI [generative AI] by Microsoft on a potentially distressing public interest story, originally written and published by Guardian journalists. Anna Bateson ,Guardian chief executive

The chief executive stressed the importance of having a strong copyright framework, as it enables publishers to establish control over how their content is leveraged. Bateson also asked Microsoft to refrain from applying experimental AI technology on or alongside the outlet's stories, especially without its consent. And in the event that it does, it's important to ensure that the readers are notified where the "extra features" stem from.

Has AI gone rogue?

This isn't the first time we've witnessed such an occurrence. In September, an article republished via MSN went viral for using AI to write an obituary that called a recently deceased 42-year-old former NBA player 'useless.'

The Verge reached out to Microsoft for a statement regarding the bizarre occurrence and how the AI-generated poll got clearance from the moderation team. Microsoft's general manager, Kit Thambiratnam, responded by stating:

Get the Windows Central Newsletter All the latest news, reviews, and guides for Windows and Xbox diehards. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

"We have deactivated Microsoft-generated polls for all news articles and we are investigating the cause of the inappropriate content. A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this kind of error from reoccurring in the future."

AI has its wins, if recent reports are anything to go by, a lot of work still needs to be done. It's also apparent that human intervention is still crucial, especially in such a case, and it is highly unlikely that such an occurrence would have taken place.

President Biden recently issued an Executive Order touching on this specific issue, alongside other AI safety, security, and trust issues. It will be interesting to see the impact it has in the long run.

Do you think AI has the capability to generate content without making such mistakes? Share your thoughts with us in the comments.