Artificial intelligence and medical algorithms are deeply intertwined with our modern health care system. These technologies mimic the thought processes of doctors to make medical decisions and are designed to help providers determine who needs care. But one big problem with artificial intelligence is that it very often replicate the biases and blind spots of the humans who create them.

Researchers and physicians have warned that algorithms used to determine who gets kidney transplants, heart surgeries and breast cancer diagnoses display racial bias. Those problems can lead to detrimental care that, in some cases, can jeopardize the health of millions of patients.

advertisement

So how exactly does bias seep into these algorithms? And what can be done to prevent it?

Hertford County Magistrate Deborah Morrison at the sheriff’s department in Winton, N.C. Her mother, a 74-year-old former pastor, had begun to suffer from extreme fatigue and shortness of breath. Morrison said her mother’s primary care doctor diagnosed her with depression, prescribed her medication, and sent her home without referring her to a cardiologist. One week later in Greenville, a city 90 miles away, her mother was diagnosed with congestive heart failure. She collapsed and died about one month later. Landon Bost for STAT

In this episode, we hear from Casey Ross, STAT’s national health tech correspondent, about his reporting on racial bias in AI. Chris Hemphill, the VP for applied AI & growth at Actium Health, tells us about the rise of responsible AI in health care. Ziad Obermeryer, an emergency medicine physician and researcher at the UC Berkeley School of Public Health, walks us through how his team found bias in an algorithm widely used in our health care system and an instance where AI was used to correct a health care injustice.

A transcript of this episode is available here.

advertisement

You can subscribe to “Color Code” on Apple Podcasts, Spotify, Google Podcasts, SoundCloud, and elsewhere. New episodes will be released every other Monday.

To read more on some of the topics discussed in the episode:

Chris Hemphill’s STAT First Opinion on responsible AI and counteracting bias

To hear more from Chris Hemphill, you can listen to their podcast, “Hello Healthcare”

A conversation with Ziad Obermeyer on dissecting bias in AI

And check out some of STAT’s coverage on the topic:

This podcast was made possible with support from the Commonwealth Fund.. Care for some of the sickest Americans is decided in part by algorithm. New research shows that software guiding care for tens of millions of people systematically privileges white patients over black patients. Analysis of records from a major US hospital revealed that the algorithm used effectively let whites cut in line for special programs for patients with complex, chronic conditions such as diabetes or kidney problems.

The hospital, which the researchers didn’t identify but described as a “large academic hospital,” was one of many US health providers that employ algorithms to identify primary care patients with the most complex health needs. Such software is often tapped to recommend people for programs that offer extra support—including dedicated appointments and nursing teams—to people with a tangle of chronic conditions.

Researchers who dug through nearly 50,000 records discovered that the algorithm effectively low-balled the health needs of the hospital’s black patients. Using its output to help select patients for extra care favored white patients over black patients with the same health burden.

When the researchers compared black patients and white patients to whom the algorithm assigned similar risk scores, they found the black patients were significantly sicker, for example with higher blood pressure and less well-controlled diabetes. This had the effect of excluding people from the extra care program on the basis of race. The hospital automatically enrolled patients above certain risk scores into the program, or referred them for consideration by doctors.

The researchers calculated that the algorithm’s bias effectively reduced the proportion of black patients receiving extra help by more than half, from almost 50 percent to less than 20 percent. Those missing out on extra care potentially faced a greater chance of emergency room visits and hospital stays.

“There were stark differences in outcomes,” says Ziad Obermeyer, a physician and researcher at UC Berkeley who worked on the project with colleagues from the University of Chicago and Brigham and Women’s and Massachusetts General hospitals in Boston.

The paper, published Thursday in Science, does not identify the company behind the algorithm that produced those skewed judgments. Obermeyer says the company has confirmed the problem and is working to address it. In a talk on the project this summer, he said the algorithm is used in the care of 70 million patients and developed by a subsidiary of an insurance company. That suggests the algorithm may be from Optum, owned by insurer UnitedHealth, which says its product that attempts to predict patient risks, including costs, is used to “manage more than 70 million lives.” Asked by WIRED if its software was that in the study, Optum said in a statement that doctors should not use algorithmic scores alone to make decisions about patients. “As we advise our customers, these tools should never be viewed as a substitute for a doctor’s expertise and knowledge of their patients’ individual needs,” it said.

Keep Reading The latest on artificial intelligence , from machine learning to computer vision and more

The algorithm studied did not take account of race when estimating a person’s risk of health problems. Its skewed performance shows how even putatively race-neutral formulas can still have discriminatory effects when they lean on data that reflects inequalities in society.

The software was designed to predict patients’ future health costs, as a proxy for their health needs. It could predict costs with reasonable accuracy for both black patients and white patients. But that had the effect of priming the system to replicate unevenness in access to healthcare in America—a case study in the hazards of combining optimizing algorithms with data that reflects raw social reality.