Academics have alleged that some peer reviews of grant applications are being written with ChatGPT, prompting the Australian Research Council (ARC) to warn academics that feeding their peers’ work into generative AI models could be a breach of confidentiality.

ARC_Tracker tweeted on Friday that it had received reports "that some ARC discovery projects assessor reports have been produced with ChatGPT."

Discovery projects are multi-year research programs vying for up to $500,000 in government grants. Typically only 15-to-20 percent of applicants are funded, and the review process is rigorous.

But ARC_Tracker said some research teams had received assessor reports that were just a "generic regurgitation" of their applications, with at least one containing the text "regenerate response" - a telltale sign that it was generated by ChatGPT.

The Twitter user behind the ARC_Tracker account - who is a researcher at an Australian university - told iTnews that it appeared some assessment reports were AI-generated.

“Researchers who’ve led proposals have sent me (all or parts of) some expert assessments they received and they read exactly like a simple ChatGPT summary of a proposal without any critique, opinion, insight or assessment at all," the ARC_Tracker account owner told iTnews.

“The researchers tell me the phrases used in these assessments are very simple rearrangements of the phrases already in their grant proposals.

“They have also commented that they put their own grant proposals into ChatGPT and got very similar summaries as they see in the assessment…

"One assessment, from one researcher, had the tell-tale “regenerate response” text at the bottom of (one section of) the assessment. This is what ChatGPT shows at the bottom of its response page.

"It’s smoking gun evidence that ChatGPT was used to generate their assessment text.”

ARC has since released a statement advising peer reviewers not to use AI as part of their assessments.

“Release of material that is not your own outside of the closed research management system, including into generative AI tools, may constitute a breach of confidentiality," the council said.

It added that it would update guidance on AI use "in the near future.”

An ARC spokesperson told iTnews that although "generative artificial intelligence (AI) tools such as ChatGPT are not explicitly named" in policies that apply to peer reviews, "common principles of confidentiality apply across both existing and emerging channels through which confidential information may be inappropriately disclosed.

"The ARC is not alone in considering a range of issues regarding the use of generative AI that uses algorithms to create new content and that may present confidentiality and security challenges for research and for grant program administration...Any concerns raised by applicants will be considered and responded to as per our policies," the spokesperson said.

The spokesperson did not comment on how common the use of ChatGPT in peer reviews is; or if it's considering using AI detection models to identify the use of ChatGPT by academics, as some universities, such as the University of Melbourne, have done to identify use by students.

ARC_Tracker said that the factors underlying ChatGPT-assisted peer-reviews of grant applications included academics’ unmanageable workloads and ARC taking too long to release clear policies about the use of AI.

“There’s been a long-running problem of ARC grant proposals being extremely long," the account owner said.

“If there’s just three or four investigators on the grant, it can easily run to 100-plus pages long. I’ve assessed ones that are 150 pages long.

“Assessors often aren’t given time to review anything in their academic workload model at universities (which have many problems themselves) and so the peer review process is generally under a lot of pressure.”

ARC_Tracker said that another reason peer reviewers may have resorted to ChatGPT is that “there’s nothing in any of the ARC’s policies explicitly about AI generative text engines" that prohibit or restrict their use.

ARC_Tracker added that the statement ARC released did not explicitly address the use of generative AI.

“Sure, the ARC’s statement…says there are general requirements, under their confidentiality policy, not to upload other people’s grant text to external websites," the account owner said.

“But take a read of that policy. Is it clear, simple and definitely - without any doubt - clearly warns people not to use ChatGPT or similar AI services? I don’t think so. I’ve read it - it’s pretty difficult to parse.

“The ARC do this all the time: when something goes wrong they rely on some worn old policy, that no one can read easily, instead of pre-empting problems that the community warns them about well in advance.”. The Australian Research Council has faced allegations that some of its peer reviewers may have used ChatGPT to assess research proposals, prompting a warning from the education minister and concerns about possible academic misconduct.

Several researchers have reported that some assessor feedback provided as part of the latest Discovery Projects round of grant funding included generic wording suggesting they may have been written by artificial intelligence.

One academic, who wished to remain anonymous, told Guardian Australia that one of the assessor reports they received included the words “Regenerate response” – text which appears as a prompt button in the ChatGPT interface.

“It’s quite a positive report, but it’s quite bland also, and it quotes back the proposal at you,” the researcher said. “It’s almost like reading something you’ve written yourself.”

After they submitted a complaint to the ARC, the report was removed.

The researcher said the apparent use of AI pointed to the time pressures faced by academics in Australia and also a possible lack of quality control internally by the ARC.

“I think it’s a sign of someone being overworked and trying to cut corners … If you’ve used artificial intelligence to generate a response, you lose the ability to engage in a proper academic cut and thrust.”

Detailed assessor reports are typically written by academics in closely related fields and are used by the ARC’s College of Experts to decide which grant proposals should ultimately receive government funding. Only 19% of Discovery Projects in last year’s funding round were ultimately successful. The outcomes of the 2023 grant round have not yet been announced.

The affected researcher called for greater transparency from the ARC. Academics receive assessor reports on their grant proposals but are not concurrently given their scores for each corresponding report.

“If you suspect this is a ChatGPT report, but you don’t have the proof that I did, you have no way to respond to it. You should be able to … [point out if] the scores are inconsistent.”

The federal education minister, Jason Clare, told Guardian Australia in a statement: “The use of AI in this way is not acceptable.”

Clare said he had instructed the ARC to “put in place measures to ensure it doesn’t happen”.

Researchers who receive ARC money are required as a formal condition of their grant funding to write assessor feedback for other academics’ proposals. In a given year, researchers are asked to assess up to 20 proposals, which are each typically 50 to 100 pages long.

skip past newsletter promotion Sign up to Afternoon Update Free daily newsletter Our Australian afternoon update breaks down the key stories of the day, telling you what’s happening and why it matters Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy . We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply. after newsletter promotion

Andrew Francis, a professor of mathematics at Western Sydney University, said if information from grant proposals was being put into ChatGPT, that would constitute “a violation of confidentiality agreements that the assessor has signed on to”.

“If actual judgments are being generated by [Chat]GPT then it’s excruciatingly dishonourable on the part of the assessor,” Francis said. “To my mind, it’s academic misconduct worthy of being denied future funding.

“The ARC must make it extremely clear that using AI to make assessments is completely unacceptable.”

An Australian academic who runs the Twitter account ARC Tracker said they had read four assessor reports received by researchers “where it was just absolutely clear [and] no one could conclude anything else but that the assessments had been done by ChatGPT”. They were aware of four other instances of suspected generative AI use.

“Quality control of assessments has been something that researchers have been talking to the ARC about for a long time, and they’ve done basically nothing about it,” ARC Tracker’s administrator said.

In 2021, a pre-budget submission co-signed by more than 1,000 academics suggested that the ARC introduce consequences for inappropriate and unprofessional reviewer feedback.

“There’s enormous pressure on the peer review approach to assessing research in Australia,” ARC Tracker’s administrator added. “Most universities don’t give their researchers time in a formal and documented way to review anything – whether other people’s papers, grant proposals, proposals for using infrastructure … that’s counted in your research time.

“As any researcher will tell you, you can spend a lot of time assessing other people’s research while not getting any time for your own.

“The ARC should have seen this coming.”

In a public statement, the ARC advised that “peer reviewers should not use AI as part of their assessment activities”.

An ARC spokesperson told Guardian Australia that more than 7,000 assessors contributed to ARC peer review processes in 2021-22.

They said: “The ARC has a conflict of interest and confidentiality policy which outlines the requirements around confidentiality in the conduct of ARC business, including peer review. All ARC assessors confirm their acceptance of this policy when undertaking assessments.

“While generative artificial intelligence (AI) tools such as ChatGPT are not explicitly named in this policy, the common principles of confidentiality apply across both existing and emerging channels through which confidential information may be inappropriately disclosed.

“Developments in generative AI are fast-moving and bring complex considerations including the balance of opportunities and risks. The ARC is closely monitoring these developments and is engaging with other research funding agencies both in Australia and overseas on these issues.”