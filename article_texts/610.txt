More than 20 girls in Spain reported receiving AI-generated naked images of themselves. But can deepfakes be legally punished?

ADVERTISEMENT

When they returned to school after the summer holidays, more than twenty girls from Almendralejo, a town in southern Spain, received naked photos of themselves on their mobile phones.

None of them had taken the pictures, but they looked completely real.

The images had been stolen from their Instagram accounts, altered using an artificial intelligence application and then shared in Whatsapp groups.

The teenagers were fully clothed in the real photos, but the app made the nudity look completely real.

Now parents and prosecutors are asking whether a crime has been committed, even if the pictures are actually real - could the images be considered child pornography?

"The montages are super realistic, it's very disturbing and a real outrage," Miriam Al Adib, one of the girls' mothers, wrote on her Instagram account.

"My daughter told me with great disgust: 'Mum, look what they have done to me'," she added.

Al Adib even claimed that the photos could have reached internet portals such as Onlyfans or pornographic websites. All the while, the girls endured the comments of their classmates.

”Don't complain, girls upload pictures that almost show their p***y," one of the girls was told.

The youngest of the girls is only 11 years old and not yet in high school.

The mothers of some of the victims have denounced what has happened. Canva

Another mother, Fátima Gómez, told Extremadura TV that her daughter had been blackmailed.

In a conversation with a boy on social media, he asked her for money and when she refused, he sent her a naked picture.

The mothers have organised themselves to complain about what has happened, and the National Police have opened an investigation and already identified several minors allegedly involved.

Some of them are classmates of the girls, a local politician revealed.

The case has been referred to the Juvenile Prosecutor's Office, and the mayor of the town himself warned: "It may have started as a joke, but the implications are much greater and could have serious consequences for those who made these photos".

€10 euros for 25 nude photos

The hyper-realistic artificial intelligence creations, better known as deepfakes, were made with the ClothOff app.

With the slogan "Undress anybody, undress girls for free", the app allows users to take the clothes off from anyone who appears in their phone's picture gallery. It costs €10 to create 25 naked images.

Although the nudity is not real, the mothers say that the girls' distress at seeing their picture is very real indeed.

ADVERTISEMENT

"You are not aware of the damage you have done to these girls and you’re also unaware of the crime you have committed," Al Adib said on her Instagram account in a message addressed to the people who shared the pictures.

"My daughter was told by one of them that he had done ‘things’ with her photo," another of the mothers told Spanish newspaper El País.

But can deepfakes be legally punished?

"One question is whether it should be punished and another is whether it can be punished by the way the law is drafted in Spain and in other EU countries," Manuel Cancio, professor of criminal law at the Autonomous University of Madrid, told Euronews.

The professor points out that there is a legal loophole because the use of minors' faces in photographs affects their privacy, but when it comes to crimes in which intimate images are distributed, it is the image as a whole that violates privacy.

ADVERTISEMENT

"Since it is generated by deepfake, the actual privacy of the person in question is not affected. The effect it has (on the victim) can be very similar to a real nude picture, but the law is one step behind," he adds.

Cancio says that the legal framework that could work in this case would be a crime against moral integrity, "a kind of disaster box for crimes that no one knows where to put".

In March 2022, the European Commission proposed criminalising this type of offence in a directive on cybercrime. According to the professor, the Dutch Criminal Code is the only one that has a provision addressing this issue.

National Police have opened an investigation and already identified several minors allegedly involved. Canva

Can it be considered child pornography?

Experts are divided as to whether the crime could be considered distribution of child pornography, which would carry a higher penalty, and prefer to err on the side of caution.

For Leandro Núñez, a lawyer specialising in new technologies at the Audens law firm, the key is not whether the photo is 100% real, but whether it appears to be.

ADVERTISEMENT

"The most important thing is whether the face is identifiable. We could be talking about child pornography, crimes against moral integrity or the distribution of images of non-consensual sexual content," the lawyer told Euronews.

"In the case of a crime against moral integrity, it would be considered a lesser crime, so it would carry a lesser sentence of six months to two years in prison," he adds.

Other experts, such as Eloi Font, a lawyer at Font Advocats, a law firm specialising in digital law, believe that it could be classified as a crime similar to the reproduction of sexual images of minors.

In this case, the penalty could be between five and nine years in prison.. In Spain, authorities are currently looking into a distressing case that has sent shockwaves across the nation. Several underage girls have become the victims of a fake nude images scandal.

These images which were created using an Artificial Intelligence (AI) tool have caused distress to the victims, who in some cases found themselves facing bullying and/or distressing comments from their classmates.

Deepfake porn

In the town of Almendralejo which is situated in the southwestern reaches of Spain, local law enforcement is dealing with 11 complaints from victims, all of whom are minors.

Speaking to AFP, a spokesperson from the local police said that those responsible for these abhorrent deeds employed a sinister method. They "manipulated photos of underage girls", superimposing their innocent faces onto the "bodies of other people" in other images.

Small price, huge ramifications

As per EuroNews, these images were created using an Artificial Intelligence (AI) tool application using which users can 'take clothes off' of anyone they have a picture of, that too, for prices as low as €10.

The app boasts the capability of crafting eerily realistic photo montages, has the slogan "Undress anybody, undress girls for free," reports EuroNews.

As per reports from Spanish media outlets, an estimated 20 girls may have tragically become the victims of these deep fake porn images.

One concerned parent, Miriam Al Adib, a mother of a 14-year-old victim, underscored the gravity of the situation. Talking to the press, she said: "This is very serious."

Also read | Breakthrough? Google develops AI tool capable of predicting harmful genetic mutations

Taking to Instagram, she recounted how her distraught daughter had showed her one such photo.

"When I came home, one of my daughters, who was really upset, told me: 'look what they did'. It turns out they took a photo of her, and they made it seem as if she was naked with the aid of artificial intelligence."

"Girls, don't be afraid to report such acts. Tell your mothers. Affected mothers, tell me, so that you can be in the group that we created," she added.

Another mother revealed that using these fake nude images, someone had attempted to extort her daughter. Allegedly, the creators of these images demanded monetary payment in exchange for their silence.

Furthermore, it has come to light that these manipulated images may have been disseminated on various platforms, including OnlyFans, an online subscription service notorious for adult content, and explicit websites.

(With inputs from agencies)

WATCH WION LIVE HERE

You can now write for wionews.com and be a part of the community. Share your stories and opinions with us here.. "I saw a naked photo of you."

Dystopia Now

"I saw a naked photo of you."

Those were the chilling words a boy told a 14-year-old girl after she arrived on the first day of school this year in Spain, Spanish newspaper El Pais reports. AI-generated, deepfake nudes of her and other female classmates were being circulated online across four schools, stoking despair among the victims and their parents. There even was one case of alleged blackmail.

"Mom, they say there’s a naked photo of me going around," the girl told her mother, as quoted by El Pais. "That they did it with an artificial intelligence app. I’m scared. Some girls have also received it.”

The case sparked a round of parental outrage in the town of Almendralejo, and the local Juvenile Prosecutor’s Office is now handling the investigation, according to the report, with 20 victims impacted so far and a group of suspected culprits behind the deepfakes already identified.

The deepfake app the culprits allegedly used is free to use and accessible to anybody with a smartphone — a dystopian use of AI tech that could continue to cause mayhem in schools and elsewhere.

Deepfaked

One of the girls, according to El Pais, was approached on Instagram by a boy who demanded money. When she turned him down, he sent her a deepfake naked photo of herself.

As the tech becomes more accessible, we should expect this kind of stuff to happen more and more. Meanwhile, in the US, the FBI sent out a warning earlier this year about deepfakes being used for extortion.

"The FBI continues to receive reports from victims, including minor children and non-consenting adults, whose photos or videos were altered into explicit content," the agency said in its statement.

To stem this tide, attorney generals from every single state in the US sent a letter to Congress earlier this month, urging a commission and action against the increase of AI-generated child sexual abuse material (CSAM).

The Washington Post reported in June that experts had noticed an increase in the dissemination of AI-generated CSAM, which is already hampering efforts to identify the many victims.

It remains to be seen if any upcoming regulations will help forestall the tide of deeply disturbing deepfake images, especially considering the proliferation of open-source generative AI and how long it takes for governments to agree on a solution.

More on deepfakes: Every Single State’s Attorney General Is Calling for Action on AI-Generated Child Abuse Materials. 