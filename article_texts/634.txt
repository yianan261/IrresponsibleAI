CNN —

A finance worker at a multinational firm was tricked into paying out $25 million to fraudsters using deepfake technology to pose as the company’s chief financial officer in a video conference call, according to Hong Kong police.

The elaborate scam saw the worker duped into attending a video call with what he thought were several other members of staff, but all of whom were in fact deepfake recreations, Hong Kong police said at a briefing on Friday.

“(In the) multi-person video conference, it turns out that everyone [he saw] was fake,” senior superintendent Baron Chan Shun-ching told the city’s public broadcaster RTHK.

Chan said the worker had grown suspicious after he received a message that was purportedly from the company’s UK-based chief financial officer. Initially, the worker suspected it was a phishing email, as it talked of the need for a secret transaction to be carried out.

However, the worker put aside his early doubts after the video call because other people in attendance had looked and sounded just like colleagues he recognized, Chan said.

Hong Kong's famous skyline. Dale De La Rey / AFP

Believing everyone else on the call was real, the worker agreed to remit a total of $200 million Hong Kong dollars – about $25.6 million, the police officer added.

The case is one of several recent episodes in which fraudsters are believed to have used deepfake technology to modify publicly available video and other footage to cheat people out of money.

At the press briefing Friday, Hong Kong police said they had made six arrests in connection with such scams.

Chan said that eight stolen Hong Kong identity cards – all of which had been reported as lost by their owners – were used to make 90 loan applications and 54 bank account registrations between July and September last year.

On at least 20 occasions, AI deepfakes had been used to trick facial recognition programs by imitating the people pictured on the identity cards, according to police.

The scam involving the fake CFO was only discovered when the employee later checked with the corporation’s head office.

Hong Kong police did not reveal the name or details of the company or the worker.

Authorities across the world are growing increasingly concerned at the sophistication of deepfake technology and the nefarious uses it can be put to.

At the end of January, pornographic, AI-generated images of the American pop star Taylor Swift spread across social media, underscoring the damaging potential posed by artificial intelligence technology.

The photos - which show the singer in sexually suggestive and explicit positions - were viewed tens of millions of times before being removed from social platforms.. At HuffPost, we believe that everyone needs high-quality journalism, but we understand that not everyone can afford to pay for expensive news subscriptions. That is why we are committed to providing deeply reported, carefully fact-checked news that is freely accessible to everyone.

Whether you come to HuffPost for updates on the 2024 presidential race, hard-hitting investigations into critical issues facing our country today, or trending stories that make you laugh, we appreciate you. The truth is, news costs money to produce, and we are proud that we have never put our stories behind an expensive paywall.

Would you join us to help keep our stories free for all? Your contribution of as little as $2 will go a long way.

Can't afford to donate? Support HuffPost by creating a free account and log in while you read.. A Hong Kong-based finance professional at a multinational was reportedly swindled out of $25 million (HK$200 million) of company money when scammers created a deepfake of his London-based chief financial officer in a video conference call.

The Hong Konger joined a vidchat in which his CFO appeared – but appeared a little off. So much so that the employee was initially suspicious. But his nerves were soothed as other colleagues he recognized appeared to join in on the call, the Hong Kong police reportedly explained.

The fake CFO made increasingly urgent entreaties to execute money transfers, and the victim complied with instructions given during the call – eventually making 15 transfers into five local bank accounts.

The AI-generated videos were reportedly created from past genuine online conferences. To add depth and credibility to the scam, the perpetrators utilized WhatsApp, email and one-to-one video conferences with Hong Kong staff members.

"I believe the fraudster downloaded videos in advance and then used artificial intelligence to add fake voices to use in the video conference," reported the city’s police senior superintendent, Baron Chan Shun-ching.

What else exactly happened on the fateful call is disputed. Some reports suggest just one participant on the call was real, while others suggest multiple participants were human.

All agree that AI-generated humans appeared and that sadly, the unnamed finance professional was duped. That reality was only discovered by the victim after he contacted the (also unnamed) corporation's head office.

Local media outlet The Standard declared the incident the first deepfake video conference scam in Hong Kong.

In a simpler, more innocent time – around a year and a half ago – Sophos researcher John Shier told The Reg deepfakes weren't much of a threat.

According to Shier, scammers preferred simpler and cheap attacks, like old fashioned phishing.

Whether driven by the appeal of larger financial incentives, or influenced by the recent significant advancements in AI technology that facilitate their creation, it seems that the era of being unconcerned about deepfakes is fast disappearing.

While the deepfaked CFO scam may be the first reported in Hong Kong to use video conferencing, it's not the only scam using the technology. According to CNN, Hong Kong police revealed in a Friday press briefing they had made six arrests in connection with other deepfake scams and that AI deepfakes had been used at least 20 times to trick facial recognition software.

The deepfake problem is also global. US senators last week introduced a bipartisan bill that would allow victims portrayed in in non-consensual AI-generated pornographic deepfakes to sue the creators of the videos.

That move came after sexually explicit AI-generated images of Taylor Swift proliferated across social media platforms – including on X/Twitter, where they racked up tens of millions of views before the Musk-owned site blocked searches for the pop icon.

India has had similar problems when a way less graphic – but still personally and professionally violating – AI-generated video of Indian actor Rashmika Mandanna appeared online in November.

Indian IT minister Rajeev Chandrasekhar reportedly warned in late January that social media platforms would be held accountable for deepfakes their users post. ®. Hong Kong police have launched an investigation after an employee at an unnamed company claimed she was duped into paying HK$200m (£20m) of her firm’s money to fraudsters in a deepfake video conference call.

The Hong Kong police force said it had received a report from a worker that she had been tricked into transferring the money by someone “posing as senior officers of the company”.

“Police received a report from a staff member of a company on 29 January that her company was deceived of some HK$200m after she received video conference calls from someone posing as senior officers of the company requesting to transfer money to designated bank accounts,” said police in a statement.

The force added that after an initial investigation the case had been classified as “obtaining property by deception” and was being handled by its cybercrime unit. No arrests have been made so far and investigations are continuing.

Hong Kong’s public broadcaster, RTHK, reported that the employee was a clerk working for an unnamed multinational firm. It quoted acting senior superintendent Baron Chan as speculating that the fraudster used artificial intelligence to dupe the worker.

“[The fraudster] invited the informant [clerk] to a video conference that would have many participants. Because the people in the video conference looked like the real people, the informant … made 15 transactions as instructed to five local bank accounts, which came to a total of HK$200m,” he said.



“I believe the fraudster downloaded videos in advance and then used artificial intelligence to add fake voices to use in the video conference.”

RTHK added that the worker received a message from the company’s chief financial officer that talked of the need for confidential transactions. It was only after going on the call and sending the money that the employee spoke to the company’s head office and realised it was a scam, reported RTHK.

“We can see from this case that fraudsters are able to use AI technology in online meetings, so people must be vigilant even in meetings with lots of participants,” said Chan.

AI-generated deepfakes are proliferating online, with social media platform X being forced to suspend Taylor Swift-related searches last month after fake sexually explicit images of the pop singer flooded its site. A fake version of US president Joe Biden’s voice was also used in robocalls to voters in the New Hampshire primary last month.

The UK’s cybersecurity agency warned in January that AI was making it increasingly difficult to identify phishing messages – where users are tricked into handing over passwords or personal details.. A deepfake video conference call paired with social engineering tricks has led to the theft of over US$25 million from a multinational firm, the South China Morning Post has reported.

The scheme and the deepfake video conference call

The attack started with messages sent to several of the firm’s employees, but it seems that only one – employed in the finance department of the company’s Hong Kong branch’s – was ultimately bamboozled.

According to the SCMP, the employee’s suspicion were raised when they received the message, purportedly by the company’s UK-based Chief Financial Officer, asking the employee to carry out a secret transaction. But they have been later quelled by a group video conference to which the employee was invited.

Present in the video conference were the company’s CFO, other company staff and even outsiders – or so it seemed.

In reality, the fraudsters used previous video and audio footage and artificial intelligence technology to create the illusion these individuals were present on the call and make these digital recreations “speak” to pull off the illusion.

Baron Chan Shun-ching, a superintendent with Hong Kong Police’s cyber security division, told the SCMP that “during the video conference, the scammers asked the victim to do a self-introduction but did not actually interact with the person. The fake images on screen mainly gave orders before the meeting ended abruptly.”

After the call, the scammers delivered additional instructions via IM, emails and one-on-one video calls. As instructed, the employee sent a total of HK$200 million to five local bank accounts.

Several other employees at the same company branch have also contacted by the scammers, the Hong Kong police said, but did not share how those interactions unfolded.

Deepfakes are getting more difficult to spot

AI-generated deepfakes (whether audio or video) are increasingly being leveraged by scammers and other crooks.

They are using artificial intelligence to impersonate family members in distress, impersonate individuals to open bank accounts or make fraudulent purchases in their name, apply for loans, obtain remote IT jobs, and (as in this case) trick executives and employees into transfering company money.

Most people overestimate their deepfake detection skills. This is all new territory, and deepfakes are getting more realistic and more difficult to spot by the day.

“We want to alert the public to these new deception tactics. In the past, we would assume these scams would only involve two people in one-on-one situations, but we can see from this case that fraudsters are able to use AI technology in online meetings, so people must be vigilant even in meetings with lots of participants,” Chan Shun-ching said during a press event.

The Hong Kong Police has advised the public to ask questions during these meetings, ask the participants to move, and confirm requests made during those calls via alternative communication channels.. A deepfake phishing scam cost a multinational company more than $25 million after an employee was fooled by digital imitations of his colleagues on a conference call.

Hong Kong police said at a press conference Friday that the employee at the unnamed firm’s Hong Kong branch initially suspected phishing when he received an email last month purporting to be from the company’s UK-based chief financial officer, CNN reported.

However, after attending a video conference and seeing convincing deepfakes of the CFO and other colleagues, the employee believed the request to carry out a secret transaction was legitimate.

The finance worker ultimately transferred $200 million HKD, the equivalent of about $25.6 million USD, to five different bank accounts across 15 transactions, following the fake colleagues’ instructions, according to The Straits Times.

The scam was revealed one week after the initial contact, when the employee reached out directly to the company’s headquarters. The case is under investigation and no arrests have yet been made, police said.

“Employees may still assume today that live audio or video cannot be faked, and act on requests they are given by colleagues or leaders without question — as we have seen in this recent case,” said Nick France, chief technology officer at Sectigo, in an email to SC Media. “Security teams should see this as another threat to their organizations and update their practices and training accordingly.”

Would you fall for this deepfake scam?

Authorities said publicly available footage of the CFO and other employees was used to create the deepfake images, and the victim was the only person on the conference call who was not a deepfake.

Two or three other employees of the same company had also been approached by the scammers, although details about these interactions were not disclosed by police.

During the video call, the employee said he was asked to give a self-introduction but did not directly interact with anyone else in the meeting, authorities said. The deepfake colleagues and CFO provided the victim with instructions, after which the call was ended abruptly.

The employee reported that both the live images and voices of the others on the call seemed real and recognizable to him. Police noted the case was the first in Hong Kong to involve multiple deepfakes in one video call.

“This was an elaborate crime. There are ways to apply cybersecurity protection to thwart these types of phishing on collaboration tools like Teams, Slack and Zoom. However, it needs to be combined with physical security protocols and training, because these types of crimes are morphing and technology is lagging behind,” Patrick Harr, CEO at anti-phishing company SlashNext, told SC Media.

Research suggests many people are not yet prepared to spot deepfakes. A survey by iProov in 2022 showed 43% of respondents did not believe they could tell the difference between a real video and a deepfake, and only 29% of respondents initially knew what a deepfake was.

Additionally, a study published in June 2023 in the Journal of Cybersecurity showed participants asked to distinguish between AI-generated and real human faces had a 62% accuracy rate overall.

Deepfake spear-phishing a new normal for cybersecurity?

Deepfake scams are becoming more common, with identity verification company Onfido detecting a 3,000% increase in deepfake fraud attempts between 2022 and 2023. Gartner predicts 30% of companies will lose faith in facial biometric authentication solutions by 2026 due to deepfake injection attacks.

Deepfakes have also proved successful in stealing large amounts of money from organizations in previous scams. In 2020, a branch manager of a Japanese company in Hong Kong sent $35 million to scammers after they used AI to clone the voice of the parent company’s director in a phone call, according to Forbes.

In 2021, fraudsters in China raked in the equivalent of $75 million via fake tax invoices by fooling government-run facial recognition systems with deepfakes, the South China Morning Post reported.

Last year, Hong Kong police said they caught scammers using AI deepfakes and stolen ID cards to make dozens of fraudulent loan applications and bank account registrations, with deepfake scams resulting in a total of six arrests overall.

Cybersecurity experts say businesses need to account for advanced spear-phishing tactics like deepfakes when updating security training programs and managing permissions for money transfers.

“There should be multiple approval levels before money is transferred, even when the CFO is requesting the transfer,” said Harr. “Companies can require all corporate video communications happen on approved collaboration channels that are secure and employees should be trained to question unusual behavior like requests to use new bank accounts or requests that seem out of the usual process.”

“Adhere to the principles of ‘least privilege,’ so employees only have access to the accounts and systems they need to perform their roles. Confirm payments and access to critical data with additional confirmations — even if you know the face on the screen,” France added.

France concluded: “Update training programs to ensure not only users are aware of the possibility of fully-forged video, but that they should be encouraged and empowered to raise concerns, or ask for additional verification or confirmation before taking business-critical actions.”. Fraudsters used deepfake technology to arrange a bogus video conference call and elaborately trick a finance worker at a multinational firm into paying out $25 million.

The name of the Hong Kong branch of this multinational company is not specified by the police. But, according to the South China Morning Post, an employee of the firm was fooled after seeing digitally recreated versions of the company's chief financial officer and others in a video call.

At a briefing, Hong Kong police said the unnamed male employee thought that the people on the conference call were real when in fact they were convincing digital replicas. Finally, he paid out approximately $25 million to the scammers.

At first, though, the worker was suspicious. When he received a message allegedly sent by the company’s UK-based chief financial officer, he suspected it was a phishing email. But he cast away any doubts after joining the conference call and recognizing his colleagues.

And when the scammers then gave the employee orders to transfer the money to five separate Hong Kong bank accounts, he agreed to do 15 transfers totalling $25 million. The scam was only discovered when the employee later checked with the company’s head office, the SCMP said.

Deepfake technology was used to turn publicly available video and other footage of staff members into convincing meeting participants. The entire episode lasted a week.

The case is one of several recent episodes in which fraudsters are believed to have used deepfake technology to modify publicly available video and other footage to cheat people out of money. Hong Kong police said they had made six arrests in connection with such scams.

Most scammers use the technology to make loan applications and bank account registrations in one-on-one video calls but this case is the first of its kind in Hong Kong which also involved a large amount of money.

This sort of fraud might only get worse. For instance, a deepfake of Jennifer Aniston promoting a “MacBook giveaway” recently went viral on YouTube, and the likeness of Taylor Swift was also used earlier this month to promote a fake Le Creuset cookware giveaway on Facebook and TikTok.

Fake sexually explicit images of Swift spread recently on social media as well, highlighting the growing problem of non-consensual deepfake pornography online.

A group of US senators have now introduced the Disrupt Explicit Forged Images and Non-Consensual Edits (DEFIANCE) Act, legislation that would “hold accountable those responsible for the proliferation of nonconsensual, sexually-explicit deepfake images and videos.”

Creators of such images would be subject to civil action lawsuits over digital forgery and entitle the victim with financial damages as relief.

More from Cybernews:

Ex-CIA hacker jailed for 40 years for his role in WikiLeaks

Murder suspect freed after cyberattack

TikTokers losing access to Taylor Swift, Billie Eilish songs

Cloudflare reveals Thanksgiving breach by 'sophisticated actor'

Apple Vision Pro apps offer 3D bonanza

Subscribe to our newsletter. The Hong Kong branch of a multinational company has lost $25.6 million (HK$200 million) after scammers using deepfake technology posed as the firm’s chief financial officer (CFO) in a video conference call and ordered money transfers, according to the police, in what is being highlighted as first of its kind cases in the city.

First of its kind in Hong Kong

The money transaction was ordered during a meeting where it was found that everyone present on the video call except the victim were deepfakes of real people, said the Hong Kong police, on Friday (Feb 2).

The police highlighted this case as being the first of its kind in Hong Kong which also involved a large amount of money. However, they did not reveal the identity of the employee or the company.

Acting senior superintendent Baron Chan Shun-ching said that in previous cases the scam victims were tricked by one-on-one video calls.

“This time, in a multi-person video conference, it turns out that everyone you see is fake,” said the Hong Kong police official, as quoted by the South China Morning Post (SCMP).

Scammers in this case used deepfake technology to turn publicly available video and other footage of staff members into convincing meeting participants.

What we know about the case

According to Chan, the worker involved had been suspicious since he received the message purportedly from the company’s United Kingdom-based CFO and first dismissed it as a phishing email back in January. However, the talks of the need for a secret transaction continued.

The worker, according to Chan, dismissed the doubts after the video call because other people in attendance had looked and sounded just like colleagues and some others he recognised.

ALSO READ | US brings new bill to tackle deepfakes post Taylor Swift AI nudes scandal

The police official also said that scammers asked the victim to introduce himself but did not actually interact with the person during the meeting. Additionally, the fake images on the screen mainly gave orders before the call ended abruptly.

The employee then followed the instructions and made 15 transfers totalling $25.6 million to five Hong Kong bank accounts.

The entire episode lasted a week before the worker involved made an inquiry with the company’s headquarters.

Six people arrested

Amid a number of such incidents, Chan said the police have arrested six people so far. He also spoke about eight stolen Hong Kong identity cards involved in scams.

ALSO READ | South Korea imposes 90-day ban on deepfake political campaign videos



According to the police, there have been at least 20 such incidents where AI deepfakes have been used to trick facial recognition programmes into making 90 loan applications and 54 bank account registrations, by imitating the people pictured on the identity cards, between July and September last year.. Scammers tricked a multinational firm out of some $26 million by impersonating senior executives using deepfake technology, Hong Kong police said Sunday, in one of the first cases of its kind in the city.

Law enforcement agencies are scrambling to keep up with generative artificial intelligence, which experts say holds potential for disinformation and misuse — such as deepfake images showing people mouthing things they never said.

A company employee in the Chinese finance hub received "video conference calls from someone posing as senior officers of the company requesting to transfer money to designated bank accounts," police told AFP.

Police received a report of the incident on January 29, at which point some HK$200 million ($26 million) had already been lost via 15 transfers.

"Investigations are still ongoing and no arrest has been made so far," police said, without disclosing the company's name.

The victim was working in the finance department, and the scammers pretended to be the firm's U.K.-based chief financial officer, according to Hong Kong media reports.

Acting Senior Superintendent Baron Chan said the video conference call involved multiple participants, but all except the victim were impersonated.

"Scammers found publicly available video and audio of the impersonation targets via YouTube, then used deepfake technology to emulate their voices... to lure the victim to follow their instructions," Chan told reporters.

The deepfake videos were pre-recorded and did not involve dialogue or interaction with the victim, he added.. A company lost $25 million after an employee was tricked by deepfake versions of his colleagues, Hong Kong police say.

The person had attended a video call with deepfakes of the firm's UK-based CFO and other colleagues.

Hong Kong police said scammers created the deepfakes based on publicly available video.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Advertisement

Scammers made off with about $25 million after they used deepfake technology to trick an employee at the Hong Kong branch of a multinational company, local media reported on Sunday, citing the city's police.

In January, an employee in the company's finance department received a message from someone who said they were the company's UK-based chief financial officer, South China Morning Post reported, citing police. The employee then had a video call with the company's CFO and other company employees — all of which turned out to be deepfakes.

Based on instructions they got during that call, the employee transferred HK$200 million, or $25.6 million, to various Hong Kong bank accounts across 15 transfers, according to the SCMP.

Related stories

It was a week into the scam, when the employee contacted the company's headquarters, that they realized something was wrong.

Advertisement

The Hong Kong police did not name the company or employees involved. They said scammers created deepfakes of meeting participants based on publicly available video and audio footage, per SCMP.

The employee who was scammed did not interact with the deepfakes during the video conference, according to the media outlet.

Investigations are ongoing, although no arrests have been made, according to the media outlet.

Deepfake videos are causing global concerns. Superstar Taylor Swift is one of the latest to be caught up in a wave of sexually explicit deepfake videos that went viral on X and Telegram last month.

Advertisement

Many politicians are calling for a federal law to combat deepfakes.

In May 2023, Democratic Rep. Joseph Morelle introduced the Preventing Deepfakes of Intimate Images Act that would make it illegal to share non-consensual deepfake pornography. The bill has been referred to the House Judiciary Committee.. A multinational company’s Hong Kong office was the victim of an elaborate scam using deepfake video technology to impersonate executives and scam the company out of HK$200 million ($25.6 million), local police reported on Sunday (Jan 4).

In what police described as the first scam of its kind in Hong Kong, scammers used deepfake technology to digitally recreate company executives and impersonate them on a video conference call. The technology allowed the scammers to generate fake but convincing representations of targeted individuals that replicated their voices and appearances.

The scam began in mid-January when an employee in the Hong Kong branch’s finance department received a phishing message, seemingly from the company’s UK-based chief financial officer, reports the South China Moring Post. The message claimed a secret transaction had to be conducted. Although initially doubtful, the employee was convinced after being invited to a video call in which the CFO and other familiar employees appeared to be present.

Except, of course, it wasn’t actually the CFO on the call.

‘Everyone is fake’

According to Acting Senior Superintendent Baron Chan Shun-ching, not only did the virtual recreations of each participant look and sound like their real-life counterparts, they were even able to interact to some degree on the call by giving orders. However, if questioned more deeply, it’s believed their impersonations would have faltered.

“This time, in a multi-person video conference, it turns out that everyone you see is fake.” said Chan

He added: “They used deepfake technology to imitate the voice of their targets reading from a script”

The scam proceeded for about a week before the employee grew suspicious and checked with company headquarters. Police investigation revealed the meeting participants were digitally faked by scammers harvesting public footage of the executives and using deepfake technology to imitate their voices and likenesses reading from a script.

Local authorities did not reveal the name of the company caught in this scam.

To avoid falling victim to similar scams using deepfake technology, Supt. Chan advised asking the person to move their head or pose questions to check their authenticity. One should also immediately suspect foul play if money is requested during a call.

The sophistication of this nefarious technology is developing rapidly. Last week X was forced to block searches for popstar Taylor Swift after explicit AI-generated deepfake images of the pop star went viral.

Featured Image: Dall-E. On Sunday, a report from the South China Morning Post revealed a significant financial loss suffered by a multinational company's Hong Kong office, amounting to HK$200 million (US$25.6 million), due to a sophisticated scam involving deepfake technology. The scam featured a digitally recreated version of the company's chief financial officer, along with other employees, who appeared in a video conference call instructing an employee to transfer funds.

Due to an ongoing investigation, Hong Kong police did not release details of which company was scammed.

Deepfakes utilize AI tools to create highly convincing fake videos or audio recordings, posing significant challenges for individuals and organizations to discern real from fabricated content.

This incident marks the first of its kind in Hong Kong involving a large sum and the use of deepfake technology to simulate a multi-person video conference where all participants (except the victim) were fabricated images of real individuals. The scammers were able to convincingly replicate the appearances and voices of targeted individuals using publicly available video and audio footage. The Hong Kong police are currently investigating the case, with no arrests reported yet.

The scam was initially uncovered following a phishing attempt, when an employee in the finance department of the company's Hong Kong branch received what seemed to be a phishing message, purportedly from the company’s UK-based chief financial officer, instructing them to execute a secret transaction. Despite initial doubts, the employee was convinced enough by the presence of the CFO and others in a group video call to make 15 transfers totaling HK$200 million to five different Hong Kong bank accounts. Officials realized the scam occurred about a week later, prompting a police investigation.

Advertisement

The high-tech theft underscores the growing concern over new uses of AI technology, which has been spotlighted recently due to incidents like the spread of fake explicit images of pop superstar Taylor Swift. Over the past year, scammers have been using audio deepfake technology to scam people out of money by impersonating loved ones in trouble.

Acting senior superintendent Baron Chan Shun-ching of the Hong Kong police emphasized the novelty of this scam, noting that it was the first instance in Hong Kong where victims were deceived in a multi-person video conference setting. He pointed out the scammer's strategy of not engaging directly with the victim beyond requesting a self-introduction, which made the scam more convincing.

The police have offered tips for verifying the authenticity of individuals in video calls, such as asking them to move their heads or answer questions that confirm their identity, especially when money transfer requests are involved. Another potential solution to deepfake scams in corporate environments is to equip every employee with an encrypted key pair, establishing trust by signing public keys at in-person meetings. Later, in remote communications, those signed keys could be used to authenticate parties within the meeting.

Additionally, the Hong Kong police plan to enhance their alert system covering the Faster Payment System (FPS) to include warnings for transactions linked to known scams, expanding the coverage to include a broader range of electronic and in-person transactions by the second half of the year.. . Fraudsters used past meetings to create AI deepfakes of the firm’s chief financial officer and other staff to scam an employee into transferring company funds

An employee at a Hong Kong branch of a multinational firm was scammed into paying out 200 million HKD (more than $25 million) of company funds after a conference call in which every single participant — other than the worker — was a deepfake, the city’s public broadcaster reported.

Fraudsters, who are yet to be caught, used the company’s past meetings to create artificial intelligence-generated deepfakes of its chief financial officer (CFO) and several other employees to execute the elaborate scam, Radio Television Hong Kong reported on Sunday.

“In the past, we would assume these scams would only involve two people in one-on-one situations, but we can see from this case that fraudsters are able to use AI technology in online meetings,” Hong Kong police’s acting senior superintendent Baron Chan said.

Also on AF: Huawei Smartphone Output Hit, As Demand Soars For AI Chips

“I believe the fraudster downloaded videos in advance and then used artificial intelligence to add fake voices to use in the video conference,” Chan was quoted as saying by RTHK.

Hong Kong police said the scam began last month, with the fraudster posing as the London-based firm’s chief financial officer and inviting the duped employee into a meeting with several of his co-workers.

On joining the meeting, the employee had a “moment of doubt” but fell for the scam because everyone on the call ‘looked and sounded real’, police said.

The scammers “used deepfake technology to imitate the voice of their targets reading from a script,” the South China Morning Post quoted Chan as saying. They “found publicly available video and audio of the impersonation targets via YouTube,” Chan said, according to CNN.

Following the meeting, the duped employee made 15 transactions amounting to HK$200 million within a week on the deepfake CFO’s instructions. The money was sent to five local bank accounts, auhtorities said.

The scammers also stayed in touch with the employee after the scam via WhatsApp, emails and one-on-one video calls, the SCMP said, adding that they also approached at least two other people at the branch using the same methods.

The employee — who was the only real person in that meeting — realised he had been scammed, during a call with the company’s head office later, police said.

Hong Kong newspaper The Standard said this was the first deepfake fraud involving such a large sum in the city.

A similar scam was reported in China last year, in which a tech worker was duped of $600,000 over a video call in which his “friend” asked for money to bid on a project.

Deepfake scams on the rise in Hong Kong

Deepfakes are realistic human faces — virtually undetectable to cybersecurity experts — generated using a technology called a generative adversarial network, or GAN.

Several AI tools and software, powered by the technology, have flooded the market, making it easy for anyone to create genuine-looking replicas of real people.

Deepfake videos available online are increasing 900% year-on-year, according to a recent KPMG report. “Deepfake-as-a-Service” opportunities have also imploded on the dark web, the report added.

Increasingly available AI tools have also made it possible to copy a person’s voice to make their deepfake uncannily believable.

In April last year, US-based Jennifer DeStefano reported receiving a telephone call with the voice of her 15-year-old daughter in a purported $1 million ransom call. DeStefano eventually discovered her daughter had not been kidnapped and testified about her ordeal in Congress in June.

Realistic deepfakes unfolded major controversy in the US again last month after explicit AI-generated images of pop star Taylor Swift flooded social media.

In Hong Kong, meanwhile, police say AI deepfakes were used at least 20 times for loan applications and bank account registrations between July and September last year.

Losses from technology-related crimes for the year were up 72% compared to 2022, amounting to 5.1 billion HKD ($652 million), they added.

Vishakha Saxena

Also read:. What is easily the most ambitious deepfake scam yet has taken place in Hong Kong, where attackers were able to convince an employee of an unnamed company to transfer HK$200 million (about $25 million) via a fake video conference populated by simulations of the CFO and other personnel. Fraud involving deepfake audio is increasingly common, but this is the first known scheme of this sort to incorporate fake representations of multiple people.

The simulated employees involved in the heist all had a public presence that the attackers made use of, and were apparently accurate enough in their efforts to make the deepfake scam work. The employee that was targeted reportedly did suspect fraud at first, but nevertheless ended up making a total of 15 bank transfers.

Deepfake scam establishes feasibility of fake video in business compromise schemes

The deepfake scam began with a phishing email from someone purporting to be the company’s chief financial officer (CFO). The employee was initially suspicious of fraud as the message sought to arrange a “secret transaction,” but the deepfake scam team was apparently able to close the deal by pressuring them into a video group chat.

That chat was entirely controlled by the attacker and used deepfake representations of the CFO and other company employees that have a public presence, at least some of whom were personally familiar to the employee. The fraud was not uncovered until a week later when the employee checked in with the company’s head office about the transactions.

Baron Chan, senior superintendent of the Hong Kong police’s cyber security division, said that it does not appear the deepfake scam made use of real-time video for most of the participants. Chan told the media that he believed videos of the participants had been downloaded from other sources, and the attackers used deepfake audio (trained on their prior public appearances) to simulate their voices in real time.

In making a public statement on the incident, Hong Kong police noted that deepfake scam activity is on the rise in their jurisdiction. The police reported at least 20 cases of fraud in the past year in which someone used deepfake video in an attempt to trick a facial recognition system.

No arrests have yet been made in relation to the deepfake scam, and the police say they are continuing to investigate. The company that was targeted has not been publicly identified, but public broadcaster RTHK said that it was a “multinational firm.”

Nick France, Chief Technology Officer at Sectigo, urges cybersecurity teams to take note of this incident: “With deepfake technology, we can no longer trust what we see and hear remotely. Perfectly-written phishing emails, audio messages with the correct tone, and now even fully fake video can be created easily and used to socially engineer into companies and steal money or valuable data and intellectual property. Employees may still assume today that live audio or video cannot be faked, and act on requests they are given seemingly by colleagues or leaders without question – as we have seen in this recent case. Security teams should see this as another threat to their organisations and update their practices and training accordingly. Following best practices for cyber security – adhere to the principles of ‘least privilege’, so employees only have access to the accounts and systems they need to perform their roles. Confirm payments and access to critical data with additional confirmations – even if you know the face on the screen.”

Dr Ilia Kolochenko, CEO and Chief Architect at ImmuniWeb, thinks that Zoom and similar platforms that attackers will make use of in this way will have to play a part in detection and prevention of deepfake scams: “I don’t think that enacting additional laws to regulate deep fakes will be a solution, moreover, in most countries use of deep fakes for illicit purposes is already a criminally punishable offense under the existing laws. What we really need is to add AI-content detection mechanisms to all major social networks and platforms where users can share content, as well as integrating detection of AI-generated content to spam filters, so all non-human content will be visibly marked as such.”

AI-enhanced fraud becoming more effective by the day

AI is already being applied to enhance all sorts of cyber crime and fraud. Scam messages and emails have been the first area to see major enhancement, with attackers able to use tools like ChatGPT to polish text that would usually contain errors that would tip off recipients. Some attackers are also training AI to write malicious code, which both lowers technical barriers of entry and makes it easier to generate custom malware that can slip by automated defenses.

As the Hong Kong deepfake scam illustrates, the biggest advancement thus far has been in fake audio. Tools now exist that can create a convincing replica of someone’s voice from just a few sentences of speech, something easily gathered if the person is a public figure or company representative. Microsoft’s new VALL-E tool can replicate a voice with as little as three seconds of audio, thought not necessarily with as sophisticated a result. This has led to a minor explosion of phone call scams where criminals pretend to be a family member and ask for money for some sort of emergency.

Most of this has developed since the start of 2023. The tools for deepfake scams have been available since 2017, but for years the threat was dismissed as too readily detectable and too minor for most organizations to worry about by many security analysts. That position is changing due to cases such as this, which are demonstrating the huge amounts of money that can be obtained and how far one can go with relatively simple techniques.

Facial recognition systems are proving particularly vulnerable to deepfake scams, to the point that some are questioning the future viability of biometric facial identification. A very recent analysis by Gartner projects that a wide range of biometric verification systems will be rendered unreliable by 2026 due to AI-powered deepfake attacks, and that 30% of organizations will abandon these methods due to inefficiency.

Kevin Vreeland, General Manager of North America at Veridas, offered some thoughts on how organizations can prepare for this new reality going forward: “With the evolution of artificial intelligence and increased identity-based security threats, companies must implement updated and improved methods of verification and authentication. These measures should focus on detecting the liveness and proof-of-life of their employees. Currently, there are companies developing biometric solutions focused on how to face the new forms of fraud, through a robust biometric engine and aligned to quality and security certifications, such as NIST and iBeta. It’s also important that companies educate their employees about the dangers of deepfakes similar to other types of scams. Deepfakes usually contain inconsistencies when there is movement. For example, an ear might have certain irregularities, or the iris doesn’t show the natural reflection of light.”

Patrick Harr, CEO at SlashNext, notes that it is inevitable that physical security and cybersecurity will have to merge to tackle this particular issue: “This was an elaborate crime. There are ways to apply cybersecurity protection to thwart these types of phishing on collaboration tools like Teams, Slack and Zoom. However, it needs to be combined with physical security protocols and training, because these types of crimes are morphing and technology is lagging behind. There should be multiple approval levels before money is transferred, even when the CFO is requesting the transfer. Companies can require all corporate video communications happen on approved collaboration channels that are secure and employees should be trained to question unusual behavior like requests to use new bank accounts or requests that seem out of the usual process.”. Learn how a multinational company’s Hong Kong branch faced a deepfake scam, causing substantial financial losses, and explore efforts to counter the rising sophistication of deepfake technology.

A multinational company’s Hong Kong branch faced a substantial financial setback due to an advanced deepfake scam. During a video call, an employee was deceived by digitally manipulated versions of the company’s CFO and others, resulting in the unauthorized transfer of funds to the scammers.

The scam recalls the August 2022 incident in which scammers created a Deepfake AI hologram of Patrick Hillmann, Binance’s Chief Communications Officer. The hologram was manipulated to deceive users into participating in online meetings and to target crypto projects of Binance clients.

Reports indicate that the employee was tricked into paying out HK$200 million (approximately US$25.6 million) after participating in a deepfake video call impersonating the company’s CFO. The worker was persuaded after seeing multiple staff members attending that call. However, all were deepfake recreations.

The worker initially became suspicious after receiving a message from the UK-based CFO and avoided it believing it was a phishing email. However, after a video call, the worker realized that the other attendees resembled his colleagues, despite initial doubts, as they appeared and sounded familiar.

What happened is that the scammers used publicly available footage to create convincing versions of the meeting’s participants, according to Hong Kong police senior superintendent Baron Chan Shun-ching’s briefing on Friday.

In the digitally altered video, the CFO issued fraudulent instructions to transfer funds to unauthorized accounts. The employee, a finance worker at the company, followed the instructions, leading to a significant financial loss because the scammers had immaculately replicated the CFO’s appearance and voice.

The worker transferred $25 million to five bank accounts in 15 transactions. The scam was discovered after the employee shared the information with the company’s head office. It is worth noting that the incident lasted a week.

However, this isn’t the first of its kind incident involving deepfake technology. Fraudsters have been relying on this technology to cheat people out of money.

Bitdefender’s latest research reveals a rise in YouTube stream-jacking campaigns using deepfake videos for cryptocurrency theft. Despite McAfee’s MockingBird tool detecting 90% of deepfake content, scammers continue to use malicious techniques for crypto scams, sometimes bypassing facial recognition systems, highlighting ongoing challenges in combating these deceptive practices.

Authorities are investigating the incident in Hong Kong, which is the first such scam involving a large sum of lost money. It has raised concerns about the scammers’ increasing sophistication and potential for financial fraud. Experts urge increased awareness and training for employees to effectively identify and resist these scams.

Hong Kong police confirmed that eight stolen identity cards were used for 90 loan applications and 54 bank account registrations between July and September 2023 using AI deepfakes to trick facial recognition programs on at least 20 occasions. The authorities have so far arrested six individuals in connection with deepfake scams.. A group of scammers recently used deepfake technology – now readily available to just about anyone – to trick a finance employee into paying them over $25 million of corporate funds. This might be one of the world’s biggest AI-fueled heists, and it should lead your organization to immediately redouble your security efforts against this new nightmare scenario. What are the five things you can proactively do to protect your company and what are some steps you should take if you find yourself the victim of a deepfake scam?

How it Went Down

A Hong Kong finance employee at a multinational company thought something was suspicious when his chief financial officer – located in the UK – sent him an urgent email saying that they needed to discuss a secret business deal. In fact, the finance employee even suspected this might be a phishing expedition and proceeded with caution.

But his fears disappeared when he joined a video call with the CFO and several other corporate executives. He recognized them all – their faces, their voices, their office backgrounds. They told him that the company was about to engage in a highly secretive business venture that required an immediate investment of capital, and that he was to lead the charge.

Following the direction of the CFO and other corporate leaders, the finance employee initiated a series of 15 bank transfers to five different Hong Kong accounts totaling HK$200 million – or just over $25.6 million in U.S. dollars. The leaders almost certainly advised him to maintain the strictest discretion and not leak any information to his coworkers.

HK$200 million – or just over $25.6 million in U.S. dollars. The leaders almost certainly advised him to maintain the strictest discretion and not leak any information to his coworkers. About a week or so later, the finance employee checked with the company’s home office to ask about the status of the secret deal. Except that there was no secret deal, and no one knew what he was talking about. That’s when he realized he had been scammed, the victim of a sophisticated AI-fueled deepfake.

“In the multi-person video conference, it turns out that everyone he saw was fake,” said Hong Kong police official Baron Chan Shun-ching during a February 2 press briefing. The police did not release information about the identity of the company or the scammed employee given the pending nature of the criminal investigation.

What’s a Deepfake?

Deepfakes are really, really good imitations. They are videos, audio, photos, text messages, and other forms of media created using AI that are extremely hard to differentiate from the real thing. Their aim is simple: to trick someone into thinking that something happened – or is happening – when it is actually untrue.

In the Hong Kong case, the scammers used fabricated images of real individuals built from photos and videos that were easily obtainable online. They also convincingly replicated the voices using publicly available audio samples.

Deepfakes have been in the news a lot lately. In just the past few weeks, we have heard stories about inappropriate deepfake videos of Taylor Swift and deepfake audio recordings purporting to be Joe Biden advising voters to stay home during the New Hampshire primary.

What’s scariest is that scammers can now use deep learning AI to improve their deepfakes. Everyone now has access to highly powerful modeling systems that can render incredibly convincing images, video, and audio.

A recent report, in fact, indicated that advanced deepfake technology that makes it virtually impossible for people to distinguish fake videos from real will be available to everyone – even beginners – sometime this year.

No doubt this is not the last we’re going to hear about deepfakes pervading our culture, our politics – and our workplaces – in 2024.

5 Considerations to Mitigate the Risk of Deepfakes

To guard against deepfakes, you should consider the following proactive measures, as first outlined by the FP AI Practice Group Chair Dave Walton and AI Team member Karen Odash in a November Insight:

Offer Your Workers Deepfake Training: Educate your employees about the existence and potential dangers of deepfakes. Start by showing them this Insight and describing what happened in Hong Kong. Explain how deepfakes work, their potential impact on the organization, and the importance of staying vigilant. This also involves fostering a culture of skepticism, similar to the way that employees are now on guard for phishing emails. Provide training about the ways to spot deepfakes (looking for blurry details, irregular lighting, unnatural eye or facial movements, mismatched audio, absence of emotion, etc.). As part of overall training, make sure your cybersecurity training is up to date and required for all employees. Develop Channels for Open Communication: Employees must feel comfortable questioning the legitimacy of information and reporting any suspicious activity. Encourage them to speak up and promote a culture that supports open communication about questionable information and activity. Give employees examples of requests that are abnormal or outside the normal company procedures. Make Sure IT Adopts Robust Authentication Protocols: Establish strong authentication measures for access to sensitive information, systems, and accounts. This may include multi-factor authentication, biometric verification, or other secure methods to minimize the risk of unauthorized access. Also, there must be failsafe measures for the requests involving financial and security issues. Assume that nefarious actors will use deepfakes to try to steal from your company. Implement multiple levels of approval before allowing certain actions to occur, such as transferring money above a certain threshold amount. Invest in New Threat-Detection Tools: This is a developing area. Technology to protect against deepfakes has not kept up with the overall deepfake technology. But stay up to speed in this area and look for opportunities to invest in advanced technologies such as AI-powered deepfake detection tools as they become more robust. These might help identify and flag potential deepfakes. Review Your Policies: Make sure your policies prohibit your employees from creating deepfakes involving company personnel and company proprietary information. There are very few legitimate businesses uses of deepfakes for most companies. In general, employees should not be allowed to use employer resources or data to create deepfakes.

3 Things to Do if Your Company is Victimized By a Deepfake. Scammers stole $25.6 million USD ( $200 million Hong Kong dollars) from a multinational finance firm using deepfake technology, CNN reported.

Hong Kong police were contacted about a case where scammers used a deepfake of the firm’s chief financial officer to appear as him in a video call. An employee had already been contacted by the scammers about secretive financial transactions.

While the employee may have been suspicious initially, the scammers invited the employee to a video call, where other members of the company staff were present, including the CFO. It turned out that every individual present in the call, save for the lone employee, was a deep fake.

The fake CFO then instructed the employee to make 15 separate financial transfers, totaling $25.6 million USD. It wasn’t until a week later that the employee realized it was a scam after speaking to his colleagues.

Police believe that the deepfakes were created using photos and videos of the company’s staff. So far, six people have been arrested in conjunction with the crime and an investigation is ongoing. It’s believed that the scammers have created deepfakes of at least 20 individuals.. Manhattan, KS (66502)

Today

Showers in the morning, then a period of strong thunderstorms in the afternoon. Storms may produce large hail and strong winds. High 71F. Winds E at 10 to 20 mph. Chance of rain 70%..

Tonight

Thunderstorms likely - possibly strong, especially during the evening. Potential for heavy rainfall. Low 61F. Winds SE at 10 to 15 mph. Chance of rain 80%.