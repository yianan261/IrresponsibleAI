A British police agency is defending (this link is inoperable for the moment) its use of facial recognition technology at the June 2017 Champions League soccer final in Cardiff, Wales—among several other instances—saying that despite the system having a 92-percent false positive rate, "no one" has ever been arrested due to such an error.

New data about the South Wales Police's use of the technology obtained by Wired UK and The Guardian through a public records request shows that of the 2,470 alerts from the facial recognition system, 2,297 were false positives. In other words, nine out of 10 times, the system erroneously flagged someone as being suspicious or worthy of arrest.

In a public statement, the SWP said that it has arrested "over 450" people as a result of its facial recognition efforts over the last nine months.

"Of course, no facial recognition system is 100 percent accurate under all conditions. Technical issues are normal to all face recognition systems, which means false positives will continue to be a common problem for the foreseeable future," the police wrote. "However, since we introduced the facial recognition technology, no individual has been arrested where a false positive alert has led to an intervention and no members of the public have complained."

The agency added that it is "very cognizant of concerns about privacy, and we have built in checks and balances into our methodology to make sure our approach is justified and balanced."

However, Big Brother Watch, a London-based advocacy group, is unsatisfied with the police's response:. Use of live facial recognition technology by UK police fails to meet “minimum ethical and legal standards” and should be banned from application in public spaces, say researchers from the University of Cambridge.

A team of researchers at the Minderoo Centre for Technology and Democracy analyzed three separate instances of facial recognition technology (FRT) used by two police forces—South Wales Police and the Metropolitan Police Service (MPS). In every case, FRT was found to potentially breach human rights.

The researchers created an audit tool to check FRT deployments against current legal guidelines—including the UK’s Data Protection and Equality acts—as well as outcomes from UK court cases.

They applied their ethical and legal standards to three uses of FRT by UK police. In two cases, the technology was used by the MPS and South Wales Police to scan crowds and compare faces to those on a criminal database and “watch list." In the third case, officers from South Wales Police used FRT smartphone apps to scan crowds and identify “wanted” individuals in real-time.

In all three cases, there was found to be a lack of transparency, accountability, and oversight in the use of FRT.

The study found that important information about police use of FRT is “kept from view” such as demographic data published on arrests or other outcomes, which the researchers say makes it difficult to evaluate whether the tools “perpetuate racial profiling." The report also found police had not published internal audits to establish if their technology was biased.

In addition to lack of transparency, the researchers found there was very little accountability for the police—with no clear recourse for people or communities negatively affected by police use, or misuse, of the tech. “Police forces are not necessarily answerable or held responsible for harms caused by facial recognition technology,” said Evani Radiya-Dixit, the report’s lead author.

“There is a lack of robust redress mechanisms for individuals and communities harmed by police deployments of the technology. To protect human rights and improve accountability in how technology is used, we must ask what values we want to embed in technology," Radiya-Dixit said.

Professor Gina Neff, Executive Director at the Minderoo Centre for Technology and Democracy, said: “Over the last few years, police forces around the world, including in England and Wales, have deployed facial recognition technologies. Our goal was to assess whether these deployments used known practices for the safe and ethical use of these technologies.

“Building a unique audit system enabled us to examine the issues of privacy, equality, accountability, and oversight that should accompany any use of such technologies by the police,” Neff said.

The researchers have joined experts from the EU and UN High Commissioner for Human Rights in calling for the prohibition of FRT in public spaces.

UK police have been testing FRT use for years in multiple situations to fight crime and terrorism. Its first documented use in the UK was in 2015 by Leicestershire Police on festival-goers. It has since been used prolifically by South Wales Police and Metropolitan Police to scan hundreds of thousands of faces at protests, sporting events, concerts, Notting Hill Carnival, train stations, and busy shopping streets.

There is global concern regarding the use of FRT by police forces. The same technology used by the Metropolitan Police was found to have wrongly identified Black men. In 2020, Amnesty International led a call to ban the use of FRT by police forces as it could “exacerbate human rights violations.". Tokyo & London, July 11, 2017 - NEC Corporation (NEC; TSE: 6701) today announced that it has provided a facial recognition system for South Wales Police in the UK through NEC Europe Ltd.



The system utilizes NeoFace® Watch, NEC's flagship facial recognition software platform featuring the world's highest recognition precision (*). NeoFace Watch is used for real-time CCTV surveillance, as well as still image and recorded video face search, which helps to ensure security in crowded locations, such as airports and stadiums.



South Wales Police has deployed NeoFace Watch using CCTV cameras mounted on a number of police vehicles and is using its real-time surveillance capability to locate persons of interest on pre-determined watchlists, including criminals, suspects, vulnerable individuals and missing persons.

Police vehicle equipped with facial recognition system

Assistant Chief Constable Richard Lewis said: "Facial recognition technology will enable us to search, scan and monitor images and video against a range of offender databases leading to faster and more accurate identification of persons of interest. This has been borne out by the recent arrest of a 34-year old man from Cardiff who was wanted for a recall to prison. He had walked past several officers on a main street in Cardiff before he was identified by the cameras and it is probably an arrest we would not have made at any previous time."



The South Wales Police system was deployed for the final of the UEFA Champions League, held on June 3 at the National Stadium of Wales with up to 170,000 football fans in Cardiff on that day. "We deployed NEC's real-time solution, which enabled trained officers to monitor the movement of people at strategic locations in and around the city centre during this massive event. It was a great success," said ACC Lewis. South Wales Police is the first police force to use a real-time facial recognition system at a large-scale sports event in the UK.



The South Wales system will also be used to cross-check still images and recorded video taken at crime scenes against approximately 500,000 photos currently held in its custody image database.



"NEC is very proud to be working closely with South Wales Police. We now have deployments of NeoFace Watch in 47 countries, used by a wide range of government and commercial organizations," said Chris de Silva, Head of Global Face Recognition Solutions, NEC Europe Ltd. "NEC is committed to providing valuable solutions for society and we will continue proposing innovative new solutions using face recognition, both in the UK and around the world."

***. Police in South Wales have been relying on facial recognition technology for 12 months.

An FOI request has revealed that the technology provides a "false positive" ID in more than 90% of cases.

The police have admitted that "of course no facial recognition system is 100% accurate".

Advertisement



British police have been forced to defend facial recognition technology which falsely identified 2297 out of 2470 football fans as "persons of interest."

South Wales police rolled out its "Automated Facial Recognition" (AFR) pilot program just before the Champion's League Final between Juventus and Real Madrid almost a year ago in Cardiff, Wales.

Late last week, Wired's Matt Burgess got an FOI request back in regard to how effective the AFR system has been for the South Wales Police since then.

It wasn't great.

Advertisement

The "false positive" rate – 92% unsuccessful – from AFR's work at the Champions League final was the most damning.

In other events, only six positive matches were confirmed out of 48 alerts at a Wales versus Australia rugby match, and no matches were made at all during a royal visit from Prince Harry and Meghan Markle to Cardiff in January 2018.

Almost immediately following the report, South Wales police put out an explainer on how its facial recognition system worked in two stages, AFR "Identity" and AFR "Locate".

Related stories

AFR "Identity" allows officers to load images of persons of interest and compare them to 500,000 images they already have on file and see if there's a match.

Advertisement

AFR "Locate" uses CCTV and roving police vehicle cameras to locate that person of interest.

The force made it clear no one had ever been arrested on the basis of a false positive result and claimed the "overall effectiveness of facial recognition has been high."

It also claimed 2000 positive matches have led to 450 arrests in the past nine months.

But Wired's FOI request has returned a total result of just 234 "true positives" from 2685 alerts across 15 events.

Advertisement

South Wales Police opened its release with:

"Of course no facial recognition system is 100% accurate under all conditions."

Its system for dealing with potential false positives is a) disregard the alert; or b) dispatch a team to "have an interaction with the potentially matched individual."

Officers would then use "traditional policing methods" (mostly, a chat) to decide whether more action was required.

Advertisement

That a new technology isn't exactly performing at 100% should come as no surprise to anyone. But for the general public, there's no doubt facial recognition and criminal profiling definitely fall in a preferred category of "get it right first."

Immediately, civil liberties groups have begun preparing campaigns for British parliament.

You can read the full story at Wired here.