. KOTA KINABALU, Feb 19 — The Malaysian judiciary passed sentences for the first time today using artificial intelligence (AI) technology in the Kota Kinabalu magistrate court.

Four cases, under Section 12 of the Dangerous Drug Act 1952 was heard by magistrate Jessica Ombou Kakayun, who meted out sentences to two accused who pleaded guilty, after reviewing recommendations from the AI system.

Chief Justice for Sabah and Sarawak Tan Sri David Wong said it was a momentous occasion for the Malaysian judicial system, which was to his knowledge, among the first in the world to use such technology to recommend sentences based on previous cases that would be more consistent, and efficient.

Advertisement

“I am happy with it. The accused was given a chance to maintain his guilty plea after being told of the likely sentence. The accused could make an informed decision.

“As compared to before he had only had an idea of the sentence, so it’s an improvement to the system,” said Wong.

He reiterated that the AI would only provide recommendations based on information of precedence from the courts database between 2014 and 2019 to save time, but the ultimate decision maker would be the person on the bench.

Advertisement

“It just makes it easier on the Magistrate or Sessions court judge. I can assure you it will lead to consistency of sentencing,” he said, explaining that disparity between sentences from one court to another is a worldwide complaint in judicial systems.

“In any jurisdiction in the world, the complaint is lack of consistency, why is one sentence for a year while another is a fine only. Using the machine to analyse all data will achieve consistency, it speeds up the process a little because the magistrate doesn’t have to look up previous cases while listening to submissions,” said Wong.

Although for now the AI will only be used for two offences — drug possession under Section 12 of the Dangerous Drug Act and rape under Section 376 of the Penal Code — Wong said it would eventually include civil cases as well to prevent backlog and improve efficiency in court hearings.

“We are in the process of doing it for the civil side — awarding damages for injuries in car accidents. We are hopeful that we will have something in 36 months. It is useful for the judiciary because both lawyers will know what are the likely damages to be awarded and with that they can negotiate settlement before court and that will mean less cases, so court can deal with genuine disputes,” he said.

Meanwhile, in today’s hearing, lawyer Hamid Ismail, acting on behalf of his client Denis P Modili, who had pleaded guilty to being in possession of 0.01 grams of methamphetamine objected to AI being used in the sentencing of his client’s case, saying it was a breach of Federal Constitution.

“The court should confine to only materials presented in the court. AI is not in accordance with the law. Although the court can choose to ignore it, I am afraid it might influence the decision,” he said.

He said that the use of AI was a breach of Article 5(1) and Article 8(1) of the Federal Constitution.

Article 5(1) states that no person shall be deprived of his life or personal liberty save in accordance with the law, while Article 8(1) said all persons are equal before the law and entitled to the equal protection of the law.

In mitigation, Hamid said that the amount of drugs found on Modili was very low and said the sentence to be under five months’ jail. He also asked for the punishment to be carried out concurrently with the present eight months’ sentence for self-administration of drugs which he has been serving since December 16.

Kakayun said the courts will proceed with the use of AI, and sentenced Modili to 12 months’ jail to run concurrently from his existing sentence. The AI had recommended 10 months of imprisonment.

Hamid said that he will file an appeal to the High Court as the use of AI involved constitutional issues.

Earlier, Kakayun had sentenced Christopher Divineson Moinol to nine months’ jail for being in possession of 0.16 grams of methamphetamine on October 22 last year at the roadside of Kampung Cenderamata 2, Likas.

Christopher, 26, who was also represented by Hamid, pleaded guilty to the offence was recommended nine months’ imprisonment by the AI, which Magistrate Kakayun adhered to.

When speaking to the press, Wong said that lawyers were entitled to make objections and that he would let the objection and appeal take its course.

“This AI is a new tool for the court; unless it is tested in court, we will not know whether it is constitutional or not. It is also not proper for us to say whether it is constitutional or not, as that means giving our views while in office.

“But we expected challenges like this. Anything new which may infringe the rule of law or the Constitution, we have to take the challenges as it comes,” he said.. The use of artificial intelligence in the legal system is growing worldwide, but as Malaysia concludes a sentencing tool trial, experts say it is no match for 'human judges'

Malaysia set to conclude trial of AI tool in sentencing

Authorities say AI clears cases cheaply, fairly and fast

Lawyers question lack of discretion, narrow data set

By Rina Chandran

BANGKOK, April 12 (Thomson Reuters Foundation) - Few cases ruffle Hamid Ismail after nearly two decades as a lawyer, but he was taken aback when a man he defended was sentenced with the help of an artificial intelligence tool in the Malaysian state of Sabah.

Ismail knew courts in Sabah and neighbouring Sarawak were testing the AI tool for sentencing recommendations as part of a nationwide pilot, but was uneasy that the technology was being used before lawyers, judges and the public fully understood it.

There was no proper consultation on the technology's use, and it is not contemplated in the country's penal code, he said.

"Our Criminal Procedure Code does not provide for use of AI in the courts ... I think it's unconstitutional," said Ismail, adding that the AI-recommended sentence for his client for a minor drug possession charge was too harsh.

The courts of Sabah and Sarawak piloted software developed by Sarawak Information Systems, a state government firm, which said at the time that it had held consultations during the process, and taken steps to address some of the concerns raised.

World over, the use of AI in the criminal justice system is growing quickly, from the popular DoNotPay chatbot lawyer mobile app to robot judges in Estonia adjudicating small claims, to robot mediators in Canada and AI judges in Chinese courts.

Authorities say AI-based systems make sentencing more consistent and can clear case backlogs quickly and cheaply, helping all parties in legal proceedings to avoid lengthy, expensive and stressful litigation.

More than a third of government respondents in a global survey last year by research firm Gartner indicated that they planned to increase investments in AI-powered systems including chatbots, facial recognition and data mining across sectors.

This month, Malaysian federal authorities aim to conclude their nationwide trial of the AI sentencing tools, which they have said "can improve the quality of judgment", though it is not entirely clear how they will be used in courts.

A spokesperson for Malaysia's Chief Justice said the use of AI in courts was "still in the trial stage", declining further comment.

BIAS, MITIGATING FACTORS

Critics warn AI risks entrenching and amplifying bias against minorities and marginalised groups, saying the technology lacks a judge's ability to weigh up individual circumstances, or adapt to changing social mores.

"In sentencing, judges don't just look at the facts of the case - they also consider mitigating factors, and use their discretion. But AI cannot use discretion," Ismail told the Thomson Reuters Foundation.

Considering aggravating and mitigating factors "requires a human mind", said Charles Hector Fernandez, a Malaysian human rights lawyer.

"Sentences also vary with changing times and changing public opinion. We need more judges and prosecutors to handle increasing caseloads; AI cannot replace human judges," he added.

Seeking to address concerns that its AI software might lead to bias in sentencing, Sarawak Information Systems said it had removed the "race" variable from the algorithm.

But while "such mitigating measures are valuable, they do not make the system perfect", said a 2020 report on the tool from the Khazanah Research Institute (KRI), a policy think-tank.

It also noted that the company had only used a dataset of five years from 2014-19 to train the algorithm, "which seems somewhat limited in comparison with the extensive databases used in global efforts".

Sarawak Information Systems could not be reached for comment on whether it had since expanded its database.

An analysis by KRI of cases in Sabah and Sarawak showed that judges followed the AI sentencing recommendation in a third of the cases, all of which involved rape or drug possession under the terms of the two states' pilot.

Some of the judges reduced the suggested sentences in light of mitigating factors. Others were toughened on the basis that they would not serve as a "strong enough deterrent".

'OPAQUE ALGORITHM'

Technology does have the potential to improve efficiency in the criminal justice system, said Simon Chesterman, a professor of law at the National University of Singapore.

But its legitimacy depends not only on the accuracy of the decisions made, but also the manner in which they are made, he added.

"Many decisions might properly be handed over to the machines. (But) a judge should not outsource discretion to an opaque algorithm," said Chesterman, a senior director at AI Singapore, a government programme.

Malayasia's Bar Council, which represents lawyers, has also voiced concern about the AI pilot.

When courts in Kuala Lumpur, the capital, started using it in mid-2021 for sentencing in 20 types of crimes, the council said it was "not given guidelines at all, and we had no opportunity to get feedback from criminal law practitioners".

In Sabah, Ismail appealed his client's sentence recommendation by the AI tool, which the judge followed.

But he said many lawyers would not mount a challenge - potentially condemning their clients to overly harsh sentences.

"The AI acts like a senior judge," Ismail said.

"Young magistrates may think it's the best decision, and accept it without question."

Related stories:

U.S. prisoner surveillance tech faces crackdown calls

African software developers use AI to fight inequality

Indian government faces lawsuit against facial recognition

(Reporting by Rina Chandran @rinachandran; Editing by Helen Popper. Please credit the Thomson Reuters Foundation, the charitable arm of Thomson Reuters, that covers the lives of people around the world who struggle to live freely or fairly. Visit http://news.trust.org)

Our Standards: The Thomson Reuters Trust Principles.