ARTICLE TITLE: TikTok's "Suggested Accounts" Algorithm Allegedly Reinforced Racial Bias through Feedback Loops
A little experiment by an artificial intelligence researcher is raising questions about how TikTok's recommendation algorithm suggests new creators to users.

Specifically, the question is whether that algorithm is sorting suggestions based on the race of the creator — something TikTok denies it's doing intentionally. But it's another example of the need for more scrutiny into how the app and other social media platforms promote particular creators or content.

Marc Faddoul is a researcher at the University of California Berkeley School of Information who studies AI and disinformation. He was checking out TikTok to look for disinformation when he noticed something curious about how the app recommends new creators to follow.

In the app, when a person follows a new account, they can click an arrow that then recommends other accounts to follow. Faddoul noticed that when he did this, the recommended accounts tended to look just like whoever he'd just followed — right down to ethnicity and hair color.

"I saw this very clear pattern that was happening," he told BuzzFeed News. "When following an account, the suggestions are very similar-looking."

He made a fresh account to try it out again, and these were his results:. According to an experiment performed by artificial intelligence researcher Marc Faddoul, the algorithm TikTok uses to suggest new users to follow might have a racial bias.

Faddoul, an AI researcher from the University of California, Berkeley, who specializes in algorithmic fairness, first pointed out his findings on Twitter this week.

“A TikTok novelty: FACE-BASED FITLER BUBBLES,” Faddoul wrote. “The AI-bias techlash seems to have had no impact on newer platforms. Follow a random profile, and TikTok will only recommend people who look almost the same.”

A TikTok novelty: FACE-BASED FITLER BUBBLES

The AI-bias techlash seems to have had no impact on newer platforms.

Follow a random profile, and TikTok will only recommend people who look almost the same.

Let’s do the experiment from a fresh account:

1/6 pic.twitter.com/VAwkh3qNjv — Marc Faddoul (@MarcFaddoul) February 24, 2020

Faddoul explained to BuzzFeed News that when a user on TikTok follows an account they are then suggested a series of other accounts they could follow. Faddoul said he noticed similarities in these accounts, from users being of the same race, hair color, and having similar appearances.

Faddoul said he repeated the experiment again with a new account with similar results.

“Clearly, recommendations are very physiognomic,” Faddoul said. “But it’s not just gender and ethnicity, you can get much more niche facial profiling. TikTok adapts ‘recommendability’ on hair style, body profile, age, how (un)dressed the person is, and even whether they have visible disabilities.”

Clearly, recommendations are very physiognomic.

But it’s not just gender and ethnicity, you can get much more niche facial profiling.

TikTok adapts 'recommendability' on hair style, body profile, age, how (un)dressed the person is, and even whether they have visible disabilities. pic.twitter.com/lm9RKxmDZ4 — Marc Faddoul (@MarcFaddoul) February 24, 2020

A representative from TikTok told BuzzFeed that the algorithm isn’t based on race, or the account’s picture, but based on the content of the account. According to the representative, this is called collaborative filtering, a similar process used by YouTube and Netflix.

“Our recommendation of accounts to follow is based on user behavior: users who follow account A also follow account B, so if you follow A you are likely to also want to follow B,” a representative told BuzzFeed.

But according to Faddoul, if this is the case, it could still render a racial bias.

“A risk is to reinforce a ‘coverage bias’ with a feedback loop,” Faddoul said. “If most popular influencers are say, blond, it’s will be easier for a blond to get followers than for a member of an underrepresented minority. And the loop goes on…”

A risk is to reinforce a 'coverage bias' with a feedback loop.



If most popular influencers are say, blond, it's will be easier for a blond to get followers than for a member of an underrepresented minority. And the loop goes on… — Marc Faddoul (@MarcFaddoul) February 25, 2020

This is not the first time the company has found itself in hot water, back in December, TikTok admitted it was burying content made by queer, fat, and disabled users.

READ MORE:

H/T BuzzFeed News