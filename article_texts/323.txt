Early on, the software had the regrettable habit of hitting police cruisers. No one knew why, though Tesla’s engineers had some good guesses: Stationary objects and flashing lights seemed to trick the A.I. The car would be driving along normally, the computer well in control, and suddenly it would veer to the right or left and — smash — at least 10 times in just over three years.

For a company that depended on an unbounded sense of optimism among investors to maintain its high stock price — Tesla was at one point worth more than Toyota, Honda, Volkswagen, Mercedes, BMW, Ford and General Motors combined — these crashes might seem like a problem. But to Elon Musk, Tesla’s chief executive, they presented an opportunity. Each collision generated data, and with enough data, the company could speed the development of the world’s first truly self-driving car. He believed in this vision so strongly that it led him to make wild predictions: “My guess as to when we would think it is safe for somebody to essentially fall asleep and wake up at their destination: probably toward the end of next year,” Musk said in 2019. “I would say I am certain of that. That is not a question mark.”

The future of Tesla may rest on whether drivers knew that they were engaged in this data-gathering experiment, and if so, whether their appetite for risk matched Musk’s. I wanted to hear from the victims of some of the more minor accidents, but they tended to fall into two categories, neither of which predisposed them to talk: They either loved Tesla and Musk and didn’t want to say anything negative to the press, or they were suing the company and remaining silent on the advice of counsel. (Umair Ali, whose Tesla steered into a highway barrier in 2017, had a different excuse: “Put me down as declined interview because I don’t want to piss off the richest man in the world.”)

Then I found Dave Key. On May 29, 2018, Key’s 2015 Tesla Model S was driving him home from the dentist in Autopilot mode. It was a route that Key had followed countless times before: a two-lane highway leading up into the hills above Laguna Beach, Calif. But on this trip, while Key was distracted, the car drifted out of its lane and slammed into the back of a parked police S.U.V., spinning the car around and pushing the S.U.V. up onto the sidewalk. No one was hurt.. 

Another Tesla On Autopilot Hits Another Emergency Vehicle - You Can't Make This Stuff Up

The Laguna Beach Police Department reports the following via its public Facebook Page:
"This morning, a Tesla sedan driving northbound along Laguna Canyon Road in "autopilot" collided with a parked Laguna Beach PD unit. The LBPD officer was not in the unit at the time of the collision. The driver of the Telsa sedan sustained minor injuries as a result of the collision."

This marks the third time a Tesla on Autopilot has been reported to have hit a parked emergency vehicle. The first time we heard this it was a fire truck in Culver City California. The second was a firetruck parked in Utah. If the Teslas were only smashing into unmoving police and fire trucks we would suspect a conspiracy. However, the Teslas also crash into the side of tractor-trailers and hit rigid barriers in the middle of the highway.

The real question is why Tesla is allowed to provide a system it admits is a beta and not a fully-tested product. The NTSB outlined the reasons why these accidents are happening after the first time a Tesla occupant was killed while Autopilot was engaged.

The most amazing part of the string of Tesla Autopilot crashes is that nobody outside the Tesla has been killed thus far. We suspect that the first time a first responder is hit by a Tesla on Autopilot that does not slow down will be the last day Autopilot is on sale in America.

