Follow us today...

The Laguna Beach Police Department reports the following via its public Facebook Page:

"This morning, a Tesla sedan driving northbound along Laguna Canyon Road in "autopilot" collided with a parked Laguna Beach PD unit. The LBPD officer was not in the unit at the time of the collision. The driver of the Telsa sedan sustained minor injuries as a result of the collision."

This marks the third time a Tesla on Autopilot has been reported to have hit a parked emergency vehicle. The first time we heard this it was a fire truck in Culver City California. The second was a firetruck parked in Utah. If the Teslas were only smashing into unmoving police and fire trucks we would suspect a conspiracy. However, the Teslas also crash into the side of tractor-trailers and hit rigid barriers in the middle of the highway.

The real question is why Tesla is allowed to provide a system it admits is a beta and not a fully-tested product. The NTSB outlined the reasons why these accidents are happening after the first time a Tesla occupant was killed while Autopilot was engaged.

The most amazing part of the string of Tesla Autopilot crashes is that nobody outside the Tesla has been killed thus far. We suspect that the first time a first responder is hit by a Tesla on Autopilot that does not slow down will be the last day Autopilot is on sale in America.

Related Stories:

NTSB Investigation of Arizona Fatality Uncovers Disturbing Facts About Uber's Self-Driving System

Self-Driving Shuttle Vehicle Crashes In Las Vegas Immediately After Launch

Running Down Self-Driving Autonomous Cars' Biggest Crashes, SNAFUs, and Unsafe Traffic Violations. . A Tesla sedan in Autopilot mode crashed into a parked Laguna Beach Police Department vehicle Tuesday morning, authorities said.

The collision happened at 11:07 a.m. at 20652 Laguna Canyon Road, according to Laguna Police Sgt. Jim Cota. The officer was not in the cruiser at the time of the crash. The Tesla driver suffered minor injuries, but refused transportation to the hospital.

“Thankfully there was not an officer at the time in the police car,” Cota said. “The police car is totaled.”

Advertisement

Cota said that a year ago in the same area there was another collision involving a Tesla running into a semi-truck.

“Why do these vehicles keep doing that?” Cota said. “We’re just lucky that people aren’t getting injured.”

Tesla’s Autopilot driver-assist feature has come under scrutiny following other collisions.

A Tesla driver in Utah crashed while using Autopilot and looking at her phone earlier this month. Two fatal crashes while the system was being used also have occurred: one in California in March and a 2016 crash in Florida.

The Palo Alto-based automaker, led by Elon Musk, has said it repeatedly warns drivers to stay alert, keep their hands on the wheel and maintain control of their vehicle at all times while using the Autopilot system.

“Tesla has always been clear that Autopilot doesn’t make the car impervious to all accidents, and before a driver can use Autopilot, they must accept a dialogue box which states that ‘Autopilot is designed for use on highways that have a center divider and clear lane markings,’” a Tesla spokesperson said in an emailed statement.

Advertisement

The Associated Press contributed to this report.

brittny.mejia@latimes.com

Twitter: @Brittny_Mejia

UPDATES:

2:50 p.m.: This article was updated with a statement from a Tesla spokesperson.

1:20 p.m.: This article was updated with details of the collision from the police sergeant.

This article was originally published at 1:05 p.m.. Early on, the software had the regrettable habit of hitting police cruisers. No one knew why, though Tesla’s engineers had some good guesses: Stationary objects and flashing lights seemed to trick the A.I. The car would be driving along normally, the computer well in control, and suddenly it would veer to the right or left and — smash — at least 10 times in just over three years.

For a company that depended on an unbounded sense of optimism among investors to maintain its high stock price — Tesla was at one point worth more than Toyota, Honda, Volkswagen, Mercedes, BMW, Ford and General Motors combined — these crashes might seem like a problem. But to Elon Musk, Tesla’s chief executive, they presented an opportunity. Each collision generated data, and with enough data, the company could speed the development of the world’s first truly self-driving car. He believed in this vision so strongly that it led him to make wild predictions: “My guess as to when we would think it is safe for somebody to essentially fall asleep and wake up at their destination: probably toward the end of next year,” Musk said in 2019. “I would say I am certain of that. That is not a question mark.”

The future of Tesla may rest on whether drivers knew that they were engaged in this data-gathering experiment, and if so, whether their appetite for risk matched Musk’s. I wanted to hear from the victims of some of the more minor accidents, but they tended to fall into two categories, neither of which predisposed them to talk: They either loved Tesla and Musk and didn’t want to say anything negative to the press, or they were suing the company and remaining silent on the advice of counsel. (Umair Ali, whose Tesla steered into a highway barrier in 2017, had a different excuse: “Put me down as declined interview because I don’t want to piss off the richest man in the world.”)

Then I found Dave Key. On May 29, 2018, Key’s 2015 Tesla Model S was driving him home from the dentist in Autopilot mode. It was a route that Key had followed countless times before: a two-lane highway leading up into the hills above Laguna Beach, Calif. But on this trip, while Key was distracted, the car drifted out of its lane and slammed into the back of a parked police S.U.V., spinning the car around and pushing the S.U.V. up onto the sidewalk. No one was hurt.