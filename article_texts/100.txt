When automated fraud detection algorithms fail, welfare services can wrongly demand the repayment of benefits. Over the last five years, several scandals showed the breadth of the problem. In Australia, 400,000 people were put in ‘robo-debt’, 40,000 in Michigan and 26,000 in the Netherlands . Journalist Lucie Inland explains how the French welfare office automatically put her in debt, and how she fought back.

I live alone and, like many of my generation, I am part of the precariat. As such, I receive several social benefits. The welfare office pays part of my rent and gives me a monthly stipend, which totals about 500€ a month. I’ve been working as an employee since 2007, and additionally registered as a freelance worker in 2020. I never had any trouble with the welfare office. I usually sends them a declaration every quarter. I know that my case can be checked, either by the welfare services or by the tax authorities.

On 17 March 2021, the welfare office sends me an email asking for new information, following the latest reform in welfare benefits. Although I have to send a year’s worth of documents about my income, I comply with the request. I send them the documents as well as a written explanation of my situation.

On the next day, I receive two e-mails, asking me to submit, again, the same documents. In addition, the welfare office tells me that I owe them 542 euros and that the amount will be automatically taken from my next payments, to the tune of 60 euros each month. Not the kind of amount that I can afford to spare. Despite my surprise and, let’s be honest, my rage, I notice what went wrong. The welfare office only took into account my status as a freelance worker and ignored my salaried work. This changes the way my benefits are computed, much to my detriment. I explain the mistake to the welfare office in an e-mail and book a phone appointment with my caseworker for 26 March.

A few hours later, someone from the welfare office leaves a message on my mailbox. She says that she read my e-mail, canceled my debt and closed the issue. I felt relieved after this emotional roller-coaster, but I wanted to find out how such a mistake could happen.

During my phone meeting on 26 March, my caseworker confirms that “the software” analyzed my file automatically, using “parameters”. My case apparently became “too complex” when I informed them that I started work as a freelance. It was entirely reset, hence the e-mail asking me to upload a year’s worth of documents.

Despite my caseworker’s answers, I still can’t understand why the software only took into account my activity as a freelance worker. All the more so because I sent all the necessary documents as required. My debt was notified as soon as the algorithm found an error in my file. The machine threatens first, humans verify later. Only the e-mail I sent let the welfare office know about their mistake. Their automated tools put me in a difficult position in the first place.

“Controls benefit welfare recipients”

The welfare office offers explanations – sort of – on its website. Under the title “putting the facts right”, a page published in September 2020 says that controls actually benefit welfare recipients. They use “automated controls” as well as “a statistical model known as ‘datamining’ (sic), which automatically targets risky cases”. Notwithstanding the obscure jargon, it’s hard for any layperson to understand what they mean. The page also says that “you can avoid incurring debts towards the welfare office by always declaring any change in your situation without delay”. Except that in my case, I was notified of my debt precisely because I did that.

Welfare offices, which are run by the French regions, have been using data mining since 2012. The method is responsible for three in four controls. The most controlled benefit in 2021 is the one that helps beneficiaries pay for rent, which I receive.

I spoke to Vincent Dubois, a sociologist at the University of Strasbourg who recently published a book on the topic, “Controlling Welfare Queens” (Contrôler les assistés). “Technically, controls that are based on data mining do not use social characteristics but ‘risk factors’. They don’t identify individuals or specific groups, but cases,” he said. “Such targeting is not socially neutral. Risk factors are not distributed randomly among the population, were it only because the criteria and the attribution process vary across benefits, and beneficiaries are socially and economically different.” Although he has no definite proof, Mr Dubois thinks that women, especially single women such as myself, are considered ‘higher risk’. Other risk factors include living abroad or failing to tell about a new job, according to the welfare office.

The welfare office’s privacy policy states that the French data protection authority regularly controls how it handles personal data. But according to Article 22 of the General Data Protection Regulation, any automated treatment that has ‘legal impact’ is prohibited. French law goes further and states that any algorithmic decision is void if the fact that it was taken automatically is not clearly mentioned to the recipient. Needless to say, the e-mail from the welfare office notifying my debt made no mention of any automated process. The French data protection authority declined to answer my questions.

Photo by Blake Cheek on Unsplash