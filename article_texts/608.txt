Insurance giant UnitedHealth Group is facing a lawsuit alleging it used an artificial intelligence algorithm to wrongfully deny coverage to older patients for care under its Medicare Advantage health policies, Bloomberg Law reported Nov. 14.

The class action, filed by public interest law firm Clarkson Law Firm in the U.S. District Court for the District of Minnesota on Nov. 14, claims UnitedHealth made care determinations via its "nH Predict" algorithm, overriding physician recommendations and denied elderly patients' claims for treatment in extended care facilities. The suit alleges that UnitedHealth "[banks] on the patients' impaired conditions, lack of knowledge and lack of resources to appeal the erroneous AI-powered decisions."

A spokesperson for naviHealth, creator of the algorithm used by UnitedHealth, said in a statement to Bloomberg that its tool was not used for making coverage determinations.

Fellow payer Cigna was hit with a similar lawsuit in July that alleged it systematically rejects patient claims using an algorithm system it put in place to automate the process, spending an average of 1.2 seconds on each claim. The suit claimed the insurer does not have a "reasonable standard" for claims processing.

"[The algorithm used by Cigna] is a simple tool to accelerate physician payments that has been grossly mischaracterized in the press. The facts speak for themselves, and we will continue to set the record straight," a Cigna spokesperson told Forbes.. Health insurance companies cannot use algorithms or artificial intelligence to determine care or deny coverage to members on Medicare Advantage plans, the Centers for Medicare & Medicaid Services (CMS) clarified in a memo sent to all Medicare Advantage insurers.

The memo—formatted like an FAQ on Medicare Advantage (MA) plan rules—comes just months after patients filed lawsuits claiming that UnitedHealth and Humana have been using a deeply flawed AI-powered tool to deny care to elderly patients on MA plans. The lawsuits, which seek class-action status, center on the same AI tool, called nH Predict, used by both insurers and developed by NaviHealth, a UnitedHealth subsidiary.

According to the lawsuits, nH Predict produces draconian estimates for how long a patient will need post-acute care in facilities like skilled nursing homes and rehabilitation centers after an acute injury, illness, or event, like a fall or a stroke. And NaviHealth employees face discipline for deviating from the estimates, even though they often don't match prescribing physicians' recommendations or Medicare coverage rules. For instance, while MA plans typically provide up to 100 days of covered care in a nursing home after a three-day hospital stay, using nH Predict, patients on UnitedHealth's MA plan rarely stay in nursing homes for more than 14 days before receiving payment denials, the lawsuits allege.

Specific warning

It's unclear how nH Predict works exactly, but it reportedly uses a database of 6 million patients to develop its predictions. Still, according to people familiar with the software, it only accounts for a small set of patient factors, not a full look at a patient's individual circumstances.

This is a clear no-no, according to the CMS's memo. For coverage decisions, insurers must "base the decision on the individual patient’s circumstances, so an algorithm that determines coverage based on a larger data set instead of the individual patient's medical history, the physician’s recommendations, or clinical notes would not be compliant," the CMS wrote.

The CMS then provided a hypothetical that matches the circumstances laid out in the lawsuits, writing:

In an example involving a decision to terminate post-acute care services, an algorithm or software tool can be used to assist providers or MA plans in predicting a potential length of stay, but that prediction alone cannot be used as the basis to terminate post-acute care services.

Instead, the CMS wrote, in order for an insurer to end coverage, the individual patient's condition must be reassessed, and denial must be based on coverage criteria that is publicly posted on a website that is not password protected. In addition, insurers who deny care "must supply a specific and detailed explanation why services are either no longer reasonable and necessary or are no longer covered, including a description of the applicable coverage criteria and rules."

Advertisement

In the lawsuits, patients claimed that when coverage of their physician-recommended care was unexpectedly wrongfully denied, insurers didn't give them full explanations.

Fidelity

In all, the CMS finds that AI tools can be used by insurers when evaluating coverage—but really only as a check to make sure the insurer is following the rules. An "algorithm or software tool should only be used to ensure fidelity" with coverage criteria, the CMS wrote. And, because "publicly posted coverage criteria are static and unchanging, artificial intelligence cannot be used to shift the coverage criteria over time" or apply hidden coverage criteria.

The CMS sidesteps any debate about what qualifies as artificial intelligence by offering a broad warning about algorithms and artificial intelligence. "There are many overlapping terms used in the context of rapidly developing software tools," the CMS wrote.

Algorithms can imply a decisional flow chart of a series of if-then statements (i.e., if the patient has a certain diagnosis, they should be able to receive a test), as well as predictive algorithms (predicting the likelihood of a future admission, for example). Artificial intelligence has been defined as a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through analysis in an automated manner; and use model inference to formulate options for information or action.

The CMS also openly worried that the use of either of these types of tools can reinforce discrimination and biases—which has already happened with racial bias. The CMS warned insurers to ensure any AI tool or algorithm they use "is not perpetuating or exacerbating existing bias, or introducing new biases."

While the memo overall was an explicit clarification of existing MA rules, the CMS ended by putting insurers on notice that it is increasing its audit activities and "will be monitoring closely whether MA plans are utilizing and applying internal coverage criteria that are not found in Medicare laws." Non-compliance can result in warning letters, corrective action plans, monetary penalties, and enrollment and marketing sanctions.. UnitedHealthcare (UHC) is the latest payer accused of using artificial intelligence (AI) to deny patient claims by trading "real doctors' recommendations" for a flawed algorithm to save money.

In a class action suit filed this week in Minnesota district court, the attorneys for the families of two deceased UHC Medicare Advantage plan policyholders say that the company uses the technology to systematically deny skilled nursing facility (SNF) claims and shirk its responsibility to adhere to Medicare's coverage determination standards.

The case raises ethical and legal questions about whether AI can replace or supplement human tasks and interactions, particularly in a field as complex as healthcare. California-based public advocacy firm Clarkson Law filed a similar complaint against Cigna earlier this year and has previously sued tech giants Google and ChatGPT creator OpenAI for harvesting internet users' data to train their AI systems.

Clarkson Law represents the plaintiffs and says that the policyholders had to pay thousands in out-of-pocket costs or forgo the recommended post-acute care owing to UHC's faulty AI model, nH Predict. The tool has a 90% error rate, says the lawsuit, as evidenced by the number of claims that are reversed following review by a medical professional. Still, just 0.2% of policyholders appeal the denials.

nH Predict was created by naviHealth and was acquired by UnitedHealth Group, UHC's parent company, in 2020. In a statement to Bloomberg Law, a spokesperson for naviHealth said that the lawsuit has no merit and the model was not used for making coverage determinations.

According to the complaint, nH Predict determines the appropriate amount of SNF, home health, or rehabilitation services a patient requires on the basis of their diagnosis, age, and living situation. The model compares the patient with their database of 6 million patients and estimates the ideal length of stay and target discharge date, "pinpointing the precise moment when [UHC] will cut off payment for a patient's treatment."

The lawsuit says that employees are instructed to strictly adhere to the AI model's predictions, and those who do not are disciplined and terminated, even when additional care for the patient is warranted. Employees are told that the generated reports contain proprietary information and that they cannot share them with physicians and patients who inquire about extending care.

"Every patient is entitled to a nuanced evaluation of their health care needs," Zarrina Ozari, senior associate at Clarkson Law Firm, said in a prepared statement. "By replacing licensed practitioners with unchecked AI, UHC is telling its patients that they are completely interchangeable with one another and undervaluing the expertise of the physicians devoted to key elements of care."

According to the complaint, Gene Lokken fell in May 2022 and fractured his leg and ankle. After a 1-month SNF stay, the 91-year-old man's doctor ordered physical therapy. However, the insurer said Lokken was safe to be discharged home two and a half weeks later, conflicting with a physical therapist's notes that indicated he still had paralyzed and weak muscles. The insurer denied Lokken's appeal. He remained in the facility for another year until his death, paying about $150,000 in out-of-pocket expenses, according to the lawsuit.

Another patient, Dale Tetzloff, initially spent just 20 days in a SNF for stroke rehabilitation before UHC denied coverage. An appeal later extended the stay to 40 days, short of the 100 days recommended by his physician. Requests for further extensions were unsuccessful, and Tetzloff ultimately paid about $70,000 in out-of-pocket expenses over the next 10 months, according to the complaint.

New federal rules prohibit Medicare Advantage plans from relying on an algorithm or software to make medically necessary determinations instead of an individual's specific circumstances. Any medical necessity denial must be "reviewed by a physician or other appropriate health care professional with expertise in the field of medicine or health care that is appropriate for the service at issue."

Clarkson is demanding a jury trial and has asked the court to certify the case as a federal class action, which could open the suit to any US resident who purchased a UHC Medicare Advantage plan in the past 4 years.

Steph Weber is a Midwest-based freelance journalist specializing in healthcare and law.. 