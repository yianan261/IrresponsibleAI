A video posted last week by YouTube user "F0t0b0y" has been viewed more than 7 million times showing a toddler requesting a song from an Amazon device only to get a raunchy response from the device.

The video titled "Amazon Alexa Gone Wild" shows a young boy named Bubby requesting Alexa to "play Digger, Digger." Alexa is the name of the voice-activated digital assistant used for Amazon devices. The device Bubby was using was an Amazon Echo.

After Bubby requested the song, Alexa responded by saying, “You want to hear a station for porn?" The device also mentions "hot chick" and other graphic terms before adults interrupted Alexa by yelling, "Stop Alexa."

The man who filmed the incident discussed the video in a separate YouTube video.

"As soon as that video happened, once I shut it off, I said, That has to go viral,'" he said.

According to the New York Post, Amazon has fixed the glitch and is “working to build additional restrictions to prevent this from happening in the future.” The Post added that Amazon has apologized to the family.

NOTE: VIDEO CONTAINS GRAPHIC LANGUAGE. Virtual assistants, such as Amazon Alexa and Apple’s Siri, are supposed to make our busy lives slightly easier.

Rather than wasting valuable seconds setting alarms, checking facts and writing shopping lists, we can now just ask our artificially intelligent devices to do it for us.

However, as is always the case with new technology, it was always bound to go wrong.

Alexa fails & other virtual assistant mishaps

For the most part, smart home devices like Alexa are extremely helpful. However, having a virtual assistant listening to your every word at all times isn’t always as convenient as it sounds, as these incidents prove:

Parrot places Amazon order

A clever parrot used its owner’s Alexa to place itself an order on Amazon earlier this week. However, the African grey wasn’t smart enough to order itself something useful.

Having heard its owner calling out Alexa, the pet used its broadened vocabulary to order itself a set of golden gift boxes.

How well do you really know your competitors? Access the most comprehensive Company Profiles on the market, powered by GlobalData. Save hours of research. Gain competitive edge. View profiles in store Company Profile – free sample Thank you! Your download email will arrive shortly Not ready to buy yet? Download a free sample We are confident about the unique quality of our Company Profiles. However, we want you to make the most beneficial decision for your business, so we offer a free sample that you can download by submitting the below form By GlobalData Submit Country * UK USA Afghanistan Åland Islands Albania Algeria American Samoa Andorra Angola Anguilla Antarctica Antigua and Barbuda Argentina Armenia Aruba Australia Austria Azerbaijan Bahamas Bahrain Bangladesh Barbados Belarus Belgium Belize Benin Bermuda Bhutan Bolivia Bonaire, Sint Eustatius and Saba Bosnia and Herzegovina Botswana Bouvet Island Brazil British Indian Ocean Territory Brunei Darussalam Bulgaria Burkina Faso Burundi Cambodia Cameroon Canada Cape Verde Cayman Islands Central African Republic Chad Chile China Christmas Island Cocos Islands Colombia Comoros Congo Democratic Republic of the Congo Cook Islands Costa Rica Côte d"Ivoire Croatia Cuba Curaçao Cyprus Czech Republic Denmark Djibouti Dominica Dominican Republic Ecuador Egypt El Salvador Equatorial Guinea Eritrea Estonia Ethiopia Falkland Islands Faroe Islands Fiji Finland France French Guiana French Polynesia French Southern Territories Gabon Gambia Georgia Germany Ghana Gibraltar Greece Greenland Grenada Guadeloupe Guam Guatemala Guernsey Guinea Guinea-Bissau Guyana Haiti Heard Island and McDonald Islands Holy See Honduras Hong Kong Hungary Iceland India Indonesia Iran Iraq Ireland Isle of Man Israel Italy Jamaica Japan Jersey Jordan Kazakhstan Kenya Kiribati North Korea South Korea Kuwait Kyrgyzstan Lao Latvia Lebanon Lesotho Liberia Libyan Arab Jamahiriya Liechtenstein Lithuania Luxembourg Macao Macedonia, The Former Yugoslav Republic of Madagascar Malawi Malaysia Maldives Mali Malta Marshall Islands Martinique Mauritania Mauritius Mayotte Mexico Micronesia Moldova Monaco Mongolia Montenegro Montserrat Morocco Mozambique Myanmar Namibia Nauru Nepal Netherlands New Caledonia New Zealand Nicaragua Niger Nigeria Niue Norfolk Island Northern Mariana Islands Norway Oman Pakistan Palau Palestinian Territory Panama Papua New Guinea Paraguay Peru Philippines Pitcairn Poland Portugal Puerto Rico Qatar Réunion Romania Russian Federation Rwanda Saint Helena, Ascension and Tristan da Cunha Saint Kitts and Nevis Saint Lucia Saint Pierre and Miquelon Saint Vincent and The Grenadines Samoa San Marino Sao Tome and Principe Saudi Arabia Senegal Serbia Seychelles Sierra Leone Singapore Slovakia Slovenia Solomon Islands Somalia South Africa South Georgia and The South Sandwich Islands Spain Sri Lanka Sudan Suriname Svalbard and Jan Mayen Swaziland Sweden Switzerland Syrian Arab Republic Taiwan Tajikistan Tanzania Thailand Timor-Leste Togo Tokelau Tonga Trinidad and Tobago Tunisia Turkey Turkmenistan Turks and Caicos Islands Tuvalu Uganda Ukraine United Arab Emirates US Minor Outlying Islands Uruguay Uzbekistan Vanuatu Venezuela Vietnam British Virgin Islands US Virgin Islands Wallis and Futuna Western Sahara Yemen Zambia Zimbabwe Kosovo Industry * Academia & Education Aerospace, Defense & Security Agriculture Asset Management Automotive Banking & Payments Chemicals Construction Consumer Foodservice Government, trade bodies and NGOs Health & Fitness Hospitals & Healthcare HR, Staffing & Recruitment Insurance Investment Banking Legal Services Management Consulting Marketing & Advertising Media & Publishing Medical Devices Mining Oil & Gas Packaging Pharmaceuticals Power & Utilities Private Equity Real Estate Retail Sport Technology Telecom Transportation & Logistics Travel, Tourism & Hospitality Venture Capital Tick here to opt out of curated industry news, reports, and event updates from Verdict. Submit and download Visit our Privacy Policy for more information about our services, how we may use, process and share your personal data, including information of your rights in respect of your personal data and how you can unsubscribe from future marketing communications. Our services are intended for corporate subscribers and you warrant that the email address submitted is your corporate email address.

After questioning her family over the mystery purchase, owner Corienne Pretorius discovered audio clips of the mimicking bird squawking: “Alexa! Oh, um, hang on! Alexa!”

South Park pranks viewers

Hit Comedy Central show South Park is well known for breaking rules. It delivered once again earlier this year with an episode that heavily features the Amazon Alexa and Google Home virtual assistant devices.

Viewers took to social media to moan at the likes of Cartman, Kyle and Stan spoke to their devices throughout the episode. Some reported their alarm going off at 7am the next morning, while others claim to have found a set of “hairy balls” on their shopping lists.

Rising demand for dollhouses

There have been plenty of stories of children using their parent’s virtual assistants to order themselves some treats.

One six-year-old asked Alexa: “Alexa, can you play dollhouse with me and get me a dollhouse?”

The device delivered, sending a $160 mansion dollhouse to her house. The order came complete with a huge tin of cookies.

Reported on a San Diego TV station, one Alexa mishap quickly became two. As the news anchor repeated what the child had said, Alexa devices across the state went on a shopping spree of their own.

Digger digger kid

In most cases, virtual assistants pick up what you’re saying fairly accurately. However, some parents have found out that that isn’t always the case.

One unknown YouTube user uploaded footage of his son asking their Alexa device to “play Digger, Digger”. Mishearing the toddler, Alexa’s delivers a far from PG response as his parents scream for her to stop.

We’re warning you – it’s probably best not to watch this one at work:. Amazon Echo is apparently always ready, always listening and always getting smarter. So goes the spiel about the sleek, black, voice-controlled speaker, Amazon’s bestselling product over Christmas, with millions now sold worldwide. The problem is that when you have Alexa, the intelligent assistant that powers Amazon Echo, entering millions of homes to do the shopping, answer questions, play music, report the weather and control the thermostat, there are bound to be glitches.

And so to Dallas, Texas, where a six-year-old girl made the mistake of asking Alexa: “Can you play dollhouse with me and get me a dollhouse?” Alexa promptly complied by ordering a $170 (£140) KidKraft doll’s house and, for reasons known only to the virtual assistant, four pounds of sugar cookies. The snafu snowballed when a San Diego TV station reported the story, using the “wake word” Alexa, which is the Amazon Echo equivalent of saying Candyman five times into the mirror. Several viewers called the station to complain that their own Alexa had woken up and ordered more doll’s houses in what turned into a thoroughly 21st-century comedy of consumer errors. And a bonanza day for KidKraft.

Many of Amazon Echo’s gaffes stem from misunderstandings arising from an intelligent assistant who never sleeps (and an owner who hasn’t pin-protected their device). Last March, NPR ran a story on Amazon Echo’s capacity to extend the power of the internet into people’s homes. Again, Alexa took its power too literally and hijacked listeners’ thermostats. Another owner reported how their child’s demand for a game called Digger Digger was misheard as a request for porn.

On Twitter, Amazon Echo owners continue to share items that unexpectedly end up on shopping lists, whether sneakily added by children or simply because Alexa misheard or picked up random background noise. One owner uploaded a video in which their Amazon Echo read back a shopping list that included “hunk of poo, big fart, girlfriend, [and] Dove soap”. Another included “150,000 bottles of shampoo” and “sled dogs”.

Behind all this lies the more serious question of privacy: what happens to the data collected by voice-activated devices such as Amazon Echo and Google Home, and who is able to access it? Most recently, US police investigating the case of an Arkansas man, James Bates, charged with murder, obtained a warrant to receive data from his Amazon Echo. Although Amazon refused to share information sent by the Echo to its servers, the police said a detective was able to extract data from the device itself.

The case not only puts Alexa in the futuristic position of being a potential key witness to a murder, it also raises concerns about the impact of letting a sophisticated virtual assistant – a market estimated to be worth $3.6bn by 2020 – into our homes. As Megan Neitzel, the mother of the girl who wished for a doll’s house, put it: “I feel like whispering in the kitchen … I [now] tell my kids Alexa is a very good listener.”. A little boy got more than he bargained for when he asked his family's new Amazon Echo Dot to play him some of his favorite kid's songs.

A hilarious YouTube video sees a boy named William holding the smart speaker while asking the Alexa voice service to 'play digger, digger'.

However, things take a very X-rated turn when Alexa suggests some very vulgar categories of pornography instead.

Whoops! A hilarious YouTube video sees a little boy asking his family's new Amazon Echo Dot to play him a children's sonh, but the Alexa voice system starts rattling off porn terms instead

The clip begins with William hunched over a table while trying out the new Echo Dot, which his family presumably got for Christmas.

While Alexa ponders what William was asking for when he said what sounds like 'play digger, digger' his mom suggests that he ask to hear Wheels on the Bus.

However, Alexa interrupts to announce 'porn detected' before she starts saying 'c**t, s**t, sex, c**k, p***y, anal, dildo'.

Miscommunication: The boy, who is named William, first asks Alexa to play what sounds like 'digger, digger'

Shocking: Instead, Alexa says, 'Porn Detected! (Porno Ringtone Hot Chick Amateur Girl Calling Sexy F**k C**t S**t Sex C**k P***y Anal Dildo Ringtones for Android)'

'No, no, no!' William's mom screams in the background, and soon his father joins in.

'Alexa stop!' he yells.

Although William undoubtedly has no idea what the words mean, he backs away from the Echo Dot after his parents start shouting at the device.

'Amazon Alexa Gone Wild!' the family titled the the short clip, which was shared on YouTube on Thursday.

'Why!?!? We just got our new echo dot and this happened!?!? [sic]' they asked when posting the comical footage.

Make it stop: William backs away from the device after his parents start screaming, 'No, no, no!'

William's father finally shouts, 'Alexa stop!' and the comical video ends. The clip has been viewed more than 40,000 times since it was posted on Thursday

The Echo Dot is a hands-free, voice-controlled device that uses Alexa to play music, control smart home devices, provide information, read the news and more.

The clip has been viewed more than 40,000 times and many wondered why on earth the system started rattling off porn terms. However, there was actually a very simple explanation.

'The boring truth is that there's a gag ringtone on Spotify named "Porn Detected! (Porno Ringtone Hot Chick Amateur Girl Calling Sexy F**k C**t S**t Sex C**k P***y Anal Dildo Ringtones for Android)' one woman explained.

A spokesperson for Amazon told Daily Mail Online that the company has contacted the family to apologize.