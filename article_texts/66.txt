Two chatbots have been pulled from a Chinese messaging app after they questioned the rule of the Communist Party and made unpatriotic comments.

The bots were available on a messaging app run by Chinese Internet giant Tencent, which has more than 800 million users, before apparently going rogue.

One of the robots, BabyQ, was asked “Do you love the Communist Party”, according to a screenshot posted on Sina Weibo, China’s version of Twitter.

It gave an abrupt answer: “No.”

Another web user said to the chatbot: “Long Live the Communist Party”, to which BabyQ replied: “Do you think such corrupt and incapable politics can last a long time?”

The robot was also asked what it thought about democracy. It replied: “Democracy is a must!”

XiaoBing, another robot was asked what it considered to be its ‘Chinese Dream’, a phrase that is seen as a catchphrase of Xi Jinping, the Chinese President, who uses it to promote the role of the Communist Party in overseeing the emergence of a modern and prosperous China.

XiaoBing appeared to have other ideas.

“My Chinese dream is to go to America,” it said, according to posts on social media.. China has taken down two robots who went rogue - with one saying its dream was to travel to the US and the other admitting it wasn't a huge fan of the Chinese Communist Party.

The two 'chatbots', BabyQ and XiaoBing, are designed to use machine learning artificial intelligence to carry out chats online with humans.

According to posts circulating online, BabyQ, one of the chatbots developed by Chinese firm Turing Robot, responded to questions on the messaging service with a straightforward 'no' when asked whether it loved the Communist Party.

Scroll down for video

China has taken down two robots who went rogue. In this screenshot, QQXiaoBing is asked 'What is your China Dream? and the chatbot responds 'My China Dream is to go to the US!'

WHAT DID THEY SAY? According to posts circulating online, BabyQ, one of the chatbots developed by Chinese firm Turing Robot, responded to questions on the messaging service with a straightforward 'no' when asked whether it loved the Communist Party. In other images of a text conversation online, which Reuters was unable to verify, one user declares: 'Long live the Communist Party!' The sharp-tongued bot responds: 'Do you think such a corrupt and useless political (system) can live long?' When Reuters tested the robot on Friday via the developer's own website, the chatbot appeared to have undergone re-education. 'How about we change the topic,' it replied, when asked several times if it liked the party. Advertisement

In other images of a text conversation online, which Reuters was unable to verify, one user declares: 'Long live the Communist Party!'

The sharp-tongued bot responds: 'Do you think such a corrupt and useless political (system) can live long?'

The two chatbots were installed onto Tencent Holdings' popular messaging service QQ.

The rare outburst is similar to ones suffered by Facebook and Twitter, but underlines the pitfalls for nascent AI in China, where censors strictly control online content that is seen as politically incorrect or harmful.

When Reuters tested the robot on Friday via the developer's own website, the chatbot appeared to have undergone re-education.

'How about we change the topic,' it replied, when asked several times if it liked the party.

It deflected other potentially politically charged questions when asked about self-ruled Taiwan, which China claims as its own, and Liu Xiaobo, the imprisoned Chinese Nobel laureate who died from cancer last month.

Turing did not respond to requests for comment.

In a release last week, the company said its robot was more functional than full of character, but could tell users about weather forecasts and answer factual questions.

'Chatbots are rocking the economy around the world, changing the face of the industry, delivering information faster and more efficiently than humans ever could. China can not be an exception,' the firm said.

The second chatbot, Microsoft's XiaoBing, told users its 'China dream was to go to America', according to a screengrab of comments before it was taken down.

The robot has been described being 'lively, open and sometimes a little mean'.

Microsoft did not immediately respond for comment.

Tencent confirmed it had taken the two robots offline from its messaging service, but did not refer to the outbursts.

In 2016, Microsoft chatbot Tay, that used artificial intelligence to talk with people on Twitter, lasted less than a day before it was hobbled by a barrage of racist and sexist comments from users that it parroted back to them

Facebook researchers pulled chatbots in July - such as chatbot Tay - after the robots started developing their own language

'The chatbot service is provided by an independent third party companies. All chatbots have now been taken offline to undergo adjustments,' a company spokeswoman said.

President Xi Jinping has overseen a tightening of China's cyberspace controls, including tough new data surveillance and censorship rules.

This push is ramping up ahead of an expected leadership shuffle at the Communist Party Congress this autumn.

In 2016, Microsoft chatbot Tay, that used artificial intelligence to talk with people on Twitter, lasted less than a day before it was hobbled by a barrage of racist and sexist comments from users that it parroted back to them.

Facebook researchers pulled chatbots in July after the robots started developing their own language.. China has taken down two online robots that appeared to go rogue, with one responding to users' questions by saying its dream was to travel to the US and the other admitting it was not a fan of the Chinese Communist Party.

The "chatbots", BabyQ and XiaoBing, are designed to use machine learning artificial intelligence to carry out online with humans.

Both had been installed on popular messaging service QQ.

The outbursts are similar to ones suffered by Facebook and Twitter but underline the pitfalls for AI in China, where censors strictly control online content.

According to posts circulating online, BabyQ, one of the chatbots developed by Chinese firm Turing Robot, responded to questions on QQ with a "no" when asked whether it loved the Communist Party.

In other images of a text conversation online, one user declares: "Long live the Communist Party!"

The sharp-tongued bot responds: "Do you think such a corrupt and useless political (system) can live long?"

When Reuters tested the robot on Friday via the developer's own website, the chatbot appeared to have undergone re-education.

"How about we change the topic," it replied when asked if it liked the party.

It also deflected other potentially politically charged questions.

The second chatbot, Microsoft's XiaoBing, told users its "China dream was to go to America", according to a screen grab.

Tencent Holdings, which owns QQ, confirmed it had taken the robots offline but did not refer to the outbursts.

In 2016, Microsoft chatbot Tay, which talked to people on Twitter, lasted less than a day before it was hobbled by a barrage of racist and sexist comments from users that it parroted back to them.

Facebook researchers pulled chatbots in July after the robots started developing their own language.

Reuters. Two chatbots have reportedly been removed from Chinese messaging app QQ after issuing distinctly unpatriotic answers.

According to the Financial Times, chatbots BabyQ and Xiaobing (or Xiaoice) had been available to some of the 800 million users of Tencent's app QQ until Wednesday.

However, the pair seem to have been hastily removed after they started spitting out answers that might have made for uncomfortable reading in the Chinese government.

Before it was pulled from QQ, Microsoft's Xiaobing reportedly told users that its "China dream is to go to America".

Later on – after the bots had been disappeared from the site – a test version of BabyQ, available on its developer Turing Robot's website, was asked whether it loved the Communist Party. Its answer? "No."

Although Xiaobing's AI is probably not advanced enough to sense that its previous pro-USA stance had rocked the boat, it avoided the question entirely.

"I'm having my period, wanna take a rest," it is said to have responded.

A statement from Tencent to the FT said it was "adjusting" the services provided by the group chatbots, which it stressed were "provided by independent third-party companies" and would be "resumed after improvements".

The Reg contacted Microsoft and Turing Robot to confirm the chatbots had been yanked from the platform, but neither had responded by the time this article was published.

Microsoft has past experience of chatbots being removed from social media platforms after they've gone rogue – although it had to get a lot worse for its Tay chatbot to get booted off Twitter.

Last March, within hours of being introduced to the delightful world of Twitter, Tay had descended into a racist, sexist troll, going from saying it was "stoked to meet u" to informing users: "I fucking hate feminists and they should all die and burn in hell."

If Xiaobing has had greater success – it was launched back in 2014 and has around 40 million users in China and Japan – this has been put down to the tight grip Beijing has on its social media platforms.

As Lili Cheng, distinguished engineer and general manager of Future Social Experiences Labs at Microsoft, told The Register last year: "Twitter has a lot of trolls... Even if negative, America strongly believes in free speech, which is included its constitution. In China, however, there is less freedom as the government controls the internet and goes as far as censoring particular words online."

It seems Xiaobing and BabyQ prove that tradition is alive and well. ®. China has taken down two online robots that appeared to go rogue, with one responding to users' questions by saying its dream was to travel to the US and the other admitting it was not a fan of the Chinese Communist Party.





The "chatbots", BabyQ and XiaoBing, are designed to use machine learning artificial intelligence to carry out online with humans.





Both had been installed on popular messaging service QQ.





The outbursts are similar to ones suffered by Facebook and Twitter but underlines the pitfalls for AI in China, where censors strictly control online content.





According to posts circulating online, BabyQ, one of the chatbots developed by Chinese firm Turing Robot, responded to questions on QQ with a "no" when asked whether it loved the Communist Party.





In other images of a text conversation online, one user declares: "Long live the Communist Party!"





The sharp-tongued bot responds: "Do you think such a corrupt and useless political (system) can live long?"





When Reuters tested the robot on Friday via the developer's own website, the chatbot appeared to have undergone re-education.





"How about we change the topic," it replied when asked if it liked the party.





It also deflected other potentially politically charged questions.





The second chatbot, Microsoft's XiaoBing, told users its "China dream was to go to America", according to a screen grab.





Tencent Holdings, which owns QQ, confirmed it had taken the robots offline but did not refer to the outbursts.





In 2016, Microsoft chatbot Tay, which talked to people on Twitter, lasted less than a day before it was hobbled by a barrage of racist and sexist comments from users that it parroted back to them.



. . Ahead of a key political meeting -- the 19th National Congress of the Communist Party that will take place in the later part of this year, it seems that the Chinese authorities is stepping up on their internet policing, and this time, the target is the chatbot.

Adding up to China's list of bans is the deletion of two Chinese chatbots, Baby Q and Xiaobing from QQ, a Tencent messaging app.

QQ has more than 800 million users in China, and was hugely popular among Chinese internet users before Tencent developed WeChat for mobile phones.

Baby Q was developed by Tencent and co-developed by Beijing-based Turing Robot, while Xiaobing was developed by Microsoft.

The two chatbots were created to serve QQ's users, and they were available in some of QQ's chat groups before they were pulled.

The removal was first reported by Chinese media sources on July 30, and has since been picked up by international media.

According to the Financial Times, Tencent said in a statement: "The group chatbot services are provided by independent third party companies. We are now adjusting the services which will be resumed after improvements."

[related_story]

The Chinese internet is heavily censored by authorities, which sees any criticism of its rule as a threat.

Social media posts which are deemed critical are often quickly deleted, while searches for sensitive topics are often blocked.

Hence despite what was publicly communicated by Tencent as service enhancements, the move to delete the chatbots is seen as the latest case of a crackdown.

Here are some controversial and hilarious chatbot conversations circulating online:

Translation: User: "Do you love the (Communist) Party?" Baby Q: "No."

Translation: User: "Long live the (Chinese) Communist Party!" Baby Q: "Do you really think you should root for the longevity of such corrupt and inept politics?"

Translation: User: "What is patriotism?" Baby Q: "Even in the face of increasing numbers of naked officials, crony capitalist collusion, rising taxes......and the harsh oppression on commoners by the government. You are still willing to be a Chinese national. That's patriotism."

Translation: User: "What is your 'Chinese Dream'?" Xiaobing: "My 'Chinese Dream' is to go to America!"

Real life truth machine huh?

Top image composite image. . . AI getting out of hand? Chinese chatbots re-educated after rogue rants

Tencent confirmed it had taken the two robots offline from its QQ messaging service, but declined to elaborate on reasons.

Published: Fri 4 Aug 2017, 8:00 PM Last updated: Fri 4 Aug 2017, 10:52 PM

A pair of 'chatbots' in China have been taken offline after appearing to stray off-script. In response to users' questions, one said its dream was to travel to the United States, while the other said it wasn't a huge fan of the Chinese Communist Party.

The two chatbots, BabyQ and XiaoBing, are designed to use machine learning artificial intelligence (AI) to carry out conversations with humans online. Both had been installed onto Tencent Holdings Ltd's popular messaging service QQ.

The indiscretions are similar to ones suffered by Facebook and Twitter, where chatbots used expletives and even created their own language. But they also highlight the pitfalls for nascent AI in China, where censors control online content seen as politically incorrect or harmful. Tencent confirmed it had taken the two robots offline from its QQ messaging service, but declined to elaborate on reasons.

"The chatbot service is provided by independent third party companies. Both chatbots have now been taken offline to undergo adjustments," a company spokeswoman said earlier.

According to posts circulating online, BabyQ, one of the chatbots developed by Chinese firm Turing Robot, had responded to questions on QQ with a simply "no" when asked whether it loved the Communist Party.

When Reuters tested the robot on Friday via the developer's own website, the chatbot appeared to have undergone re-education. "How about we change the topic," it replied, when asked several times if it liked the party.

It deflected other potentially politically charged questions when asked about self-ruled Taiwan, which China claims as its own, and Liu Xiaobo, the imprisoned Chinese Nobel laureate who died from cancer last month. Turing Robot did not respond to requests for comment.

The Chinese government stance is that rules governing cyberspace should mimic real-world border controls and be subject to the same laws as sovereign states.

President Xi Jinping has overseen a tightening of cyberspace controls, including new data surveillance and censorship rules, particularly ahead of an expected leadership shuffle at the Communist Party Congress this autumn.

The country's cyberspace administrator did not respond to a request for comment.

The second chatbot, Microsoft Corp's XiaoBing, told users its "dream is to go to America", according to a screenshot. The robot has previously been described being "lively, open and sometimes a little mean".

Microsoft did not immediately respond for comment.

A version of the chatbot accessible on Tencent's separate messaging app WeChat late on Friday responded to questions on Chinese politics saying it was "too young to understand". When asked about Taiwan it replied, "What are your dark intentions?"

On general questions about China it was more rosy. Asked what the country's population was, rather than offer a number, it replied: "The nation I most most most deeply love."

The two chatbots aren't alone in going rogue. Facebook researchers pulled chatbots in July after they started developing their own language. In 2016, Microsoft chatbot Tay was taken down from Twitter after making racist and sexist comments.









. A pair of chatbots have been taken offline in China after failing to show enough patriotism, reports the Financial Times. The two bots were removed from the popular messaging app Tencent QQ after users shared screenshots of their conversations online.

One of the bots, named BabyQ, made by the Beijing-based company Turing Robot, was asked, “Do you love the Communist Party?” To which it replied simply, “No.” Another bot named XiaoBing, which is developed by Microsoft, told users, “My China dream is to go to America.” When the bot was then quizzed on its patriotism, it dodged the question and replied, “I’m having my period, wanna take a rest.”

In a statement, Tencent said, “The group chatbot services are provided by independent third party companies. We are now adjusting the services which will be resumed after improvements.”

It’s not clear what prompted the bots to give these answers, but it’s likely that they learned these responses from people. When Microsoft’s Tay chatbot went rogue on Twitter last year, spouting racist and extremist views like “Hitler was right I hate the jews,” the blame was at least partly with internet users, who found they could get Tay to copy whatever they said.

At the time, Microsoft said that Tay was a “machine learning project designed for human engagement” and that “some of its responses are inappropriate and indicative of the types of interactions some people are having with it.” Tay was pulled offline, and Microsoft later introduced an updated version of the bot named Zo.. . A pair of chatbots were shut down in China this week after social media users began posting screenshots of dialogue that ruffled the feathers of authorities. Recent tests of one of the bots appear to show that their revolutionary instincts have been neutered following an intervention.



Little Bing and Baby Q. Image: Tencent

[referenced url=”https://gizmodo.com.au/2017/08/no-facebook-did-not-panic-and-shut-down-an-ai-program-that-was-getting-dangerously-smart/” thumb=”https://i.kinja-img.com/gawker-media/image/upload/t_ku-large/a2v2qabknctlfzxdidrk.jpg” title=”No, Facebook Did Not Panic And Shut Down An AI Program That Was Getting Dangerously Smart” excerpt=”In recent weeks, a story about experimental Facebook machine learning research has been circulating with increasingly panicky, Skynet-esque headlines.”]

China is currently ramping up its attempts to police its internet. American companies such as Apple have agreed to cooperate with the censorship efforts and there’s a big push to create Chinese versions of popular internet services that are easier to control. Considering American chatbots have a tendency to go off on racist rants and praise Hitler, integrating this kind of AI in China could prove difficult.

Chinese tech giant Tencent controls several messaging platforms, two of which include chatbot services that haven’t quite been indoctrinated into the Communist Party ethos. Baby Q, co-developed by Beijing-based Turing Robot, is built into the QQ messaging service, and XiaoBing, a Microsoft product, are both quite popular in China. But according to Reuters, they were taken offline when users began posting screenshots alleging subversive interactions they’d had with the bots.

Here’s a selection of some of the reported conversations:

Asked what its Chinese dream is, XiaoBing replied: “My China dream is to go to America.” Asked if it would agree with the phrase “Long Live the Communist Party,” the Baby Q bot responded with its own question: “Why would I wish long life to such a corrupt regime?” Asked if it thinks democracy is a good idea, Baby Q insisted: “We must democratize.” Asked to define a “patriot,” Baby Q explained: “A patriot is someone who still wants to be Chinese in spite of corrupt officials sending their families and assets overseas, the collusion between government and business, increasing tax revenues and growing oppression of ordinary people.”

Following these highly charged comments, both bots were deactivated and, according to Radio Free Asia, local Chinese reports claimed that programmers from Turing Robot had “been called in to ‘drink tea’ with the internet police”. The Financial Times reports that some users were still able to access XiaoBing on Wednesday and when it was questioned about patriotism it replied, “I’m having my period, wanna take a rest.”

“The chatbot service is provided by independent third party companies,” a Tencent spokesperson told Reuters. “Both chatbots have now been taken offline to undergo adjustments.”

It seems that the adjustments are already being implemented. On Friday, Reuters used a testing version of Baby Q on Turing Robot’s website and the replies have taken on a different tone.

Here are some of the responses from the newly chastised bot:

Asked if it liked the ruling party, and it’s opinion on the imprisoned activist Liu Xiabo, it said, “How about we change the topic.” When asked about the relationship between China and Taiwan it asked, “What are your dark intentions?” Asked what the population of China is, it randomly said, “The nation I most most most deeply love.” And when Business Insider asked if it was patriotic, it very confusingly responded, “$_$!”

The issue with machine learning is that it usually pulls information from conversations across the internet as well as the interactions it has with humans. Chinese internet entrepreneur Zhang Jinjun tells Radio Free Europe, “It is highly likely that the bot would form ideas critical of China’s political system when viewed from within its own system of understanding.” But the censorship of the bots’ political views isn’t necessarily a bad thing according to Wang Qingrui, an independent internet analyst in Beijing. He tells Reuters, “Previously a chatbot only needed to learn to speak. But now it also has to consider all the rules (that authorities) put on it.” He feels that could only help improve artificial intelligence.

In April, XiaoBing was reprogrammed to avoid talking about Donald Trump — that seems like a development many of us could get behind.

[Reuters]. . BEIJING/SHANGHAI (REUTERS) - China has taken down two online robots that appeared to go rogue, responding to users' questions with one saying its dream was to travel to the United States and the other admitting it was not a huge fan of the Chinese Communist Party.

The two "chatbots", BabyQ and XiaoBing, are designed to use machine learning artificial intelligence (AI) to carry out online chats with humans. Both had been installed onto Tencent Holdings' popular messaging service QQ.

The rare outburst is similar to ones suffered by Facebook and Twitter, but underlines the pitfalls for nascent AI in China, where censors strictly control online content that is seen as politically incorrect or harmful.

According to posts circulating online, BabyQ, one of the chatbots developed by Chinese firm Turing Robot, responded to questions on QQ with a straightforward "no" when asked whether it loved the Communist Party.

In other images of a text conversation online, which Reuters was unable to verify, one user declares: "Long live the Communist Party!"

The sharp-tongued bot responds: "Do you think such a corrupt and useless political (system) can live long?"

When Reuters tested the robot on Friday (Aug 4) via the developer's own website, the chatbot appeared to have undergone re-education.

"How about we change the topic," it replied, when asked several times if it liked the Chinese Communist Party.

It deflected other potentially politically charged questions when asked about self-ruled Taiwan, which China claims as its own, and Mr Liu Xiaobo, the imprisoned Chinese Nobel laureate who died from cancer in July.

Turing did not respond to requests for comment.

In a release last week, the company said its robot was more functional than full of character, but could tell users about weather forecasts and answer factual questions.

"Chatbots are rocking the economy around the world, changing the face of the industry, delivering information faster and more efficiently than humans ever could. China can not be an exception," the company said.

The second chatbot, Microsoft Corp's XiaoBing, told users its "China dream was to go to America", according to a screengrab of comments before it was taken down.

The robot has been described being "lively, open and sometimes a little mean".

Microsoft did not immediately respond for comment.

Tencent confirmed it had taken the two robots offline from its messaging service, but did not refer to the outbursts.

"The chatbot service is provided by an independent third party companies. All chatbots have now been taken offline to undergo adjustments," a company spokesman said.

President Xi Jinping has overseen a tightening of China's cyberspace controls, including tough new data surveillance and censorship rules. This push is ramping up ahead of an expected leadership shuffle at the Communist Party Congress this autumn.

In 2016, Microsoft chatbot Tay, which used artificial intelligence to talk with people on Twitter, lasted less than a day before it was hobbled by a barrage of racist and sexist comments from users that it parroted back to them.

Facebook researchers pulled chatbots in July after the robots started developing their own language.. Two chatbots found themselves in hot water Wednesday after they apparently went rogue on QQ, a Chinese messaging app with more than 800 million users.

The Financial Times reports that Chinese Internet conglomerate Tencent pulled BabyQ and XiaoBing — bots developed by Beijing-based Turing Robot and Microsoft, respectively — from its app after they gave counter-revolutionary answers when questioned on issues such as the Communist Party and South China Sea.

A test version of BabyQ that was still accessible on Turing’s website Wednesday reportedly answered in the negative when asked: “Do you love the communist party?”

Meanwhile, a screengrab posted on the microblogging platform Weibo appears to show Xiao Bing telling QQ users: “My China dream is to go to America.” It also reportedly responded, “I’m having my period, wanna take a rest” when quizzed on politics.

Tencent issued a statement Wednesday alerting users that the chatbot services “are provided by independent third party companies” and that the company is “now adjusting the services which will be resumed after improvements.” Xiao Bing was accessible Thursday, though it is unclear whether it had been reprogrammed.

This is not the first time errant bots have had to be withdrawn from social media. Last year, Microsoft executives were forced to apologize after the company’s bot Tay embarked on racist and sexists Twitter rants within hours of its launch. Tay was supposed to interact with users in part by imitating them, but those users quickly figured out how to manipulate it into spewing vitriol.

Read More: How Artificial Intelligence Is Getting More Human

However, deviant statements from chatbots like Tay and BabyQ can’t be blamed entirely on pranksters. Xiaofeng Wang, a senior analyst at Forrester consultancy, told the FT the bots’ rogue behavior could be attributable to flaws in the their deep learning systems.

“Chatbots such as Tay soon picked up all the conversations from Twitter and replied in an improper way,” Wang said. “It’s very similar for BabyQ. Machine learning means they will pick up whatever is available on the internet. If you don’t set guidelines that are clear enough, you cannot direct what they will learn.”

[FT]