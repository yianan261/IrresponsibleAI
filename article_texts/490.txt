One side effect of unlimited content-creation machines—generative AI—is unlimited content. On Monday, the editor of the renowned sci-fi publication Clarkesworld Magazine announced that he had temporarily closed story submissions due to a massive increase in machine-generated stories sent to the publication.

In a graph shared on Twitter, Clarkesworld editor Neil Clarke tallied the number of banned writers submitting plagiarized or machine-generated stories. The numbers totaled 500 in February, up from just over 100 in January and a low baseline of around 25 in October 2022. The rise in banned submissions roughly coincides with the release of ChatGPT on November 30, 2022.

Large language models (LLM) such as ChatGPT have been trained on millions of books and websites and can author original stories quickly. They don't work autonomously, however, and a human must guide their output with a prompt that the AI model then attempts to automatically complete.

Since 2006, Clarkesworld has published renowned sci-fi authors and won several Hugo awards. Among sci-fi publications, it is well known for having an open submission process and typically pays 12 cents per word. On its submissions page, the publication states, "We are not considering stories written, co-written, or assisted by AI at this time." However, that has not stopped the number of submissions from increasing dramatically, and Clarke attributes it mostly to get-rich-quick schemes.

"The people causing the problem are from outside the SF/F community," wrote Clarke in a tweet. "Largely driven in by 'side hustle' experts making claims of easy money with ChatGPT. They are driving this and deserve some of the disdain shown to the AI developers."

Advertisement

At press time, a quick search on YouTube for terms like "get rich with ChatGPT" and "make money writing with ChatGPT" returned many results, although we did not identify a video that points to Clarkesworld in particular.

The problem of AI-authored content isn't unique to Clarkesworld. On Tuesday, Reuters wrote a report about the rise of AI-generated e-books on Amazon. Reuters identified over 200 e-books on the Amazon Kindle store that list ChatGPT as the author or co-author.

The influx of AI-generated content has left Clarkesworld in an awkward position of trying to keep the bar to submission high enough to keep away the spammers but not so high that it discourages undiscovered writers or writers from certain regions of the world who might be unfairly targeted by geographical-based bans. In a series of tweets, Clarke explained his predicament:

We don't have a solution for the problem. We have some ideas for minimizing it, but the problem isn't going away. Detectors are unreliable. Pay-to-submit sacrifices too many legit authors. Print submissions are not viable for us. Various third-party tools for identity confirmation are more expensive than magazines can afford and tend to have regional holes. Adopting them would be the same as banning entire countries. We could easily implement a system that only allowed authors that had previously submitted work to us. That would effectively ban new authors, which is not acceptable. They are an essential part of this ecosystem and our future.

It's worth reiterating that so far, tools that purport to detect text written by LLMs have low accuracy rates (often returning false positives when tested with human-written text), so they aren't currently a viable solution. Despite these issues, Clarke says the magazine isn't closing, and submissions will resume again at a future time. But for now, the way ahead is unclear.

"It’s not just going to go away on its own and I don’t have a solution," wrote Clarke in a blog post last Wednesday. "I’m tinkering with some, but this isn’t a game of whack-a-mole that anyone can 'win.' The best we can hope for is to bail enough water to stay afloat." In the meantime, Clarke encourages those who want to support the magazine to subscribe.. Since the early days of the pandemic, I’ve observed an increase in the number of spammy submissions to Clarkesworld. What I mean by that is that there’s an honest interest in being published, but not in having to do the actual work. Up until recently, these were almost entirely cases of plagiarism, first by replacing the author’s name and then later by use of programs designed to “make it your own.” The latter often results in rather ham-fisted results like this one I received in 2021:

These are the same sentences from the original story, “Human Error” by Raymond F. Jones, published in If (April 1956).

These cases were often easy to spot and infrequent enough that they were only a minor nuisance. Sometimes it would pick up for a month or two, but overall growth was very slow and number of cases stayed low. Anyone caught plagiarizing was banned from future submissions. Some even had the nerve to complain about it. “But I really need the money.”

Towards the end of 2022, there was another spike in plagiarism and then “AI” chatbots started gaining some attention, putting a new tool in their arsenal and encouraging more to give this “side hustle” a try. It quickly got out of hand:

(Note: This is being published on the 15th of February. In 15 days, we’ve more than doubled the total for all of January.)

I’m not going to detail how I know these stories are “AI” spam or outline any of the data I have collected from these submissions. There are some very obvious patterns and I have no intention of helping those people become less likely to be caught. Furthermore, some of the patterns I’ve observed could be abused and paint legitimate authors with the same brush. Regional trends, for example.

What I can say is that the number of spam submissions resulting in bans has hit 38% this month. While rejecting and banning these submissions has been simple, it’s growing at a rate that will necessitate changes. To make matters worse, the technology is only going to get better, so detection will become more challenging. (I have no doubt that several rejected stories have already evaded detection or were cases where we simply erred on the side of caution.)

Yes, there are tools out there for detecting plagiarized and machine-written text, but they are prone to false negatives and positives. One of the companies selling these services is even playing both sides, offering a tool to help authors prevent detection. Even if used solely for preliminary scoring and later reviewed by staff, automating these third-party tools into a submissions process would be costly. I don’t think any of the short fiction markets can currently afford the expense.

I’ve reached out to several editors and the situation I’m experiencing is by no means unique. It does appear to be hitting higher-profile “always open” markets much harder than those with limited submission windows or lower pay rates. This isn’t terribly surprising since the websites and channels that promote “write for money” schemes tend to focus more attention on “always open” markets with higher per-word rates.

This might suggest to some that it is in the best interest of a market to have limited submission windows, but I have no doubt that such reprieves would be short-lived. (That, however, might be all some editors need.) Others might seek the safety of solicited submissions or offering private submission opportunities to a narrower set of “known” authors instead of open calls. Editors might even find themselves having to push back on the privacy-minded desire among some authors to provide less contact information. Some might resort to blocking submissions from sources that mask their location with a VPN or other services. Taken a step further, others might employ regional bans as a strategy–much as we have seen happen with financial transactions–due to the high percentage of fraudulent submissions coming from those places.

It’s clear that business as usual won’t be sustainable and I worry that this path will lead to an increased number of barriers for new and international authors. Short fiction needs these people.

It’s not just going to go away on its own and I don’t have a solution. I’m tinkering with some, but this isn’t a game of whack-a-mole that anyone can “win.” The best we can hope for is to bail enough water to stay afloat. (Like we needed one more thing to bail.)

If the field can’t find a way to address this situation, things will begin to break. Response times will get worse and I don’t even want to think about what will happen to my colleagues that offer feedback on submissions. No, it’s not the death of short fiction (please just stop that nonsense), but it is going to complicate things.

Edit 2/17/2023 — I’ve closed comments on this post. There are plenty of places to have fights about publishing or AI. The world doesn’t need one more.

Edit 2/20/2023 — Submissions spiked this morning–over 50 before noon–so I’ve temporarily closed submissions. Here’s a refreshed version of the above graph:. 