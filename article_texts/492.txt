ARTICLE TITLE: Canadian Parents Tricked out of Thousands Using Their Son's AI Voice
You may very well get a call in the near future from a relative in dire need of help, asking you to send them money quickly. And you might be convinced it’s them because, well, you know their voice.

Artificial intelligence changes that. New generative A.I. tools can create all manner of output from simple text prompts, including essays written in a particular author’s style, images worthy of art prizes, and—with just a snippet of someone’s voice to work with—speech that sounds convincingly like a particular person.

In January, Microsoft researchers demonstrated a text-to-speech A.I. tool that, when given just a three-second audio sample, can closely simulate a person’s voice. They did not share the code for others to play around with; instead, they warned that the tool, called VALL-E, “may carry potential risks in misuse…such as spoofing voice identification or impersonating a specific speaker.”

But similar technology is already out in the wild—and scammers are taking advantage of it. If they can find 30 seconds of your voice somewhere online, there’s a good chance they can clone it—and make it say anything.

“Two years ago, even a year ago, you needed a lot of audio to clone a person’s voice. Now…if you have a Facebook page…or if you’ve recorded a TikTok and your voice is in there for 30 seconds, people can clone your voice,” Hany Farid, a digital forensics professor at the University of California at Berkeley, told the Washington Post.

‘The money’s gone’

The Post reported this weekend on the peril, describing how one Canadian family fell victim to scammers using A.I. voice cloning—and lost thousand of dollars. Elderly parents were told by a “lawyer” that their son had killed an American diplomat in a car accident, was in jail, and needed money for legal fees.

The supposed attorney then purportedly handed the phone over to the son, who told the parents he loved and appreciated them and needed the money. The cloned voice sounded “close enough for my parents to truly believe they did speak with me,” the son, Benjamin Perkin, told the Post.

The parents sent more than $15,000 through a Bitcoin terminal to—well, to scammers, not to their son, as they thought.

“The money’s gone,” Perkin told the paper. “There’s no insurance. There’s no getting it back. It’s gone.”

One company that offers a generative A.I. voice tool, ElevenLabs, tweeted on Jan. 30 that it was seeing “an increasing number of voice cloning misuse cases.” The next day, it announced the voice cloning capability would no longer be available to users of the free version of its tool VoiceLab.

Fortune reached out to the company for comment but did not receive an immediate reply.

“Almost all of the malicious content was generated by free, anonymous accounts,” it wrote. “Additional identity verification is necessary. For this reason, VoiceLab will only be available on paid tiers.” (Subscriptions start at $5 per month.)

Card verification won’t stop every bad actor, it acknowledged, but it will make users less anonymous and “force them to think twice.”. A couple in Canada reportedly lost $21,000 from a scammer claiming to be a lawyer and their son.

Benjamin Perkin told The Washington Post his parents thought the AI-generated voice was him.

The rise of AI is making it easier for scammers to make people think they're talking to loved ones.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Advertisement

A couple in Canada were reportedly scammed out of $21,000 after they received a call from someone claiming to be a lawyer who said their son was in jail for killing a diplomat in a car accident.

Benjamin Perkin told The Washington Post the caller put an AI-generated voice that sounded like him on the phone with his parents to ask for money. The alleged lawyer called his parents again after the initial call, and told them Perkin needed $21,000 for legal fees before going to court.

Perkin told the Post the voice was "close enough for my parents to truly believe they did speak with me."

His parents collected the cash and sent the scammer money through Bitcoin, Perkin said, but they later admitted they thought the phone call sounded strange. They realized they had been scammed after Perkin called to check in later that evening.

Advertisement

Perkin did not immediately respond to a reachout from Insider to discuss what happened.

He told the Post his family filed a police report with Canadian authorities, but that, "The money's gone. There's no insurance. There's no getting it back."

The Post reported that while Perkin doesn't know how the scammers found his voice, he has posted videos about snowmobiling on YouTube.

Related stories

The rise of more powerful AI tools is coinciding with a rise in scams involving people impersonating other people. The most commonly reported scam last year was imposter scams, the Federal Trade Commission found. The FTC saw fraud reports from 2.4 million people in 2022, which was lower than in 2021. However, the amount of money lost was higher, with $8.8 billion reported lost.

Advertisement

Scams involving AI technology predate the emergence of ChatGPT and other AI bots going viral right now. In 2019, the managing director at a British energy company reportedly wired over $240,000 to an account in Hungary after he thought his boss asked him to do so in a phone call.

In January, ElevenLabs, a research lab exploring voice cloning and tools for synthetic speech, shared a Twitter thread addressing people who "use our tech for malicious purposes."

The startup tweeted that it was releasing a tool to let people verify if an audio sample was made using the company's technology, and that its VoiceLab would only be accessible with payment.

A day before writing the thread, ElevenLabs tweeted that it was aware of "an increasing number of voice cloning misuse cases," after releasing its Beta platform.

Advertisement

Motherboard found that members on the anonymous site, 4chan, were using ElevenLabs' technology to generate voices that sound like celebrities to say racist and inappropriate things.

The FTC has created a new Office of Technology to investigate the potential uses of AI that companies are promising, and to see if companies are mitigating the risks their products can cause.

"We're also concerned with the risk that deepfakes and other AI-based synthetic media, which are becoming easier to create and disseminate, will be used for fraud," FTC spokesperson Juliana Gruenwald previously told Insider.

Gruenwald also told Insider that the FTC "has already seen a staggering rise in fraud on social media."

Advertisement

"AI tools that generate authentic-seeming videos, photos, audio, and text could supercharge this trend, allowing fraudsters greater reach and speed," she said.