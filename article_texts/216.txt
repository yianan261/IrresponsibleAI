ARTICLE TITLE: WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”
For free real time breaking news alerts sent straight to your inbox sign up to our breaking news emails Sign up to our free breaking news emails Please enter a valid email address Please enter a valid email address SIGN UP I would like to be emailed about offers, events and updates from The Independent. Read our privacy policy Thanks for signing up to the

Breaking News email {{ #verifyErrors }} {{ message }} {{ /verifyErrors }} {{ ^verifyErrors }} Something went wrong. Please try again later {{ /verifyErrors }}

WeChat, the Chinese messaging app, has apologised for translating “black foreigner” into the N-word.

It was noticed by Ann James, a black American director and actor who featured in China’s highest-grossing film ever, this summer’s Wolf Warrior 2.

Ms Jones recently texted Chinese colleagues to tell them she was running late. When Ms Jones translated their Chinese response into English using WeChat’s translation feature, it read: “The [N-word] is late.”

“I was just horrified”, Ms James, who has lived in China for five years, told news site Sixth Tone.

But a Chinese colleague assured Ms James that the original Chinese used – “hei laowai” – was a neutral phrase.

Local news outlet That’s Shanghai tested the app. It found that in some sentences the phrase “black foreigner” was translated neutrally, but when the phrase was used in a negative context, the app translated it into the N-word.

WeChat admitted the error.

"We're very sorry for the inappropriate translation”, a spokesperson told Sixth Tone.

“After receiving users' feedback, we immediately fixed the problem."

The app's translation software uses artificial intelligence. It learns how to use language in context by analysing huge volumes of material, which is why it may choose insulting language to translate negative sentences.

Ms James questioned why WeChat included material containing the N-word in its machine learning process.

“Why is that word even in the translator?”

Nearly a billion people used WeChat for chatting, shopping and gaming. It is censored by the Chinese government. Whatsapp, another messaging app which WeChat resembles, which has been blocked in China.

WeChat’s parent company, Tencent, is worth $275 million, making it the world’s tenth most valuable public company, according to The Economist.. The translation service in China’s biggest messaging app, WeChat, is being retooled after offering a racist slur as a translation for the phrase “black foreigner.”



Ann James, a black theater director based in Shanghai, messaged her colleagues in English on Wednesday to say she was running late. When a coworker replied in Chinese, WeChat translated their message into English as “The nigger is late.” As Sixth Tone explains, “hei laowai,” the term the coworker actually used, is a neutral phrase meaning “black foreigner.” But until the issue was raised following James’ rude awakening, WeChat sometimes translated it as the n-word.

Advertisement

WeChat sent Sixth Tone the following apology, but gave no further explanation: “We’re very sorry for the inappropriate translation. After receiving users’ feedback, we immediately fixed the problem.” The platform boasts a staggering 700 million users worldwide and, in China, is used for everything from booking plane tickets to paying utility bills to office communications.



WeChat confirmed their software uses neural machine translation, AI that’s been trained on vast quantities of text to gain new vocabulary and, crucially, discern the specific contexts in which to use these new words. That second part may be what triggered the slur. From Sixth Tone:

A local English-language media outlet, That’s Shanghai, reported the story and found that the translator gave neutral translations in some instances but used the slur when the phrase in question included a negative term, such as “late” or “lazy.” Sixth Tone’s own testing on Wednesday evening found similar results.

Advertisement

Recognizing patterns is the core of language AI. Neural language processing AI picks up on patterns between associated words, then spits them back out. In 2016, for example, researchers used algorithms trained on Google News copy to uncover associations the news crawler was picking up. As the algorithm determined, “Emily” is to “Ebony” as “pancakes” are to “fried chicken.” In another case, it found “man” is to “woman” as “doctor” is to “nurse.”



Advertisement

This is essentially how you “teach” AI to be racist. AI literalizes negative connotations. If the phrases “black foreigner” or “black person” are used as slurs in conjunction with words like “lazy” or “slow” in the source text, the AI picks up on those patterns and makes them explicit. All the AI does is repeat the associations buried in its source.

Advertisement

Interestingly, the derogatory translations seem to have been provided by an unspecified service, while the inoffensive translations were explicitly performed by Microsoft Translator. That’s Shanghai couldn’t replicate the offensive translation in either Bing Translator or Microsoft’s Neural Machine Translation system. “Hei laowai,” even when coupled with words like “lazy” or “rude,” still produced “black foreigner.” One could infer that Microsoft’s platform either removed the slur already or that association had never been made.

Neural language processing was invented so AI could speak and think more like humans. Sadly, they’re learning the worst of what we offer.

Advertisement

[Sixth Tone]