. A military investigation has concluded that a "friendly fire" incident in which a Navy pilot was shot down and killed by U.S. forces during the spring 2003 invasion of Iraq occurred because operators at two Patriot missile batteries and a command center all mistakenly took his F/A-18 Hornet for an incoming Iraqi missile, the U.S. Central Command said last night.

The April 2003 incident was one of two during the campaign in which Patriot anti-missile batteries mistakenly hit allied aircraft. In the other, in late March 2003, a Patriot destroyed a British Tornado GR4 fighter-bomber near the border of Iraq and Kuwait, killing two crew members.

The core conclusion of the Central Command report, that the Navy jet was downed by Patriot missiles, confirms what was widely believed almost immediately after the incident occurred.

Advertisement

According to the summary released by the Central Command, on April 2, 2003, two Navy F/A-18s were near Karbala in central Iraq and heading back to their ship, the USS Kitty Hawk. A Patriot missile battery mistakenly identified the plane as an Iraqi missile and notified the headquarters for air defense, the Information Coordination Center. The center mistakenly designated the flight path of the Navy jet as a missile track, the report said.

Seconds later, a second battery located closer to the front line of fighting also detected the plane and also mistakenly determined it was a missile. The second battery decided that it and the military unit it was defending were the missile's target.

The effect of the corroborating reports made operators at the two batteries and at the command center "increasingly confident that they were all detecting the same hostile missile, that their detection was accurate, and that this missile was a direct threat to U.S. forces," said the summary of the report released last night. The command center then ordered that two missiles be launched, it said. The summary does not explain why operators were fooled or how they mistook the radar profile of a plane for that of a faster missile.

Advertisement

There are no plans to punish the personnel involved, said Marine Capt. Kelly Frushour, a spokeswoman for the Central Command. "It was determined . . . that no disciplinary action was warranted," she said.

The report was released on Friday evening because the family of the Navy pilot, Lt. Nathan White, first had to be notified of its findings, she said. It took more than 20 months to release the report because Army Gen. John P. Abizaid, the chief of the Central Command, asked that its findings be reviewed, she said. But she said she did not know what the outcome of that review was.

Dennis White, father of the downed pilot, said he did not want punitive action taken. "It's a heartbreak for us, but I personally do not hold these young men responsible," he said. An Air Force veteran, he added, "I was a combat pilot during the Vietnam War, and I know what the pressures of combat can do.". On March 22, 2003, two days into the U.S.-led invasion of Iraq, American troops fired a Patriot interceptor missile at what they assumed was an Iraqi anti-radiation missile designed to destroy air-defense systems. Acting on the recommendation of their computer-powered weapon, the Americans fired in self-defense, thinking they were shooting down a missile coming to destroy their outpost. What the Patriot missile system had identified as an incoming missile, was in fact a UK Tornado fighter jet, and when the Patriot struck the aircraft, it killed two crew on board instantly. The deaths were the first losses suffered by the Royal Air Force in the war and the tragic result of friendly fire.

A subsequent RAF Board of Inquiry investigation concluded that the shoot-down was the result of a combination of factors: how the Patriot missile classified targets, rules for firing the missiles, autonomous operation of Patriot missile batteries, and several other technical and procedural factors, like the Tornado not broadcasting its “friend or foe” identifier at the time of the friendly fire. The destruction of Tornado ZG710, the report concluded, represented a tragic error enabled by the missile’s computer routines.

The shoot-down of the Tornado happened nearly 20 years ago, but it offers an insight into how AI-enabled systems or automated tools on the battlefield will affect the kinds of errors that happen in war. Today, human decisionmaking is shifting toward machines. With this shift comes the potential to reduce human error, but also to introduce new and novel types of mistakes. Where humans might have once misidentified a civilian as a combatant, computers are expected to step in and provide more accurate judgment. Across a range of military functions, from the movement of autonomous planes and cars to identifying tanks on a battlefield, computers are expected to provide quick, accurate decisions. But the embrace of AI in military applications also comes with immense risk. New systems introduce the possibility of new types of error, and understanding how autonomous machines will fail is important when crafting policy for buying and overseeing this new generation of autonomous weapons.

What went wrong in 2003

The Patriot missile began development in the 1960s, when the U.S. Army sought a means to reliably shoot down enemy airplanes. Later, the missile would gain the ability to also intercept other missiles, and as the roles assigned to the missile expanded, its autonomous capabilities increased. Patriot missile batteries use a phased array radar to detect and identify targets. This information is then fed into a computer control station to manage how the missiles are launched in response. Once fired, the missiles fly toward an identified intercept point calculated before firing, directions that can be altered by sending updated sensor readings over radio signal to the fired missile. As it approaches for impact, the missile’s own radar tracks the target. Raytheon, which manufactures the Patriot, has described the system as having “automated operations” with “man-in-the-loop (human) override” capabilities—technology that allows the weapon to quickly engage targets with the necessary speed to carry out its missile defense mission.

Automation is a compelling feature for an anti-air and, especially, for an anti-missile system. The calculations involved in shooting down aircraft and missiles are hard and require immediate translation of sensor information. Both interceptors and targets are traveling exceptionally fast. It’s the kind of task in which the involvement of a human introduces lag, slows down the process, and makes it less likely a missile is going to successfully shoot down an incoming projectile or aircraft. But human operators also serve an essential role: preventing accidental, incorrect shootdowns. And this requires a balance between human and machine decisionmaking that is difficult to achieve.

When the Pentagon investigated the causes of the Tornado shootdown, as well as two other incidents of friendly fire involving Patriot systems, the missile system’s automated functions were identified as contributing factors in misidentifying friend as foe. U.S. Patriot batteries deployed to Iraq under the assumption that they would face heavy missile attacks, which would require the batteries to operate with a relative degree of autonomy in order to respond with sufficient speed. As a 2005 report by the Defense Science Board Task Force on the Patriot system’s performance observed, operating autonomously required U.S. forces to trust that the automated features of the system were functioning properly. So when the assumptions underlying the decision to allow the Patriot system to autonomously identify and sometimes fire on targets no longer applied, the soldiers operating the system were not in a position to question what the weapon’s sensors were telling them.

Had U.S. and coalition forces faced heavy missile attacks in the war, automating such defenses would have made more sense. Instead, U.S. and allied forces quickly established air superiority, enough to drastically shift the balance of what was in the sky. Instead of facing large amounts of incoming missiles, Patriot batteries were observing large numbers of allied planes operating in the sky above them and sometimes struggling to identify friend from foe. According to the Defense Science Board’s task force, the first 30 days of combat in Iraq saw nine ballistic missile attacks that Patriot batteries might have been expected to counter, compared to 41,000 aircraft sorties, amounting to a “4,000-to-1 friendly-to-enemy ratio.” Picking out the correct targets against the background of a large number of potential false positives proved highly challenging.

In the case of the Tornado shootdown, automation—and the speed with which automated action was taken—was likely sufficient on its own to cause the tragedy, but it might have been prevented if other systems hadn’t failed. As the UK Ministry of Defence concluded in its report examining the incident, the battery culpable for the shootdown was without its communications suite, which was still in transit from the United States. Contact with battalion headquarters occurred through a radio relay with another battery equipped with voice and data links to headquarters. “The lack of communications equipment meant that the Patriot crew did not have access to the widest possible ‘picture’ of the airspace around them to build situational awareness,” the report found.

Another system that failed and that might have prevented the shootdown was the identification-as-friend-or-foe system, a safety measure designed to avoid such deadly mistakes. That kind of information, transmitted securely and immediately, could have prevented an automated system from shooting down the jet. If the information was communicated to the human crew operating the Patriot battery, it would have been a signal to call off the attack. Tragically, the IFF transponder or the Patriot battery’s ability to receive such a signal failed.

While it is tempting to focus on the automated features of the Patriot system when examining the shootdown—or autonomous and semi-autonomous systems more broadly—it is important to consider such weapons as part of broader systems. As policymakers consider how to evaluate the deployment of increasingly autonomous weapons and military systems, the complexity of such systems, the ways in which they might fail, and how human operators oversee them are key issues to consider. Failures in communication, identification, and fire-control can occur at different points of a chain of events, and it can be difficult to predict how failures will interact with one another and produce a potentially lethal outcome. The Defense Science Board’s examination of the Patriot concluded that future conflicts will likely be “more stressing” and involve “simultaneous missile and air defense engagements.” In such a scenario, “a protocol that allows more operator oversight and control of major system actions will be needed,” the task force argued.

Lessons learned since

Finding the right mix of trust between an autonomous machine and the human relying on it is a delicate balance, especially given the inevitability of error. Seventeen years after the Tornado shootdown, the automated features of the Patriot missile remain in place, but the way in which they are used has shifted. Air threats, such as aircraft, helicopters, and cruise missiles can now only be engaged in manual mode “to reduce the risk of fratricide,” as the U.S. Army’s manual for air and missile defense outlines. In manual mode, automated systems still detect and track targets, but it’s a human who makes the call about when and if to fire. But “for ballistic missiles and anti-radiation missiles,” like the kind the Patriot in Iraq assumed the Tornado was, “the operator has a choice of engaging in the automatic or manual mode,” though the manual notes that these “engagements are typically conducted in the automatic mode.”

Defense researchers caution that human beings are not well-suited to monitoring autonomous systems in this way. “Problems can arise when the automated control system has been developed because it presumably can do the job better than a human operator, but the operator is left in to ‘monitor’ that the automated system is performing correctly and intervene when it is not,” the engineering psychologist John Hawley, who was involved in the U.S. Army’s efforts to study the 2003 friendly fire incidents, wrote in a 2017 report. “Humans are very poor at meeting the monitoring and intervention demands imposed by supervisory control.”

This dynamic played out in the other fatal friendly fire incident involving a Patriot missile battery during the Iraq War, when a U.S. Navy F/A-18 aircraft was misidentified as a ballistic missile and shot down, killing the pilot. According to a 2019 Center for Naval Analyses report, the Patriot recommended that the operator fire missiles in response to what it had identified as an enemy projectile, and the operator approved the recommendation to fire “without independent scrutiny of the information available to him.”

This difficulty faced by Patriot missile batteries in correctly identifying potential targets illustrates one of the most serious challenges facing autonomous weapons—getting accurate training data. As militaries move toward greater autonomy in a wide range of systems, they are increasingly reliant on machine learning technology that uses large data sets to make predictions about how a machine should operate. The challenge of acquiring accurate data sets autonomous systems up for inevitable failure. “Conflict environments are harsh, dynamic and adversarial, and there will always be more variability in the real-world data of the battlefield than in the limited sample of data on which autonomous systems are built and verified,” as Arthur Holland Michel, and associate researcher in the Security and Technology Programme at the UN Institute for Disarmament Research, wrote in a report last year addressing data issues in military autonomous weapons. A lack of reliable data or an inability to produce datasets that replicate combat conditions will make it more likely that autonomous weapons fail to make accurate identifications.

Aware of the potential for error, one way to adopt autonomous systems while addressing the risk to civilians and servicemembers is to shift toward a posture in which risk is borne primarily by the machine. The 2003 shootdowns involved Patriot missiles acting in self-defense and misidentifying their enemy. By accepting greater risk to autonomous systems—that they might be destroyed or disabled—autonomous systems can avoid the risk of friendly fire or civilian casualties by “using tactical patience, or allowing the platform to move in closer to get a more accurate determination of whether a threat actually exists,” as Larry Lewis, the author of the 2019 CNA report, argues. Rather than quickly firing in self-defense, this view argues for patience and sacrificing a measure of speed in favor of accuracy.

More broadly, Lewis recommends a risk management approach to using AI. While the specific nature of every given error is hard to anticipate, the range of bad and undesired outcomes can fall in similar categories of error or outcome. Planning for AI incorporated into weapons, sensors, and information displays could include an awareness of error, and present that information in a useful way without adding to the cognitive load of the person using the machine.

Artificial Intelligence has already moved beyond the speculative to tangible, real-world applications. It already informs the targeting decisions of military weapons, and will increasingly shape how people in combat use machines and tools. Adapting to this future, as the Pentagon and other military establishments seem intent to do, means planning for error, accidents, and novel harm, the way militaries have already adapted to such error in human hands.

The Pentagon has taken some steps to address these risks. In February 2020, the Department of Defense released a set of principles AI ethics drafted by the Defense Innovation Board. One of these principles is “traceability,” emphasizing that relevant personnel will “possess an appropriate understanding of the technology,” including transparent and auditable data methodology. To foster that understanding and ensure that nondeterministic systems can be audited, the Pentagon is investing in testing, evaluation, validation, and verification methods for AI. The development of testing and explainability tools for military AI applications represents one of the key challenges for the technology, and making the necessary investments to develop these tools will be key to responsibly deploying AI tools on the battlefield. This work is ongoing at the Joint Artificial Intelligence Center, which in February awarded contracts to 79 vendors worth up to $15 million a piece to develop testing and evaluation technology.

At this relatively early stage of deploying AI in military applications, it’s important that researchers and policymakers develop what Holland Michel describes as a “a finer-grain scheme for differentiating between different types of failure. By developing criteria to distinguish known unknown issues from unknown unknown issues,” policymakers can gain a more clear understanding of how AI systems are failing, which could “aid efforts to quantify risk in operations and assign due responsibility for unintended harm arising from data issues.” Another policy approach would be incorporating red teaming and adversarial assessment into the evaluation of AI products, as it would allow engineers of military AI to anticipate and plan for future failures in combat based on hostile action.

The additional challenges AI brings will come not in the existence of error, but in the nature of the error and the limits of explainability of the error. Thoughtful policymaking can anticipate this, and when in doubt, design systems that put machines in harm’s way before risking the lives of civilians or servicemembers.

Kelsey Atherton is a military technology journalist based in Albuquerque, New Mexico. His reporting has appeared in Popular Science, Breaking Defense, and The New York Times.. Our recent story on the 2003 friendly-fire incident which saw a US Patriot missile down a RAF Tornado with the loss of both crew members, prompted several reader comments on the weapon's chequered history.

Long before Gulf War II, there was considerable concern and doubt surrounding the Patriot's reliability and performance. The missile (overview here), which is manufactured by Raytheon and Lockheed Martin, began life some 40 years ago as an anti-aircraft weapon. According to the Raytheon blurb:

Patriot is a long-range, high-altitude, all-weather system designed to defeat advanced threats, including aircraft, tactical ballistic missiles, and cruise missiles. Combat proven during Operation Desert Storm, Patriot can simultaneously engage multiple targets under the most severe electronic countermeasure conditions. Since Operation Desert Storm, the United States Department of Defense has invested over $3.0 billion to further improve and extend Patriot ground equipment performance. Multifunction phased array radar, track-via-missile guidance, and automated operations - including man-in-the-loop (human) override - are the key features of the Patriot system. In addition to the phased array radar, a Patriot Fire Unit is deployed with an engagement control station, an electronic power plant vehicle, an antenna mast group for communications, and up to sixteen remote launching stations. Each launcher contains four ready-to-fire Patriot missiles.

The list of threats is significant here. In fact, the Patriot was hurriedly modified for anti-ballistic missile service in Desert Storm. It was heralded as a great success at the time for its performance against Scuds - particularly in Israel - but later analysis told a different story.

The tally of Scuds claimed was, in fact, fictitious. An initial kill rate of 40-50 per cent soon became a mere 5-10 per cent. Worse still, Patriot suffered from a serious software problem which quickly manifested itself with disastrous results:

On February 25, 1991, a Patriot missile defense system operating at Dhahran, Saudi Arabia, during Operation Desert Storm failed to track and intercept an incoming Scud. This Scud subsequently hit an Army barracks, killing 28 Americans. This report responds to your request that we review the facts associated with this incident and determine if a computer software problem was involved. If so, you asked that we provide information on what the specific software problem was, and what has been done to correct it.

That's the first paragraph of a 1992 report by the Information Management and Technology Division of the General Accounting Office in response to a request by Howard Wolpe, Chairman, Subcommittee on Investigations and Oversight Committee on Science, Space, and Technology, House of Representatives.

The report's summary conclusion (there are more detailed extracts at the end of this article) states:

The Patriot battery at Dhahran failed to track and intercept the Scud missile because of a software problem in the system's weapons control computer. This problem led to an inaccurate tracking calculation that became worse the longer the system operated. At the time of the incident, the battery had been operating continuously for over 100 hours. By then, the inaccuracy was serious enough to cause the system to look in the wrong place for the incoming Scud. The Patriot had never before been used to defend against Scud missiles nor was it expected to operate continuously for long periods of time. Two weeks before the incident, Army officials received Israeli data indicating some loss in accuracy after the system had been running for 8 consecutive hours. Consequently, Army officials modified the software to improve the system's accuracy. However, the modified software did not reach Dhahran until February 26, 1991--the day after the Scud incident.

No surprise then that "since Operation Desert Storm, the United States Department of Defense has invested over $3.0 billion to further improve and extend Patriot ground equipment performance", as Raytheon puts it.

Perhaps, then, it might be reasonable to expect a considerable improvement in Patriot performance during Gulf War II. An abc news report dated 23 March 2003 tells of Patriot batteries bogged down in sand en route to Nasiriya:

Patriot missile systems are made up of a system of delicate electronics susceptible to frequent failures. While stationary in Kuwait, each battery in this unit had almost daily problems that caused the system to shut down. Commanders worried that the combined stress of a long trip and sand in the electronics could render the radar and computers useless by the time they arrived on site. In less than an hour, the Patriot missiles were set up, and it was the moment of truth for the computers and the radar. Everything worked and everyone was relieved. Maybe Patriot systems were made for this, after all.

Not so. On the same day a Patriot battery downed an RAF Tornado returning from a mission over Iraq, killing Flt Lt Kevin Main and Flt Lt David Williams.

Two days later, a US Air Force pilot in an F-16 fighter was alerted to the fact that he had been targeted by radar. Assuming it to be enemy in origin, he counter-attacked and fired a missile at a Patriot battery, an event witnessed by embedded reporter Robert Riggs from the Dallas station KTVT: "Suddenly, my whole field of vision is just-becomes white light. We all thought we were under Iraqi mortar attack. We had no idea this is the good guys shooting at us."

The CBS report which contains Riggs' experiences with the Patriot battery makes sobering reading:

This was like a bad science fiction movie in which the computer starts creating false targets. And you have the operators of the system wondering is this a figment of a computer's imagination or is this real. They were seeing what were called spurious targets that were identified as incoming tactical ballistic missiles. Sometimes, they didn't exist at all in time and space. Other times, they were identifying friendly U.S. aircraft as incoming TBMs.

Sometimes, as CBS notes, the system realised its error, and sometimes it didn't. Riggs continues:

We were in one of the command posts. And I walked in and all the operators and officers are focused intently on their screens. And so you know something's going on here. And suddenly the door flies open, and a Raytheon tech representative runs in and says, ‘Don't shoot! Don't shoot!’ Well, that got our attention real quick.

On 2 April, 2003 two Patriots downed the F-A-18C of US Navy Pilot Lt. Nathan White while he was returning to the USS Kitty Hawk. He was killed instantly.

Last week's report by UK defence minister Ivor Caplin on the Tornado incident fingered a "system error" as the cause, linked to failure of the aircraft's "identification friend or foe" (IFF) system against a backdrop of of "inexperienced US troops, heavily reliant on technology to make decisions, but lacking crucial equipment which could have helped them identify the Tornado as a friendly aircraft".

More specifically, the Ministry of Defence Military Aircraft Accident Summary (PDF) notes that:

1. Royal Air Force Tornado GR4A ZG710 was returning to Ali Al Salem Air Base in Kuwait at 2348 hrs on 22 Mar 03 (0248 hrs on 23 Mar 03 local time) when it was destroyed by a US Army Patriot Surface-to-Air-Missile after being wrongly identified as an Iraqi Anti-Radiation Missile. The aircraft was the second of a pair of Tornados, flying as part of a package of Coalition aircraft, operating during the early part of the war in Iraq. Both members of the crew were killed instantly when the missile hit their aircraft. 4. The Patriot Battery crew were monitoring for Iraqi Tactical Ballistic Missiles when ZG710 was tracked by their system. The symbol which appeared on their radar indicated that an Anti-Radiation Missile was coming directly towards them. The track was interrogated for IFF but there was no response. Having met all classification criteria, the Patriot crew launched the missile, and the Tornado, mistaken for an "Anti-Radiation Missile", was engaged in self-defence. The Patriot crew had complied with extant self-defence Rules of Engagement for dealing with Anti-Radiation Missiles.

How, then, could the Patriot mistake a Tornado for an anti-radiation missile?

Patriot System Anti-Radiation Missile Classification. 9. The Patriot system identifies hostile missiles through their flight profile and other characteristics, including the lack of an IFF response. The criteria programmed into the Patriot computer were based on the many different Anti-Radiation Missiles available worldwide, and were therefore very broad. ZG710's flight profile met these criteria as it commenced its descent into Ali Al Salem. The Board considered that the criteria should have been much tauter, based on the known threat from Iraq, and concluded that the generic Anti-Radiation Missile classification criteria programmed into the Patriot computer were a contributory factor in the accident.

Regarding the Patriot's operators' role in the disaster, the report notes:

Patriot Anti-Radiation Missile Rules Of Engagement. 10. The Board concluded that the Patriot Anti-Radiation Missile Rules Of Engagement were not robust enough to prevent a friendly aircraft being classified as an Anti-Radiation Missile and then engaged in self-defence, and were thus contributory factors in the accident. Patriot Firing Doctrine and Training. 11. Patriot crews are trained to react quickly, engage early and to trust the Patriot system. If the crew had delayed firing, ZG710 would probably have been reclassified as its flight path changed. The crew had about one minute to decide whether to engage. The crew were fully trained, but their training had focused on recognising generic threats rather than on those that were specific to Iraq or on identifying false alarms. The Board concluded that both Patriot firing doctrine and training were contributory factors in the accident.

To add a final twist to this tale, there is the matter of the Tornado's IFF system:

15. The Board considered IFF serviceability, potential IFF failures, and aircrew actions relating to the IFF. The Board was able to discount external damage to the IFF. a. Serviceability. The ground engineering check on ZG710's encrypted Mode 4 IFF was completed satisfactorily pre-engine start, and an RAF Regiment Rapier Missile unit that regularly checked the IFF of departing aircraft did not report the aircraft or log a fault. In line with extant procedures, only Mode 4 was checked on the ground. However, there is no firm evidence that ZG710 responded to any IFF interrogations throughout the entire mission, although there is evidence that the navigator checked the IFF switches at the appropriate times. The Board concluded that ZG710's IFF had a fault and, as an IFF Mode 4 response would have prevented the Patriot Anti-Radiation Missile classification and engagement, concluded that the lack of IFF at the time of the accident was a contributory factor. b. Failure Modes. Following initial investigation, it became apparent that certain power failures associated with the IFF may not be displayed to the crew. The most likely explanation for the absence of an IFF response was that there had been a power supply failure. The Board recommended that further work be conducted to research the failure modes, reliability and serviceability of the Tornado IFF system.

We spoke to Theodore Postol, professor of science, technology, and national security policy at MIT, and a vociferous analyst of the Patriot's performance. His 1992 statement to the Committee on Government Operations, US House of Representatives, dissects the missile's failure against Scuds.

His analysis of the RAF report is as follows:

The facts provided in the RAF Report issued on May 14 raise more doubts, rather than less, about the accuracy of US Army information provided to the UK - and about the technical and operational reliability of the Patriots in Operation Iraqi Freedom. A careful reading of the RAF Report indicates that the Patriot Fire Unit did not have its imbedded data recorder operating during the shoot-down of the Tornado, which basically means that there is no reliable information about what the Patriot operators saw and how they responded. It is not even clear to me that the IFF Mode 4 on the Tornado failed, as we do not have recorded data from the Patriot unit and can therefore not be certain that the Tornado was properly interrogated as claimed by the Patriot operators. In addition, the RAF Reported that the Tornado was mis-classified as an anti-radiation homing missile, which raises very serious and basic additional questions that remain unanswered. The only such missile in-theater was the HARM (High-Speed Ant-Radiation Homing Missile) which travels at Mach 2 (roughly 2,000+ feet/sec). The RAF reported that the Patriot crew fired on the Tornado immediately, rather than using an available one minute to further evaluate the nature of the potentially hostile target reported to them by the Patriot computer software - which was known to be unreliable. Since the Patriot unit had one minute to decide whether or not to fire on a target classified as a HARM, this would mean that the HARM was roughly 120,000 to 140,000 feet downrange, or roughly 25 to 30 miles distance when Patriot's were launched. However, we know that the Tornado had to be traveling no faster than roughly Mach 0.8 (800+ feet/sec). Since the Patriot unit fired when they had one minute to assess the approaching target, this suggests that the Tornado must have been at a range of roughly 50,000 to 70,000 feet ( 10 to 15 miles) when the Patriot interceptors were actually launched. If the Tornado was in fact at 10 to 15 miles range (as well as at 17,000 feet - according to the RAF report), then this indicates that a subsonic air-supported vehicle was mis-classified as a supersonic homing missile. If this was the case, the Army needs to explain how a subsonic aircraft following pre-established flight-approach rules could possibly have been mis-classified as an anti-radiation missile by the Patriot's artificial intelligence software. The Army also needs to explain why the Patriot Unit was allowed to operate autonomously when it could not directly communicate with its Battalion headquarters, and why the unit was allowed to engage any target under these inherently unsafe conditions of operations.

We're obliged to Professor Postol for addressing what are some fundamental - and to date unanswered - questions about the Patriot's effectiveness as a weapon.

The Patriot has been sold to the armed forces of Germany, Greece, Israel, Japan , Kuwait, Netherlands, Saudi Arabia and Taiwan. In 1999, Egypt received a $3.2bn grant for a military modernisation programme, including the purchase of 3 Patriot missile system fire units. This Autumn, the US will augment its Patriot capability in South Korea with the deployment of two further batteries.

But is Patriot the defence panacea its champions claim - or a neurotic and expensive flying turkey? ®

Related links

Ministry of Defence Military Aircraft Accident Summary for Royal Air Force Tornado GR MK4A ZG710 (PDF)

Patriot overview

Patriot specs

Lockheed Martin

Raytheon

Related stories

'System error' downed RAF Tornado

AMD powered missile hits Intel quarters in Baghdad

Related material

More from the1992 report by the Information Management and Technology Division of the General Accounting Office in response to a request by Howard Wolpe, Chairman, Subcommittee on Investigations and Oversight Committee on Science, Space, and Technology, House of Representatives:

The heart of the Patriot system is its weapons control computer. It performs the system's major functions for tracking and intercepting a target, as well as other battle management, command and control functions. The Patriot's weapons control computer used in Operation Desert Storm is based on a 1970s design with relatively limited capability to perform high precision calculations. To carry out its mission, the Patriot's weapons control computer obtains target information from the system's radar. The Patriot's radar sends out electronic pulses that scan the air space above it. When the pulses hit a target they are reflected back to the radar system and shown as an object (or plot) on the Patriot's display screens.(1) Patriot operators use the software to instruct the system to intercept certain types of objects such as planes, cruise missiles, or tactical ballistic missiles (such as Scuds). During Desert Storm the Patriot was instructed to intercept tactical ballistic missiles. For the Patriot's computer to identify, track, and intercept these missiles, important information(2) describing them was kept by the system's range-gate algorithm.(3) After the Patriot's radar detects an airborne object that has the characteristics of a Scud, the range gate--an electronic detection device within the radar system--calculates an area in the air space where the system should next look for it. The range gate filters out information about airborne objects outside its calculated area and only processes the information needed for tracking, targeting, and intercepting Scuds. Finding an object within the calculated range gate area confirms that it is a Scud missile. The range gate's prediction of where the Scud will next appear is a function of the Scud's know velocity and the time of the last radar detection. Velocity is a real number that can be expressed as a whole number and a decimal (e.g., 3750.2563...miles per hour). Time is kept continuously by the system's internal clock in tenths of seconds but is expressed as an integer or whole number (e.g., 32, 33, 34...). The longer the system has been running, the larger the number representing time. To predict where the Scud will next appear, both time and velocity must be expressed as real numbers. Because of the way the Patriot computer performs its calculations and the fact that its registers(4) are only 24 bits long, the conversion of time from an integer to a real number cannot be any more precise than 24 bits.(5) This conversion results in a loss of precision causing a less accurate time calculation. The effect of this inaccuracy on the range gate's calculation is directly proportional to the target's velocity and the length of time the system has been running. Consequently, performing the conversion after the Patriot has been running continuously for extended periods causes the range gate to shift away from the center of the target, making it less likely that the target, in this case a Scud, will be successfully intercepted.