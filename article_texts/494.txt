In a Facebook ad, a woman with a face identical to actor Emma Watson’s face smiles coyly and bends down in front of the camera, appearing to initiate a sexual act. But the woman isn’t Watson, the “Harry Potter” star. The ad was part of a massive campaign this week for a deepfake app, which allows users to swap any face into any video of their choosing.

Deepfakes are content where faces or sounds are switched out or manipulated. Commonly, deepfake creators make videos in which celebrities are made to look like they are willingly appearing in them, even though they are not. Increasingly, the technology has been used to make nonconsensual pornography featuring the faces of celebrities, influencers or any person, including children.

The ad campaign on Meta nods to the fact that this once-advanced technology has rapidly spread to readily available consumer applications being advertised on mainstream parts of the internet. Despite many platforms prohibiting manipulative and malicious deepfake content, apps like the ones reviewed by NBC News have been able to slip through the cracks.

Stills from the ads appearing to feature Watson's face.

On Sunday and Monday, an app for creating “DeepFake FaceSwap” videos rolled out more than 230 ads on Meta’s services, including Facebook, Instagram and Messenger, according to a review of Meta’s ad library. Some of the ads showed what looked like the beginning of pornographic videos with the well-known sound of the porn platform Pornhub’s intro track playing. Seconds in, the women’s faces were swapped with those of famous actors.

When Lauren Barton, a journalism student in Tennessee, saw the same ad on a separate application, she was shocked enough to screen-record it and tweet it out, where it received over 10 million views, according to Twitter’s views counter.

“This could be used with high schoolers in public schools who are bullied,” Barton said. “It could ruin somebody’s life. They could get in trouble at their job. And this is extremely easy to do and free. All I had to do was upload a picture of my face and I had access to 50 free templates.”

NBC News / Getty Images

Of the Meta ads, 127 featured Watson’s likeness. Another 74 featured the actor Scarlett Johansson’s face swapped with those of women in similarly provocative videos. Neither actor responded to a request for comment.

“Replace face with anyone,” the captions on 80 of the ads read. “Enjoy yourself with AI swap face technology.”

On Tuesday, after NBC News asked Meta for comment, all of the app’s ads were removed from Meta’s services.

While no sexual acts were shown in the videos, their suggestive nature illustrates how the application can potentially be used to generate faked sexual content. The app allows users to upload videos to manipulate and also includes dozens of video templates, many of which appear to be taken from TikTok and similar social media platforms.

The preset categories include “Fashion,” “Bride,” “For Men,” “For Women,” and “TikTok,” while the category with the most options is called “Hot.” It features videos of scantily clad women and men dancing and posing. After selecting a video template or uploading their own, users can input a single photo of anyone’s face, and receive a face-swapped version of the video in seconds.

The terms of service for the app, which costs $8 per week, say it does not allow users to impersonate others via their services or upload sexually explicit content. The app developer listed on the App Store is called Ufoto Limited, owned by a Chinese parent company, Wondershare. Neither company responded to a request for comment.

Meta banned most deepfake content in 2020, and the company prohibits adult content in ads, including nudity, depictions of people in explicit or suggestive positions, or activities that are sexually provocative.

“Our policies prohibit adult content regardless of whether it is generated by AI or not, and we have restricted this Page from advertising on our platform,” a Meta spokesperson said in a statement.

The same ads were also spotted on free photo-editing and gaming apps downloaded from Apple’s App Store, where the app first appeared in 2022 for free for ages 9 and up.

An Apple representative said that the company does not have specific rules about deepfakes but that it prohibits apps that include pornography and defamatory content. Apple said it removed the app from the App Store after having been contacted by NBC News.

The app was also previously available to download for free on Google Play, where it was rated "Teen" for "suggestive themes." Google said Wednesday it removed the app from Google Play after having been contacted by NBC News.

Apple and Google have taken action against similar AI face-swap apps, including a different app that was the subject of a Reuters investigation in December 2021. Reuters found that the app was advertising the creation of “deepfake porn” on pornographic websites. At the time, Apple said it didn’t have specific guidelines around deepfake apps but prohibited content that was defamatory, discriminatory or likely to intimidate, humiliate or harm anyone. While its ratings and ad campaigns have been adjusted, the app that Reuters reported on is still available to download free on Apple’s App Store and Google Play.

The app NBC News reviewed is one of the latest in a boom of freely accessible consumer deepfake products.

When searching “deepfake” on app stores, dozens of apps with similar technological capabilities appear, including ones that promote making “hot” content.

Mainstream examples of the technology show celebrities and politicians doing and saying things they’ve never actually said or done. Sometimes the effects are comical.

However, deepfake technology has overwhelmingly been used to make pornography with nonconsenting stars. As the technology has improved and become more widespread, the market for nonconsensual sexual imagery has ballooned. Some websites allow users to sell nonconsensual deepfake porn from behind a paywall.

A 2019 report from DeepTrace, an Amsterdam-based company monitoring synthetic media online, found that 96% of deepfake material online is of a pornographic nature.

In January, female Twitch streamers spoke out after a popular male streamer apologized for consuming deepfake porn of his peers.

Livestreaming research conducted by the independent analyst Genevieve Oh found that the top website for consuming deepfake porn exploded in traffic following the Twitch streamer’s apology. Oh’s research also found that the number of deepfake pornographic videos has nearly doubled every year since 2018. February had the largest number of deepfake porn videos uploaded in a month ever, Oh said.

While the nonconsensual sharing of sexually explicit photos and videos is illegal in most states, laws addressing deepfake media are in effect only in California, Georgia, New York and Virginia.. Looking at the video of a deep fake’d Emma Watson above, you can see how realistic the technology is.

Seriously, I went to the critically-acclaimed ABBA holographic concert in London recently and the lifelike movements in that clip are strikingly similar in quality.

But it’s hard to miss the suggestive nature of the video, which perfectly illustrates the dark intentions of users – and perhaps the programmers themselves. Making things more problematic is that this clip is used as advertising.

Retweeting the screen recording of the ad, one Twitter user said: ‘This is just a new way to sexually harass women. It’s taking away your bodily autonomy and forcing you into non-consensual sexual material, which can then be used to humiliate and discriminate against you. Not to mention the psychological effects.’

Encouraging the use of deepfake AI for this purpose is obviously sinister. However, it shouldn’t be surprising, as the most famous uses of deep fake technology so far have either been pornographic or tied to politics.

In 2019 – just two years after the technology was created – it was reported that at least 96 percent of all deepfake videos found online were pornographic, according to research conducted by Deeptrace.

Fuelling the creation of these videos are numerous websites that exclusively host deepfake pornography. Many falsified clips uploaded to these platforms have been created by vengeful exes or people looking to tarnish the image of their enemies.

As a result, governments around the world have started to build stronger legal frameworks that limit the ways deepfake technology can be used. Admittedly, these had to be informed by existing cases, which is why tech experts warned we were unprepared for its dangers.

Back in November 2022, the UK government made deepfake pornography a jailable criminal offence. However, courts can only prosecute individuals in the event that they circulate these images or videos online.

Some US states have also put similar laws in place. Realistically, though, these policies cannot protect anyone from being inserted into graphic videos for another individual’s own viewing behind closed doors.

This thought, for the vast majority of women, will be enough to incite disgust and anger, if not a shudder and skin-crawling reaction.

As mentioned, deepfakes have also been used to incite political uproar.

Barak Obama has been depicted insulting Donald Trump. Mark Zuckerberg has been poised to say that Facebook’s sole purpose is to control and exploit users of the platform.

These all went viral, revealing the level of interest, awe, and in some cases, the trickery of deepfake technology.

Used in other contexts, the consequences could be far more dangerous. During the initial months of Russia’s invasion of Ukraine, videos of President Zelensky emerged in which he told Ukrainian soldiers to surrender to Russian soldiers.

Luckily, the real President Zelensky took to his personal social media accounts to confirm that the video had been doctored by opposition forces. He reminded his people that the fight for their country was not yet over and urged them to remain united.

It seems as if deepfakes, even when used to make a chuckle-worthy version of Queen Elizabeth II’s traditional Christmas speech, tend to arise an unsettling feeling within us.

Perhaps we know deep down that the technology is far more likely to be used with malicious intent. So, what will happen when it becomes so advanced that we can’t tell the difference between what is fact and fiction?

With free-to-download apps like Facemega, should we be worried that deepfake technology is becoming widely available through our smartphones?

I’d say that, unfortunately, we should be.. Photo:Uwe Krejci (Getty Images)

Earlier this week, an NBC report unearthed a celebrity face-swapping app, Facemega, with the potential to easily create deepfake porn depicting famous or public-facing women. Deepfake porn refers to fake but highly realistic, often AI-generated porn and sexual imagery of people without their consent. Unsurprisingly, it typically targets women and especially female celebrities; victims have thus far included popular female Twitch streamers and, as early as 2018, Gal Gadot.

Per NBC’s report, Facemega ran hundreds of different ads on Facebook, Instagram, and other Meta apps, advertising how easily users could face-swap themselves with the likes of Emma Watson or Scarlet Johansson, accompanied by highly realistic, sexually suggestive video examples. (This, of course, is despite how Meta banned most deepfake content back in 2020.) The app also placed ads in the Apple store, where it first became available sometime last year. As of Tuesday evening, NBC’s Kat Tenbarge reported that the Apple app store had taken down the face-swapping app, and Meta stopped running ads for it, shortly after NBC’s original report. But the app remains on Google Play.

NBC’s report notes that “no sexual acts were shown in the videos” but “their suggestive nature” makes it clear that at least one purpose of the app is to “generate faked sexual content.” NBC also found that “some of the ads showed what looked like the beginning of pornographic videos with the well-known sound of the porn platform Pornhub’s intro track playing.”

“Replace face with anyone,” the captions on some of the Meta ads say. “Enjoy yourself with AI swap face technology.” Facemega also offers users the opportunity to face-swap varying celebrities onto preset videos, and among other categories, includes a “Hot” category that “features videos of scantily clad women and men dancing and posing.”

Even as Meta and Apple seem to have taken action to rein in Facemega, with or without the app, deepfake porn is a rapidly growing crisis. Per one streaming researcher who spoke to NBC, last month saw the greatest volume of deepfake porn videos uploaded ever. These alarming numbers—and a recent Twitch scandal involving a popular male streamer outed for watching deepfake porn of female streamers in January—make it clear that none of this is hypothetical. And the problem is getting worse, as deepfake tools become more accessible.

Face-swapping apps and other AI technologies can be wielded to create deepfake porn targeting not just celebrities, but friends, co-workers, and even casual acquaintances. Experts say that increasingly popular AI-generated imagery apps like Lensa AI have been a boon for child sexual abuse content. One researcher wrote in Wired last year that upon uploading childhood photos of herself to Lensa, “what resulted were fully nude photos of an adolescent and sometimes childlike face but a distinctly adult body.”

And, especially concerning, our laws are wildly unequipped to protect people. While most states have varying anti-cyber-exploitation laws to rein in “revenge porn” (nonconsensual nude images of individuals shared by former partners or harassers), the only states that explicitly prohibit nonconsensual deepfake sexual content are California, Virginia, and Texas. As apps like Facemega proliferate, likely aided by social platforms like Meta, we’re simply not prepared for the scope of the damage this could inflict.. In the ad, a woman in a white lace dress makes suggestive faces at the camera, and then kneels. There’s something a bit uncanny about her; a quiver at the side of her temple, a peculiar stillness of her lip. But if you saw the video in the wild, you might not know that it’s a deepfake fabrication. It would just look like a video, like the opening shots of some cheesy, low-budget internet porn.

In top right corner, as the video loops, there is a still image of the actress Emma Watson, taken when she was a teenager, from a promotional shoot for the Harry Potter movies. It’s her face that has been pasted on to the porn performer’s. Suddenly, a woman who has never performed in pornography is featured in it.

The ads, which directed users to an app that makes deepfake videos, were discovered in more than 230 iterations across Facebook, Instagram and Meta’s Messenger, according to an NBC news investigation by Kat Tenbarge. Most of the ads featured Watson’s image; some others used the face of Scarlett Johansson. The same ads appeared in photo-editing and gaming apps available in the Apple App Store. Lest the message be lost on viewers, the ads make explicit that they are intended to help users create non-consensual porn of any women they like. “Swap ANY FACE in the video!” the ads read. “Replace face with anyone. Enjoy yourself with AI face swap technology.”

Similar ads for deepfake services appear directly next to explicit videos on PornHub. Though deepfake technology can theoretically be used for any kind of content – anything from joking satire to malicious political disinformation campaigns – overwhelmingly, the tech is being used to create nonconsensual porn. According to a 2019 report, 96% of deepfake material online is pornographic.

That figure might well be increasing. The ads on Meta and Apple platforms appeared as consumer demand for deepfake pornography is exploding. The surge comes on the heels of a controversy that rocked online video game communities in January, when a popular streamer, Brandon Ewing – who calls himself “Atrioc” – displayed deepfake pornography of several popular women streamers in one of his online broadcasts. He later admitted to having paid for the artificial porn of the women, who were his colleagues and friends, after seeing an ad similar to those that appeared on Meta and Apple platforms. The women whose images were commandeered for Ewing’s pornography issued angry and hurt responses; Ewing himself apologized. But the controversy seems to have only made the streamer’s overwhelmingly young and male follower base more aware of the availability of deepfake content – and eager to use it themselves.

Genevieve Oh, a researcher who studies livestreaming, told NBC that after Ewing’s apology, web traffic to the top deepfake porn sites exploded. That rapid increase over the past few weeks has followed a slower, but still alarming, growth of the deepfake revenge porn sector over the past several years. In 2018, fewer than 2,000 videos had been uploaded to the best-known deepfake streaming site; by 2022, that number had ballooned to 13,000, with a monthly view count of 16m. As deepfake revenge porn becomes more popular, the barrier to access is quite low: the app that misused Watson’s face in its ads charges just $8 per week.

The rapid increase in the number and availability of nonconsensual deepfake porn videos raises alarming questions about privacy and consent in the digital future. How will the huge numbers of women – and the smaller, but significant, numbers of men – who are affected by this new AI-enabled revenge porn manage their reputations and lives? As the technology improves, how will viewers know the difference between fact and AI-generated fiction? How can nonconsensual material be removed when the internet moves so much faster than regulation?

But the example of these apps – and of the men, like Ewing and his fans, who use them – also illuminates something older, and more uncomfortable, about the nature of porn: that men often use it as an expression of their contempt for women, and feel that the sexual depiction of women degrades and violates them. This is, in fact, much of mainstream porn’s appeal, at least according to the sentiments of many of the men who consume it: that it enables men to imagine themselves in control of women, and of inflicting pain and degradation on them. Deepfake revenge porn, then, merely fulfills with technology what mainstream porn has offered men in fantasy: the assurance that any woman can be made lesser, degraded and humiliated, through sexual force. The non-consent is the point; the humiliation is the point; the cruelty is the point.

There is no other way, really, to understand deepfake pornography’s appeal: it is not as if the internet lacks sexual content depicting real and consenting adults. What these apps offer their users is specifically and explicitly the opportunity to hurt women by forcing them into pornography against their will. After Ewing exposed his deepfake pornography to his streaming audience in January, one of the women depicted issued her own tearful video, describing how the malice and violation of the deepfake had wounded her. In response, a man sent her a picture of her own crying face appearing on his tablet. The screen was covered in semen.

For now, the women and others who are targeted by deepfake revenge porn have few avenues of legal recourse. Most states have laws punishing revenge porn, but only four – California, New York, Georgia and Virginia – ban nonconsensual deepfakes. Companies hosting the apps are often based overseas, mostly beyond the reach of legal enforcement – the company whose app was advertised on Meta appears to be owned by a parent company based in China. Meanwhile, more and more men will begin to use the technology against more and more women. “I was on fucking Pornhub … and there was an ad [for the deepfake site],” Ewing said in his apology video, by way of explaining how he discovered the AI revenge porn site. “There’s an ad on every fucking video for this so I know other people must be clicking it.”. By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Access your favorite topics in a personalized feed while you're on the go. download the app

Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview

Multiple online stores and Meta have removed a controversial face swap app that promoted a sexually suggestive ad featuring the face of the "Harry Potter" actor Emma Watson imposed onto someone else.

The app for creating deepfakes, called Facemega, showed a woman with Watson's face smiling flirtatiously and then getting down on her knees for what appears to be a man. The caption read: "Swap any face into the video!" A screen recording of the ad posted to Twitter got 3.2 million views.

This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.

Deepfakes use artificial intelligence to replace the likeness of one person with another in videos and other digital media, and its use has raised ethical and privacy concerns.

An attorney told Insider that this is just one illustration of how emerging deepfake technology could be used as a "weapon" against women and girls.

Advertisement

Michael Farhi, an attorney who has published material on the subject before, told Insider that the use of AI "is going to result in a huge jump in it being a weapon against women online all across the world." He added that women are the most popular demographic to target with such harassment.

Deepfakes and revenge porn are already threats to women, and AI technology, which can make fake videos look convincingly real, is going to "quadruple" the negative impacts, Farhi said.

The Facemega ad ran on Facebook until the site removed it following coverage by NBC News, who reported that the app also published advertisements with Scarlett Johansson's face in provocative videos. Facemega was listed for free on Apple and Google Play, who have both since removed it, but similar apps remain listed in both stores.

Related stories

A spokesperson for Apple told Insider that the company removed the app from the Apple Store and that the company does not allow apps that include defamatory, pornographic, or mean-spirited content intended to humiliate others. A spokesperson for Google said the company took "appropriate action" and removed the app for "violations of our policies."

Advertisement

A Meta spokesperson told Insider that their "policies prohibit adult content regardless of whether it is generated by AI or not," and that FaceMega's page was restricted on Facebook.

Watson's legal representation could not be reached for comment.

Stills of the advertisement for a deepfake app that used Emma Watson's face. Twitter

The suggestive ad appeared to violate Facemega's own terms and conditions of service, which prohibit users from uploading content that is defamatory or sexually explicit.

The Chinese software company Wondershare owns Facemega, a spokesperson for the company confirmed to Insider. When asked about the advertisement, the Wondershare spokesperson said: "Our legal department is already following up on this matter, and the advertising content has also been removed from the shelves."

Advertisement

Deepfake technology will be used as a 'weapon' against women, attorney said

In the US, victims of deepfake porn "have potential claims like defamation, invasion of privacy, infliction of emotional distress," Farhi told Insider. But he also said that initiating legal action internationally against a Chinese company would be a "hurdle."

"A lawyer wherever in the US sending a cease-and-desist type letter to an entity in China, even if it's translated appropriately, it's going to have little to no effect as a practical matter. So where do you go next? You go to Facebook, which has challenging rules and regulations of its own in terms of what it posts and what ads it puts up," Farhi said.

Public pressure against companies who share the content may be more effective than legal actions, Farhi said. He added that "the advances in technology are happening too fast for it to be legislated." Deepfake technology, like all tech advancements, comes with "pluses and minuses," but Farhi said the potential damages are being "swept under the rug."

"The advocates of AI are, of course, pushing the idea that you'll get instant research, instant assistance at work. For creators, it's a great asset and a great tool," Farhi said. "It's going to be a frigging nightmare, even more than what's out there now, as a tool or a weapon to harm women."

Advertisement

Farhi said an especially vulnerable group is likely to be teen girls, whom revenge and deepfake porn already bombard on a regular basis.

"This is going to have real harm to untold numbers of girls and women. Not just in high school, before high school at the elementary-school or middle-school level, all the way up to women in their twenties, thirties, and beyond," Farhi said. "And the easier it is to do, or the easier it is for a predator to do — and it's going to be a lot easier — the more it's going to be done."