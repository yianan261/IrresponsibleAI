App Drivers & Couriers Union files ground-breaking legal challenge against Uber’s dismissal of drivers by algorithm in the UK and Portugal

‍

· In landmark legal case, former Uber drivers asks courts in the Netherlands to over-rule the algorithm that fired them

· Drivers in London, Birmingham and Lisbon wrongly accused of ‘fraudulent activity’ as detected by Uber systems before being fired without right of appeal

· Case will test the extent that Article 22 of the EU General Data Protection Regulation (GDPR) can protect individuals from unfair automated decision making

· Union invites all Uber drivers & couriers who have been similarly deactivated to register with them for potential future action

· Crowd fund appeal launched to fund this legal action to protect the digital rights of Uber drivers

‍

In a landmark case, the App Drivers & Couriers Union have today filed a complaint in the Amsterdam district court to challenge Uber’s practice of robo-firing of drivers by algorithm. The union is bringing the case on behalf of three drivers from London and Birmingham in the UK. The International Alliance of App-based Transport workers is supporting the claim of a fourth driver from Lisbon,Portugal. The action is also supported by Worker Info Exchange, a non-profit organisation dedicated to workplace digital rights.

Under the UK Data Protection Act and Article 22 of the EU General Data Protection Regulation (GDPR), individuals have the right to certain protections from automated decisions which create negative affects but are carried out without meaningful human intervention.

In each of the cases the drivers were dismissed after Uber said its systems had detected fraudulent activity on the part of the individuals concerned. The drivers absolutely deny that they were in any way engaged in fraud and Uber has never made any such complaint to the police. Uber has never given the drivers access to any of the purported evidence against them nor allowed them the opportunity to challenge or appeal the decision to terminate.

Driver1, based in London, was summarily dismissed after Uber said their systems had detected ‘irregular trips associated with fraudulent activities’. He was never given any explanation and was denied a right of appeal.

Driver2, based in London, was summarily dismissed by Uber after claiming their systems detected ‘the installation of and use of software which has the intention and effect of manipulating the Driver App’. The driver was given no further explanation of the allegations and was denied the right of appeal.

Driver3, based in Birmingham, was terminated without right of appeal after Uber said their systems had detected ‘a continued pattern of improper use of the Uber application…..& this created a poor experience for all parties.’

Driver4, based in Lisbon, Portugal was terminated in a manner almost identical to circumstances experienced by the UK drivers. Uber summarily dismissed the driver after claiming its systems detected ‘the recurrent practice of irregular activities during use of the Uber App.’

Uber’s so called ‘Community Guidelines’ defines ‘fraud’ to include declining work offered and strategically logging out to await higher surge pricing. As such, the ADCU believes that Uber seeks to undercut its obligation to driver’s worker rights by concealing performance related dismissals as ‘fraud’ related dismissals. In London, drivers who are dismissed by Uber are automatically reported to TfL who then may take licensing action against them.

The ADCU is inviting all former Uber drivers from the UK throughout the European Economic Area who have been similarly dismissed over alleged ‘fraudulent activity’ to register on their website at www.adcu.org.uk/wie.

The union also has launched a crowdfunding appeal to help pay for the legal action against Uber in the interests of low paid workers. https://www.crowdjustice.com/case/help-protect-uber-drivers-from/

‍

Yaseen Aslam, President of the App Drivers & Couriers Union (ADCU) and member ofthe International Alliance of App-based Transport Workers (IIATW) steering committee said:

Uber has been allowed to violate employment law with impunity for years and now we are seeing a glimpse into an Orwellian world of work where workers have no rights and are managed by machine. If Uber are not checked, this practice will become the norm for everyone.

‍

James Farrar, Director of Worker Info Exchange said:

Uber has industrialised the process for the firing of drivers at scale in a frighteningly uniform way across the UK and Europe. It is morally offensive that workers can be dismissed in such a callously automated way without any right of appeal or to even know the basis of the algorithmically generated allegations made against them.

‍

Anton Ekker, the lawyer representing the drivers said:

This case demonstrates the impact of automated decision making for the millions of people that are working in the platform economy. For the first time, Uber drivers are challenging these decisions based on the GDPR.

‍

‍BACKGROUND

1. Copies of the complaints can be found at this link.

2. The App Drivers & Couriers Union (ADCU) is the largest UK trade union dedicated to app-based workers primarily employed in the so-called gig economy.

3. The ADCU is supporting Yaseen Aslam and James Farrar in their 2016 worker status case which they won against Uber at the Employment Tribunal in 2016. Uber’s final appeal was heard by the UK Supreme Court in July 2020 and a decision is due soon.

4. The ADCU has also made complaints against Ola and Uber over failure to provide workers with access to their data pursuant to Article 15 of the GDPR. The cases will be heard by the Amsterdam District Court on December 10 and 16 respectively.

5. Worker Info Exchange is a UK based NGO dedicated to helping workers fight for their digital rights in the so-called gig economy www.workerinfoexchange.org

6. The International Alliance of App-based Transport Workers (IAATW) is the leading international organisation representing app-based workers worldwide. www.iaatw.org

‍. Try unlimited access Only $1 for 4 weeks

Then $75 per month.

Complete digital access to quality FT journalism on any device. Cancel anytime during your trial.. A group of U.K. Uber drivers has launched a legal challenge against the company’s subsidiary in the Netherlands. The complaints relate to access to personal data and algorithmic accountability.

Uber drivers and Uber Eats couriers are being invited to join the challenge, which targets Uber’s use of profiling and data-fueled algorithms to manage gig workers in Europe. Platform workers involved in the case are also seeking to exercise a broader suite of data access rights baked into EU data protection law.

It looks like a fascinating test of how far existing legal protections wrap around automated decisions at a time when regional lawmakers are busy drawing up a risk-based framework for regulating applications of artificial intelligence.

Many uses of AI technology look set to remain subject only to protections baked into the existing General Data Protection Regulation (GDPR). So determining how far existing protections extend in the context of modern data-driven platforms is important.

The European Commission is also working on rebooting liability rules for platforms, with a proposal for a Digital Services Act due by year’s end. As part of that work it’s actively consulting on related issues such as data portability and platform worker rights — so the case looks very timely.

Via the lawsuit, which has been filed in Amsterdam’s district court today, the group of Uber drivers from London, Birmingham, Nottingham and Glasgow will argue the tech giant is failing to comply with the GDPR and will ask the court to order immediate compliance — urging it be fined €10,000 for each day it fails to comply.

They will also ask the court to order Uber to comply with a request to enable them to port personal data held in the platform to a data trust they want to establish, administered by a union.

For its part, Uber U.K. said it works hard to comply with data access requests, further claiming it provides explanations when it’s unable to provide data.

Data rights to crack open an AI blackbox?

The GDPR gives EU citizens data access rights over personal information held on them, including a right to obtain a copy of data they have provided so that it can be reused elsewhere.

The regulation also provides some additional access rights for individuals who are subject to wholly automated decision making processes where there is a substantial legal or similar impact — which looks relevant here because Uber’s algorithms essentially determine the earning potential of a driver or courier based on how the platforms assigns (or withholds) jobs from the available pool.

As we wrote two years ago, Article 22 of the GDPR offers a potential route to put a check on the power of AI blackboxes to determine the trajectory of humankind — because it requires that data controllers provide some information about the logic of the processing to affected individuals. Although it’s unclear how much detail they have to give, hence the suit looks set to test the boundaries of Article 22, as well as making reference to more general transparency and data access rights baked into the regulation.

James Farrar, an Uber driver who is supporting the action — and who was also one of the lead claimants in a landmark U.K. tribunal action over Uber driver employment rights (which is, in related news, due to reach the U.K. Supreme Court tomorrow, as Uber has continued appealing the 2016 ruling) — confirmed the latest challenge is “full spectrum” in the GDPR rights regard.

The drivers made subject access requests to Uber last year, asking the company for detailed data about how its algorithm profiles and performance manages them. “Multiple drivers have been provided access to little or no data despite making a comprehensive request and providing clear detail on the data requested,” they write in a press release today.

Farrar confirmed that Uber provided him with some data last year, after what he called “multiple and continuous requests,” but he flagged multiple gaps in the information — such as GPS data only being provided for a month out of two years of work; no information on the trip rating assigned to him by passengers; and no information on his profile nor the tags assigned to it.

“I know Uber maintain a profile on me but they have never revealed it,” he told TechCrunch, adding that the same is true of performance tags.

“Under GDPR Uber must explain the logic of processing, it never really has explained management algorithms and how they work to drivers. Uber has never explained to me how they process the electronic performance tags attached to my profile for instance.

“Many drivers have been deactivated with bogus claims of ‘fraudulent use’ being detected by Uber systems. This is another area of transparency required by law but which Uber does not uphold.”

The legal challenge is being supported by the App Drivers & Couriers Union (ADCU), which says it will argue Uber drivers are subject to performance monitoring at work.

It also says it will present evidence of how Uber has attached performance-related electronic tags to driver profiles with categories including: Late arrival/missed ETAs; Cancelled on rider; Attitude; Inappropriate behaviour.

“This runs contrary to Uber’s insistence in many employment misclassification legal challenges across multiple jurisdictions worldwide that drivers are self-employed and not subject to management control,” the drivers further note in their press release.

Commenting in a statement, their attorney, Anton Ekker of Ekker Advocatuur, added: “With Uber BV based in the Netherlands as operator of the Uber platform, the Dutch courts now have an important role to play in ensuring Uber’s compliance with the GDPR. This is a landmark case in the gig economy with workers asserting their digital rights for the purposes of advancing their worker rights.”

The legal action is being further supported by the International Alliance of App-based Transport (IAATW) workers in what the ADCU dubs an “unprecedented international collaboration.”

Reached for comment on the challenge, Uber emailed us the following statement:

Our privacy team works hard to provide any requested personal data that individuals are entitled to. We will give explanations when we cannot provide certain data, such as when it doesn’t exist or disclosing it would infringe on the rights of another person under GDPR. Under the law, individuals have the right to escalate their concerns by contacting Uber’s Data Protection Officer or their national data protection authority for additional review.

The company also told us it responded to the drivers’ subject access requests last year, saying it had not received any further correspondence since.

It added that it’s waiting to see the substance of the claims in court.

The unions backing the case are pushing for Uber to hand over driver data to a trust they want to administer.

Farrar’s not-for-profit, Worker Info Exchange (WIE), wants to establish a data trust for drivers for the purposes of collective bargaining.

“Our union wants to establish a data trust but we are blocked in doing so long as Uber do not disclose in a consistent way and not obstruct the process. API would be best,” he said on that, adding: “But the big issue here is that 99.99% of drivers are fobbed off with little or no proper access to data or explanation of algorithm.”

In a note about WIE on the drivers’ attorney’s website the law firm says other Uber drivers can participate by providing their permission for the not-for-profit to put in a data request on their behalf, writing:

Worker Info Exchange aims to tilt the balance away from big platforms in favour of the people who make these companies so successful every day – the workers. Uber drivers can participate by giving Worker Info Exchange their mandate to send a GDPR-request on their behalf.

The drivers have also launched a Crowdjustice campaign to help raise £30,000 to fund the case.

Discussing the legal challenge and its implications for Uber, Newcastle University law professor Lilian Edwards suggested the tech giant will have to show it has “suitable safeguards” in place around its algorithm, assuming the challenge focuses on Article 22.

Wow. This could be historic: the first art 22 case to really crack the veil of algorithmic black box secrecy and givevpowed back to dstified platform workers. Go @jamesfarrar who drove this ( sic) from the start!! #uber #a22 https://t.co/DEoX1bdCGY — Lilian Edwards (@lilianedwards) July 20, 2020

“Article 22 normally gives you the right to demand that a decision made in a solely automated way — such as the Uber algorithm — should either not be made or made by a human. In this case Uber might claim however, with some success, that the algorithm was necessary for the Uber context with the driver,” she told us.

“However that doesn’t clear their path. They still have to provide ‘suitable safeguards’ — the biggest of which is the much-discussed right to an explanation of how the algorithm works. But no one knows how that might operate.

“Would a general statement of roughly how the algorithm operates suffice? What a worker would want instead is to know specifically how it made decisions based on his data — and maybe how it discriminated against him or disfavoured him. Uber may argue that’s simply impossible for them to do. They might also say it reveals too much about their internal trade secrets. But it’s still terrific to finally have a post GDPR case exploring these issues.”

In its guidance on Article 22 requirements on its website, the U.K.’s data watchdog, the ICO, specifies that data controllers “must provide meaningful information about the logic involved in the decision-making process, as well as the significance and the envisaged consequences for the individual”.

It also notes Article 22 requires that individuals who are subject to automated decisions must be able to obtain human review of the outcome if they ask. The law also allows them to challenge algorithmic decisions. While data controllers using automation in this way must take steps to prevent bias and discrimination.. In a major win over opaque algorithmic management in the so-called gig economy an appeals court in the Netherlands has found largely in favor of platform workers litigating against ride-hailing giants Uber and Ola — judging the platforms violated the drivers’ rights in a number of instances, including when algorithms were involved in terminating driver accounts.

The court also ruled the platforms cannot rely on trade secrets exemptions to deny drivers access to their data. Although challenges remain for regional workers to use existing laws to get enough visibility into platforms’ data processing to know what information to ask for to be able to meaningfully exercise their data access rights.

The appeal court rulings can be found here, here and here (in Dutch).

The appeal was brought by the not-for-profit data trust Worker Info Exchange (WIE) in support of members of the App Drivers & Couriers Union (ADCU) in the U.K. and a driver based in Portugal.

One case against Uber’s robo-firings involved four drivers (three based in the U.K., one in Portugal); a second case against Uber over data access involved six U.K.-based drivers; while a data access case against Ola involved thee U.K.-based drivers.

In the data access cases drivers were seeking information such as passenger ratings, fraud probability scores, earning profiles, as well as data on the allocation of journeys to drivers — including Uber’s batch matching and upfront pricing systems — as well as information about the existence of automated decision-making touching their work on the platforms.

Several decisions taken by the ride-hailing platforms were found to meet the relevant legal test of automated decision-making — including assigning rides; calculating prices; rating drivers; calculating ‘fraud probability scores’; and deactivating drivers’ accounts in response to suspicions of fraud — meaning drivers are entitled to information on the underlying logic of these decisions. (And also to a right to meaningful human review if they object to decisions.)

“The court ordered that Uber must explain how driver personal data and profiling is used in Uber’s upfront, dynamic pay and pricing system. Similarly, the court ordered Uber to transparently disclose how automated decision making and worker profiling is used to determine how work is allocated amongst a waiting workforce,” said WIE in a press release.

“Ola Cabs was also ordered to disclose meaningful information about the use in automated decision making of worker earnings profiles and so called ‘fraud probability scores’ used in automated decision making for work and fares allocation. The court also ruled that internally held profiles relating drivers and associated performance related tags must be disclosed to drivers.”

Commenting in a statement, James Farrar, director of WIE, added:

This ruling is a huge win for gig economy workers in Britain and right across Europe. The information asymmetry & trade secrets protections relied upon by gig economy employers to exploit workers and deny them even the most basic employment rights for fundamentals like pay, work allocation and unfair dismissals must now come to an end as a result of this ruling. Uber, Ola Cabs and all other platform employers cannot continue to get away with concealing the controlling hand of an employment relationship in clandestine algorithms. Too many workers have had their working lives and mental health destroyed by false claims of fraudulent activity without any opportunity to know precisely what allegations have been made let alone answer them. Instead, to save money and avoid their responsibility as employers, platforms have built unjust automated HR decision making systems with no humans in the loop. Left unchecked, such callous systems risk becoming the norm in the future world of work. I’m grateful for the moral courage of the courts expressed in this important ruling.

The companies have been given two months to provide the requested information to the drivers (with the risk of fines of daily several thousand euros apiece for non-compliance), as well as being ordered to pick up the majority of the case costs.

Taking the algorithm to court

Legal challenges against the algorithmic management practices of Uber and Ola were originally lodged on behalf of drivers in the U.K. back in 2020 — in July and September — centred on digital and data access rights enshrined in the European Union’s General Data Protection Regulation (GDPR).

The pan-EU regulation provides individuals with rights to data held on them and information about algorithmic decision making applied to them — where it has a substantial or legal effect (such as employment/access to work). And while the U.K. is no longer an EU member it transposed the European data protection framework into national law before leaving the bloc. Which means that (for now) it retains the same suite of data rights.

The appeal court decisions yesterday follow earlier judgements, in March 2021, by the Court of Amsterdam — which did not accept the robo-firing charges in those instances and largely rejected the drivers’ requests for specific data. However the court also tossed the platforms’ arguments seeking to deny the right of workers to collectively organize their data and establish a data trust as an abuse of GDPR data access rights — leaving the door open to fresh challenges.

Transparency is a key lever in the fight for platform workers rights since there’s no way for workers to assess the fairness of algorithms or automated decisions being applied to them without having access to information on the processes involved. So this ruling looks significant in that it could help crack open black boxes systems used for algorithmic management of workforces in a way that has, oftentimes, shielded platforms from scrutiny over the fairness (or indeed legality) of their decisions.

This is also a class of worker that still typically lacks full employment rights and protections, exacerbating the power imbalance vs data-mining platforms and supercharging the risks of worker exploitation. (Albeit, legal challenges in Europe have unpicked some bogus claims of self employment by platforms; while planned EU legislation in this area aims to tackle worker precariousness by setting minimum standards for platform work.)

While the legal challenges against Uber and Ola involved a small number of drivers, and the rulings naturally reference their individual circumstances, the appeal victory could force gig platforms to change their process — not least to avoid the risk of more challenges being filed.

Conditions of their licences to operate in markets like London may also create regulatory problems for them if they’re seen to be failing to prevent recurrences of data protection issues, the litigants suggest.

Although it also may not yet be the end of the road for these particular cases as the companies could seek to appeal the decisions to the Dutch Supreme Court.

In a statement an Uber spokesperson told us it is “carefully” studying the rulings, adding that it will take a decision on whether to file an appeal “in due course”.

(Ola was also contacted for comment but at the time of writing it had not responded.)

In other remarks provided to TechCrunch Uber said:

We are disappointed that the court did not recognize the robust processes we have in place, including meaningful human review, when making a decision to deactivate a driver’s account due to suspected fraud. Uber maintains the position that these decisions were based on human review and not on automated decision making, which was acknowledged earlier by the previous court. These rulings only relate to a few specific drivers from the UK that were deactivated in the period between 2018 and 2020 in relation to very specific circumstances.

Uber also flagged one instance in which it said the appeal court found it did have meaningful human involvement in an automated decision related to a termination.

In the other cases, where the court found in favor of the litigants over robo-firings, Uber was unable to prove that the human intervention was much more than a “symbolic act” — meaning it could not demonstrate the staff involved had been able to exercise a meaningful check on the automated decision that led to drivers being fired.

On this WIE said the drivers in the lawsuit faced “spurious allegations of ‘fraudulent activity’ by Uber and were dismissed without appeal”. “When the drivers requested an explanation for how Uber systems had surveilled their work and wrongly determined they had engaged in fraud, Uber stonewalled them,” it claimed, adding: “The decision to dismiss the drivers was taken remotely at an Uber office in Krakow and the drivers were denied any opportunity to be heard. The court noted that Uber had failed to make ‘clear what the qualifications and level of knowledge of the employees in question are. There was thus insufficient evidence of actual human intervention.'”

Discussing the outcome of the appeal in a phone call with TechCrunch, Farrer — a former Uber driver who has also successfully sued the ride-hailing giant over the employment status of U.K. drivers — said it would be “foolish” if the platforms seek to appeal to the Supreme Court. “Not only is the ruling, very decisive but it’s very sensible,” he told us. “And it also gives them very sensible guidance, in my opinion, in how you should be managing the platform in this way.”

“What the court was coming down against Uber on was this very absolutist approach that they took to managing fairly straightforward HR problems,” he argued, describing it as “nonsense” for platforms to fire someone for alleged fraud but refuse to tell them why, preventing them from responding to the charges by claiming doing so would undermine trade secrets and platform security.

“It’s nonsense. Anybody can see that. And that’s what they relied on. They relied on being able to get away with doing that. And so, okay, you may choose to — foolishly — appeal that or you may want to take a sensible line that that’s not really a sensible or sustainable position to take. But if you want to continue taking it we’ll continue beating you on it. So I think, if they’re up for it, there’s some really good learning points and signposting for them — about how platforms in the modern day ought to be going about managing people.”

On the data access issue, Farrer said the outcome of the appeal shows they’re “bumping up against the limits of the law” — since the court upheld some earlier decisions to withhold data from drivers based on their asks not being specific enough. The Catch-22-style situation here is if the platforms aren’t fully up-front and transparent about the data they’re processing how can the drivers know what to ask them for with enough specificity to get given the data? So setting governance on platform transparency is an area lawmakers should be focused on.

“On that point we didn’t make significant progress,” he said. “We asked for access to all personal data. And then the platforms kicked back and — denial and obfuscation — either say you need to specify [the data you want] or they’ll tell you they’re taking a ‘phased approach’, whatever that is — but without telling you that that’s what they’re doing. So they’ll give you some data and then later, if you complain, they can say, well, we were taking a phased approach. But they forgot to tell anyone.

“And here what the court is saying is that if you’re not getting all the data you think you want then you have an obligation, under Article 15, to go back and say, what are the categories of data you’re processing and then hone your requests based on on that. But… that’s where we reach the limits of the law, I suppose. Because if these companies are not really very clear or transparent, or if they’re vague about the categories of data they say the processing, then you’re still in that chicken and egg problem that you don’t know what you don’t know. So that still kind of remains the same.”

Per Farrer, the litigants did get one good result on this aspect via the appeal — in relation to data processing categories in an Uber guidance document, which he said the court agreed Uber should have to hand over. “So I think what the court is saying is that when you’re able to be more specific there’s very little defence [in withholding data]. So when we’re getting to the specifics around automated decision-making, or also information about automated decision-making, as well as data processing around some of these difficult decisions, then, yeah, there’s little defense in not giving it.”

Gig worker rights organizations are also concerned about emergent rights risks coming down the pipe — warning, for example, about the rise of personalized pricing (aka dynamic pricing) — as platforms seek ever more complex systems for calculating and fragmenting payments to workers (and, indeed, the amounts billed to users).

Dynamic pricing not only clearly boosts opacity around how the platforms’ payment/charging systems work but could create fresh opportunities for harm by scaling unfairness and discrimination on both sides of two-sided marketplaces and in ever more multi-faceted ways. (Such as, for example, female users facing higher surge prices at night based on the perception of increased vulnerability.)

WIE points to a paper published in the Harvard Business Review last year that warned algorithmic pricing systems pose policy challenges which are far broader than collusive conduct — and can lead to higher prices for consumers in competitive markets (even without collusion; so outside traditional antitrust law) — with the researchers called for pricing regulation to prevent harms. And it argues pretty much the same set of harms issues arise for platform workers subject to dynamic pricing too.

“It is very important for us to be able to help workers understand the basis for how and what they’re being paid but also to safeguard against personalization in pay — either directly or indirectly,” said Farrer on this. “These platforms have furiously denied personalization in pay. But sure, what’s the optimization in here then? I mean it’s going to happen directly or indirectly and we absolutely have to have an eagle eye on it, because if not, there will be abuses because the controls aren’t there. And because as these platforms seek to optimise that’s the effect it’s going to have — either directly or indirectly.”

3. Platforms such as Uber and Ola cannot rely on trade secrets exemptions, as these "claims were entirely disproportionate relative to the negative effect of unexplained automated dismissal and disciplining of workers." — Jill Toh (@jilltoh) April 4, 2023

What will WIE be doing with the driver information it has been to extract from platforms?

“We are already starting to get data at scale — and we are working with data scientists at the moment to build the analytics we need to [build workers’ collective bargaining power],” said Farrer. “Where it’s transformative is… there’s an information power asymmetry between the worker and the platform. The workers have very weak bargaining power because of the oversubscription problem. Because of the lack of a sensible employment relationship that confers rights. Because of the difficulty in building collective union participation, although that’s changing rapidly for ADCU.

“Then we need to find the means to building that collective power. Platforms trade on our personal data but it’s our personal data so we have to try and beat them at their own game — or fight them in their own game — by aggregating that data. And aggregating that data will be able to tell what are the true pay conditions. Because so many workers have to rely on the myth of what the platform is telling them, rather than what’s really happening… And that picture is actually getting more complex. Because companies like Uber and Deliveroo they’re not happy just to rely on set pay being highly variable. They actually want to take a sledgehammer to the pay structure and fragment it into more and more pieces — incentives for this, bonus for this, boost for this — so by the time you’re done you don’t know what you’re being paid or what the basis of your pay is. And that’s a very deliberate thing… And the move to dynamic pay is a big part of that.”

“We are already getting enough information to be very useful. So we seem to have ironed out some of those problems in that at least what we’re getting is the trip information. So we can we can do analysis on that much at least,” he added. “But there’s still, of course, and there will always be a battle over the level of algorithmic transparency that’s required from the workers relative to what these platforms are willing to do.

“And, of course, their message of algorithmic control is a moveable feast. We’ve seen that over the last couple of years — with upfront pricing and now dynamic pricing. Those are progressive changes in the development of the platform and our job is to try and understand the processing that’s going on with that — and that’s a moveable feast in that there’s always going to be a challenge because we’re going to want to know and they’re going to want to not tell us.”

Uber et al.’s push-back on calls for greater transparency is — typically — to claim their anti-fraud systems won’t work if workers know enough about how they function to be able to circumvent them. They also tend to claim they’re prevented from releasing more data because they’re protecting passengers’ privacy. (It remains to be seen what multi-tiered excuses platforms will drum up to argue against providing total pay transparency.)

Farrer responds to such lines by suggesting the platforms are seeking to deflect attention off their own security failings and management and regulatory deficiencies — by creating a red-herring concept of driver “fraud” in order to foist blame for their own business management failings onto rights denuded workers.

“There’s no real plausible way that the driver can defraud the platform — because they don’t have access to any kind of credit card information or anything behind the scene. And I think the whole idea of account account security is a sensitive issue for Uber, and certainly their investors, because they need to maintain the confidence of passengers that if you give me your personal data and your credit card details, it’ll be secure. So I think for them they would either consciously or unconsciously prefer to blame their platform security problems on the worker, rather than admitting that they may have their own cybersecurity problems to deal with,” he suggested.

“These are hollowed out companies,” he added. “They want to automate as much of the management inside the company as they do service delivery outside the company. So if they can find a way to tack something on an 80:20 [system accuracy] basis that’s good enough for them because the workers have no recourse anyway. And anyway, the whole nature of the platform is to be massively over oversubscribed. So they’re not short of drivers that they can just sling off.”

“The truth of it is, is that transport business — I don’t care whether it’s road transport, air, rail — it’s a capital intensive, labour intensive, low margin business, and it always has been. But you can still make money in it. But what these platforms thought they could do is descend from the cloud, deny they’re a transport operator, insist that they’re a technology company, and cream margins away from that business that were never there to begin with. And so unless they want to acclimatize themselves to the industry that they’re in — and figure out how they can make money in a low margin business, instead of trying to take the easy way and illegal way — then, yeah, they are going to face annihilation. But maybe if they get some sensible people in to understand how to devise a strategy for the business they’re really in, not the business they want to be in, then maybe they’ve have better luck.”

In the EU, lawmakers are aiming to make it harder for platforms to just sling off precarious workers — by setting down minimum standards atop a (rebuttable) presumption of employment for gig workers. Although the file has proved divisive with Member States and the Council still hasn’t adopted a negotiating position. But MEPs in the parliament agreed their position back in February.

The litigants are calling for EU lawmakers to get on and pass this reform to improve protections for gig workers. And while Farrer confirms they won’t stop filing legal challenges to try to unpick exploitation he argues there’s a clear need for lawmakers to get a handle on the power imbalance and pass proper regulation to guarantee workers are protected without needing to spend years fighting through the courts. (The much touted modern working practices employment reforms, promised by former U.K. PM Theresa May in the wake of the 2017 Taylor review, ended with a damp squib package of measures that unions savaged on arrival as “big on grandiose claims, light on substance”; and which Farrer dismisses now as “nothing” having being done.)

He also suggests regulators are sleeping on the job — pointing, for example, to Transport for London’s (TfL) licensing for Uber which requires any changes to its business model need to be communicated to it 30 days in advance. Yet when WIE asked TfL if it’s reviewed Uber’s switch to upfront pricing the regulator failed to respond. (We’ve reached out to TfL with questions about this and will update this report with any response. Update: The regulator ignored our questions asking for confirmation of whether or not Uber notified it of the change to its pricing model in advance; whether it has reviewed the new business model and if it has any concerns; and whether it has sought a legal review of Uber’s switch to dynamic pricing — sending us this brief statement instead: “We are aware of the judgment from the Amsterdam Court of Appeal and are considering the ruling.” )

“Workers are already in a very weak position. But if you’ve got this tacit collusion problem, well, that amounts to grey- and black-listing of the worker — and that’s illegal under employment law. So for those reasons, we really have our work cut out to to aggregate this data and keep a very close eye on this,” he said, adding: “We need a platform worker directive equivalent in the U.K.”

Where workers right are concerned there’s actually more bad news zooming into view in the U.K. — where the government is in the processing of passing a data reform bill the litigants warn will strip away some of the protections workers have been able to exercise in this case. Such as a requirement to carry out a data protection impact assessment (a procedure that would typically entail platforms consulting with workers — so the reform looks set to discourage that type of engagement by platforms).

The draft bill also proposes to raise the threshold for individuals to get access to their data by allowing more leeway to platforms to deny requests — which could mean workers in the U.K. have the added challenge of having to argue for the validity of their right to access their own data, even to just get a chance of a sniff of seeing any of the stuff.

So, as it stands, U.K. lawmakers are intending to burden workers with even more friction atop a process that can already take years of legal action to see even a partial victory. Making life harder for platform workers to exercise their rights obviously won’t tip the already-stacked scales on gig economy exploitation.

The litigants are urging parliamentarians to amend the draft reform to ensure key protections stand. (Albeit, given the U.K.’s sclerotic record in this area, it may take a change of government before there’s any meaningful action to rein in platform power and support workers rights.)

In a statement, Farrer dubbed the ruling “a bittersweet victory considering that the U.K. government plans to strip workers of the very protections successfully claimed in this case”, adding: “Lawmakers must learn important lessons from this case, amend the bill and protect these vital rights before it is too late. Similarly, the Council of the European Union must not hesitate in passing the proposed Platform Work Directive as passed by the European Parliament.”. Uber and Ola found to violate driver rights in robo-firing of workers.



Court REJECTS Uber and Ola arguments that disclosure of information about fraud allegations made against the workers would undermine platform security & expose trade secrets.



Uber and Ola Cabs ordered to provide information to workers on automated decision making relating to work allocation and fares including dynamic pay & pricing.



Court rules that secret worker profiling and management assessments are personal data and must be disclosed.



Ruling a bittersweet victory as the UK government advances a bill through parliament this month which strips workers of the rights successfully claimed in this ruling.





In a series of historic and wide-ranging digital rights rulings, the Court of Appeals in Amsterdam has found in favour of workers and against Uber and Ola Cabs. Worker Info Exchange brought the cases in support of members of the App Drivers & Couriers Union in Great Britain and a driver based in Portugal.



The cases were brought under the GDPR which guarantees everyone the right to demand access to their personal data processed by any organisation and to receive meaningful information about the processing of such data. In addition, the GDPR gives everyone certain protections from automated decision making where there are significant negative consequences.



The first case involved four drivers who were found to be effectively robo-fired by Uber without recourse.

The second case involved the denial of access to personal data upon requests made to Uber by six drivers.

The third case involved the denial of access to personal data upon requests made to Ola Cabs by three drivers.





Unfair automated decision making



The drivers faced spurious allegations of ‘fraudulent activity’ by Uber and were dismissed without appeal. When the drivers requested an explanation for how Uber systems had surveilled their work and wrongly determined they had engaged in fraud, Uber stonewalled them.





The court found that the limited human intervention in Uber’s automated decisions to dismiss workers was not "much more than a purely symbolic act". The decision to dismiss the drivers was taken remotely at an Uber office in Krakow and the drivers were denied any opportunity to be heard. The court noted that Uber had failed to make“clear what the qualifications and level of knowledge of the employees in question are. There was thus insufficient evidence of actual human intervention.”





The court found that the drivers had been profiled and performance managed by Uber: “This example illustrates, in the court's view, that it involves automated processing of personal data of drivers whereby certain personal aspects of them are evaluated on the basis of that data, with the intention of analysing or predicting their job performance, reliability and behaviour.”





Uber and Ola Cabs must reveal how automated decision making is used to determine pay and allocation of work.

The court ordered that Uber must explain how driver personal data and profiling is used in Uber’s upfront, dynamic pay and pricing system. Similarly, the court ordered Uber to transparently disclose how automated decision making and worker profiling is used to determine how work is allocated amongst a waiting workforce. Last year, a Harvard Business review paper called for dynamic pricing systems to be closely regulated due to the risk of exploitation and tacit collusion.



In ruling in favour of the drivers, the court noted that Uber’s dynamic pricing"taken as a whole, affects the drivers to a considerable extent. This system is applied to every passenger they carry. These are therefore successive decisions, each with financial consequences that determine the income they can earn.”



Ola Cabs was also ordered to disclose meaningful information about the use in automated decision making of worker earnings profiles and so called ‘fraud probability scores’ used in automated decision making for work and fares allocation.

The court also ruled that internally held profiles relating drivers and associated performance related tags must be disclosed to drivers.





Abuse of rights?



The court rejected Ola’s far-reaching argument that the requests for data and the involvement of Worker Info Exchange and the ADCU trade union amounted to an abuse of the data protection rights of the individual appellants.





Platforms cannot rely on ‘trade secret’ arguments to deny transparency to workers.



The court rejected arguments by both Uber and Ola Cabs that to explain allegations and automated decision making negatively effecting workers would threaten their rights to protect trade secrets. The court ruled that such claims were entirely disproportionate relative to the negative effect of unexplained automated dismissal and disciplining of workers.





Significance in the UK and beyond





Beyond the data protection violations, the evidence of performance profiling is a strong indication that Uber workers are indeed employees but are still denied employment protections across Europe which would include protections from unfair dismissal.





Uber and Ola Cabs have relied on technology and automated processes for driver workforce management to the extent that they have singularly failed to convince the court that decisions relating to dismissals, pay and work allocation contained any meaningful human intervention.





It is clear in their so-called fraud detection procedures, Uber and Ola Cabs relied on a high degree of automation without the proper checks and balances of due process including an appeals process. In the case of the innocent drivers represented in this case and for many others, the consequences of such solely automated decision making can have devastating effects as the court recognised:



"In the opinion of the court of appeal, it is evident that these decisions affect the [appellant] to at least a considerable extent, as they have the consequence that the drivers can no longer provide for their income through the use of the Uber Driver app and can thus no longer recoup the investments they have made. In addition, the allegations in this case are serious and may also have repercussions (criminal or otherwise) have for [appellant] et al, in particular for their further or future activities, such as, for example, with regard to their taxi licence. Similarly, in its email to [appellant] dated 4 August 2020, Uber added: In certain circumstances we may also notify the police if your activity could constitute a criminal offence. Moreover, the present decisions also entail a legal consequence for [appellant] et al, as Uber thereby terminated the agreement with them.”





Ironically, in the UK the government this month will be introducing the Data Protection and Digital Information Bill for its second reading in parliament. If passed, the bill will strip workers of protections against abusive employer automated decision making as successfully claimed in this case. In addition, workers will face an increased hurdle to access personal data and to receive an explanation of processing, the importance of which has also been illustrated by this case.





James Farrar, Director of Worker Info Exchange said:





This ruling is a huge win for gig economy workers in Britain and right across Europe. The information asymmetry & trade secrets protections relied upon by gig economy employers to exploit workers and deny them even the most basic employment rights for fundamentals like pay, work allocation and unfair dismissals must now come to an end as a result of this ruling. Uber, Ola Cabs and all other platform employers cannot continue to get away with concealing the controlling hand of an employment relationship in clandestine algorithms.

Too many workers have had their working lives and mental health destroyed by false claims of fraudulent activity without any opportunity to know precisely what allegations have been made let alone answer them. Instead, to save money and avoid their responsibility as employers, platforms have built unjust automated HR decision making systems with no humans in the loop. Left unchecked, such callous systems risk becoming the norm in the future world of work. I’m grateful for the moral courage of the courts expressed in this important ruling.





The ruling comes as a bittersweet victory considering that the UK government plans to strip workers of the very protections successfully claimed in this case. Law makers must learn important lessons from this case, amend the bill and protect these vital rights before it is too late. Similarly, the Council of the European Union must not hesitate in passing the proposed Platform Work Directive as passed by the European Parliament. "





Azeem Hanif, Chair of ADCU Nottingham and member of the ADCU National Executive Committee said:





"I am gratified to see that the courts have resisted Uber and Ola Cabs to uphold the rights of trade unions to assist workers in their demands for algorithmic transparency at work individually and for data aggregation for the purposes of collective bargaining."





Anton Ekker of Ekker law representing in this case said:





"Today’s judgments are a big win for Uber and Ola drivers and for all people working in the platform economy. Transparency about data processing on Uber and Ola's platforms is essential for drivers to do their jobs properly and to understand how Uber makes decisions about them. The practical and legal objections raised by Uber and Ola were largely rejected by the Amsterdam Court of Appeals.

Of great importance, in addition, is the Court's finding that several automated processes on Uber and Ola's platforms qualify as automated decision-making within the meaning of Article 22 GDPR. These include assigning rides, calculating prices, rating drivers, calculating 'fraud probability scores' and deactivating drivers' accounts in response to suspicions of fraud. The judgments clearly establish that drivers are entitled to information on the underlying logic of these decisions."









BACKGROUND:

Rulings in Dutch can be accessed here:







Dutch rulings translated to English here: (Please note that this is an unofficial translation)



Press release from the court: Uber en Ola-Cabs moeten Londense taxichauffeurs beter informeren over automatische besluiten (rechtspraak.nl)