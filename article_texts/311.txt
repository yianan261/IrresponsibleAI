ARTICLE TITLE: YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference
YouTube is blaming its auto-moderation tool for removing a live-stream of a women's sex conference.

According to a report from the Daily Dot, the conference, called Women of Sex Tech, had its live feed auto-banned from YouTube just four minutes into the broadcast for allegedly violating the platform's community guidelines.

The conference has reportedly been ongoing for the last five years but was moved online due to the coronavirus pandemic.

YouTube shut out a women's sex tech conference after just four minutes of streaming. The platform blamed an auto-moderation feature (stock)

In a statement to the DailyDot, YouTube said the incident was caused by increased reliance on the algorithm meant to automatically weed out content that breaks YouTube's guidelines

The reliance on auto-moderation has been driven by a lack of human moderators due to constraints brought on by an ongoing the coronavirus pandemic, YouTube said.

'We know that this may result in some videos being removed that do not violate our policies, but this allows us to continue to act quickly and protect our ecosystem,' the spokesperson said.

'If creators think that their content was removed in error, they can appeal decisions and our teams will take a look.'

Motherboard reports that though YouTube's community guidelines are meant to prevent 'sexually gratifying' content as well as nudity and pornography, the entire five-hour conference contained no such material.

Sex tech has only recently found a home in major conferences like CES where toys for women and men were on display this year

'I was so confused, I thought it had to be a glitch considering there was no mention of sex or adult content at that time,' Women of Sex Tech president Alison Falk told Motherboard.

'Considering this isn't a one-time occurrence and there are frequent stories of folks being shadowbanned, demonetized, having their accounts disabled, and so on within our communities, I can't help but wonder what variables within the automation their smart detection has been told to look for that would trigger a violation of inappropriate content,' Falk told Motherboard.