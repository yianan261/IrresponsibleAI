E ra fim de tarde. Depois de sair do trabalho, o assistente administrativo Davi esperava a última condução do dia com um amigo em um ponto de ônibus na Avenida Paralela, em Salvador, quando foi abordado por uma guarnição da Polícia Militar. “Eu entreguei meu RG, ele pegou o celular dele e ficou comparando, olhando para o meu rosto e olhando para o RG”, lembra ele.

Em seguida, os policiais o informaram que, ao passar na Estação Lapa do metrô, as câmeras de reconhecimento facial encontraram similaridades do seu rosto com o de um procurado pela justiça que tem seus dados cadastrados no banco de dados da Secretaria de Segurança Pública. Uma vez detectado pelo sistema, Davi foi monitorado por 15 estações, da Lapa à Mussurunga, até ser abordado pelos policiais.

Você possui 1 artigo para ler sem se cadastrar Assine nossa newsletter gratuita Conteúdo exclusivo e gratuito. Direto na sua caixa de entrada Continuar Lendo Cadastro enviado

Davi era inocente, mas não para as câmeras que o seguiram pelo percurso de 22 quilômetros. Foi liberado depois de identificado pelos policiais, que constataram que ele não era quem as câmeras e a inteligência artificial apontaram. Mas entrou para a estatística como mais um caso de jovem negro identificado erroneamente pelas tecnologias de reconhecimento facial adotadas pela polícia.

A taxa de acertos é pequena: na Micareta da Feira de Santana de 2019, por exemplo, só 3,6% dos 903 alertas gerados viraram mandados de prisão. Apesar disso, o governo da Bahia segue tratando o reconhecimento facial como vitrine de suas políticas de segurança pública. Em dois anos e meio, 215 procurados foram capturados com o uso da tecnologia.

Em julho deste ano, o governador Rui Costa, do PT, decidiu expandir o sistema e fez uma parceria de R$ 665 milhões com o conglomerado Oi e Avantia, especializada em tecnologias de segurança. Assim, além de Salvador, outras 77 cidades ganharão 4.095 câmeras conectadas no estado.

“Antes, a identificação era feita pelo policial, visualmente. Agora, o próprio sistema identifica criminosos, suspeitos, armas e placas de veículos”, declarou o governador, sem esconder seu entusiasmo pela tecnologia. Mais: o governo baiano também quer que a iniciativa privada integre o sistema de vigilância e reconhecimento facial. Agências bancárias, shoppings e condomínios, por exemplo, poderiam conectar suas câmeras e entregar os movimentos e rostos de quem passa por lá às autoridades. “[Com isso,] podemos multiplicar os olhos da segurança pública da Bahia”, comemorou Costa.

Instalar câmeras de reconhecimento facial foi uma das promessas da campanha de Rui Costa ao governo da Bahia. Agora, o projeto-piloto se transformará em política pública. Foto: Márcio Lima/Folhapress

Dados do suspeito direto no celular

A capital, Salvador, foi a escolhida para sediar o projeto-piloto do novo sistema, fornecido pela espanhola Iecisa em parceria com a Huawei por R$ 18 milhões. No Brasil, a Huawei também foi a responsável por fornecer a tecnologia para o Rio de Janeiro. O termo de serviço que fechou os detalhes do sistema comprado pelo governo baiano especifica que ele deve reconhecer pessoas mesmo que estejam de óculos ou barba – ainda que não tenham pelos faciais ou acessórios nos registros anteriores.

Também deve agrupar fotos da mesma face “para posterior consulta”. As imagens devem ser arquivadas com data, horário e localização e podem ser buscadas por nome, datas ou mesmo a partir de uma imagem da própria face. Assim, em poucos cliques – ao menos tecnicamente – as forças de segurança da Bahia conseguiriam saber não apenas quem passou por uma localidade, mas também por onde essa pessoa já andou antes disso.

O sistema usa inteligência artificial para comparar os rostos obtidos pelas câmeras com as imagens disponíveis no banco de dados de procurados da Secretaria de Segurança Pública, a SSP, alimentada pela Superintendência de Inteligência. “Caso a pessoa tenha alguma restrição, como mandado de prisão ou desaparecidos, a ferramenta emite um alerta ao Centro Integrado de Telecomunicações, que aciona uma equipe policial mais próxima do local para realização de abordagem”, explicou a SSP em resposta a um pedido feito via Lei de Acesso à Informação, a LAI.

Mas, em uma uma reportagem elogiosa do Fantástico, as autoridades baianas afirmaram ir além dos bancos de dados oficiais. “Cheguei na Bahia e estou aqui identificado pelo sistema de vocês?”, perguntou o repórter Murilo Salviano, ao coronel Marcos Oliveira. “Com toda a certeza”, ele garantiu. Na demonstração, as imagens de Salviano são comparadas no monitor a fotos dele postadas em redes sociais.

Ao Intercept, o coronel confirmou que os policiais usam “imagens públicas das redes sociais” para fazer a investigação de algum crime. A Secretaria de Segurança afirmou que a reportagem fala apenas da “possibilidade de uso de fotos extraídas de mídias sociais, como o Facebook que possui fonte aberta”. Por meio de sua assessoria de imprensa, garantiu que o recurso “até o momento” é usado apenas para localizar pessoas desaparecidas.

Quando o algoritmo identifica 90% de semelhança da face detectada com um suspeito do banco de dados, um alerta é emitido e há uma “análise humana”, diz a SSP. Se eles confirmarem a semelhança, uma guarnição que está próxima ao local é orientada a realizar a abordagem.

Nas ruas, os policiais ainda usam um aplicativo chamado Sistema de Mobilidade em Operações Policiais para levantar informações do cidadão. O MOP, como é conhecido, é instalado diretamente nos aparelhos celulares dos agentes e permite consulta de dados de condutores, veículos, antecedentes criminais e boletins de ocorrência. Ele pode ser usado, inclusive, em celulares particulares. O MOP tem acesso a dados de veículos, impressões digitais e registros criminais, dados demográficos, gênero e localização, inclusive de crianças e adolescentes – se o fim for “segurança pública”, diz a política de privacidade.

Ilustração: Henri Campeã para o Intercept Brasil

Os números por trás dos releases

C om um governo eleito por um discurso fortemente ligado ao combate à violência, Costa teve os aparatos tecnológicos de vigilância como uma de suas promessas de campanha. As câmeras de reconhecimento facial, que começaram a ser instaladas em dezembro de 2018, foram propagandeadas como instrumentos eficientes de combate à criminalidade. A prisão de um criminoso foragido durante o Carnaval daquele ano ajudou a impulsionar a opinião pública a favor do investimento.

Os novos gastos do governo baiano em tecnologia para segurança pública superam R$ 900 milhões, o que é propagandeado como o “maior investimento da história em segurança pública na Bahia”. Mas, apesar do vultoso anúncio do governo, os gastos estaduais com segurança pública têm caído ano a ano. A Bahia é um dos estados brasileiros com o menor gasto neste setor por habitante: R$ 289, menos da metade de, por exemplo, no Mato Grosso, Minas Gerais ou Tocantins.

Além disso, os dados de violência do estado colocam em xeque a aposta do governo. Em 2019 e 2020, a Bahia foi a unidade federativa que registrou o maior número de mortes violentas do país. No primeiro semestre de 2021, esse índice cresceu mais 7,1%.

Como a localização exata das câmeras de reconhecimento facial não é revelada, não é possível fazer cruzamentos para ver o impacto delas nos índices de violência. Mas os dados das regiões onde câmeras comuns foram instaladas podem dar algumas pistas. Na região do Lobato, com 10 câmeras, crimes contra o patrimônio aumentaram 144% desde 2012, ano em que o sistema de monitoramento foi iniciado na capital, até 2019. Na região de Cajazeiras, com 22 câmeras, o aumento foi de 71,3% e, na região da Sussuarana, com nove câmeras, foi 50,8% maior.

A redução de fato aconteceu na Barra, bairro nobre com 34 câmeras, onde o índice caiu 84% no período. Mas não na região de Liberdade e Cidade Nova: apesar das 34 câmeras instaladas, o índice subiu 12,7% no período analisado.

A Secretaria de Segurança Pública não comentou os números. Para o governo, o uso das tecnologias de reconhecimento facial é “salutar para o combate à criminalidade” e “um instrumento agregador no mecanismo de prevenção ao crime quando empregadas em conjunto com processos e práticas eficientes de policiamento”.

Quando o robô erra

E m um país cuja seletividade penal é notória contra pessoas negras e pobres e em um estado em que 97% das vítimas de violência policial são negras, não é difícil imaginar quem são os alvos principais das operações policiais movidas pelo sistema de caça de suspeitos turbinado pela tecnologia. Uma pesquisa da Rede de Observatórios de Segurança em cinco estados já mostrou que 90,5% dos presos por reconhecimento facial no Brasil eram negros.

Os algoritmos reproduzem os vieses racistas da sociedade, e seu uso em larga escala é especialmente preocupante na Bahia – estado que tem a maior porcentagem de negros do Brasil. Um relatório produzido em 2019 pela Defensoria Pública baiana mostrou que 98,8% dos presos em flagrante em Salvador são negros.

Se a seletividade penal já existe no mundo analógico, o uso da tecnologia pode piorar esse cenário. Além de amplificarem o viés racial já presente nas forças de segurança, elas também estão sujeitas a erros – caso de Davi. Vários estudos já mostraram que pessoas negras e asiáticas são mais identificadas erroneamente por sistemas de reconhecimento facial – especialmente mulheres negras.

Na Bahia, quase todas as vítimas de violência policial são negras. Foto: Romildo de Jesus/Futura Press/Folhapress

A cientista da computação e pesquisadora do Instituto de Tecnologia de Massachusetts Joy Buolamwini, que tem a pele preta, identificou a dificuldade que o sistema tem em reconhecer rostos de pessoas pretas quando se posicionou em frente a uma câmera e não teve seu rosto identificado de imediato pela inteligência artificial. Isso só aconteceu quando posicionou uma máscara branca em sua frente.

Esses erros já são inaceitáveis para fins comerciais – mas, usados para segurança pública, têm um potencial devastador.

“A população negra já sofre diuturnamente com o estereótipo de criminoso, desde microagressões que envolvem uma excessiva vigilância em estabelecimento comercial, cuja intencionalidade é facilmente negada, até casos de prisões indevidas e injustas”, escreveram Rosane Leal da Silva e Fernanda dos Santos Rodrigues da Silva, pesquisadoras em Direito pela Universidade Federal de Santa Maria, em artigo acadêmico publicado em 2019. “Com uma tecnologia em que o próprio algoritmo cumprirá este papel de indicar pessoas negras, equivocadamente, como potenciais suspeitas de um crime, novamente elas estarão ‘sujeitas à automatização de constrangimentos e violências, como abordagens policiais indevidas e atribuição inverídica de antecedentes criminais'”.

Segundo Luciano Oliveira, doutor em Engenharia Elétrica e de Computadores pela Universidade de Coimbra, Portugal, e especialista na área de Visão Computacional, é a fase de comparar as imagens com o banco de dados o maior desafio de um sistema do tipo.

“Se ele treinar o algoritmo com mais rostos de pessoas brancas, ele pode ter mais problemas para encontrar pessoas negras”, explica Oliveira. No caso da Bahia, como a maior parte do banco de suspeitos é composta de pessoas negras, o algoritmo precisa ser treinado justamente nessa população para não errar. “Se ele não treinar, não vai achar nenhum rosto, ou vai achar poucos rostos”, diz o pesquisador. Como em Salvador a maior parte da população é negra, é provável que o maior número de erros aconteça com essa parcela da população.

É aí que entra outra questão: os próprios bancos de dados de suspeitos usados no comparativo são problemáticos e com viés racial. “Precisamos questionar quais as garantias que nós temos de que esse banco de mandados têm dados corretos”, me disse Pedro Diogo, advogado que pesquisa Tecnologias de Vigilância e Terror Racial de Estado na Universidade Federal da Bahia. Segundo ele, há um grande número de mandados de prisão que ficam em aberto, apesar de já não terem mais funcionalidade – erros nos nomes, por exemplo, são comuns. Então, é grande a chance de alguém ser identificado por causa de um equívoco no próprio banco de dados da Secretaria de Segurança Pública.

“Um dos maiores riscos da instalação desses sistemas é a forma como ele possibilita combinar problemas específicos dessas tecnologias, como os vieses raciais, com problemas tradicionais do sistema penal brasileiro”, diz Diogo. Segundo ele, o número de identificações errôneas do sistema, como a que aconteceu com Davi, sequer é contabilizado. Se a PM identifica o erro do sistema, a ação é finalizada no local sem registro de ocorrência.

“As instituições policiais no país foram organizadas desde seu início para perseguir pessoas negras, tanto escravizadas quanto alforriadas, em prol da expropriação de trabalho, capital, terras e produção para a acumulação de propriedade em um projeto eugenista”, diz o pesquisador Tarcizio Silva, que estuda o chamado racismo algorítmico e atua em promoção da segurança digital e defesa contra danos algorítmicos na Fundação Mozilla. Como os algoritmos são programados por uma estrutura racista, a tendência é que eles reproduzam, sem freio, o viés de achar que toda pessoa negra é uma criminosa em potencial.

“A polícia que usa esse sistema que realiza chacinas, assassinatos e desaparecimentos, seja oficialmente ou por meio de milícias e grupos de extermínio. E aí vem o sistema de reconhecimento facial a ser instalado e a expandir a capacidade do estado de promover o terror em face da população negra desse país”, diz Diogo.

Apesar de ter sido liberado logo após a abordagem policial, as sequelas permanecem na vida de Davi. “Eu fiquei com bastante medo, porque há muito tempo que pego metrô e faço sempre a mesma rota. As câmeras sempre me filmaram e justamente naquele dia me confundiram”, ele me disse. A abordagem policial está sempre à espreita – agora, turbinada por câmeras e inteligência policial. “Eu comecei a pensar se era meu cabelo que estava grande, fiquei pensando até em uma forma de mudar a aparência, com medo de acontecer algo comigo”.

Esta reportagem é resultado de uma bolsa para investigações jornalísticas sobre tecnoautoritarismo, uma iniciativa da Associação Data Privacy Brasil de Pesquisa em parceria com o Intercept.