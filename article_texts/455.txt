When internet sleuths discovered last week that CNET had quietly published dozens of feature articles generated entirely by artificial intelligence, the popular tech site acknowledged that it was true — but described the move as a mere experiment.. . Last week, we reported that the prominent technology news site CNET had been quietly publishing articles generated by an unspecified "AI engine."

The news sparked outrage. Critics pointed out that the experiment felt like an attempt to eliminate work for entry-level writers, and that the accuracy of current-generation AI text generators is notoriously poor. The fact that CNET never publicly announced the program, and that the disclosure that the posts were bot-written was hidden away behind a human-sounding byline — "CNET Money Staff" — made it feel as though the outlet was trying to camouflage the provocative initiative from scrutiny.

After the outcry, CNET editor-in-chief Connie Guglielmo acknowledged the AI-written articles in a post that celebrated CNET's reputation for "being transparent."

Without acknowledging the criticism, Guglielmo wrote that the publication was changing the byline on its AI-generated articles from "CNET Money Staff" to simply "CNET Money," as well as making the disclosure more prominent.

Furthermore, she promised, every story published under the program had been "reviewed, fact-checked and edited by an editor with topical expertise before we hit publish."

That may well be the case. But we couldn't help but notice that one of the very same AI-generated articles that Guglielmo highlighted in her post makes a series of boneheaded errors that drag the concept of replacing human writers with AI down to earth.

Take this section in the article, which is a basic explainer about compound interest (emphasis ours):

"To calculate compound interest, use the following formula:

Initial balance (1+ interest rate / number of compounding periods) ^ number of compoundings per period x number of periods

For example, if you deposit $10,000 into a savings account that earns 3% interest compounding annually, you'll earn $10,300 at the end of the first year."

It sounds authoritative, but it's wrong. In reality, of course, the person the AI is describing would earn only $300 over the first year. It's true that the total value of their principal plus their interest would total $10,300, but that's very different from earnings — the principal is money that the investor had already accumulated prior to putting it in an interest-bearing account.

"It is simply not correct, or common practice, to say that you have 'earned' both the principal sum and the interest," Michael Dowling, an associate dean and professor of finance at Dublin College University Business School, told us of the AI-generated article.

It's a dumb error, and one that many financially literate people would have the common sense not to take at face value. But then again, the article is written at a level so basic that it would only really be of interest to those with extremely low information about personal finance in the first place, so it seems to run the risk of providing wildly unrealistic expectations — claiming you could earn $10,300 in a year on a $10,000 investment — to the exact readers who don't know enough to be skeptical.

Another error in the article involves the AI's description of how loans work. Here's what it wrote (again, emphasis ours):

"With mortgages, car loans and personal loans, interest is usually calculated in simple terms.

For example, if you take out a car loan for $25,000, and your interest rate is 4%, you'll pay a flat $1,000 in interest per year."

Again, the AI is writing with the panache of a knowledgeable financial advisor. But as a human expert would know, it's making another ignorant mistake.

What it's bungling this time is that the way mortgages and auto loans are typically structured, the borrower doesn't pay a flat amount of interest per year, or even per monthly payment. Instead, on each successive payment they owe interest only on the remaining balance. That means that toward the beginning of the loan, the borrower pays more interest and less principal, which gradually reverses as the payments continue.

It's easy to illustrate the error by entering the details from the CNET AI's hypothetical scenario — a $25,000 loan with an interest rate of 4 percent — into an auto loan amortization calculator. The result? Contrary to what the AI claimed, there's never a year when the borrower will pay a full $1,000 in interest, since they start chipping away at the balance on their first payment.

CNET's AI is "absolutely" wrong in how it described loan payments, Dowling said.

"That's just simply not the case that it would be $1,000 per year in interest," he said, "as the loan balance is being reduced every year and you only pay interest on the outstanding balance."

The problem with this description isn't just that it's wrong. It's that the AI is eliding an important reality about many loans: that if you pay them down faster, you end up paying less interest in the future. In other words, it's feeding terrible financial advice directly to people trying to improve their grasp of it.

The AI made yet another gaffe when it attempted to describe certificates of deposit, better known as CDs, which are financial products that offer interest, but typically discourage withdrawing the funds before a set period has elapsed (once more, emphasis ours):

"Note that a high-yield savings account or money market account may offer interest that compounds daily, weekly or monthly. But a one-year certificate of deposit only compounds once, after the initial deposit reaches maturity."

This one is just straight-up false. For instance, here's a one-year CD by Chase Bank that compounds daily. And here's one by Capital One that compounds monthly.

All three screwups, each of which the AI presented with the easy authority of an actual subject matter expert, highlight a core issue with current-generation AI text generators: while they're legitimately impressive at spitting out glib, true-sounding prose, they have a notoriously difficult time distinguishing fact from fiction.

For an editor, that's bound to pose an issue. It's one thing to work with a writer who does their best to produce accurate work, but another entirely if they pepper their drafts with casual mistakes and embellishments. BuzzFeed News perfectly illustrated that risk this week, when a reporter there used ChatGPT to generate a story about CNET's secretive use of AI — only to find that she "had to rewrite the prompt a few times to get it to stop inserting factual errors."

Another issue that may be at play here is well known in the separate AI-inflected field of self-driving cars. Researchers have found that human safety drivers, tasked with sitting behind the wheel of an autonomous vehicle to take over if it malfunctions, tend to quickly lose focus when they don't have to actively work the controls. The same dynamic may be at play when an editor is put in charge of approving a deluge of AI-generated explainers: in the face of endless synthetic writing, maybe it makes sense that human editors start to go on autopilot themselves.

Everyone makes mistakes, so we're certainly sympathetic. But in these early days of CNET's AI experiment — nevermind in a piece published the same day that the site's editor went public in response to a storm of criticism — you'd expect the editors tasked with monitoring the AI to be on their highest alert.

If these are the sorts of blunders that slip through during that period of peak scrutiny, what should we expect when there aren't so many eyes on the AI's work? And what about when copycats see that CNET is getting away with the practice and start filling the web with their own AI-generated content, with even fewer scruples?

It's also worth asking what readers actually want: financial advice from a real human with real financial concerns, or logorrhea from a bot that's been trained to rehash existing financial writing with no financial stake of its own.

Dowling said that while he's optimistic about the potential of AI in general, he suspects that an algorithm like CNET's lack of personal perspective or "insights that go beyond mere summary" will keep it from producing genuinely interesting work.

"People already approach finance reading with an advance sense of boredom and reluctance — will ChatGPT just embed those negative features even deeper in finance writing?" he asked.

After Futurism reached out to CNET about the errors, staff there issued a lengthy correction to the article and edited the text to address all three mistakes.

Staff at CNET also seemingly identified a fourth error by the AI, which they also described in the correction, regarding the distinction between Annual Percentage Rate (APR) and Annual Percentage Yield (APY).

A CNET spokesperson provided Futurism with a brief statement about the corrections.

"We are actively reviewing all our AI-assisted pieces to make sure no further inaccuracies made it through the editing process, as humans make mistakes, too," they said. "We will continue to issue any necessary corrections according to CNET's correction policy."

Are you a current or former CNET employee who wants to discuss the company's foray into AI-generated articles? Email tips@futurism.com to share your perspective. It's okay if you don't want to be identified by name.

The spokesperson didn't respond to a question about CNET's confidence in the other articles the AI has published to its site. After we reached out, however, a new message appeared at the top of almost every piece the AI has published, dating back to November.

"Editors' note: We are currently reviewing this story for accuracy," reads the message. "If we find errors, we will update and issue corrections."

It's worth pointing out, as Platformer's Casey Newton did this week, that CNET's AI-generated finance articles arguably only exist in the first place because they're trying to manipulate Google's algorithm for profit. Countless better explanations of compound interest already exist; CNET's strategy is simply to publish large volumes of cheaply produced text, carefully optimized to float to the top of search results, in a bid to capture the monetizable eyeballs of the financially curious.

"Over time, we should expect more consumer websites to feature this kind of 'gray' material: good-enough AI writing, lightly reviewed (but not always) by human editors, will take over as much of digital publishing as readers will tolerate," Newton wrote. "The quiet spread of AI kudzu vines across CNET is a grim development for journalism, as more of the work once reserved for entry-level writers building their resumes is swiftly automated away."

In other words, it's not just AI that's the issue here. It's that AI is maturing at a moment when the journalism industry has already been hollowed out by a decades-long race to the bottom — a perfect storm for media bosses eager to cut funding for human writers.

Frank Landymore contributed reporting to this story.

More on CNET: CNET Is Quietly Publishing Entire Articles Generated by AI. Aside from stringing together human-like, fluid English language sentences, one of ChatGPT’s biggest skillsets seems to be getting things wrong. In the pursuit of generating passable paragraphs, the AI-program fabricates information and bungles facts like nobody’s business. Unfortunately, tech outlet CNET decided to make AI’s mistakes its business.



Generating Video Via Text? | Future Tech CC Share Subtitles Off

English view video Generating Video Via Text? | Future Tech

The tech media site has been forced to issue multiple, major corrections to a post published on CNET, created via AI, as first reported by Futurism. In one single AI-written explainer on compounding interest, there were at least five significant inaccuracies, which have now been amended. The errors were as follows, according to CNET’s hefty correction:

The article implied a savings account initially containing $10,000 with a 3% interest rate, compounding annually, would accrue $10,300 in interest after a year. The real earned interest would amount to $300.

An error similar to the above showed up in a second example, based on the first.

The post incorrectly stated that one-year CD accounts’ interest only compounds annually. In reality: CD accounts compound at variable frequencies.

The article mis-reported how much a person would have to pay on a car loan with a 4% interest rate over five years.

The original post incorrectly conflated APR and APY, and offered bad advice accordingly.

Advertisement

For more than two months, CNET has been pumping out posts generated by an artificial intelligence program. The site has published 78 of these articles total, and up to 12 in a single day, originally under the byline “CNET Money Staff,” and now just “CNET Money.” Initially, the outlet seemed eager to have its AI authorship fly under the radar, disclosing the lack of a human writer only in an obscure byline description on the robot’s “author” page. Then, Futurism and other media outlets caught on. Critique followed. CNET’s editor in chief, Connie Guglielmo, wrote a statement about it.

Advertisement

And just like the outlet’s public acknowledgement of its use of AI only followed widespread criticism, CNET didn’t identify nor aim to fix all these inaccuracies noted on Tuesday, all on its own. The media outlet’s correction only came after Futurism directly alerted CNET to some of the errors, Futurism reported.

Advertisement

CNET has claimed that all of its AI-generated articles are “reviewed, fact-checked and edited” by real, human staff. And each post has an editor’s name attached to it in the byline. But clearly, that alleged oversight isn’t enough to stop artificial intelligence’s many generated mistakes from slipping through the cracks.

Advertisement

Usually, when an editor approaches an article (particularly an explainer as basic as “What is Compound Interest”), it’s safe to assume that the writer has done their best to provide accurate information. But with AI, there is no intent, only the product. An editor evaluating an AI-generated text cannot assume anything, and instead has to take an exacting, critical eye to every phrase, world, and punctuation mark. It’s a different type of task from editing a person, and one people might not be well-equipped for, considering the degree of complete, unfailing attention it must take and the high volume CNET seems to be aiming for with its AI-produced stories.

It’s easy to understand (though not excusable) that when sifting through piles of AI-generated posts, an editor could miss an error about the nature of interest rates among the authoritative-sounding string of statements. When writing gets outsourced to AI, editors end up bearing the burden, and their failure seems inevitable.

Advertisement

And the failures are almost certainly not just limited to the one article. Nearly all of CNET’s AI-written articles now come with an “Editors’ note” at the top which says, “We are currently reviewing this story for accuracy If we find errors, we will update and issue corrections,” indicating the outlet has realized the inadequacy of its initial editing process.

Gizmodo reached out to CNET for more clarification about what this secondary review process means via email. (Will each story be re-read for accuracy by the same editor? A different editor? An AI fact-checker?) However, CNET didn’t directly respond to my questions. Instead, Ivey Oneal, the outlet’s PR manager, referred Gizmodo to Guglielmo’s earlier statement and wrote, “We are actively reviewing all our AI-assisted pieces to make sure no further inaccuracies made it through the editing process. We will continue to issue any necessary corrections according to CNET’s correction policy.”

Advertisement

Given the apparent high likelihood of AI-generated errors, one might ask why CNET is pivoting away from people to robots. Other journalistic outlets, like the Associated Press, also use artificial intelligence—but only in very limited contexts, like filling information into pre-set templates. And in these narrower settings, the use of AI seems intended to free up journalists to do other work, more worthy of their time. But CNET’s application of the technology is clearly different in both scope and intent.

All of the articles published under the “CNET Money” byline are very general explainers with plain language questions as headlines. They are clearly optimized to take advantage of Google’s search algorithms, and to end up at the top of peoples’ results pages—drowning out existing content and capturing clicks. CNET, like Gizmodo and many other digital media sites, earns revenue from ads on its pages. The more clicks, the more money an advertiser pays for their miniature digital billboard(s).

Advertisement

From a financial perspective, you can’t beat AI: there’s no overhead cost and there’s no human limit to how much can be produced in a day. But from a journalistic viewpoint, AI-generation is a looming crisis, wherein accuracy becomes entirely secondary to SEO and volume. Click-based revenue doesn’t incentivize thorough reporting or well-put explanation. And in a world where AI-posts become an accepted norm, the computer will only know how to reward itself.



Update 1/17/2023, 5:05 p.m. ET: This post has been updated with comment from CNET.. After getting caught using an algorithm to write dozens of articles, the tech publication CNET has apologized (sorta) but wants everybody to know that it definitely has no intention of calling it quits on AI journalism.

ChatGPT’s Creator Buddies Up to Congress | Future Tech CC Share Subtitles Off

English view video ChatGPT’s Creator Buddies Up to Congress | Future Tech

R oughly two weeks ago Futurism reported that CNET had been using an in-house artificial intelligence program to pen droves of financial explainers. The articles—some 78 in total—were published over the course of two months under the bylines “CNET Money Staff” or “CNET Money,” and weren’t directly attributed to a non-human writer. Last week, after an online uproar over Futurism’s findings, CNET and its parent company, media firm Red Ventures, announced that it would be temporarily pressing “pause” on the AI editorials.

Advertisement

It would appear that this “pause” isn’t going to last long, however. On Wednesday, CNET’s editor and senior vice president, Connie Guglielmo, published a new statement about the scandal, in which she noted that, eventually, the outlet would continue to use what she called its “AI engine” to write (or help write) more articles. In her own words, Guglielmo said that...

[Readers should] ...expect CNET to continue exploring and testing how AI can be used to help our teams as they go about their work testing, researching and crafting the unbiased advice and fact-based reporting we’re known for. The process may not always be easy or pretty, but we’re going to continue embracing it – and any new tech that we believe makes life better.

Advertisement

Guglielmo also used Wednesday’s piece as an opportunity to address some of the other criticisms aimed at CNET’s dystopian algo—namely, that it had frequently created content that was both factually inaccurate and potentially plagiaristic. Under a section titled “AI engines, like humans, make mistakes,” Guglielmo copped to the fact that its so-called engine made quite a few mistakes:

After one of the AI-assisted stories was cited, rightly, for factual errors, the CNET Money editorial team did a full audit...We identified additional stories that required correction, with a small number requiring substantial correction and several stories with minor issues such as incomplete company names, transposed numbers or language that our senior editors viewed as vague.

Advertisement

The editor also admitted that some of the automated articles may have not passed the sniff test when it comes to original content:

In a handful of stories, our plagiarism checker tool either wasn’t properly used by the editor or it failed to catch sentences or partial sentences that closely resembled the original language. We’re developing additional ways to flag exact or similar matches to other published content identified by the AI tool, including automatic citations and external links for proprietary information such as data points or direct quotes.

Advertisement

It would be one thing if CNET had very publicly announced that it was engaging in a bold new experiment to automate some of its editorial tasks, thus letting everybody know that it was doing something new and weird. However, CNET did just the opposite of this—quietly rolling out article after article under vague bylines and clearly hoping nobody would notice. Guglielmo now admits that “when you read a story on CNET, you should know how it was created”—which seems like standard journalism ethics 101.. CNET told staff it would halt the publication of articles generated via artificial intelligence, in a Friday call, according to a report from The Verge. Or, at least, the company said it would pause the AI-article practice “for now,” as it waits out a stream of media criticism.



ChatGPT’s Creator Buddies Up to Congress | Future Tech CC Share Subtitles Off

English view video ChatGPT’s Creator Buddies Up to Congress | Future Tech

“I just want to reassure everybody: this will pass,” Lindsey Turrentine, a CNET executive, told staff regarding the recent coverage of the site’s AI use. “It’s uncomfortable, we will get through it, the news cycle will move on,” she added, in the hour-long call.

Advertisement

The storied tech media outlet, acquired in 2020 by private equity group Red Ventures, had been quietly publishing AI-generated content for months, under the byline “CNET Money Staff” or “CNET Money.” Other sites owned by Red Ventures, including Bankrate and CreditCards.com, have also been using the same, unnamed proprietary AI tool to generate content, Lance Davis, a Red Ventures executive, noted in the staff call, according to The Verge.

In the CNET stories, a small, hard-to-locate disclaimer on the “author” page was the only initial hint that a human hadn’t crafted the prose behind the posts. Until the true nature of those articles—almost entirely basic financial explainers transparently intended to garner clicks through SEO—was first widely noted in a January report from Futurism. And from there, multiple other major media outlets picked up the story .

Advertisement

A follow-up report from Futurism noted an alarming number of errors in just one of the AI-assisted posts. The article, titled “What is Compound Interest?,” misrepresented compound interest multiple times. CNET was forced to issue a hefty correction, and began reviewing the accuracy of all of its similarly produced content

Then, interviews with current and former CNET staff members revealed that the “CNET Money” posts were just the tip of the AI-iceberg. CNET had been using some form of automated assistance in posts for at least 18-months, and editorial staff were often left in the dark about when are where automation was being used, according to an earlier report from The Verge.

Advertisement

In the Friday staff call, Davis, Turrentine, and CNET editor-in-chief Connie Guglielmo offered staff more details about how AI was being used on the site. Editors using the AI tool can choose domains and sections for articles, pull data, and generate text. They can also include or add their own, human-written text or reporting.

Worth noting: multiple major news outlets use automation or AI for some content on their sites. For instance, the Associated Press began using AI to generate articles on earnings reports in 2014, and later expanded that to sports recaps. The Washington Post has used artificial intelligence to keep tabs on election results and football games.

Advertisement

However, CNET’s application of AI has been slightly different. By publishing a slew of articles with basic questions as headlines, meant to rank as high as possible in Google’s algorithmic assessment, the company was clearly trying to corner the click-market on financial advice—not free up journalists for other work. And all this from the same outlet that published an (actual, reported) article arguing that large language models wouldn’t replace humans in media. CNET didn’t immediately respond to Gizmodo’s request for comment.

Of course CNET and Red Ventures aren’t solely to blame in the rise of AI-written content on the web. Google has allowed these posts to flourish on its search results pages, providing companies ample financial incentive to continue pursuing artificial intelligence as an avenue of content creation.

Advertisement

“Our ranking team focuses on the usefulness of content, rather than how the content is produced,” Danny Sullivan, Google’s public search liaison, told Futurism. Though “useful” is a misleading term when SEO headlines can mask faulty financial advice. And, if Google continues to take that stance, the trustworthiness of your search results could get even shakier, as spammers and click-farmers aim to take advantage. Gizmodo reached out to Google with questions, but did not immediately receive a response.. CNET will pause publication of stories generated using artificial intelligence “for now,” the site’s leadership told employees on a staff call Friday.

The call, which lasted under an hour, was held a week after CNET came under fire for its use of AI tools on stories and one day after The Verge reported that AI tools had been in use for months, with little transparency to readers or staff. CNET hadn’t formally announced the use of AI until readers noticed a small disclosure.

“We didn’t do it in secret,” CNET editor-in-chief Connie Guglielmo told the group. “We did it quietly.”

CNET’s pop-up disclosure before it was rewritten last week.

CNET, owned by private equity firm Red Ventures, is among several websites that have been publishing articles written using AI. Other sites like Bankrate and CreditCards.com would also pause AI stories, executives on the call said.

Futurism noted that CNET and Bankrate appeared to have stopped running AI stories as early as Wednesday.

The call was hosted by Guglielmo, Lindsey Turrentine, CNET’s EVP of content and audience, and Lance Davis, Red Ventures’ vice president of content. They answered a handful of questions submitted by staff ahead of time in the AMA-style call.

Davis, who was listed as the point of contact for CNET’s AI stories until recently, also gave staff a more detailed rundown of the tool that has been utilized for the robot-written articles. Until now, most staff had very little insight into the machine that was generating dozens of stories appearing on CNET.

Are you a former or current CNET / Red Ventures employee? I’d love to hear from you. Contact me at mia@theverge.com, and I’ll share my Signal.

The AI, which is as of yet unnamed, is a proprietary tool built by Red Ventures, according to Davis. AI editors are able to choose domains and domain-level sections from which to pull data from and generate stories; editors can also use a combination of AI-generated text and their own writing or reporting.

Turrentine declined to answer staff questions about the dataset used to train AI in today’s meeting as well as around plagiarism concerns but said more information would be available next week and that some staff would get a preview of the tool.

Leadership also differentiated between the unnamed internal tool and other automated technology Red Ventures uses on its sites to auto-insert numbers into mortgage rate and refinance rate stories, which The Verge reported had been in use for far longer but that the company didn’t disclose.

CNET will begin including disclosures on their own stories about AI

“Some writers — I won’t call them reporters — have conflated these two things and had caused confusion and have somehow said that using a tool to insert numbers into interest rate or stock price stories is somehow part of some, I don’t know, devious enterprise,” Guglielmo said. “I’m sure that’s news to The Wall Street Journal, Bloomberg, The New York Times, Forbes, and everyone else who does that and has been doing it for a very, very long time.”

Guglielmo said that, going forward, stories on CNET about artificial intelligence will have a disclosure that the outlet uses its own automated technologies. Red Ventures also created an AI working group spanning across multiple departments, though it’s unclear what the council has done so far — leadership noted that the Slack channel had been created.

“I just want to reassure everybody: this will pass,” Turrentine said of the media coverage in recent weeks. “It’s uncomfortable, we will get through it, the news cycle will move on.”

Yesterday, The Verge reported that despite CNET’s “experiments” in AI-generated technology, many on staff were largely kept in the dark about what tools the company was using or how it was using them. At times, staffers told The Verge that they didn’t know if content published to CNET was AI-generated or written by their human colleagues. CNET and Red Ventures declined to answer any of The Verge’s questions about the tools used or disclosure policies.