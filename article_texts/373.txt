LANSING, Mich. (AP) — A state official who is conducting a wide-ranging review of Michigan’s embattled unemployment benefits office apologized for the fiasco that led at least 20,000 people to be falsely accused of defrauding a system that provides the jobless with temporary financial assistance.

Talent Investment Agency Director Wanda Stokes, whose agency includes the state Unemployment Insurance Agency, added that lawmakers should consider reducing what she said are the country’s highest financial penalties for unemployment fraud.

“I really feel horrible about this whole situation,” she told The Associated Press in an interview Friday. “At the most vulnerable and stressful time in their life, they are now being accused of fraud. ... I understand that they’re angry and I’m angry, too. It shouldn’t have happened.”

Stokes, who took charge of the umbrella agency that oversees the unemployment office in July, said Republican Gov. Rick Snyder appointed her to “assess the situation and then fix it.”

The state is reviewing about 50,000 cases from a nearly two-year period that cover roughly 40,000 people who were determined to have committed fraud — either solely by an automated computer system or by a mix of the software and some level of staff involvement. That typically means they were flagged for receiving “overpayments” to which they had not been entitled.

In many cases between October 2013 and August 2015, however, they did not commit fraud and — to compound being forced to pay restitution — were hit with interest along with penalties equaling two or four times the overpayment. Their wages and income tax refunds were garnished. Lawyers for people suing the state say some suffered worse credit ratings, job prospects and consequences from not being able to spend money they needed.

On Jan. 11, U.S. District Judge Robert Cleland approved an agreement by which the state is halting all collection activities against people who were subject to fraud determinations in the period in question, “unless and until individually reviewed by agency staff and affirmed with new notice to claimant.” The state must comply by late February.

Separately, the Michigan Court of Appeals is expected to soon schedule arguments in a 2015 class-action lawsuit that seeks economic damages.

“People have suffered greatly in addition to the financial losses that they’ve experienced. I think it’s only just that they receive some compensation from the state for the stress and the strain,” said Jennifer Lord, a Royal Oak-based attorney representing the plaintiffs in state court.

The state started using the Michigan Integrated Data Automated System (MiDAS) in 2013. The “robo-" or “auto-adjudication” system issued fraud determinations based on discrepancies in reported earnings, hours worked and other information.

The problem, Lord said, is three-fold.

The state rushed the implementation of a “fatally” designed computer program, which led to improper fraud claims. And a faulty notification process ensured many people were unaware of alleged discrepancies and unable to respond quickly before determinations were finalized, she said. For instance, questions were sent to online accounts for claimants who no longer were getting benefits and had no reason to check.

“I want them to know that we apologize for this situation and that we are looking at now going forward with a system that works for them and one that they can trust in the future,” said Stokes, who previously held top roles at the Michigan Department of Licensing and Regulatory Affairs, the state attorney general’s office and in the private sector. She reassigned the director of the Unemployment Insurance Agency more than three weeks ago.

Stokes said the agency cannot “unilaterally” lower 400 percent penalties that are codified in law, but she plans to talk to legislators about more “reasonable” penalties. While she did not specify an amount, she said penalties should be designed to encourage compliance and “shouldn’t be too harsh.”

A review of unemployment fraud cases made public in December found an error rate of 93 percent for about 22,000 cases in which determinations were solely made by the computer system between 2013 and 2015. The state now is reviewing 28,000 other cases from that time that were handled by the computers and staff.

A new law prevents the agency from adjudicating a claimant’s case as fraud without human verification and reduces the statute of limitations so it can pursue fraud three years back instead of six. But legislators plan to propose more bills in the new two-year session as needed.

Senate Minority Leader Jim Ananich, a Flint Democrat, wants to create a fund so people are paid back and to address a potential statute of limitations issue — which may be resolved in court — for people who were flagged for fraud involving benefits they had gotten years ago.

“This was something the government did wrong, and the citizens didn’t, so we’ve got to solve it,” he said.

Ann Arbor-based lawyer David Blanchard, who represents individuals in the federal case whose plaintiffs also include the United Auto Workers union and the Sugar Law Center in Detroit, said he is hopeful after the state agreed to stop collections.

“It’s sad that it’s taken so long. But it’s good that it’s finally gotten to the point where it’s impossible to deny that the system is broke and that it needs to be fixed,” he said. “That was not the first response from the state.”

___

Follow David Eggert on Twitter at https://twitter.com/DavidEggert00. His work can be found at http://bigstory.ap.org/author/david-eggert. LANSING (AP) — Gov. Rick Snyder and lawmakers are looking to create a state fund to compensate thousands of people who were falsely accused of fraudulently collecting unemployment benefits.

The proposal was not included in changes to the Unemployment Insurance Agency that won approval on the last day of legislative voting in 2017. But legislators, who a week before had begun negotiations on adding the compensation proposal to the bills at the request of the Snyder administration, plan to revisit the issue in January.

The compensation has long been demanded by Democrats in the GOP-led Legislature. It would help claimants who were refunded penalties and interest but have faced other financial hardships because of the fiasco that occurred between October 2013 and September 2015, when the state mostly relied on a computer system to determine that people collected excessive benefits based on discrepancies in reported earnings, hours worked and other information.

Some people had to hire lawyers to fight false findings. Others had to file for bankruptcy, saw their wages garnished, suffered worse credit ratings or had trouble finding a job and housing, according to an attorney for people who are suing for economic damages.

Rep. Joseph Graves, who helped spearhead the reform legislation and was involved in late-night talks

on the compensation plan, said the concept needs pursuing but cautioned it may not make people whole. More study is needed of the mechanism and if it is feasible, he said, citing legal and other questions that were raised.

“To just really quickly bum rush this through didn’t seem like the right thing to do,” said Graves, a Republican from Genesee County’s Argentine Township. “We need to slow down and say, ‘What can we offer and what does that look like?'”

While legislators involved in the discussions said the compensation would total $30 million, Snyder’s office declined to confirm that amount. To qualify, victims would have to agree not to sue the state.

“The intent is just to compensate people above and beyond their refund — to make things right for those who were unfairly treated,” said spokeswoman Anna Heaton. She said the governor will seek to reopen the negotiations in conjunction with work on the next budget, which he will propose in February.

The Unemployment Insurance Agency said of the nearly 67,000 cases in the two-year period in which claimants were found to have committed fraud and did not appeal, there were reversals for slightly more than 40,000 people. Nearly 20,000 of them had collections processed for restitution, penalties and interest. About $21 million has been or is being refunded.

Lawmakers’ decision to wait on the compensation fund was welcomed by Jennifer Lord, a lawyer who has been leading a lawsuit against the state that seeks class-action status for 46,000 residents. She questioned if $30 million would be enough to pay back what was improperly seized from claimants, let alone their related financial losses.

“It’s not enough money. I encourage the Legislature to really spend a lot of time with a lot of different stakeholders and understand the depths of the losses that people have suffered,” Lord said. “The concept needs a lot of work.”

She credited government officials for “trying to do the right thing” but said they must ensure that “someone is not asked to take $200 when they lost $10,000 and had to file bankruptcy. We just can’t get this done for political expediency and kind of hurt people one more time.”

Victims’ ability to sue has been in doubt since the state Court of Appeals tossed the suit in July, saying the three plaintiffs waited too long to file it. An appeal is pending with the state Supreme Court.

Snyder will soon sign the bills to overhaul the jobless benefits agency, which stopped “auto adjudicating” cases solely with the Michigan Integrated Data Automated System in 2015. The legislation is designed to prevent such a mess from occurring again and to help claimants navigate the system. Changes include cutting the nation’s highest financial penalties except for “impostor” claimants and easing employers’ ability to flag fake claims filed by identity thieves.

Rep. Kevin Hertel, a Democrat from St. Clair Shores, said “the biggest remaining piece and I think the most important out of all of this is to ensure we’re taking care of the individuals who were impacted by the MiDAS failure.”

He said he is “extremely glad” that Snyder now supports paying damages, and the Legislature should immediately consider the compensation fund upon returning in January. He opposed linking it to the multi-month budget process.

“If we’re going to do this, I think we need to do it right away,” Hertel said. “These people have waited too long.”. A Michigan government agency wrongly accused individuals in at least 20,000 cases of fraudulently seeking unemployment payments, according to a review by the state.

The review released this week found that an automated system had erroneously accused claimants in 93% of cases – a rate that stunned even lawyers suing the state over the computer system and faulty fraud claims.

“It’s literally balancing the books on the backs of Michigan’s poorest and jobless,” attorney David Blanchard, who is pursuing a class action in federal court on behalf of several claimants, told the Guardian on Friday.

The Michigan unemployment insurance agency (UIA) reviewed 22,427 cases in which an automated computer system determined a claimant had committed insurance fraud, after federal officials, including the Michigan congressman Sander Levin, raised concerns with the system.

The review found that the overwhelming majority of claims over a two-year period between October 2013 and August 2015 were in error.

In 2015, the state revised its policy and required fraud determinations to be reviewed and issued by employees. But the new data is the first indication of just how widespread the improper accusations were during that period.

The people accused lost access to unemployment payments, and reported facing fines as high as $100,000. Those who appealed against the fines fought the claims in lengthy administrative hearings. And some had their federal and state taxes garnished.



Kevin Grifka, an electrician who lives in metro Detroit, had his entire federal income tax garnished by the UIA, after it accused him of fraudulently collecting $12,000 in unemployment benefits.



The notice came just weeks before Christmas in 2014.

“To be honest with you, it was really hard to see your wife in tears around Christmas time, when all of this went on for me,” Grifka said.

The computer system claimed that he had failed to accurately represent his income over a 13-week period. But the system was wrong: Grifka, 39, had not committed insurance fraud.

In a statement issued on Friday, Levin called on state officials to review the remaining fraud cases that were generated by the system before the policy revision.

“While I’m pleased that a small subset of the cases has been reviewed, the state has a responsibility to look at the additional 30,000 fraud determinations made during this same time period,” he said.

Figures released by the state show 2,571 individuals have been repaid a total of $5.4m. It’s unclear if multiple cases were filed against the same claimants.

The findings come as Michigan’s Republican-led legislature passed a bill this week to use $10m from the unemployment agency’s contingent fund – which is composed mostly of fines generated by fraud claims – to balance the state’s budget. Since 2011, the balance of the contingent fund has jumped from $3.1m to $155m, according to a report from a Michigan house agency.

The system, known as the Michigan Integrated Data Automated System (Midas), caused an immediate spike in claims of fraud when it was implemented in October 2013 under the state’s Republican governor, Rick Snyder, at a cost of $47m.

In the run-up to a scathing report on the system issued last year by Michigan’s auditor general, the UIA began requiring employees to review the fraud determinations before they were issued.

The fraud accusations can carry an emotional burden for claimants.

“These accusations [have] a pretty big burden on people,” Grifka said. While he said the new findings were validating and his own case had been resolved, he called for state accountability.



“There’s no recourse from the state on what they’re doing to people’s lives. That’s my biggest problem with all of this.”

Steve Gray, director of the University of Michigan law school’s unemployment insurance clinic, told the Guardian earlier this year that he routinely came across claimants facing a significant emotional toll. As a result, he said, the clinic added the number for a suicide hotline to a referral resource page on the program’s website.

“We had just a number of clients who were so desperate, saying that they were going to lose their house … they’ve never been unemployed before, they didn’t know,” said Gray, who filed a complaint with the US labor department in 2015 about the Midas system.

The fines can be enormous. Residents interviewed by local news outlets have highlighted fraud penalties from the UIA upwards of $100,000. Bankruptcy petitions filed as a result of unemployment insurance fraud also increased during the timeframe when Midas was in use.

One bankruptcy attorney told the Detroit Metro Times he had as many as 30 cases in 2015 tied to debt from the UIA; before the automated system was implemented, he said he would typically have at most one per year with such claims. The newspaper also found claimants who were charged with fraud despite never having received a single dollar in unemployment insurance benefits.

A pair of lawsuits were filed in 2015 against the UIA over Midas. According to a pending federal case, in which the state revealed it had discontinued using Midas for fraud determinations, the system “resulted in countless unemployment insurance claimants being accused of fraud even though they did nothing wrong”.

Blanchard told the Guardian in February that many unemployment applicants may not have realized they were even eligible to appeal against the fraud charge, due to the setup of Midas. Attorneys representing claimants have said that many refuse to ever apply for unemployment benefits again.

A spokesman for the unemployment insurance agency, Dave Murray, said it appreciated Levin’s work on the issue and said it was continuing “to study fraud determinations”.

The agency had already made changes to the fraud determination process, he said, and “we appreciate that the state legislature this week approved a bill that codifies the reforms we’ve set in place”.

Levin, who represents part of metropolitan Detroit, said in his statement that Michigan officials had to fully account for the money that has flowed into the unemployment agency’s contingent fund.



“While I am pleased that $5m has been repaid, it strikes me as small compared to the amount of money that was collected at the time,” he said. “Only a full audit will ensure the public that the problem has been fully rectified.”. LANSING — Michigan residents falsely accused of unemployment insurance fraud by the state of Michigan — and subjected to harsh financial penalties that forced some of them into bankruptcy — can proceed with their lawsuit against not just state officials but the private companies that designed and helped implement the state's badly flawed robo-adjudication system, a federal judge said Thursday.

The companies — FAST Enterprises LLC and CSG Government Solutions — have argued they were only following the state's orders.

But that defense, which is similar to the one put forward by defendants at the Nuremberg trials, will not fly, U.S. District Judge David Lawson said in a 68-page opinion.

"Since World War II, the ‘just following orders’ defense has not occupied a respected position in our jurisprudence, and (government actors) in such cases may be held liable ... if there is a reason why any of them should question the validity of that order," Lawson wrote, quoting federal appeals judges in an earlier case.

Meanwhile, a lawyer for the plaintiffs said the state has continued to use the MiDAS (Michigan Integrated Data Automated System) to make fraud determinations amid record-high filings for jobless claims during the coronavirus pandemic, and he believes the system continues to falsely accuse significant numbers of Michigan claimants of fraud.

MiDAS is intentionally programmed "to make it difficult to get benefits," said Anthony Paris, the lead attorney for the plaintiffs.

Attorneys for the companies had no immediate comment on the ruling. The Michigan Attorney General's Office, which represents the state defendants, is "still reviewing the decision with our clients," spokeswoman Courtney Covington Watkins said. Officials at the Unemployment Insurance Agency did not immediately respond to questions about the ruling and the assertion from Paris that the false fraud problem is likely to recur amid the coronavirus pandemic, despite more human oversight.

Lawson ruled a lawsuit brought by attorneys from two Detroit law firms — the Sugar Law Center for Economic and Social Justice and Ernst Charara & Lovell — can proceed against FAST and CSG and two state officials. He dismissed allegations against three other state officials, and also removed one of the five plaintiffs from the lawsuit.

"It's good news," Paris said. "Following orders is not an excuse to violating constitutional rights."

The state has acknowledged that at least 20,000 Michigan residents — and possibly as many as 40,000 — were wrongly accused of fraud between 2013 and 2015 by a $47-million computer system, purchased from FAST, that the state operated without human supervision and with an error rate as high as 93%.

Those wrongly accused were subjected to highest-in-the-nation quadruple penalties and many were subjected to aggressive collection techniques such as wage garnishment and seizure of income tax refunds.

In the same case, Lawson earlier denied a request to certify the lawsuit as a class action. But he is soon expected to rule on a fresh class-action certification request that is more carefully built around plaintiffs who can show the state never properly notified them of the fraud allegations in a way that gave them a reasonable chance to defend themselves.

The state replaced its older system, which sent adequate notices and questions to jobless claimants suspected of fraud, with MiDAS, which "produced deficient notices and questionnaires with much less (if any) human oversight," Lawson wrote.

Though the Unemployment Insurance Agency was ultimately responsible, "the record contains sufficient evidence that FAST contributed to the alleged deprivation of the plaintiffs’ property interests without due process," Lawson said.

More:Michigan residents falsely accused of jobless fraud can sue, Supreme Court says

More:'Under attack': How criminals stole hundreds of millions in unemployment benefits

As for CSG, were it not for the consulting firm's "extensive research, work, advice, and ongoing management, the UIA would have been unable to develop MiDAS," the judge said.

Lawson said the suit can also proceed against Sharon Moffett-Massey, who headed the agency at the time of the false fraud findings, and Stephen Geskey, who held a variety of top jobs at the agency relevant to the MiDAS project.

A similar case involving MiDAS, in which the lead plaintiffs are Grant Bauserman and Teddy Broes, is now before the Michigan Supreme Court. A key difference is the Bauserman case only names state parties as defendants, not the private contractors.

Michigan’s Unemployment Insurance Agency has been flooded with jobless claims over the past year, as businesses around the state shut down under the state’s stay-home order and federal programs expanded eligibility.

Nearly 3.2 million unemployment claims have been created since the start of the pandemic a year ago, with nearly 400,000 claims in one week in early April.

In order to keep up with the influx of claims, the agency relaxed certain fraud prevention policies. What it didn’t know at the time was that an international crime ring was targeting state unemployment programs across the country, including Michigan.

It’s estimated that hundreds of millions of dollars were distributed to criminals as a result of these relaxed policies. In response, the agency reinstated those fraud prevention policies, now running claims through its fraud manager filter before they are paid out.

The result is that some legitimate claimants who are out of work have had their benefits help up, either waiting on their identity to be verified or falsely being accused of fraud.

Paris said the administration of President Joe Biden recently provided funding for the unemployment agency to hire 50 more officials, not to provide badly needed help paying out claims, but to root out suspected fraud.

"It's going to happen again," Paris said. Though the state says more human oversight is not in place, "we still have the same computer system."

Contact Paul Egan: 517-372-8660 or pegan@freepress.com. Follow him on Twitter @paulegan4. Read more on Michigan politics and sign up for our elections newsletter.

Become a subscriber.. The state of Michigan has reached a $20-million settlement in a class action lawsuit from unemployment claimants who were wrongly accused of fraud, resulting in the seizure of their property without the right to be heard.

The lawsuit, Bauserman v. Unemployment Insurance Agency, was filed in 2015 and argued that the state's automated jobless system, called MiDAS, falsely accused thousands of Michigan residents of fraud, resulting in the seizure of paychecks, income tax refunds and other assets.

"First, as counsel for the class action plaintiffs, we fought hard for seven years to vindicate the plaintiffs’ civil rights," Michael Pitt, counsel for the plaintiffs and founding member of the law firm Pitt, McGehee, Palmer, Bonanni and Rivers in Royal Oak, said in a news release. "Second, the attorney general and the state of Michigan demonstrated the will to come to the table and make this right, and by agreeing to this settlement, we believe they have done so."

The state has acknowledged that as many as 40,000 Michigan residents were wrongly accused of fraud but there's no estimate currently available as to how many claimants will be eligible for settlement payments, according to a spokesperson for the office of Michigan Attorney General Dana Nessel.

Earlier this year, the parties worked with a mediator to negotiate a resolution of the class action, a news release from the attorney general's office said. The mediator had access to detailed records and information to determine how many people were affected by the auto-adjudication system, how much of their money was seized and how much money had already been refunded by the state since the fraud auto-adjudication system was discontinued, the release said.

In April 2019, the Michigan Supreme Court ruled claimants who had money collected from them for the first time on or after March 9, 2015, could be included in the potential class.

In July, the state Supreme Court ruled that the thousands of Michigan residents wrongly accused of fraud could seek financial relief from the state.

"This settlement honors my commitment to ensure those falsely accused by their government receive fair compensation for their suffering," Nessel said in the news release.

The settlement money was appropriated last month in a supplemental funding bill. In the coming months, the parties will submit the settlement to the Court of Claims for approval.

Another class action lawsuit filed against Michigan's Unemployment Insurance Agency

Judge says Michigan's UIA must halt collection efforts for claimants with pending appeals

Separately, two lawsuits were filed this year against the state's jobless agency from claimants who received jobless benefits in the pandemic. The first, filed in the Michigan Court of Claims, said the agency violated the due process rights of Michigan residents by seizing tax returns and engaging in other collection efforts more than a year after benefits were paid and seeking recovery of overpayments that are required to be waived, among other allegations.

In August, a judge said the agency must halt collection activities for claimants who were told they were overpaid benefits in the pandemic and then appealed that decision.

A separate lawsuit was filed in U.S. District Court for the Eastern District of Michigan in August from several claimants who say they have not received all the benefits they were entitled to in the pandemic, if at all.

Contact Adrienne Roberts: amroberts@freepress.com.. A weekly newsletter—delivered every Saturday morning—that goes deep into our original reporting and the questions we put to big thinkers in the field. Browse the archive

Hello, friends,

This week, the Biden administration released its Blueprint for an AI Bill of Rights, a wish list of principles that “should guide the design, use, and deployment of automated systems.”

The principles state that Americans should:

Be protected from unsafe or ineffective systems.

Not face discrimination by algorithms.

Be protected from abusive data practices.

Be informed when an automated system is being used.

Be able to opt out from automated systems “where appropriate” and have access to a human decision-maker.

These principles, while laudable, do not say much about how we will get there. The White House did not propose legislation, the creation of a new agency, or any other holistic measure to regulate automated systems. It did issue a list of actions agencies are taking within their current mandates, such as an effort by the U.S. Department of Housing and Urban Development to establish standards for home valuation algorithms.

Meanwhile, there are people fighting for algorithmic accountability all over the world without any of these rights to back them up. So I thought this would be a good moment to highlight one of the most gruesome struggles out there—the story of the out-of-control automated system that was inflicted on the people of Michigan.

In 2013, Michigan laid off most of the humans who worked to identify fraudulent unemployment claims and instead installed an automated system to replace them. But it turns out the system was wrong the vast majority of the times that it flagged a claim as fraudulent. As a result, the state wrongfully seized millions of dollars from tens of thousands of people over the two years that the system was operating.

These are the kinds of unsafe, ineffective practices that the AI Bill of Rights seeks to prevent. But there has yet to be independent accountability for Michigan’s mistakes. In 2017, the state passed a law requiring the agency to make fraud determinations manually and said it would refund $20.8 million to residents who were wrongfully accused of fraud. But lawyers say that is not the full amount of refunds owed and doesn’t account for the damages suffered by people who lost jobs, homes, and filed for bankruptcy as a result of this system.

To understand the case of Michigan’s rogue fraud-detection system, I spoke to Jennifer Lord, a civil rights and employment attorney and partner at Pitt, McGehee, Palmer, Bonanni & Rivers in Michigan, who has been fighting for seven years to get that money back for those wrongfully accused. In July of this year, the Michigan Supreme Court finally ruled that workers falsely accused of unemployment fraud can sue the state for the violation of their constitutional rights. She and her colleagues are now proceeding to trial seeking money damages.

Our conversation, edited for clarity and brevity, is below.

Jennifer Lord

Angwin: Let’s start at the beginning. What is MiDAS and what happened in 2013 when Michigan implemented this technology?

Lord: In 2013, our office, which does employment and civil rights law, started getting a ton of calls from our current clients saying that the [Michigan] Unemployment Insurance Agency was billing them for some obscene amount, $10,000 or $25,000, because they allegedly committed fraud when they applied for their unemployment benefits.

We spoke with other civil rights and employment attorneys in the state of Michigan, and we all started digging, and we found a press release where the state of Michigan had nominated itself for this tech award for having rolled out this brand-new computer system, a $46 million system called MiDAS. MiDAS was tasked with deciding whether someone committed fraud in connection with their application for unemployment benefits. For example, if someone was applying for unemployment insurance but still had a job, that would be fraud, and that person would get in trouble. What happened here is that MiDAS was wrong 93 percent of the time, and in about 40,000 instances it incorrectly found fraud.

Angwin: Can you explain to me what exactly transpired for the people who were wrongfully accused?

Lord: Let’s say someone gets disqualified from unemployment benefits on the basis of fraud. Problem number one is that the determination letter they send you doesn’t say what the state thinks you did. There are no specifics, so you don’t know what you’re defending against. The person is supposed to know what they did wrong and then they have 30 days to write a handwritten protest and literally fax it back to the agency. Let’s say it’s received within 30 days, in a perfect world that will go to an administrative law judge who would then rule as to whether you’re entitled to the benefits or not.

The problem is that MiDAS wasn’t sending paper copies of these fraud determination notices. They were sending pings to an electronic portal. To complicate this, MiDAS did a six-year audit so people were being accused of having committed fraud in 2015 when they hadn’t collected benefits since 2010 or 2009. Returning to the problem of online notifications—people weren’t going on their portals anymore. People weren’t responding to these determinations within 30 days, and then they became final and nonappealable.

If MiDAS found that you committed fraud, you would owe back the benefits you already received and a quadruple penalty. The government was taking this money from people in two ways: the seizure of tax refunds and administrative garnishment. MiDAS interfaced with the state and federal treasury, so it would seize people’s tax refunds to pay down the debt.

Second, the state used something called an administrative garnishment. With a traditional garnishment, there’s a judicial process before wages are taken. With the state administrative garnishment, there’s no process. It’s automatic and not subject to judicial review. This means the first time someone would find out what was happening is when they found a new job and then 25 percent of their new paycheck was garnished, and the garnishment continues until the debt is paid.

Angwin: This sounds like it could be financially devastating. Can you talk about how this affected people?

Lord: We know for a fact that at least 11,000 families in the state of Michigan filed for bankruptcy. That’s a very real harm, and that family isn’t going to be able to get a mortgage, or it will be at a much higher rate, or if they need to lease a new car, they will have a ridiculous rate.

It’s also shown up on people’s background checks. One woman I met had completed her training to become a police officer in the city of Detroit and then failed the background check and didn’t get the job because MiDAS had flagged her as having committed fraud.

Angwin: You have been representing the people wronged by MiDAS for seven years now. Can you give us an overview of the allegations you brought against the state and what has been happening?

Lord: Our lawsuit, Bauserman v. Unemployment Insurance Agency, says that the state of Michigan violated the Michigan constitution when it seized people’s property without due process. For the first three and a half years, the legal issue was that in Michigan, if you’re suing the state, there are extra procedural rules with separate timelines. The state argued that we missed this very specific time frame—that we sued too late. This went all the way up to the Michigan Supreme Court, which ruled that we did not sue too late. That was issue number one. Issue number two, which surprisingly had never been clarified in Michigan, was the question of whether somebody can sue the state for money damages when the state violates the constitution. This ruling just happened in July and was in our favor.

Angwin: Now that you have this ruling from the Michigan Supreme Court, what are the next steps and how long will this take?

Lord: The short answer is we’ve got to start discovery like we were ready to do seven years ago. We also have to get this class certified; right now, we represent two individuals on behalf of a putative class of tens of thousands. One of the first things on the agenda will be to ensure that we officially and legally represent everyone with a claim.

Since it is a tort, we will argue for consequential damages, so at a minimum, money back plus interest, but there also has to be some recognition that this was a real harm. Even if you didn’t declare bankruptcy, the stress of being told you owe $40,000 or $20,000 shortly after you’re fired from your job—there’s not going to be a formula for that.

You never know with litigation, but there’s no inherent reason for this to take any longer than any other case. We need to start getting people under oath and hearing what they have to say and what they remember. I have a feeling that the agency is going to have known that this was a problem almost from the get-go, and the real interesting thing will be figuring out who knew what, when.

Angwin: What have you learned about holding this kind of AI system to account? What should be done in the future to prevent this type of event, and what might other lawyers want to look for when investigating?

Lord: I’ve been surprised how little this worries most people. I don’t know if it’s the fact that in Michigan this story was breaking at the same time as the Flint water crisis, so if you’re looking at two debacles, the one with the brown glass of water is very disturbing. MiDAS just didn’t seem to ignite the imagination like I thought it would. The state of Michigan was basically stealing tens of millions of dollars from its citizens!

How to fix it going forward? One idea is having an independent, knowledgeable, and interdisciplinary group vetting technology before any purchase is made. I can only imagine a skilled salesperson selling the agency on promises of efficiency, cost cutting, and profit increases. What politician is going to say no to that?

I think the problem is that there are some jobs computers and algorithms can’t and shouldn’t do, such as determining whether or not someone committed fraud. It’s wrong that we asked the computer to do this all by itself, with no human intervention. It’s one thing if a computer flags it and then a human takes a deeper look. That’s not what happened because at the same time that the Unemployment Insurance Agency purchased MiDAS, it laid off a third of its workforce, almost its entire fraud detection unit.

The algorithm is alleging that these 40,000 people intentionally defrauded the unemployment insurance agency. I think a judge or a jury should decide the question of intent. When assessing credibility, it should not be done by an algorithm. I don’t think that a computer looking at a series of numbers is capable of determining intent.

As always, thanks for reading.

Best,

Julia Angwin

The Markup

(Additional Hello World research by Eve Zelickson.). Ed White

Thousands of people who were wrongly accused of fraud when seeking unemployment benefits can seek financial relief from the state, the Michigan Supreme Court ruled Tuesday, breaking new ground when someone claims their constitutional rights have been violated by the government.

"The state is prohibited from violating the rights the Constitution guarantees. If it does so, it is liable for the harm it causes," Justice Megan Cavanagh wrote in a 4-3 opinion.

The three dissenters were justices nominated by the Republican Party.

An automated computer system used during the administration of Gov. Rick Snyder was a disaster over a two-year period. People were accused of cheating to get jobless aid. They were forced to repay money, along with substantial penalties, before the Unemployment Insurance Agency finally acknowledged widespread errors that affected more than 40,000 people.

Although refunds were dispersed, the state still is being sued by people who argue that their due-process rights — a right to be heard — were violated while they tried to untangle themselves from the mess.

More:Former Michigan claims examiner sentenced to prison in unemployment insurance fraud scheme

More:Michigan Unemployment agency says claimants made big mistake. Claimants say UIA is lying

Some victims had to hire lawyers to fight false fraud findings. Others filed for bankruptcy, lost wages, suffered poor credit ratings or had trouble finding a job and housing.

The state Supreme Court said it has the power to step in, especially when the Legislature hasn't come up with a law that offers a remedy to people whose rights have been violated by the state.

"If our Constitution is to function, then the fundamental rights it guarantees must be enforceable. Our basic rights cannot be mere ethereal hopes if they are to serve as the bedrock of our government," Cavanagh wrote.

In dissent, Justice David Viviano said the majority opinion was a "thunderbolt" with "stunning sweep."

"It represents a gross overreach given that the judicial branch has now seized legislative power to fashion remedies for all manner of constitutional violations. ... A deluge of cases and a swelling of taxpayer liability will surely ensue," said Viviano, who was joined by Justice Brian Zahra.

Viviano said it's the Legislature's job to approve a solution if there should be one.

Follow Ed White at http://twitter.com/edwritez

► Stay connected and stay informed. Subscribe to the Detroit Free Press today.. I n 2014, Carmelita Colvin was living just north of Detroit and taking classes at a local college, when she received a letter from the Michigan Unemployment Insurance Agency. The letter stated that she’d committed unemployment fraud and that she owed over $13,000 in repayment of benefits and fines.

Colvin’s reaction, she recalled, was: “This has got to be impossible. I just don’t believe it.” She’d collected unemployment benefits in 2013 after the cleaning company she worked for let her go, but she’d been eligible. She couldn’t figure out why she was being charged with fraud.

What Colvin didn’t realize at the time was that thousands of others across the state were experiencing the same thing. The agency had introduced a new computer program — the Michigan Integrated Data Automated System, or MiDAS — to not only detect fraud, but to automatically charge people with misrepresentation and demand repayment. While the agency still hasn’t publicly released details about the algorithm, class actions lawsuits allege that the system searched unemployment datasets and used flawed assumptions to flag people for fraud, such as deferring to an employer who said an employee had quit — and was thus ineligible for benefits — when they were really laid off.

Carmelita Colvin, who obtained two degrees in criminal justice, only to be denied a job with a county sheriff’s office because of an erroneous fraud charge and her then outstanding debt to the state. Visual: Courtesy of Carmelita Colvin

Over a two-year period, the agency charged more than 40,000 people, billing them about five times the original benefits, which included repayment and fines of 400 percent plus interest. Amid later outcry, the agency later ran a partial audit and admitted that 93 percent of the changes had been erroneous — yet the agency had already taken millions from people and failed to repay them for years. So far, the agency has made no public statements explaining what, exactly, went wrong. (Lynda Robinson, an agency representative, declined Undark’s interview request by email, writing: “We cannot comment due to pending litigation.”)

Government use of automated systems is on the rise in many domains, from criminal justice and health care to teacher evaluation to job recruitment. But the people who use the algorithms don’t always understand how they work, and the functions are even murkier to the public.

“These types of tools can be used to inform human judgment, but they should never be replacing human beings,” said Frank Pasquale, a professor of law at the University of Maryland who studies accountability in the use of these opaque algorithms. One of the big dangers, he said, is that the systems fail to give people due process rights. If an algorithm is “used by the government, there should be full transparency,” he added — both in how the software works and the data it uses — “to the people who are affected, at the very least.”

In cases like Michigan’s, flawed automated systems punish people whom the agencies are supposed to help, said Michele Gilman, a University of Baltimore law professor who directs a legal clinic that represents clients with public benefits cases. She pointed to other examples, including algorithms adopted in states like Arkansas and Idaho that agencies used to cut Medicaid benefits, sometimes erroneously. And the issues extend beyond the United States: In 2019, a Dutch court found that an algorithm used to detect welfare fraud violated human rights and ordered the government to stop using it.

In Michigan, while the agency says it repaid $21 million, attorneys in the class-action lawsuits argue that this doesn’t account for all of the damages. People like Colvin suffered long-term harm — many came out with damaged credit and lost job opportunities and homes. More than a thousand filed for bankruptcy.

Many came out with damaged credit and lost job opportunities and homes. More than a thousand filed for bankruptcy.

Nearly half the states in the U.S. have modernized the software and information technology infrastructure for their unemployment insurance systems. In many cases, these updates are crucial to keep the systems running smoothly and many actually help claimants more easily file for benefits. But this is not always the case — in Florida, for example, the new system adopted about five years ago made it much harder for people to apply. Gilman and other researchers that Undark spoke with are also concerned that in the coming years, states may adopt algorithms that lead to similar problems as in Michigan — particularly if they cut human review of fraud charges, in violation of federal due process requirements. With an unprecedented surge in unemployment claims during the Covid-19 pandemic — more than 40 million Americans have filed since mid-March — the problems could be amplified.

The automated system in Michigan is “a case study in all the ways an algorithm can go wrong,” Gilman added. “The citizens shouldn’t be the guinea pigs in testing whether the systems work.”

Michigan’s automated system popped up just after the Great Recession of 2007 to 2009, when the auto and other manufacturing industries were hit hard and workers applied for unemployment benefits at high rates. Such benefits are intended to help those who have lost a job through no fault of their own, and are funded by federal and state payroll taxes. Benefits typically last 26 weeks, though the federal government covers extended benefits during economic downturns, including today’s Covid-19 crisis.

In March 2011, Rick Snyder, the newly elected Republican governor of Michigan, signed a bill shortening state unemployment benefits from 26 to 20 weeks. The bill also allocated funding for software to detect unemployment fraud.

The state’s unemployment agency hired three private companies to develop MiDAS, as well as additional software. The new system was intended to replace one that was 30 years old and to consolidate data and functions that were previously spread over several platforms, according to the agency’s 2013 self-nomination for an award with the National Association of State Chief Information Officers. The contract to build the system was for more than $47 million.

At the same time as the update, the agency also laid off hundreds of employees who had previously investigated fraud claims.

While MiDAS’s exact process isn’t public, interviews with attorneys and court documents from class action lawsuits provide some context. Part of the system searched records of employers and claimants in its database, then flagged people for potential unemployment fraud. Next, MiDAS sent questionnaires to an electronic mailbox on the benefits website that recipients may not have had reason to monitor, gave them 10 days to respond, and then sent a letter informing them they had been charged with fraud. After a 30-day appeal period, the system began garnishing wages and tax refunds. The agency later acknowledged that in the majority of the cases between 2013 and 2015, the system ran from start to finish without any human review.

“The citizens shouldn’t be the guinea pigs in testing whether the systems work.”

Using automated decision-making systems to detect fraud is a problem because the stakes are so high, said Julia Simon-Mishel, an attorney at Philadelphia Legal Assistance who has served on the advisory committee for Pennsylvania’s unemployment compensation benefit modernization for the past two years. The automated systems don’t always gather key information or allow for “a back and forth that is required by federal guidelines, in terms of the conversations that states need to have with an employer and a worker,” she said.

“If you’re just using analytics to automatically flag fraud without anything else, you have a garbage in, garbage out problem,” she added. “Who knows whether the data you’re using to build your predictive analytics is correct?”

Some of the bad data comes from simple, unintentional application errors. Public benefit applications are often complicated, said Gilman, who called them “the tax code for poor people.” Because of this complexity, the majority of overpayments are due to either the employee or employer making a mistake on a form, Gilman said. But, she added, “a mistake is not intentional fraud.”

In October of 2013, MiDAS began to flag people for fraud. Soon after, lawyers across the state were deluged with calls from people who were bewildered over their alleged fraud charges. Those who couldn’t afford a lawyer faced another hurdle: At the time, Michigan did not extend the right to free legal representation to those charged unemployment fraud. (The state extended this right through legislation in 2017.) Some turned to nonprofits, including the Unemployment Insurance Clinic at the University of Michigan Law School (re-named the Workers’ Rights Clinic in 2019) and the Maurice and Jane Sugar Law Center for Economic and Social Justice, a nonprofit legal advocacy organization in Detroit.

Anthony Paris, an attorney at the Sugar Law Center, told Undark that he and his colleagues assisted hundreds of clients who were accused of fraud between 2013 and 2015 — including Colvin. Over time, the legal team pieced together an understanding of the source of the surge of fraud charges: The new computer system had searched the unemployment database going back six years and flagged people for fraud based on error-prone rules.

One rule led to the agency to incorrectly accuse people of working while claiming unemployment benefits. Here, the system assumed, as described in a federal class action lawsuit filed in 2015 by Sugar Law Center and others, that the reported income from a part of the year was actually earned over a longer period. For example, a plaintiff named Kevin Grifka had reported $9,407.13 in earnings in 2015 before he was laid off in early February of that year and claimed unemployment benefits. The agency later claimed that he had made $723.62 each week throughout the full first quarter of the year — including the period when he said he was unemployed. As the lawsuit describes, this was based on dividing his income before being laid off by the 13 weeks of the whole quarter, and the same erroneous calculation was used to charge other plaintiffs.

Related The Real AI Threat Is Online

The system also automatically accused people of intentional fraud when their story didn’t match that of their employer. Rather than assign a staff member to investigate discrepancies between what the employer and employee reported, Paris said, the system was programmed “to automatically assume that the employer was right.”

This is what led to Colvin’s fraud charge, according to court documents reviewed by Undark. Colvin’s employer reported that she had quit. Colvin said that her employer had told her she was suspended from work due to an issue reported at a house that was cleaned by her and another employee. Colvin never heard back and assumed she was laid off. Late in 2019, when Paris represented Colvin at a court hearing, her employer was called in to testify. The employer acknowledged she’d based her assumption that Colvin had quit on second-hand accounts from two other workers.

Colvin’s case highlighted another problem with MiDAS: It was designed with little attention to the right to due process. It’s a common problem in automated systems, said Jason Schultz, a law professor at New York University and a legal and policy researcher for the school’s AI Now Institute. “Even though the systems claim to notify people, they typically only notify them of the end result,” he added. “They don’t usually give them any information about how to actually understand what happened, why a decision was made, what the evidence is against them, what the rationale was, what the criteria were, and how to fix things if they’re wrong.”

Although MiDAS had several steps for notification, the forms were confusing, leading some innocent people to self-incriminate, according to Steve Gray — then director of the University of Michigan’s clinic — who described the problem in a co-authored letter to the Department of Labor. Moreover, many people never received the messages. The first one, the questionnaire, appeared in an online account that most people only checked when they were receiving benefits. And by the time the second notification by letter came around, many people had moved to a new address, according to a 2016 report from Michigan’s auditor general.

Brian Russell, an electrician from Zealand, Michigan, only learned about his alleged fraud after the state took $11,000 from his 2015 tax refund. He visited a state unemployment agency office and was astounded to learn that they would take even more: “They were charging me $22,000, and I had no idea what was going on.”

An Oversight Committee hearing video showing Brian Russell (left), who realized he’d been hit with an alleged fraud charge after Michigan took $11,000 from his 2015 tax refund.

Russell said he tried everything he could think of to figure out why he was being charged — he visited the nearest unemployment office and called the agency “probably hundreds of times,” but the phone system was overloaded. He’d wait for hours on hold. (The state auditor’s report found that of the over 260,000 calls made to the line during business hours in a one month period in 2014, about 90 percent went unanswered.) Once Russell finally got a person on the line, he said he was told he’d missed the 30-day window to appeal.

Russell finally got representation from the University of Michigan’s law clinic, which appealed his case to an administrative law judge. A judge dismissed Russell’s charge and the agency refunded most of the money. (Russell said he is still owed about $1,500.) But in the meantime, he said he had to declare bankruptcy, which hit his credit score. And because he didn’t have the money for basic needs, he had to forgo some of his diabetes treatments and move into a friend’s basement.

While Michigan is a striking case of an automated system going wrong, it’s not the only area in which governments are using artificial intelligence systems for decision-making. Such systems are used in criminal justice, policing, child protective services, the allocation health care benefits, teacher evaluations, and more. In many cases, governments are hiring private companies to build these systems, said Pasquale, and since the companies want to protect their intellectual property, they sometimes hide details of how the products work. “The trade secret protection is a real problem, because you can’t even understand what the problems are,” he said.

Over the past few years, policymakers, academics, and advocates — including at organizations such as the AI Now Institute at NYU and Georgetown Law’s Center on Privacy and Technology — have explored different ways that governments could build better, more accountable automated systems.

Agencies also need to understand the limitations of a particular system before they implement it, said Julia Stoyanovich, an assistant professor of computer science at NYU. “My belief is that folks in government just think that AI is magic somehow,” she said, which can lead to big problems when the automated systems don’t run as smoothly in reality. Schultz agreed, adding that when government employees don’t have the background or resources to evaluate claims made by private companies “they’ll just get sold snake oil.”

Advocates and researchers are also pushing for governments to solicit guidance before implementing a new system, both from experts and from people who will be targeted by the new tools. In 2018, the AI Now Institute published a framework for this process, which Schultz co-authored. The idea is that governments need to think through steps for algorithms before they deploy them, Schultz said, asking questions like: “Does this system actually do what it says it’s going to do? Is it going to impact society in a way that actually helps and doesn’t hurt?” The authors also suggested that the assessment should be published and open for public comment.

Agencies need to understand the limitations of a particular system before they implement it, one expert said.

Another model for accountability is designating an oversight body to audit algorithms. In early 2020, attorneys in the Michigan class action lawsuits called for the creation of a task force to oversee all algorithms and automated systems implemented by the state government. Other states and cities have formed similar task forces. Stoyanovich, who served on one formed in New York City, said she thought it was an important step. But it was also widely criticized — researchers from the AI Now Institute and other organizations, for instance, critiqued the effort for failing to adequately involve the wider community. And while oversight bodies could be important, Pasquale said, they need to have “real teeth” in order to yield meaningful enforcement.

But one of the biggest questions is whether and when to use algorithms to begin with — particularly for tools that could quickly erode privacy and civil liberties such as facial recognition. “I don’t think any government has to adopt any of these systems,” Schultz said. “I think spending millions of dollars on an unproven system that has no accountability and no way of ensuring it works is a really, really bad idea when it’s not required.”

In 2016 — in the midst of a flood of negative media attention — Michigan congressman Sander Levin pushed the agency to conduct an internal audit of the approximately 60,000 fraud charges in the prior two years. The agency responded with a partial audit, reviewing 22,000 of the MiDAS fraud charges and determining that nearly all were wrong. (The agency also reviewed another set of fraud charges made with some level of human review; while the error rate was still high at 44 percent, the automated system had more than twice that rate.)

By 2017, as part of a settlement of a class action lawsuit, the agency agreed it wouldn’t use the automated system without human review (and clarified that it actually stopped the practice in late 2015). The agency also agreed to review and overturn the remaining erroneous charges that it had issued between 2013 and 2015, later reporting that it had reversed about two-thirds of the fraud determinations and had repaid $21 million.

Also in 2017, state legislators passed a law to prevent such a disaster from happening again through improvements in fraud charge notifications and reduced fines. And in 2019, in a move that several attorneys described to Undark as a step in a positive direction, Michigan Gov. Gretchen Whitmer appointed Gray, formerly the head of the unemployment insurance law clinic at the University of Michigan Law School, as director of the agency.

In available court documents, which include depositions of agency staff and the three companies, none of the people involved in making or approving the automated system admit responsibility (as plaintiffs’ lawyers confirmed). While the ongoing cases should eventually reveal more details — including discovery involving more than a million documents such as internal agency emails — the suit will take a long time to work its way through the courts, Paris said.

Get Our Newsletter Sent Weekly Email *

Comments This field is for validation purposes and should be left unchanged. Δ

Meanwhile, for some people who were falsely accused of fraud, the struggle continues. In addition to the class action lawsuits, in March 2020, the current director of the University of Michigan Law School’s Workers’ Rights Clinic testified to the state Senate Oversight Committee that they believe close to 20,000 of those charged by MiDAS are still being actively pursued and having their wages garnished.

For Colvin, it wasn’t until early 2020, nearly six years after she had been charged, that an administrative judge finally dismissed her case. In the middle of that stretch, in 2017, Colvin completed her bachelor’s degree in criminal justice, adding to a previous associate’s degree in forensic photography, and applied for a job with a county sheriff’s office. She soon got a call letting her know that she wouldn’t be hired because of the fraud charge and her outstanding debt to the state.

Today, Colvin said she is working as a security guard to support herself and her daughter. She is 32, and wonders if it was a waste of time to get two degrees in criminal justice.

“I can’t get the job I wanted,” she said, “because they suggested that I was a criminal.”. Summary

This submission examines the human rights implications of Artificial Intelligence (AI) [1] and other data-driven technologies in welfare benefits programs, such as cash and food assistance programs. Through a series of case studies, this submission explains how States delegate key welfare functions, such as determinations of eligibility and benefits levels, to automated decision-making models, some of which rely on data mining, machine learning and other processes or technologies typically associated with the field of AI. It also assesses how automated decision-making interferes with the rights to privacy and social security, and the obligations of States to guarantee the exercise of these rights without discrimination and undue private interference.

Overview of Applicable International Human Rights Law

The right to privacy

Article 17 of the International Covenant on Civil and Political Rights (ICCPR), which derives from Article 12 of the Universal Declaration of Human Rights (UDHR), establishes the right to “the protection of the law” against “arbitrary or unlawful interference” with one’s “privacy, family, home or correspondence.”

The Human Rights Committee has concluded that the prohibition against “arbitrary or unlawful interference” establishes a two-part test. First, interferences with privacy can take place only “in cases envisaged by the law.”[2] Under this requirement, States must “specify in detail” in relevant legislation “the precise circumstances in which such interferences may be permitted,” and ensure that decisions “to make use of such authorized interference must be made only by the authority designated under the law, and on a case-by-case basis.”[3] Second, for interferences to be non-arbitrary, the Committee has concluded that they must be “proportionate to the end sought, and ... necessary in the circumstances of any given case.”[4]

The right to social security

Article 9 of the International Covenant on Economic, Social and Cultural Rights (ICESCR) and Article 22 of the UDHR recognize the right of everyone to “social security, including social insurance.” The Committee on Economic, Social and Cultural Rights (CESCR) has concluded that this right establishes the obligation of States to ensure that eligibility criteria for social security benefits are “reasonable, proportionate and transparent.”[5] Furthermore, the “withdrawal, reduction or suspension of benefits should be “based on grounds that are reasonable, subject to due process, and provided for in national law.”[6]

Access to information is also a precondition of the enjoyment of the right to social security. The CESCR has found that beneficiaries of social security schemes “must be able to participate in the administration of the social security system.”[7] Accordingly, the system should “ensure the right of individuals and organizations to seek, receive and impart information on all social security entitlements in a clear and transparent manner.”[8]

Non-Discrimination Obligations

Article 2(1) of the ICCPR and Article 2(2) the ICESCR require States to guarantee Covenant rights without discrimination of any kind based on “race, color, sex, language, religion, political or other opinion, national or social origin, property, birth or other status.” Article 26 of the ICCPR additionally guarantees the right “to all persons equal and effective protection against discrimination on any ground.” The Human Rights Committee has found that Article 26 establishes an “autonomous right” that “prohibits discrimination in law or in fact in any field regulated and protected by public authorities.”[9]

In the context of social security, the CESCR has found that States should ensure that social security schemes “do not discriminate in law or in fact.”[10] States should also “pay special attention” to those that disproportionately experience difficulties in accessing social security, such as women, people with disabilities, minorities and “casual” or “seasonal” workers.[11]

Obligation to Protect Against Third-Party Interference

States have a duty to protect individuals from undue third-party interferences with their rights to privacy and social security. The Human Rights Committee has concluded that Article 2(1) of the ICCPR, which establishes the State’s duty to “ensure” the right to privacy and other Covenant rights, imposes a positive obligation to protect individuals against “acts committed by private persons or entities that would impair the enjoyment of [these] rights.”[12] This duty requires the adoption of “appropriate measures” or “due diligence to prevent, punish, investigate or redress the harm caused by ... private persons or entities.”[13]

The CESCR has categorized State obligations under the ICESCR as obligations to respect, protect and fulfill Covenant rights.[14] The obligation to protect the right to social security requires States to prevent corporations and “agents acting under their authority” from interfering with that right.[15] In the context of social security schemes that are “operated or controlled by third parties,” States “retain the responsibility of administering the national social security system and ensuring that private actors do not compromise equal, adequate, affordable, and accessible social security.”[16] To prevent abuses, “an effective regulatory system must be established which includes framework legislation, independent monitoring, genuine public participation and imposition of penalties for non-compliance.”[17]

Human Rights Implications of Using Technology in Cash and Food Assistance Programs

States rely on AI and related technologies to automate two critical stages of the welfare distribution process: the verification of claimants’ identity, and the assessment of eligibility and benefits levels. Throughout the entire welfare delivery cycle, States also employ these technologies to investigate, adjudicate and impose penalties for fraud.

Identity Verification

Aadhaar (India)

The use of AI to verify the identity of welfare recipients may be part of a broader push to establish national digital identity frameworks that manage individuals’ access to government entitlements through a single, government issued identity. In 2009, India launched Aadhaar, a digital identity framework that assigns every citizen a unique twelve-digit identification number linked to the individual’s biometric and demographic data. Under the Aadhaar Act of 2016, beneficiaries of various government welfare programs such as the Public Distribution System (PDS), which provides subsidized food grains to millions of households, are required to register and use Aadhaar to access their entitlements.[18]

In 2018, the Indian Supreme Court upheld the government’s authority to mandate Aadhaar as a precondition for accessing food rations and other welfare benefits.[19] However, the Court ruled that certain provisions of the Aadhaar Act were unconstitutional, and also barred the private sector from seeking access to Aadhaar data.[20] In February 2019, the government passed amendments to the Aadhaar Act that restored such access and bypassed the Court’s ruling.[21]

Concerns

Human Rights Watch has found that eligible families have been denied access to subsidized food grains and other benefits because they did not have an Aadhaar number, had not linked it to their ration cards or experienced failures in authenticating their fingerprints.[22] Authentication failures disproportionately affect manual laborers, older persons and other individuals with worn fingerprints.[23] Since the Aadhaar machines installed in food distribution outlets require an internet connection, poor connectivity in rural areas has also led to disruptions in food distribution schedules.[24] Local activists have found that Aadhaar-related denials of food rations have led some to starve to death.[25]

Aadhaar also imposes invasive biometric identification and data collection requirements as conditions for accessing subsidized food grains and other essential public services. These requirements have created the world’s largest database of biometric identity information, escalating the risk of unnecessary and disproportionate surveillance.[26] To mitigate this risk, the Supreme Court imposed several restrictions, including the requirement of judicial approval for law enforcement access to Aadhaar data, and a six-month limit on the retention of authentication records and transaction logs.[27] However, these changes do not address the scope of biometric data and personal information collected under the program. Human Rights Watch has also raised concern about the multiple data breaches associated with Aadhaar since its implementation.[28]

These interferences with privacy disproportionately affect minorities: for example, local activists fear that transgender individuals are at greater risk of discrimination and persecution when they are forced to disclose their gender identity to the government, or if such information is leaked to the public.[29] These risks also raise the possibility that transgender individuals will be deterred from seeking access to essential public services linked to Aadhaar.

Knowledge Based Authentication System (California, United States)

Countries without national ID schemes also rely on automated decision-making to verify the identity of welfare claimants by comparing multiple sources of identity-related information drawn from a wide range of government and private databases. In the United States, the California state legislature in 2017 amended the Welfare and Institutions Code to replace fingerprint imaging with an “automated, nonbiometric” method for verifying the identity of applicants to the CalWORKs program, which provides cash assistance to needy families.[30] The Department of Social Services (DSS) selected US-based private company Pondera Solutions[31] to conduct a pilot of a cloud-based identity verification system known as the Knowledge Based Authentication system (KBA).[32] The pilot was conducted in six counties.[33]

KBA checks a CalWORKs application against “over 10,000 public sources” of data from “dozens of categories and hundreds of jurisdictions,” including data from credit bureaus, government agencies and “utility and telephone companies.”[34] This initial assessment is “designed to verify that the identity provided to the program is legitimate.”[35] It also generates a multiple-choice quiz for applicants that “seeks to ensure that the applicant is in fact the individual that they are representing themselves to be.”[36] Applicants are assigned a fraud risk code based on the system’s initial assessment and their answers to the quiz.[37]

At the conclusion of the pilot in October 2017, DSS announced that it was intending to roll out KBA for phone or online benefits applications by the summer of 2018.[38] It is unclear, however, whether it has adhered to this timeline.

Concerns

In its report on the results of the pilot, DSS did not explain how the KBA analyzes the wide variety of data sources at its disposal to verify an applicant’s identity and generate quiz questions. Although KBA standardizes the spelling of addresses “to avoid misspellings and other common mistakes,” it is unclear how the system responds to other errors in the data it is provided, such as discrepancies in dates, phone numbers and demographic details.[39] The report also acknowledges KBA’s potential to generate “false positives,” but does not provide information about DSS’s plans to prevent or mitigate such errors.[40]

This lack of transparency makes it difficult for welfare claimants and the broader public to assess the reliability, accuracy or fairness of KBA’s risk assessment calculus. If incorrect information is associated with claimants and answers to the quiz questions are wrongly marked as errors, it will be difficult for them to identify the source of the error and hold the relevant authorities accountable. In addition, KBA’s analysis of large datasets containing a wide range of sensitive and personal information raises questions about how the system safeguards applicants’ privacy.

The Coalition of California Welfare Rights Organizations has also raised concern that KBA’s multiple-choice quiz creates additional obstacles for marginalized populations. Families that have been homeless for a long time may be unable to answer questions such as “How long have you lived in your current residence?” or “Which of the following streets have you ever lived or used as your address?”[41] Furthermore, questions regarding residential and relationship history in the United States assume that respondents have longstanding community ties, and are ill-suited to the needs and concerns of newly arrived immigrant families.

Assessment of Eligibility and Benefits Levels

Ontario Works (Ontario, Canada)

Governments are also replacing or supplementing case workers’ assessments of eligibility and benefits levels with predictive analytics and other AI-based assessment tools. Since November 2014, Ontario Works, the financial assistance program of the Canadian province of Ontario, has been relying on the Social Assistance Management System (SAMS) to automatically generate decisions on eligibility for cash transfers and other benefits. Decisions are generated based on data that frontline workers collect from applicants and recipients and subsequently “fit into narrow-drop down menu categories.”[42]

SAMS is based on Cúram, a customizable off-the-shelf software sold by IBM as a platform for “complete intake, eligibility determination and benefit calculation for social programs.”[43] Latest versions of the software are also equipped with functions to monitor impermissible instances of “concurrent eligibility” in food and cash assistance programs, potentially indicating the system’s ability to perform both benefits assessments and fraud detection.[44] Cúram is also used to administer welfare programs in Alberta, North Carolina, Hamburg, Queensland and New Zealand.[45]

A 2015 audit of SAMS conducted by the state’s Auditor General found that SAMS suffered from “serious defects and was not fully functional,”[46] leading to potential underpayments of benefits totaling $51 million CAD.[47] In one case, SAMS erroneously deducted $32 from a client’s total benefit payments each month after it incorrectly determined that the client had been previously overpaid.[48]

The Auditor General also found that SAMS “automatically generated” letters to beneficiaries with “incorrect information” that caused “stress and confusion.”[49] For example, a letter sent to two beneficiaries, whom owed $1,328 in overpayments, accused them of owing $8,736.[50] Another letter notified a beneficiary that their benefits would be withdrawn because they no longer lived in Ontario, but caseworkers found that the beneficiary “had never left Ontario.”[51]

Universal Credit (United Kingdom)

The Special Rapporteur on extreme poverty and human rights has observed that the Universal Credit (UC), the UK’s welfare benefits program, “is only possible because of the automated calculation of benefits.”[52] The Real Time Information (RTI) system calculates UC payments based on earnings information reported by employers to Her Majesty's Revenue and Customs (HMRC), the country’s tax authority.[53]

It appears that RTI’s calculations are unable to correct for late, inaccurate or missing reports, and this can lead to delays and errors in UC payments.[54] In the 2016/2017 fiscal year, 5.7% of 590m UC payments were marred by late reporting.[55] To address RTI’s inability to take into account reporting errors, HMRC and the Department of Work and Pensions, which oversees UC, have established a special joint initiative known as the Late, Missing and Incorrect RTI Project.[56]

Concerns

The failures of automated decision-making in Ontario Works and UC indicate that governments have overestimated the technology’s capacity to conduct complex and context-sensitive assessments of eligibility and benefits levels. Benefits calculators are only as accurate as the data provided to them: unlike case workers, these systems are unable to investigate the reasons for data inaccuracies and other discrepancies and make necessary adjustments on a case-by-case basis.

Despite these limitations, both programs fail to supplement automated decision-making with human review that ensures benefits changes are reasonable and in accordance with due process and domestic law requirements. In the Ontario Works program, Professor Jennifer Raso of the University of Toronto Law School has found that the design of SAMS “obstructs frontline workers from challenging the substance of its decisions.”[57] For example, SAMS does not permit frontline workers to challenge its assessments of whether Ontario Works recipients with a history of living in the same household are dependent on each other – a common ground for reducing the value of benefits.[58]

In the UK, service workers have not been provided with training that enables them to effectively troubleshoot RTI and other IT errors that may lead to the withdrawal, reduction or suspension of benefits. According to welfare researchers from the University of Birmingham and the University of Leeds, former staff of Jobcentre Plus, an agency which administers UC’s benefits for jobseekers, “described being permanently on the ‘back foot’, in that digital services were rolled out without staff being given the relevant training.”[59] A former UC call center worker in Grimsby also told The Guardian that there was “massive variation” in staff’s understanding of the UC policies and systems, leading to contradictory responses to the same query.[60]

Detection, Investigation and Punishment of Welfare Fraud

Systeem Risico Inventarisatie (The Netherlands)

Governments increasingly rely on automated fraud detection systems to detect and flag risks of welfare fraud. In the Netherlands, the Ministry of Social Affairs and Employment operates the Systeem Risico Inventarisatie or System Risk Indication (SyRI), which is used by several municipal governments to detect benefits fraud. SyRI flags individuals as potential fraud risks through an algorithmic risk assessment tool that draws on multiple sources of data, including tax returns.[61] However, the government has offered few details on the specific types of data used and the criteria for determining risk. It has rejected calls for transparency about how the algorithm works, claiming that disclosing such information would reduce its effectiveness in detecting fraud.[62] It has also not explained the circumstances under which case workers or fraud investigators may deviate from these risk assessments, if at all.

Online Compliance Intervention (Australia)

Several governments do not only automate assessments of welfare fraud, but also the imposition of penalties such as fines or the reduction or withdrawal of benefits. In July 2016, Australia’s Department of Human Services (DHS) launched Online Compliance Intervention (OCI), a fully automated income data verification system that generates debt notices based on differences between fortnightly income figures reported by welfare beneficiaries and their employers.[63] A Parliamentary inquiry conducted by the Senate’s Community Affairs Reference Committee found that OCI’s income calculation formula is not programmed to take into account fluctuations in a beneficiary’s income, leading to “inaccurate calculations of debt,” particularly for casual or seasonal workers with irregular incomes.[64] OCI is also unable to make adjustments for employer error.[65]

DHS does not require manual review of the OCI’s findings, instead placing the onus on beneficiaries to submit evidence rebutting debt notices.[66] However, affected beneficiaries and their representatives testified before the Senate that debt notices either provided inadequate information or were too complicated to understand, making them difficult to challenge.[67] Some complained that they had to submit Freedom of Information requests to compel DHS to release information about how their debts were calculated.[68]

The Senate Committee has urged DHS to put OCI “on hold” until these issues are resolved,[69] but the Department has rejected this recommendation and claimed that its implementation has gone “quite well.”[70]

Michigan Integrated Data Automated System (Michigan, United States)

In October 2013, Michigan’s Unemployment Insurance Agency (UIA) launched the Michigan Integrated Data Automated System (MiDAS) to adjudicate and impose penalties for unemployment benefits fraud. Between October 2013 and August 2015, MiDAS was programmed to automatically treat differences between income figures reported by beneficiaries and their employers as evidence of fraud.[71] The system was not capable of investigating whether there are legitimate reasons for these discrepancies, such as employer error or pay disputes.[72] Like OCI, MiDAS was also unable to determine whether these discrepancies are attributable to fluctuations in a beneficiary’s income.[73]

Based on its initial assessments, MiDAS sent beneficiaries suspected of fraud online multiple-choice questionnaires asking whether they are “intentionally provid[ing] false information to obtain benefits you were not entitle[d] to receive,” and “[w]hy ... you believe you were entitled to benefits.”[74] Failure to respond in ten days, or a response that MiDAS deemed unsatisfactory, would automatically trigger conclusive determinations of fraud.[75] Based on these determinations, MiDAS would terminate the benefits of affected beneficiaries and initiate proceedings to seize their tax refunds or garnish their wages.[76]

UIA subsequently found that, between October 2013 and August 2015, about 44,000 of the 62,784 determinations of fraud that MiDAS generated were in error.[77] In a lawsuit that a group of beneficiaries filed against UIA, the U.S. Federal Court of Appeals for the region concluded that MiDAS “did not allow for a fact-based adjudication or give the claimant the opportunity to present evidence to prove that he or she did not engage in disqualifying conduct.”[78]

Despite these failures, UIA continues to operate MiDAS.[79] It has committed to additional data analysis to detect benefits payments needing “further review” and to enhance the appeals process.[80] However, it is unclear whether UIA has made any changes to the underlying data matching algorithm or incorporated meaningful human review into the system’s fraud detection functions.

Automated Verification of Job Activity Reports (Sweden)

The Swedish Employment Service (Arbetsförmedlingen) relies on automated decision-making to verify whether recipients of unemployment benefits have complied with job-seeking and other workfare obligations, and issue warnings, withhold payments and enforce other sanctions based on these assessments.[81] At the end of 2018, Arbetsförmedlingen discovered a 10 – 15% error rate in the automated verification of beneficiaries’ job activity reports, potentially leading to 70,000 erroneous decisions to withhold benefit payments.[82] These errors have forced Arbetsförmedlingen to manually screen all job activity reports until the system can be repaired.[83]

Concerns

These cases reinforce the need for appropriate human review that corroborates fraud findings generated by automated systems, as well as clear, transparent and accessible appeals mechanisms that enable beneficiaries to meaningfully challenge these findings. Without these safeguards, limitations or errors in automated decision-making potentially lead to mass violations of the right to social security. The Swedish and Michigan examples illustrate that the automation of fraud determinations at scale replicates errors in data processing and analysis across the entire system, leading to incorrect benefits changes and penalties that affect thousands of beneficiaries. The lack of transparency compounds these failures, preventing beneficiaries from accessing information about their case or participating in its adjudication.

These failures also illustrate the potential for welfare discrimination based on beneficiaries’ socio-economic backgrounds. Flaws in OCI and MiDAS’ income calculation formulae, for example, disproportionately affect workers with irregular incomes, whom the CESCR has designated as a protected category in the social security context.[84] The Michigan Law School Unemployment Insurance Clinic has also raised concern that beneficiaries experiencing financial hardship have extremely limited options to challenge MiDAS’s determinations: Charges of fraud disqualify them from free representation under the state’s pro bono program, and it is unlikely that they are able to afford private representation.[85] Under OCI, the Senate Committee heard evidence that beneficiaries with poor literacy or English language skills found it particularly difficult to understand the highly technical language used in debt notices.[86]

The Role of the Private Sector

The case studies outlined in this submission show that the private sector is key in developing and operating automated systems of welfare governance. Companies involved range from those providing specialized fraud detection services to large enterprise software manufacturers. However, it is unclear whether these companies have established policies or processes that meaningfully address their human rights impacts.

These public-private partnerships make it difficult to hold both State and non-State actors accountable for failures in the welfare delivery services that are outsourced. AI Now, an organization dedicated to examining AI’s public and social impacts, has found that risk assessment models and other automated decision-making tools are typically hidden behind broad assertions of intellectual property and trade secrets, making it difficult for affected rights holders and the broader public to scrutinize their potential for discrimination and other human rights impacts.[87] There also does not appear to be much pressure on companies to conduct human rights impact assessments or consultations with welfare recipients during the design, customization and implementation of welfare delivery software, particularly since governments are not insisting on adherence to the UN Guiding Principles.

Implementation of the UN Guiding Principles in the Information and communications technology sector, which has hitherto focused on the responsibilities of internet and telecommunications companies to respect freedom of expression and privacy, offers general guidance and best practices that are adaptable to the commercial delivery of welfare-related services.

Human rights due diligence is a central component of these responsibilities, and requires impact assessments that address issues of privacy, discrimination and exclusion early on in the design and engineering phase, internal training, dialogue and collaboration on these issues, and regular consultations with civil society and affected rights holders.[88] Companies should also establish meaningful transparency measures, such as policies to disclose the outcomes of impact assessments and the concrete steps they have taken to prevent or mitigate human rights risks.[89] Furthermore, companies have a responsibility to provide access to effective remedies (such as financial restitution) when they have “caused or contributed to adverse [human rights] impacts.”[90]

In the context of digital welfare, companies should, at a minimum, provide accessible explanations of how AI and other data-driven technologies are integrated into welfare decision-making, disclose and address automation errors in a timely fashion, submit to audits of algorithms and training data by external assessors, and develop processes for identifying, correcting and mitigating discrimination and bias in system inputs and outcomes.[91]

In accordance with their obligations to protect against private interference with Covenant rights, States should establish implementation of the UN Guiding Principles as a mandatory condition for the sale of identity verification, benefits assessment and fraud detection products and services to welfare agencies and other relevant authorities.. LANSING – In a ruling that could affect tens of thousands of Michigan residents falsely accused of unemployment insurance fraud, the Michigan Supreme Court on Friday revived a proposed class-action lawsuit that a lower court had dismissed.

Two of the three named plaintiffs who sued the State of Michigan after they were wrongly subjected to harsh financial penalties can sue the state, the Supreme Court ruled.

Under Michigan law, the suits had to be filed within six months of the event that gave rise to the legal action.

The unanimous opinion, written by Justice Stephen Markman, said the clock started ticking when the state seized their income tax returns or other property as it sought to collect tens of thousands of dollars in penalties wrongly assessed against each of the plaintiffs for alleged fraud that never occurred.

The Michigan Court of Appeals had ruled in 2017 that the clock began ticking much earlier — when the state "issued notices informing plaintiffs of its determination that plaintiffs had engaged in fraudulent conduct." Using that standard, which was also endorsed by the Michigan Unemployment Insurance Agency, all three plaintiffs filed their suits too late.

"The Court of Appeals erred by holding that plaintiffs' due-process claims seeking monetary relief accrued when plaintiffs were deprived of process," Markman wrote. "Rather, these claims accrued only when they were deprived of property, as they incurred no harm before that deprivation."

Under the new ruling, plaintiffs Grant Bauserman and Teddy Broe can proceed with their lawsuits, the court ruled. A third plaintiff, Karl Williams, still filed too late and his suit cannot proceed, the court ruled.

More:Suit dismissed over false fraud charges; court says jobless claimants filed too late

More:After MiDAS fiasco, unemployment fraud bills getting speedy passage

The case still has a legal hurdle to clear before class certification can be considered by the Michigan Court of Claims. The Supreme Court sent the case back to the Michigan Court of Appeals to consider whether an individual can sue the state for monetary damages for violation of constitutional rights.

The state has acknowledged that at least 20,000 Michigan residents — and possibly as many as 40,000 — were wrongly accused of fraud by a $47-million state computer system that the state operated without human supervision and with an error rate as high as 93%.

Those wrongly accused of fraud through robo-adjudications by the Michigan Integrated Data Automated System (MiDAS) were subjected to highest-in-the-nation quadruple penalties and many were subjected to aggressive collection techniques such as wage garnishment and seizure of income tax refunds.

Jennifer Lord, the Royal Oak attorney representing the plaintiffs, said she is "gratified that the Michigan Supreme Court has revived this important case."

"We will keep fighting for the 40,000 victims of a computer that ran amok and falsely accused them of fraud," she said. "I hope that our elected officials will take this opportunity to finally right this wrong for the many, many Michiganders who are still suffering from a harm inflicted on them by the state."

Lord said she hopes Friday's ruling will prompt discussions aimed at settling the lawsuit.

Contact Paul Egan: 517-372-8660 or pegan@freepress.com. Follow him on Twitter @paulegan4. Read more on Michigan politics and sign up for our elections newsletter.. . A $20 million settlement in a class-action lawsuit filed by unemployment insurance claimants who were wrongly accused of fraud and then had money and other assets seized has been approved by the Michigan Court of Claims.

Claimants are eligible for compensation if they received an initial determination or redetermination of intentional misrepresentation issued by the state's Unemployment Insurance Agency's automated jobless system, called MiDAS, between Oct. 1, 2013, and Aug. 31, 2015, and had their paychecks or other assets seized on or after March 9, 2015.

The $20 million settlement was reached in October in the class-action lawsuit, filed in 2015, called Bauserman v. Unemployment Insurance Agency. The Court of Claims approved the settlement on Jan. 19, but the approval was entered into the court system Monday. The state has acknowledged that about 40,000 people were accused of fraud by the computer system, which operated without human supervision and had an error rate as high as 93%.

Counsel for the class — the law firm Pitt, McGehee, Palmer, Bonanni and Rivers — and the Attorney General have a list of about 8,100 claimants, which they believe "identifies all eligible class members."

The reason not all 40,000 claimants are included in the class list stems from a Michigan Supreme Court decision that ultimately limited who could sue based on the timing of when the harm was done, said Jennifer Lord, a partner at Pitt, McGehee, Palmer, Bonanni and Rivers. In practical terms, she said, claimants are eligible if the first seizure of property occurred on or after March 9, 2015.

The claimants on this list will automatically be eligible to participate in the settlement, the Attorney General's Office said in a Monday news release.

Mailed notices of the settlement will go out on Feb. 1 to these claimants with instructions on what documents must be submitted. These notices will also detail an appeal process over disputes about eligibility for participation in the settlement class and disagreements over the amount of settlement money.

To begin the process, claimants must submit a completed registration form by April 5, and submit a claim form by April 14.

Claimants who do not directly receive a notice but believe they qualify as an eligible member of the settlement class can find the notice posted on Michigan.gov/AG, Michigan.gov/LEO/Bureaus-Agencies/UIA and UIAClassAction.com starting Feb. 1 and can submit the requested documents to determine if they qualify for the settlement.

More:Michigan unemployment agency wasn't effective in processing pandemic claims, audit shows

More:Michigan unemployment agency to pause collection activities for all pandemic overpayments

Eligible class members may also apply for additional compensation from a "Hardship Fund," the news release said. Those who meet the definition of a class member and who do not exclude themselves will have their legal rights adjudicated and will be bound by the final judgment entered in the case, the release said. Class members may exclude themselves by submitting an opt-out form by April 5.

Counsel for the class can be reached by phone at 248-658-0014 or by email at uiafraudclass@pittlawpc.com.

Contact Adrienne Roberts: amroberts@freepress.com.