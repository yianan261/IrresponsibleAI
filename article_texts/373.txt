LANSING (AP) — Gov. Rick Snyder and lawmakers are looking to create a state fund to compensate thousands of people who were falsely accused of fraudulently collecting unemployment benefits.

The proposal was not included in changes to the Unemployment Insurance Agency that won approval on the last day of legislative voting in 2017. But legislators, who a week before had begun negotiations on adding the compensation proposal to the bills at the request of the Snyder administration, plan to revisit the issue in January.

The compensation has long been demanded by Democrats in the GOP-led Legislature. It would help claimants who were refunded penalties and interest but have faced other financial hardships because of the fiasco that occurred between October 2013 and September 2015, when the state mostly relied on a computer system to determine that people collected excessive benefits based on discrepancies in reported earnings, hours worked and other information.

Some people had to hire lawyers to fight false findings. Others had to file for bankruptcy, saw their wages garnished, suffered worse credit ratings or had trouble finding a job and housing, according to an attorney for people who are suing for economic damages.

Rep. Joseph Graves, who helped spearhead the reform legislation and was involved in late-night talks

on the compensation plan, said the concept needs pursuing but cautioned it may not make people whole. More study is needed of the mechanism and if it is feasible, he said, citing legal and other questions that were raised.

“To just really quickly bum rush this through didn’t seem like the right thing to do,” said Graves, a Republican from Genesee County’s Argentine Township. “We need to slow down and say, ‘What can we offer and what does that look like?'”

While legislators involved in the discussions said the compensation would total $30 million, Snyder’s office declined to confirm that amount. To qualify, victims would have to agree not to sue the state.

“The intent is just to compensate people above and beyond their refund — to make things right for those who were unfairly treated,” said spokeswoman Anna Heaton. She said the governor will seek to reopen the negotiations in conjunction with work on the next budget, which he will propose in February.

The Unemployment Insurance Agency said of the nearly 67,000 cases in the two-year period in which claimants were found to have committed fraud and did not appeal, there were reversals for slightly more than 40,000 people. Nearly 20,000 of them had collections processed for restitution, penalties and interest. About $21 million has been or is being refunded.

Lawmakers’ decision to wait on the compensation fund was welcomed by Jennifer Lord, a lawyer who has been leading a lawsuit against the state that seeks class-action status for 46,000 residents. She questioned if $30 million would be enough to pay back what was improperly seized from claimants, let alone their related financial losses.

“It’s not enough money. I encourage the Legislature to really spend a lot of time with a lot of different stakeholders and understand the depths of the losses that people have suffered,” Lord said. “The concept needs a lot of work.”

She credited government officials for “trying to do the right thing” but said they must ensure that “someone is not asked to take $200 when they lost $10,000 and had to file bankruptcy. We just can’t get this done for political expediency and kind of hurt people one more time.”

Victims’ ability to sue has been in doubt since the state Court of Appeals tossed the suit in July, saying the three plaintiffs waited too long to file it. An appeal is pending with the state Supreme Court.

Snyder will soon sign the bills to overhaul the jobless benefits agency, which stopped “auto adjudicating” cases solely with the Michigan Integrated Data Automated System in 2015. The legislation is designed to prevent such a mess from occurring again and to help claimants navigate the system. Changes include cutting the nation’s highest financial penalties except for “impostor” claimants and easing employers’ ability to flag fake claims filed by identity thieves.

Rep. Kevin Hertel, a Democrat from St. Clair Shores, said “the biggest remaining piece and I think the most important out of all of this is to ensure we’re taking care of the individuals who were impacted by the MiDAS failure.”

He said he is “extremely glad” that Snyder now supports paying damages, and the Legislature should immediately consider the compensation fund upon returning in January. He opposed linking it to the multi-month budget process.

“If we’re going to do this, I think we need to do it right away,” Hertel said. “These people have waited too long.”. A Michigan government agency wrongly accused individuals in at least 20,000 cases of fraudulently seeking unemployment payments, according to a review by the state.

The review released this week found that an automated system had erroneously accused claimants in 93% of cases – a rate that stunned even lawyers suing the state over the computer system and faulty fraud claims.

“It’s literally balancing the books on the backs of Michigan’s poorest and jobless,” attorney David Blanchard, who is pursuing a class action in federal court on behalf of several claimants, told the Guardian on Friday.

The Michigan unemployment insurance agency (UIA) reviewed 22,427 cases in which an automated computer system determined a claimant had committed insurance fraud, after federal officials, including the Michigan congressman Sander Levin, raised concerns with the system.

The review found that the overwhelming majority of claims over a two-year period between October 2013 and August 2015 were in error.

In 2015, the state revised its policy and required fraud determinations to be reviewed and issued by employees. But the new data is the first indication of just how widespread the improper accusations were during that period.

The people accused lost access to unemployment payments, and reported facing fines as high as $100,000. Those who appealed against the fines fought the claims in lengthy administrative hearings. And some had their federal and state taxes garnished.



Kevin Grifka, an electrician who lives in metro Detroit, had his entire federal income tax garnished by the UIA, after it accused him of fraudulently collecting $12,000 in unemployment benefits.



The notice came just weeks before Christmas in 2014.

“To be honest with you, it was really hard to see your wife in tears around Christmas time, when all of this went on for me,” Grifka said.

The computer system claimed that he had failed to accurately represent his income over a 13-week period. But the system was wrong: Grifka, 39, had not committed insurance fraud.

In a statement issued on Friday, Levin called on state officials to review the remaining fraud cases that were generated by the system before the policy revision.

“While I’m pleased that a small subset of the cases has been reviewed, the state has a responsibility to look at the additional 30,000 fraud determinations made during this same time period,” he said.

Figures released by the state show 2,571 individuals have been repaid a total of $5.4m. It’s unclear if multiple cases were filed against the same claimants.

The findings come as Michigan’s Republican-led legislature passed a bill this week to use $10m from the unemployment agency’s contingent fund – which is composed mostly of fines generated by fraud claims – to balance the state’s budget. Since 2011, the balance of the contingent fund has jumped from $3.1m to $155m, according to a report from a Michigan house agency.

The system, known as the Michigan Integrated Data Automated System (Midas), caused an immediate spike in claims of fraud when it was implemented in October 2013 under the state’s Republican governor, Rick Snyder, at a cost of $47m.

In the run-up to a scathing report on the system issued last year by Michigan’s auditor general, the UIA began requiring employees to review the fraud determinations before they were issued.

The fraud accusations can carry an emotional burden for claimants.

“These accusations [have] a pretty big burden on people,” Grifka said. While he said the new findings were validating and his own case had been resolved, he called for state accountability.



“There’s no recourse from the state on what they’re doing to people’s lives. That’s my biggest problem with all of this.”

Steve Gray, director of the University of Michigan law school’s unemployment insurance clinic, told the Guardian earlier this year that he routinely came across claimants facing a significant emotional toll. As a result, he said, the clinic added the number for a suicide hotline to a referral resource page on the program’s website.

“We had just a number of clients who were so desperate, saying that they were going to lose their house … they’ve never been unemployed before, they didn’t know,” said Gray, who filed a complaint with the US labor department in 2015 about the Midas system.

The fines can be enormous. Residents interviewed by local news outlets have highlighted fraud penalties from the UIA upwards of $100,000. Bankruptcy petitions filed as a result of unemployment insurance fraud also increased during the timeframe when Midas was in use.

One bankruptcy attorney told the Detroit Metro Times he had as many as 30 cases in 2015 tied to debt from the UIA; before the automated system was implemented, he said he would typically have at most one per year with such claims. The newspaper also found claimants who were charged with fraud despite never having received a single dollar in unemployment insurance benefits.

A pair of lawsuits were filed in 2015 against the UIA over Midas. According to a pending federal case, in which the state revealed it had discontinued using Midas for fraud determinations, the system “resulted in countless unemployment insurance claimants being accused of fraud even though they did nothing wrong”.

Blanchard told the Guardian in February that many unemployment applicants may not have realized they were even eligible to appeal against the fraud charge, due to the setup of Midas. Attorneys representing claimants have said that many refuse to ever apply for unemployment benefits again.

A spokesman for the unemployment insurance agency, Dave Murray, said it appreciated Levin’s work on the issue and said it was continuing “to study fraud determinations”.

The agency had already made changes to the fraud determination process, he said, and “we appreciate that the state legislature this week approved a bill that codifies the reforms we’ve set in place”.

Levin, who represents part of metropolitan Detroit, said in his statement that Michigan officials had to fully account for the money that has flowed into the unemployment agency’s contingent fund.



“While I am pleased that $5m has been repaid, it strikes me as small compared to the amount of money that was collected at the time,” he said. “Only a full audit will ensure the public that the problem has been fully rectified.”. A weekly newsletter—delivered every Saturday morning—that goes deep into our original reporting and the questions we put to big thinkers in the field. Browse the archive

Hello, friends,

This week, the Biden administration released its Blueprint for an AI Bill of Rights, a wish list of principles that “should guide the design, use, and deployment of automated systems.”

The principles state that Americans should:

Be protected from unsafe or ineffective systems.

Not face discrimination by algorithms.

Be protected from abusive data practices.

Be informed when an automated system is being used.

Be able to opt out from automated systems “where appropriate” and have access to a human decision-maker.

These principles, while laudable, do not say much about how we will get there. The White House did not propose legislation, the creation of a new agency, or any other holistic measure to regulate automated systems. It did issue a list of actions agencies are taking within their current mandates, such as an effort by the U.S. Department of Housing and Urban Development to establish standards for home valuation algorithms.

Meanwhile, there are people fighting for algorithmic accountability all over the world without any of these rights to back them up. So I thought this would be a good moment to highlight one of the most gruesome struggles out there—the story of the out-of-control automated system that was inflicted on the people of Michigan.

In 2013, Michigan laid off most of the humans who worked to identify fraudulent unemployment claims and instead installed an automated system to replace them. But it turns out the system was wrong the vast majority of the times that it flagged a claim as fraudulent. As a result, the state wrongfully seized millions of dollars from tens of thousands of people over the two years that the system was operating.

These are the kinds of unsafe, ineffective practices that the AI Bill of Rights seeks to prevent. But there has yet to be independent accountability for Michigan’s mistakes. In 2017, the state passed a law requiring the agency to make fraud determinations manually and said it would refund $20.8 million to residents who were wrongfully accused of fraud. But lawyers say that is not the full amount of refunds owed and doesn’t account for the damages suffered by people who lost jobs, homes, and filed for bankruptcy as a result of this system.

To understand the case of Michigan’s rogue fraud-detection system, I spoke to Jennifer Lord, a civil rights and employment attorney and partner at Pitt, McGehee, Palmer, Bonanni & Rivers in Michigan, who has been fighting for seven years to get that money back for those wrongfully accused. In July of this year, the Michigan Supreme Court finally ruled that workers falsely accused of unemployment fraud can sue the state for the violation of their constitutional rights. She and her colleagues are now proceeding to trial seeking money damages.

Our conversation, edited for clarity and brevity, is below.

Jennifer Lord

Angwin: Let’s start at the beginning. What is MiDAS and what happened in 2013 when Michigan implemented this technology?

Lord: In 2013, our office, which does employment and civil rights law, started getting a ton of calls from our current clients saying that the [Michigan] Unemployment Insurance Agency was billing them for some obscene amount, $10,000 or $25,000, because they allegedly committed fraud when they applied for their unemployment benefits.

We spoke with other civil rights and employment attorneys in the state of Michigan, and we all started digging, and we found a press release where the state of Michigan had nominated itself for this tech award for having rolled out this brand-new computer system, a $46 million system called MiDAS. MiDAS was tasked with deciding whether someone committed fraud in connection with their application for unemployment benefits. For example, if someone was applying for unemployment insurance but still had a job, that would be fraud, and that person would get in trouble. What happened here is that MiDAS was wrong 93 percent of the time, and in about 40,000 instances it incorrectly found fraud.

Angwin: Can you explain to me what exactly transpired for the people who were wrongfully accused?

Lord: Let’s say someone gets disqualified from unemployment benefits on the basis of fraud. Problem number one is that the determination letter they send you doesn’t say what the state thinks you did. There are no specifics, so you don’t know what you’re defending against. The person is supposed to know what they did wrong and then they have 30 days to write a handwritten protest and literally fax it back to the agency. Let’s say it’s received within 30 days, in a perfect world that will go to an administrative law judge who would then rule as to whether you’re entitled to the benefits or not.

The problem is that MiDAS wasn’t sending paper copies of these fraud determination notices. They were sending pings to an electronic portal. To complicate this, MiDAS did a six-year audit so people were being accused of having committed fraud in 2015 when they hadn’t collected benefits since 2010 or 2009. Returning to the problem of online notifications—people weren’t going on their portals anymore. People weren’t responding to these determinations within 30 days, and then they became final and nonappealable.

If MiDAS found that you committed fraud, you would owe back the benefits you already received and a quadruple penalty. The government was taking this money from people in two ways: the seizure of tax refunds and administrative garnishment. MiDAS interfaced with the state and federal treasury, so it would seize people’s tax refunds to pay down the debt.

Second, the state used something called an administrative garnishment. With a traditional garnishment, there’s a judicial process before wages are taken. With the state administrative garnishment, there’s no process. It’s automatic and not subject to judicial review. This means the first time someone would find out what was happening is when they found a new job and then 25 percent of their new paycheck was garnished, and the garnishment continues until the debt is paid.

Angwin: This sounds like it could be financially devastating. Can you talk about how this affected people?

Lord: We know for a fact that at least 11,000 families in the state of Michigan filed for bankruptcy. That’s a very real harm, and that family isn’t going to be able to get a mortgage, or it will be at a much higher rate, or if they need to lease a new car, they will have a ridiculous rate.

It’s also shown up on people’s background checks. One woman I met had completed her training to become a police officer in the city of Detroit and then failed the background check and didn’t get the job because MiDAS had flagged her as having committed fraud.

Angwin: You have been representing the people wronged by MiDAS for seven years now. Can you give us an overview of the allegations you brought against the state and what has been happening?

Lord: Our lawsuit, Bauserman v. Unemployment Insurance Agency, says that the state of Michigan violated the Michigan constitution when it seized people’s property without due process. For the first three and a half years, the legal issue was that in Michigan, if you’re suing the state, there are extra procedural rules with separate timelines. The state argued that we missed this very specific time frame—that we sued too late. This went all the way up to the Michigan Supreme Court, which ruled that we did not sue too late. That was issue number one. Issue number two, which surprisingly had never been clarified in Michigan, was the question of whether somebody can sue the state for money damages when the state violates the constitution. This ruling just happened in July and was in our favor.

Angwin: Now that you have this ruling from the Michigan Supreme Court, what are the next steps and how long will this take?

Lord: The short answer is we’ve got to start discovery like we were ready to do seven years ago. We also have to get this class certified; right now, we represent two individuals on behalf of a putative class of tens of thousands. One of the first things on the agenda will be to ensure that we officially and legally represent everyone with a claim.

Since it is a tort, we will argue for consequential damages, so at a minimum, money back plus interest, but there also has to be some recognition that this was a real harm. Even if you didn’t declare bankruptcy, the stress of being told you owe $40,000 or $20,000 shortly after you’re fired from your job—there’s not going to be a formula for that.

You never know with litigation, but there’s no inherent reason for this to take any longer than any other case. We need to start getting people under oath and hearing what they have to say and what they remember. I have a feeling that the agency is going to have known that this was a problem almost from the get-go, and the real interesting thing will be figuring out who knew what, when.

Angwin: What have you learned about holding this kind of AI system to account? What should be done in the future to prevent this type of event, and what might other lawyers want to look for when investigating?

Lord: I’ve been surprised how little this worries most people. I don’t know if it’s the fact that in Michigan this story was breaking at the same time as the Flint water crisis, so if you’re looking at two debacles, the one with the brown glass of water is very disturbing. MiDAS just didn’t seem to ignite the imagination like I thought it would. The state of Michigan was basically stealing tens of millions of dollars from its citizens!

How to fix it going forward? One idea is having an independent, knowledgeable, and interdisciplinary group vetting technology before any purchase is made. I can only imagine a skilled salesperson selling the agency on promises of efficiency, cost cutting, and profit increases. What politician is going to say no to that?

I think the problem is that there are some jobs computers and algorithms can’t and shouldn’t do, such as determining whether or not someone committed fraud. It’s wrong that we asked the computer to do this all by itself, with no human intervention. It’s one thing if a computer flags it and then a human takes a deeper look. That’s not what happened because at the same time that the Unemployment Insurance Agency purchased MiDAS, it laid off a third of its workforce, almost its entire fraud detection unit.

The algorithm is alleging that these 40,000 people intentionally defrauded the unemployment insurance agency. I think a judge or a jury should decide the question of intent. When assessing credibility, it should not be done by an algorithm. I don’t think that a computer looking at a series of numbers is capable of determining intent.

As always, thanks for reading.

Best,

Julia Angwin

The Markup

(Additional Hello World research by Eve Zelickson.). Summary

This submission examines the human rights implications of Artificial Intelligence (AI) [1] and other data-driven technologies in welfare benefits programs, such as cash and food assistance programs. Through a series of case studies, this submission explains how States delegate key welfare functions, such as determinations of eligibility and benefits levels, to automated decision-making models, some of which rely on data mining, machine learning and other processes or technologies typically associated with the field of AI. It also assesses how automated decision-making interferes with the rights to privacy and social security, and the obligations of States to guarantee the exercise of these rights without discrimination and undue private interference.

Overview of Applicable International Human Rights Law

The right to privacy

Article 17 of the International Covenant on Civil and Political Rights (ICCPR), which derives from Article 12 of the Universal Declaration of Human Rights (UDHR), establishes the right to “the protection of the law” against “arbitrary or unlawful interference” with one’s “privacy, family, home or correspondence.”

The Human Rights Committee has concluded that the prohibition against “arbitrary or unlawful interference” establishes a two-part test. First, interferences with privacy can take place only “in cases envisaged by the law.”[2] Under this requirement, States must “specify in detail” in relevant legislation “the precise circumstances in which such interferences may be permitted,” and ensure that decisions “to make use of such authorized interference must be made only by the authority designated under the law, and on a case-by-case basis.”[3] Second, for interferences to be non-arbitrary, the Committee has concluded that they must be “proportionate to the end sought, and ... necessary in the circumstances of any given case.”[4]

The right to social security

Article 9 of the International Covenant on Economic, Social and Cultural Rights (ICESCR) and Article 22 of the UDHR recognize the right of everyone to “social security, including social insurance.” The Committee on Economic, Social and Cultural Rights (CESCR) has concluded that this right establishes the obligation of States to ensure that eligibility criteria for social security benefits are “reasonable, proportionate and transparent.”[5] Furthermore, the “withdrawal, reduction or suspension of benefits should be “based on grounds that are reasonable, subject to due process, and provided for in national law.”[6]

Access to information is also a precondition of the enjoyment of the right to social security. The CESCR has found that beneficiaries of social security schemes “must be able to participate in the administration of the social security system.”[7] Accordingly, the system should “ensure the right of individuals and organizations to seek, receive and impart information on all social security entitlements in a clear and transparent manner.”[8]

Non-Discrimination Obligations

Article 2(1) of the ICCPR and Article 2(2) the ICESCR require States to guarantee Covenant rights without discrimination of any kind based on “race, color, sex, language, religion, political or other opinion, national or social origin, property, birth or other status.” Article 26 of the ICCPR additionally guarantees the right “to all persons equal and effective protection against discrimination on any ground.” The Human Rights Committee has found that Article 26 establishes an “autonomous right” that “prohibits discrimination in law or in fact in any field regulated and protected by public authorities.”[9]

In the context of social security, the CESCR has found that States should ensure that social security schemes “do not discriminate in law or in fact.”[10] States should also “pay special attention” to those that disproportionately experience difficulties in accessing social security, such as women, people with disabilities, minorities and “casual” or “seasonal” workers.[11]

Obligation to Protect Against Third-Party Interference

States have a duty to protect individuals from undue third-party interferences with their rights to privacy and social security. The Human Rights Committee has concluded that Article 2(1) of the ICCPR, which establishes the State’s duty to “ensure” the right to privacy and other Covenant rights, imposes a positive obligation to protect individuals against “acts committed by private persons or entities that would impair the enjoyment of [these] rights.”[12] This duty requires the adoption of “appropriate measures” or “due diligence to prevent, punish, investigate or redress the harm caused by ... private persons or entities.”[13]

The CESCR has categorized State obligations under the ICESCR as obligations to respect, protect and fulfill Covenant rights.[14] The obligation to protect the right to social security requires States to prevent corporations and “agents acting under their authority” from interfering with that right.[15] In the context of social security schemes that are “operated or controlled by third parties,” States “retain the responsibility of administering the national social security system and ensuring that private actors do not compromise equal, adequate, affordable, and accessible social security.”[16] To prevent abuses, “an effective regulatory system must be established which includes framework legislation, independent monitoring, genuine public participation and imposition of penalties for non-compliance.”[17]

Human Rights Implications of Using Technology in Cash and Food Assistance Programs

States rely on AI and related technologies to automate two critical stages of the welfare distribution process: the verification of claimants’ identity, and the assessment of eligibility and benefits levels. Throughout the entire welfare delivery cycle, States also employ these technologies to investigate, adjudicate and impose penalties for fraud.

Identity Verification

Aadhaar (India)

The use of AI to verify the identity of welfare recipients may be part of a broader push to establish national digital identity frameworks that manage individuals’ access to government entitlements through a single, government issued identity. In 2009, India launched Aadhaar, a digital identity framework that assigns every citizen a unique twelve-digit identification number linked to the individual’s biometric and demographic data. Under the Aadhaar Act of 2016, beneficiaries of various government welfare programs such as the Public Distribution System (PDS), which provides subsidized food grains to millions of households, are required to register and use Aadhaar to access their entitlements.[18]

In 2018, the Indian Supreme Court upheld the government’s authority to mandate Aadhaar as a precondition for accessing food rations and other welfare benefits.[19] However, the Court ruled that certain provisions of the Aadhaar Act were unconstitutional, and also barred the private sector from seeking access to Aadhaar data.[20] In February 2019, the government passed amendments to the Aadhaar Act that restored such access and bypassed the Court’s ruling.[21]

Concerns

Human Rights Watch has found that eligible families have been denied access to subsidized food grains and other benefits because they did not have an Aadhaar number, had not linked it to their ration cards or experienced failures in authenticating their fingerprints.[22] Authentication failures disproportionately affect manual laborers, older persons and other individuals with worn fingerprints.[23] Since the Aadhaar machines installed in food distribution outlets require an internet connection, poor connectivity in rural areas has also led to disruptions in food distribution schedules.[24] Local activists have found that Aadhaar-related denials of food rations have led some to starve to death.[25]

Aadhaar also imposes invasive biometric identification and data collection requirements as conditions for accessing subsidized food grains and other essential public services. These requirements have created the world’s largest database of biometric identity information, escalating the risk of unnecessary and disproportionate surveillance.[26] To mitigate this risk, the Supreme Court imposed several restrictions, including the requirement of judicial approval for law enforcement access to Aadhaar data, and a six-month limit on the retention of authentication records and transaction logs.[27] However, these changes do not address the scope of biometric data and personal information collected under the program. Human Rights Watch has also raised concern about the multiple data breaches associated with Aadhaar since its implementation.[28]

These interferences with privacy disproportionately affect minorities: for example, local activists fear that transgender individuals are at greater risk of discrimination and persecution when they are forced to disclose their gender identity to the government, or if such information is leaked to the public.[29] These risks also raise the possibility that transgender individuals will be deterred from seeking access to essential public services linked to Aadhaar.

Knowledge Based Authentication System (California, United States)

Countries without national ID schemes also rely on automated decision-making to verify the identity of welfare claimants by comparing multiple sources of identity-related information drawn from a wide range of government and private databases. In the United States, the California state legislature in 2017 amended the Welfare and Institutions Code to replace fingerprint imaging with an “automated, nonbiometric” method for verifying the identity of applicants to the CalWORKs program, which provides cash assistance to needy families.[30] The Department of Social Services (DSS) selected US-based private company Pondera Solutions[31] to conduct a pilot of a cloud-based identity verification system known as the Knowledge Based Authentication system (KBA).[32] The pilot was conducted in six counties.[33]

KBA checks a CalWORKs application against “over 10,000 public sources” of data from “dozens of categories and hundreds of jurisdictions,” including data from credit bureaus, government agencies and “utility and telephone companies.”[34] This initial assessment is “designed to verify that the identity provided to the program is legitimate.”[35] It also generates a multiple-choice quiz for applicants that “seeks to ensure that the applicant is in fact the individual that they are representing themselves to be.”[36] Applicants are assigned a fraud risk code based on the system’s initial assessment and their answers to the quiz.[37]

At the conclusion of the pilot in October 2017, DSS announced that it was intending to roll out KBA for phone or online benefits applications by the summer of 2018.[38] It is unclear, however, whether it has adhered to this timeline.

Concerns

In its report on the results of the pilot, DSS did not explain how the KBA analyzes the wide variety of data sources at its disposal to verify an applicant’s identity and generate quiz questions. Although KBA standardizes the spelling of addresses “to avoid misspellings and other common mistakes,” it is unclear how the system responds to other errors in the data it is provided, such as discrepancies in dates, phone numbers and demographic details.[39] The report also acknowledges KBA’s potential to generate “false positives,” but does not provide information about DSS’s plans to prevent or mitigate such errors.[40]

This lack of transparency makes it difficult for welfare claimants and the broader public to assess the reliability, accuracy or fairness of KBA’s risk assessment calculus. If incorrect information is associated with claimants and answers to the quiz questions are wrongly marked as errors, it will be difficult for them to identify the source of the error and hold the relevant authorities accountable. In addition, KBA’s analysis of large datasets containing a wide range of sensitive and personal information raises questions about how the system safeguards applicants’ privacy.

The Coalition of California Welfare Rights Organizations has also raised concern that KBA’s multiple-choice quiz creates additional obstacles for marginalized populations. Families that have been homeless for a long time may be unable to answer questions such as “How long have you lived in your current residence?” or “Which of the following streets have you ever lived or used as your address?”[41] Furthermore, questions regarding residential and relationship history in the United States assume that respondents have longstanding community ties, and are ill-suited to the needs and concerns of newly arrived immigrant families.

Assessment of Eligibility and Benefits Levels

Ontario Works (Ontario, Canada)

Governments are also replacing or supplementing case workers’ assessments of eligibility and benefits levels with predictive analytics and other AI-based assessment tools. Since November 2014, Ontario Works, the financial assistance program of the Canadian province of Ontario, has been relying on the Social Assistance Management System (SAMS) to automatically generate decisions on eligibility for cash transfers and other benefits. Decisions are generated based on data that frontline workers collect from applicants and recipients and subsequently “fit into narrow-drop down menu categories.”[42]

SAMS is based on Cúram, a customizable off-the-shelf software sold by IBM as a platform for “complete intake, eligibility determination and benefit calculation for social programs.”[43] Latest versions of the software are also equipped with functions to monitor impermissible instances of “concurrent eligibility” in food and cash assistance programs, potentially indicating the system’s ability to perform both benefits assessments and fraud detection.[44] Cúram is also used to administer welfare programs in Alberta, North Carolina, Hamburg, Queensland and New Zealand.[45]

A 2015 audit of SAMS conducted by the state’s Auditor General found that SAMS suffered from “serious defects and was not fully functional,”[46] leading to potential underpayments of benefits totaling $51 million CAD.[47] In one case, SAMS erroneously deducted $32 from a client’s total benefit payments each month after it incorrectly determined that the client had been previously overpaid.[48]

The Auditor General also found that SAMS “automatically generated” letters to beneficiaries with “incorrect information” that caused “stress and confusion.”[49] For example, a letter sent to two beneficiaries, whom owed $1,328 in overpayments, accused them of owing $8,736.[50] Another letter notified a beneficiary that their benefits would be withdrawn because they no longer lived in Ontario, but caseworkers found that the beneficiary “had never left Ontario.”[51]

Universal Credit (United Kingdom)

The Special Rapporteur on extreme poverty and human rights has observed that the Universal Credit (UC), the UK’s welfare benefits program, “is only possible because of the automated calculation of benefits.”[52] The Real Time Information (RTI) system calculates UC payments based on earnings information reported by employers to Her Majesty's Revenue and Customs (HMRC), the country’s tax authority.[53]

It appears that RTI’s calculations are unable to correct for late, inaccurate or missing reports, and this can lead to delays and errors in UC payments.[54] In the 2016/2017 fiscal year, 5.7% of 590m UC payments were marred by late reporting.[55] To address RTI’s inability to take into account reporting errors, HMRC and the Department of Work and Pensions, which oversees UC, have established a special joint initiative known as the Late, Missing and Incorrect RTI Project.[56]

Concerns

The failures of automated decision-making in Ontario Works and UC indicate that governments have overestimated the technology’s capacity to conduct complex and context-sensitive assessments of eligibility and benefits levels. Benefits calculators are only as accurate as the data provided to them: unlike case workers, these systems are unable to investigate the reasons for data inaccuracies and other discrepancies and make necessary adjustments on a case-by-case basis.

Despite these limitations, both programs fail to supplement automated decision-making with human review that ensures benefits changes are reasonable and in accordance with due process and domestic law requirements. In the Ontario Works program, Professor Jennifer Raso of the University of Toronto Law School has found that the design of SAMS “obstructs frontline workers from challenging the substance of its decisions.”[57] For example, SAMS does not permit frontline workers to challenge its assessments of whether Ontario Works recipients with a history of living in the same household are dependent on each other – a common ground for reducing the value of benefits.[58]

In the UK, service workers have not been provided with training that enables them to effectively troubleshoot RTI and other IT errors that may lead to the withdrawal, reduction or suspension of benefits. According to welfare researchers from the University of Birmingham and the University of Leeds, former staff of Jobcentre Plus, an agency which administers UC’s benefits for jobseekers, “described being permanently on the ‘back foot’, in that digital services were rolled out without staff being given the relevant training.”[59] A former UC call center worker in Grimsby also told The Guardian that there was “massive variation” in staff’s understanding of the UC policies and systems, leading to contradictory responses to the same query.[60]

Detection, Investigation and Punishment of Welfare Fraud

Systeem Risico Inventarisatie (The Netherlands)

Governments increasingly rely on automated fraud detection systems to detect and flag risks of welfare fraud. In the Netherlands, the Ministry of Social Affairs and Employment operates the Systeem Risico Inventarisatie or System Risk Indication (SyRI), which is used by several municipal governments to detect benefits fraud. SyRI flags individuals as potential fraud risks through an algorithmic risk assessment tool that draws on multiple sources of data, including tax returns.[61] However, the government has offered few details on the specific types of data used and the criteria for determining risk. It has rejected calls for transparency about how the algorithm works, claiming that disclosing such information would reduce its effectiveness in detecting fraud.[62] It has also not explained the circumstances under which case workers or fraud investigators may deviate from these risk assessments, if at all.

Online Compliance Intervention (Australia)

Several governments do not only automate assessments of welfare fraud, but also the imposition of penalties such as fines or the reduction or withdrawal of benefits. In July 2016, Australia’s Department of Human Services (DHS) launched Online Compliance Intervention (OCI), a fully automated income data verification system that generates debt notices based on differences between fortnightly income figures reported by welfare beneficiaries and their employers.[63] A Parliamentary inquiry conducted by the Senate’s Community Affairs Reference Committee found that OCI’s income calculation formula is not programmed to take into account fluctuations in a beneficiary’s income, leading to “inaccurate calculations of debt,” particularly for casual or seasonal workers with irregular incomes.[64] OCI is also unable to make adjustments for employer error.[65]

DHS does not require manual review of the OCI’s findings, instead placing the onus on beneficiaries to submit evidence rebutting debt notices.[66] However, affected beneficiaries and their representatives testified before the Senate that debt notices either provided inadequate information or were too complicated to understand, making them difficult to challenge.[67] Some complained that they had to submit Freedom of Information requests to compel DHS to release information about how their debts were calculated.[68]

The Senate Committee has urged DHS to put OCI “on hold” until these issues are resolved,[69] but the Department has rejected this recommendation and claimed that its implementation has gone “quite well.”[70]

Michigan Integrated Data Automated System (Michigan, United States)

In October 2013, Michigan’s Unemployment Insurance Agency (UIA) launched the Michigan Integrated Data Automated System (MiDAS) to adjudicate and impose penalties for unemployment benefits fraud. Between October 2013 and August 2015, MiDAS was programmed to automatically treat differences between income figures reported by beneficiaries and their employers as evidence of fraud.[71] The system was not capable of investigating whether there are legitimate reasons for these discrepancies, such as employer error or pay disputes.[72] Like OCI, MiDAS was also unable to determine whether these discrepancies are attributable to fluctuations in a beneficiary’s income.[73]

Based on its initial assessments, MiDAS sent beneficiaries suspected of fraud online multiple-choice questionnaires asking whether they are “intentionally provid[ing] false information to obtain benefits you were not entitle[d] to receive,” and “[w]hy ... you believe you were entitled to benefits.”[74] Failure to respond in ten days, or a response that MiDAS deemed unsatisfactory, would automatically trigger conclusive determinations of fraud.[75] Based on these determinations, MiDAS would terminate the benefits of affected beneficiaries and initiate proceedings to seize their tax refunds or garnish their wages.[76]

UIA subsequently found that, between October 2013 and August 2015, about 44,000 of the 62,784 determinations of fraud that MiDAS generated were in error.[77] In a lawsuit that a group of beneficiaries filed against UIA, the U.S. Federal Court of Appeals for the region concluded that MiDAS “did not allow for a fact-based adjudication or give the claimant the opportunity to present evidence to prove that he or she did not engage in disqualifying conduct.”[78]

Despite these failures, UIA continues to operate MiDAS.[79] It has committed to additional data analysis to detect benefits payments needing “further review” and to enhance the appeals process.[80] However, it is unclear whether UIA has made any changes to the underlying data matching algorithm or incorporated meaningful human review into the system’s fraud detection functions.

Automated Verification of Job Activity Reports (Sweden)

The Swedish Employment Service (Arbetsförmedlingen) relies on automated decision-making to verify whether recipients of unemployment benefits have complied with job-seeking and other workfare obligations, and issue warnings, withhold payments and enforce other sanctions based on these assessments.[81] At the end of 2018, Arbetsförmedlingen discovered a 10 – 15% error rate in the automated verification of beneficiaries’ job activity reports, potentially leading to 70,000 erroneous decisions to withhold benefit payments.[82] These errors have forced Arbetsförmedlingen to manually screen all job activity reports until the system can be repaired.[83]

Concerns

These cases reinforce the need for appropriate human review that corroborates fraud findings generated by automated systems, as well as clear, transparent and accessible appeals mechanisms that enable beneficiaries to meaningfully challenge these findings. Without these safeguards, limitations or errors in automated decision-making potentially lead to mass violations of the right to social security. The Swedish and Michigan examples illustrate that the automation of fraud determinations at scale replicates errors in data processing and analysis across the entire system, leading to incorrect benefits changes and penalties that affect thousands of beneficiaries. The lack of transparency compounds these failures, preventing beneficiaries from accessing information about their case or participating in its adjudication.

These failures also illustrate the potential for welfare discrimination based on beneficiaries’ socio-economic backgrounds. Flaws in OCI and MiDAS’ income calculation formulae, for example, disproportionately affect workers with irregular incomes, whom the CESCR has designated as a protected category in the social security context.[84] The Michigan Law School Unemployment Insurance Clinic has also raised concern that beneficiaries experiencing financial hardship have extremely limited options to challenge MiDAS’s determinations: Charges of fraud disqualify them from free representation under the state’s pro bono program, and it is unlikely that they are able to afford private representation.[85] Under OCI, the Senate Committee heard evidence that beneficiaries with poor literacy or English language skills found it particularly difficult to understand the highly technical language used in debt notices.[86]

The Role of the Private Sector

The case studies outlined in this submission show that the private sector is key in developing and operating automated systems of welfare governance. Companies involved range from those providing specialized fraud detection services to large enterprise software manufacturers. However, it is unclear whether these companies have established policies or processes that meaningfully address their human rights impacts.

These public-private partnerships make it difficult to hold both State and non-State actors accountable for failures in the welfare delivery services that are outsourced. AI Now, an organization dedicated to examining AI’s public and social impacts, has found that risk assessment models and other automated decision-making tools are typically hidden behind broad assertions of intellectual property and trade secrets, making it difficult for affected rights holders and the broader public to scrutinize their potential for discrimination and other human rights impacts.[87] There also does not appear to be much pressure on companies to conduct human rights impact assessments or consultations with welfare recipients during the design, customization and implementation of welfare delivery software, particularly since governments are not insisting on adherence to the UN Guiding Principles.

Implementation of the UN Guiding Principles in the Information and communications technology sector, which has hitherto focused on the responsibilities of internet and telecommunications companies to respect freedom of expression and privacy, offers general guidance and best practices that are adaptable to the commercial delivery of welfare-related services.

Human rights due diligence is a central component of these responsibilities, and requires impact assessments that address issues of privacy, discrimination and exclusion early on in the design and engineering phase, internal training, dialogue and collaboration on these issues, and regular consultations with civil society and affected rights holders.[88] Companies should also establish meaningful transparency measures, such as policies to disclose the outcomes of impact assessments and the concrete steps they have taken to prevent or mitigate human rights risks.[89] Furthermore, companies have a responsibility to provide access to effective remedies (such as financial restitution) when they have “caused or contributed to adverse [human rights] impacts.”[90]

In the context of digital welfare, companies should, at a minimum, provide accessible explanations of how AI and other data-driven technologies are integrated into welfare decision-making, disclose and address automation errors in a timely fashion, submit to audits of algorithms and training data by external assessors, and develop processes for identifying, correcting and mitigating discrimination and bias in system inputs and outcomes.[91]

In accordance with their obligations to protect against private interference with Covenant rights, States should establish implementation of the UN Guiding Principles as a mandatory condition for the sale of identity verification, benefits assessment and fraud detection products and services to welfare agencies and other relevant authorities.