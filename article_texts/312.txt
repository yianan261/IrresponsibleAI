. A Silicon Valley startup is sparking controversy for its, what critics call, “racist software.”

Palo Alto's Sanas uses artificial intelligence to alter or remove accents that you may hear when calling into a tech helpline.

"And to get the conversation away from how we speak, to what we say,” said CEO Marty Massih Sarim.

It has raised more than 30 million dollars in venture funding to, as it says, make the process of calling into a call center easier and smoother.

Get a weekly recap of the latest San Francisco Bay Area housing news. Sign up for NBC Bay Area’s Housing Deconstructed newsletter.

The blowback has been swift and brutal. Critics call the software racist, saying it eliminates rich accents and cultures for a more "white sounding" tone. An accusation the company's CEO strongly denies.

"That we should all sound the same, that the world should be a world void of accents, that we should all speak English, and not only should we all speak English, we should all speak midwestern English," said Don Heider, chief executive at the Markkula Ethics Center. "It doesn't counteract the bias, it reaffirms it, basically that everyone should speak in a certain particular way, rather than teach us it doesn't matter if somebody has an accent."

Sarim, who worked in and built call centers himself, said that's just not true.

"Certain articles say we're trying to make people sound white,” he said. “Well, I'm not white, my founders aren't white, 87% of our company is not white, we're not building a white program. This software, this ability, can do this in many countries, and many cultures."

The goal, Sarim said, is to help call center workers keep their jobs and help companies do more business faster.

"I don't want to use this call to teach you about my culture, how I pronounce things, and how I react to things, I need this business to be done, this phone call needs to be as short as possible, somebody else is waiting in the queue, they look at it from a purely business perspective,” said Ahmed Banafa, cyber security professor at SJSU.

The Sanas CEO said, “We built this for the agent, for their mental health, for them to be able to be on an even playing field, for them to do their job, be allowed to do their job the right way, and to get the conversation away from how we speak, to what we say.". The premise of Sanas is pretty simple: remove your accent in real-time. It’s created with businesses like call centers in mind, where callers deal with racial biases based purely on their voice profiles. But Sanas doesn’t just want to make your voice more “neutral” — it wants to solve the overwhelmingly large problem of voice-based racial bias in the process.

Marty Sarim, president of Sanas, made it pretty clear where he believes his company stands to help the world in a recent talk with SFGate.

“We don’t want to say that accents are a problem because you have one,” Sarim said. “They’re only a problem because they cause bias and they cause misunderstandings.”

As is the case with most deepfake technology, Sanas’s lofty dream is greatly hampered by the harsh realities it hopes to change. Racial bias won’t be eradicated by making everyone sound the same; it is, in fact, antithetical to that progress. It’s just racial color blindness by a different name.

Accents don’t cause bias — Sanas uses algorithms to make voices sound whiter. The example on the company’s website removes a man’s noticeable Indian accent and turns it into something robotic and uncanny — and, yes, white.

Sarim says accents are a problem because “they cause bias.” Bias does not work this way, of course; it’s not the object of the bias that causes it to exist. Removing the object of that bias — an accent, in this case — doesn’t do anything to rid the world of that bias. It simply sweeps it aside in the name of peaceful conversation.

But you don’t even need to speak with Sarim directly to understand where Sanas’s mission veers off course. Here’s where it happens: right at the start. Sanas’s website says the software is “creating a more connected, friendly, and empathetic world by revolutionizing how we communicate.” Sanas is doing none of these things; it’s just masking your identity.

Pure capitalism — It’s that easy to parse out how, exactly, Sanas will fail to affect radical change. That’s because Sanas’s goal is actually just to make money. Plain and simple.

“We don’t foresee anything bad coming out of this,” Sarim told SFGate. “In fact, I’ll take the opposite approach and just say, this is a GDP-shifting product.”

Plenty of investors have signed on board to back Sanas, including, most recently, a $32 million Series A funding round in June. That’s a testament not to the product’s ability to fight bias but instead to how much revenue investors believe it can make. While there’s nothing illegal about using deepfake software, we do know people are pretty bad at recognizing deepfakes when they see (or hear) them — so it may be in our best interest to better regulate this technology before it really takes off.. Have you seen the 2018 movie Sorry to Bother You? It's about a young black man who gets a job at a call center and has trouble making sales until he adopts a "white voice."

A new company called Sanas seems to have based its business plan on the movie. It has developed software that converts call center workers' accents into "standard American English." If you listen to Sanas' demo, it sounds remarkably like the white voice in Sorry to Bother You.

From SF Gate: