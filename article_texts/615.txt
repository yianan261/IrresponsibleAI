COLORADO SPRINGS, Colo. (KRDO) - Colorado Springs attorney Zachariah Crabill thought he was filing a motion with cited cases that would favor his client’s argument, only to find out many of the cases were made up by Artificial Intelligence software ChatGPT.

Crabill, a licensed Colorado attorney for about a year and a half, was working on his first civil litigation case. He was defending a client that was accused of breaching a car payment agreement.

In a court document, admitting his mistake, Crabill said it was the first motion to set aside a summary judgment he had ever researched, drafted, and filed by himself. He had heard of ChatGPT, an artificial intelligence chatbot developed by OpenAI, trained to follow instructions in a prompt and provide a detailed response. So he turned to AI technology to help find case laws that would strengthen his client’s argument.

“I felt my lack of experience in legal research and writing, and consequently, my efficiency in this regard could be exponentially augmented to the benefit of my clients by expediting the time-intensive research portion of drafting,” Crabill said in a court document.

Ramsey Lama, a former Fremont County judge turned defense attorney, said law research can be very time-intensive, taking 20 to 30 hours for some cases. While he has never used ChatGPT, he said he can see how it would be useful in the legal industry.

“What previously took a lawyer maybe 40 hours or 20 hours to do, maybe a tool like this could condense it to two hours or maybe 30 minutes,” Lama said. “A quicker result for the client is better for the client. A quicker result for the client saves the client money.”

This was Crabill’s hope. At first, he asked ChatGPT about existing Colorado laws. He said the responses were accurate and he trusted the technology.

However, when Crabill started researching cases to cite in his motion, ChatGPT betrayed him without him even realizing it. The AI technology spit out dozens of cases similar to his client’s, only the cases didn’t exist.

Sean Williams, the director of the Technical Communication and Information Design Program at the University of Colorado-Colorado Springs, said this is a common mistake many people make when using AI technology.

“After we’re confident and comfortable with the information that we have, then we assume that the information it's giving us is correct,” Williams said. “This case shows it wasn't true and that's the downside.”

One of the cases ChatGPT cited for Crabill was Gonzales v. Allstate Ins. Co. from 2014. ChatGPT said in that case the defendant didn’t appear at a hearing but the court found her absence excusable. But this case doesn’t exist, at least not in its entirety. There is a Gonzales v. Allstate Ins. Co. case, but it’s from 2002 and involves a dispute over an insurance policy after a crash happened outside of the country.

“Based on the accuracy of prior validated responses, and the apparent accuracy of the case law citations, it never even dawned on me that this technology could be deceptive,” Crabill said in court documents.

Crabill claims he filed the motion without knowing he cited fake cases. On the day of the hearing, he realized his mistake. In a message to one of the Baker Law Firm’s legal aides, he said he thinks all the case cites from ChatGPT are “garbage” and he can’t find them in LexisNexis.

The judge overseeing the hearing couldn’t find the cases either and denied the motion due to the false citations. He then threatened to file a complaint against the attorney. The Office of Attorney Regulations couldn’t confirm if a complaint had been filed against Crabill.

Lama said Crabill violated his “duty of candor to the tribunal” — a lawyer’s obligation to not make material misrepresentations of fact or law. While Lama sees the benefits of AI technology, there are clear dangers, he said.

“Somebody uses software and it generates inaccurate information and they just submit it to the court — there's a danger right there on display,” Lama said.

Lama even joked he doesn’t want AI to “put (him) out of work.”

However, Williams is more optimistic. While he said the technology poses a threat to existing jobs, he also said it will create new ones.

“There's definitely a future for it in the workforce because it's already being used,” Williams said referencing a marketing company that was using ChatGPT to write copy drafts.

“It gives us the opportunity to see things or to imagine things that might not have occurred to us otherwise,” Williams said.

But the creativity of AI can also bring “falseness,” he said.

“In this particular case, it took existing data, existing information, and skewed it,” Williams said.. A Colorado lawyer has been suspended for a year for using an AI chatbot to draft a legal document.

A judge ordered Zachariah Crabill to a one year and one day suspension after Crabill allegedly "cited case law that he found through the artificial intelligence platform ChatGPT" to to draft a motion in a civil case in May. The platform them produced cases that were incorrect and fictitious.

Crabill allegedly did not alert the court to the existence of the incorrect cases after he filed the motion. He also did not withdraw the motion.

A ruling handed down notes that when the judge asked Crabill about possible inaccuracies, Crabill attributed the mistakes to a legal intern. Six days after the hearing, he filed an affidavit explaining that he used the platform when he drafted the motion.

The presiding judge noted that Crabill violated several of the Colorado Bar Association's Rules of Professional Conduct. If he successfully completes a 90-day suspension and two subsequent years of probation, the rest of the year suspension will be forgiven.