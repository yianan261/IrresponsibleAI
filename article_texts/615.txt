COLORADO SPRINGS, Colo. (KRDO) - Colorado Springs attorney Zachariah Crabill thought he was filing a motion with cited cases that would favor his client’s argument, only to find out many of the cases were made up by Artificial Intelligence software ChatGPT.

Crabill, a licensed Colorado attorney for about a year and a half, was working on his first civil litigation case. He was defending a client that was accused of breaching a car payment agreement.

In a court document, admitting his mistake, Crabill said it was the first motion to set aside a summary judgment he had ever researched, drafted, and filed by himself. He had heard of ChatGPT, an artificial intelligence chatbot developed by OpenAI, trained to follow instructions in a prompt and provide a detailed response. So he turned to AI technology to help find case laws that would strengthen his client’s argument.

“I felt my lack of experience in legal research and writing, and consequently, my efficiency in this regard could be exponentially augmented to the benefit of my clients by expediting the time-intensive research portion of drafting,” Crabill said in a court document.

Ramsey Lama, a former Fremont County judge turned defense attorney, said law research can be very time-intensive, taking 20 to 30 hours for some cases. While he has never used ChatGPT, he said he can see how it would be useful in the legal industry.

“What previously took a lawyer maybe 40 hours or 20 hours to do, maybe a tool like this could condense it to two hours or maybe 30 minutes,” Lama said. “A quicker result for the client is better for the client. A quicker result for the client saves the client money.”

This was Crabill’s hope. At first, he asked ChatGPT about existing Colorado laws. He said the responses were accurate and he trusted the technology.

However, when Crabill started researching cases to cite in his motion, ChatGPT betrayed him without him even realizing it. The AI technology spit out dozens of cases similar to his client’s, only the cases didn’t exist.

Sean Williams, the director of the Technical Communication and Information Design Program at the University of Colorado-Colorado Springs, said this is a common mistake many people make when using AI technology.

“After we’re confident and comfortable with the information that we have, then we assume that the information it's giving us is correct,” Williams said. “This case shows it wasn't true and that's the downside.”

One of the cases ChatGPT cited for Crabill was Gonzales v. Allstate Ins. Co. from 2014. ChatGPT said in that case the defendant didn’t appear at a hearing but the court found her absence excusable. But this case doesn’t exist, at least not in its entirety. There is a Gonzales v. Allstate Ins. Co. case, but it’s from 2002 and involves a dispute over an insurance policy after a crash happened outside of the country.

“Based on the accuracy of prior validated responses, and the apparent accuracy of the case law citations, it never even dawned on me that this technology could be deceptive,” Crabill said in court documents.

Crabill claims he filed the motion without knowing he cited fake cases. On the day of the hearing, he realized his mistake. In a message to one of the Baker Law Firm’s legal aides, he said he thinks all the case cites from ChatGPT are “garbage” and he can’t find them in LexisNexis.

The judge overseeing the hearing couldn’t find the cases either and denied the motion due to the false citations. He then threatened to file a complaint against the attorney. The Office of Attorney Regulations couldn’t confirm if a complaint had been filed against Crabill.

Lama said Crabill violated his “duty of candor to the tribunal” — a lawyer’s obligation to not make material misrepresentations of fact or law. While Lama sees the benefits of AI technology, there are clear dangers, he said.

“Somebody uses software and it generates inaccurate information and they just submit it to the court — there's a danger right there on display,” Lama said.

Lama even joked he doesn’t want AI to “put (him) out of work.”

However, Williams is more optimistic. While he said the technology poses a threat to existing jobs, he also said it will create new ones.

“There's definitely a future for it in the workforce because it's already being used,” Williams said referencing a marketing company that was using ChatGPT to write copy drafts.

“It gives us the opportunity to see things or to imagine things that might not have occurred to us otherwise,” Williams said.

But the creativity of AI can also bring “falseness,” he said.

“In this particular case, it took existing data, existing information, and skewed it,” Williams said.. By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Access your favorite topics in a personalized feed while you're on the go. download the app

Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview

Thinking about using OpenAI's ChatGPT on the job? Be careful about false information — or risk getting fired.

This summer, Zachariah Crabill, a 29-year-old lawyer who previously worked at Baker Law Group, was fired after he used ChatGPT at work, he confirmed to Insider.

Crabill said he was feeling stressed about mounting deadlines and internal workplace dynamics when his bosses at the Colorado-based law firm added more work to his plate in May.

This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.

To get through it all, he turned to ChatGPT, which he had used before and trusted as an accurate research tool. He asked the chatbot to bolster a motion he had written with details from Colorado case law.

Advertisement

"When ChatGPT saved me hours of work, it was a tiny ray of sunlight in an otherwise abysmal situation," Crabill said in an email to Insider. "My experience is not unique, sadly I've heard many attorneys say they too were 'thrown to wolves' early in their career."

Once the motion was complete, the lawyer submitted it to his boss to review and, ultimately, filed it with the Colorado court — but he missed the critical step of checking the AI chatbot's work.

His excitement quickly turned into horror when he realized ChatGPT created multiple fake lawsuit citations in the motion.

Related stories

"I think all my cases cited from chatGPT are garbage … I can't even find the cases in Lexis…" Crabill said regarding the motion, according to screenshots of his text messages reviewed by Law Week Colorado.

Advertisement

The errors can likely be chalked up to hallucinations, when ChatGPT generates seemingly convincing responses that are actually not grounded in fact.

He told the judge he used the AI chatbot to help strengthen the document. The judge later reported him to a statewide office.

Soon after, he was fired, The Washington Post first reported. Crabill maintained to Insider that using ChatGPT was not the reason he was fired, though he didn't respond when asked for further clarification.

Despite losing his job, Crabill said he still believes AI has the power to make lawyers more productive. He has started his own company that offers legal services through AI.

Advertisement

"I still use ChatGPT in my day-to-day, much like most people use Google on the job," Crabill said.

Baker Law Group didn't respond to Insider's request for comment before publication.

Crabill's ChatGPT snafu isn't the first time lawyers used AI to the detriment of their employer, clients, or their jobs. In June, a New York law firm was fined $5,000 because one its lawyers used ChatGPT to write a court brief that referenced nonexistent cases and opinions.

Workers in other industries, too, claim they are being let go for using AI on the job.

Advertisement

In June, Tina Sendin, a marketing professional, claimed she got fired by a client after she used an AI writing tool to generate articles.. A Colorado lawyer has been suspended for a year for using an AI chatbot to draft a legal document.

A judge ordered Zachariah Crabill to a one year and one day suspension after Crabill allegedly "cited case law that he found through the artificial intelligence platform ChatGPT" to to draft a motion in a civil case in May. The platform them produced cases that were incorrect and fictitious.

Crabill allegedly did not alert the court to the existence of the incorrect cases after he filed the motion. He also did not withdraw the motion.

A ruling handed down notes that when the judge asked Crabill about possible inaccuracies, Crabill attributed the mistakes to a legal intern. Six days after the hearing, he filed an affidavit explaining that he used the platform when he drafted the motion.

The presiding judge noted that Crabill violated several of the Colorado Bar Association's Rules of Professional Conduct. If he successfully completes a 90-day suspension and two subsequent years of probation, the rest of the year suspension will be forgiven.