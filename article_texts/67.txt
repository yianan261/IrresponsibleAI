Redwood City California Highway Patrol stopped a Tesla Model 3 they suspected was running Autopilot with a drunk driver asleep at the wheel. The incident occurred last Friday, November 30th at 3:37AM PT, when officers observed a car going 70 mph on Highway 101 with a driver that appeared to be asleep.

After flashing their lights and sirens in an attempt to pull the car over, the officers deployed a strategy based around their assumption that the Tesla Model 3 was running on Autopilot. According to the CHP incident report, two unit cars pulled up in front and behind the Tesla to get the car to gradually come to a stop, after a seven-mile chase. A statement from the CHP reads, “We cannot confirm at this time if the “driver assist” feature was activated but considering the vehicle’s ability to slow to a stop when [the driver] was asleep, it appears the “driver assist” feature may have been active at the time.”

It’s difficult to determine whether Autopilot was actually on at the time, as the feature requires drivers to keep a firm grip on the steering wheel for it to stay engaged. It’s possible that the driver may have had another Tesla Model 3 feature on, like Traffic Aware Cruise Control, which manages speed against the car in front of the Tesla.

it’s not confirmed whether it was actually on autopilot

It’s not clear which exact feature was engaged, as Teslas have several different autonomous driving features and it can be confusing to keep track of all of them. Most people, even cops and some Tesla drivers, aren’t totally sure what Teslas can do. Tesla warns that Autopilot is only meant to be used on highways, and still requires the driver to remain fully alert while driving, but cases like these show that drivers will continue to abuse Autopilot features and misinterpret them as “self-driving.”. A TESLA driver was arrested in California after police found the motorist asleep behind the wheel at 70mph.

A California Highway Patrol officer spotted the Tesla Model S driver out for the count along a highway south of San Francisco, and was unable to stir the driver from his slumber with flashing lights or sirens.

Assuming the Tesla’s semi-autonomous “Autopilot” driver aids were turned on, the police positioned squad cars either side and ahead of the Model S, and slowed down to simulate a traffic jam, bringing the dormant driver’s electric saloon to a complete stop safely.

After waking the driver up, police conducted a breathalyser test on the man, where they found he was above the drink drive limit. He was then charged with driving under the influence of alcohol and arrested.

This isn’t the first time this year the California Highway Patrol have encountered a drowsy Tesla driver. In January 2018, officers arrested a different man who fell asleep in his Model S on the San Francisco-Oakland Bay Bridge, and was later found to be over twice the drink drive limit.

When u pass out behind the wheel on the Bay Bridge with more than 2x legal alcohol BAC limit and are found by a CHP Motor. Driver explained Tesla had been set on autopilot. He was arrested and charged with suspicion of DUI. Car towed (no it didn’t drive itself to the tow yard). pic.twitter.com/4NSRlOBRBL — CHP San Francisco (@CHPSanFrancisco) 19 January 2018

In July 2018, the UK car safety body Thatcham Research called out the “deeply unhelpful” names that some car makers give their driver aids, and highlighted systems such as Tesla’s Autopilot for potentially “lulling drivers into a false sense of security”.

Tweet to @J_S_Allen Follow @J_S_Allen. "When a pair of California Highway Patrol officers pulled alongside a car cruising down Highway 101 in Redwood City before dawn Friday, they reported a shocking sight: a man fast asleep behind the wheel," reports the San Francisco Chronicle:Tesla declined to comment on the incident, but John Simpson, privacy/technology project director for Consumer Watchdog, calls this proof that Tesla has wrongly convinced drivers their cars' "autopilot" function really could perform fully autonomous driving..."They've really unconscionably led people to believe, I think, that the car is far more capable of self-driving than actually is the case. That's a huge problem.". As technology advances, so must policing. Last week, when a couple of California Highway Patrol officers spotted a man apparently sleeping in the driver’s seat of a Tesla Model S going 70 mph down Highway 101 in Palo Alto around 3:30 am, they moved behind the car and turned on their siren and lights. When the driver didn’t respond, the cops went beyond their standard playbook. Figuring the Tesla might be using Autopilot, they called for backup to slow traffic behind them, then pulled in front of the car and gradually started braking. And so the Tesla slowed down, too, until it was stopped in its lane.

“Our officers’ quick thinking got the vehicle to stop,” says CHP public information officer Art Montiel. The officers arrested the driver, identified in a police report as 45-year-old Alexander Joseph Samek of Los Altos, for driving under the influence of alcohol.

Neither the cops nor Tesla has confirmed whether the Model S had Autopilot engaged at the time. It seems likely it was, though, since the vehicle was staying in its lane and responding to vehicles around it, even though its driver didn’t wake up until the cops knocked on his window.

LEARN MORE The WIRED Guide to Self-Driving Cars

Tesla clearly tells its customers who pay the extra $5,000 for Autopilot that they are always responsible for the car’s driving, and that they must remain vigilant at all times. Driving drunk is illegal. And the vehicle’s sorta-self-driving tech may have prevented a crash. But if Autopilot did allow a slumbering and allegedly drunk driver to speed down the highway, it brings up another question: Is Elon Musk’s car company doing enough to prevent human abuse of its technology?

It’s long-standing but still-relevant criticism. Last year, a National Transportation Safety Board investigation into the 2016 death of an Ohio man whose Tesla hit a semi-truck while Autopilot was engaged concluded that Tesla bore some of the blame. When the oncoming truck turned across the path of the Tesla, the sedan didn’t slow down until impact. “The combined effects of human error and the lack of sufficient system controls resulted in a fatal collision that should not have happened,” NTSB Chairman Robert Sumwalt said at the time.

Since then, Tesla has restricted how long a driver can go without touching the steering wheel before the receiving a warning beep. If they don’t respond, the system will eventually direct the car to stop and hit its hazard lights. That makes this incident a bit confusing, as Musk noted in a tweet: