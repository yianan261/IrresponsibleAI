Michael Cohen, a former fixer and lawyer for former president Donald Trump, said in a new court filing that he unknowingly gave his attorney bogus case citations after using artificial intelligence to create them as part of a legal bid to end his probation on tax evasion and campaign finance violation charges.

According to the filing, which was unsealed Friday, Cohen said he used Google Bard, an AI chatbot, to generate case citations that his lawyer could use to assist in making the case to shorten his supervised release. He pleaded guilty to the crimes in 2018 and had served time in prison.

Cohen said he gave those citations to one of his attorneys, David M. Schwartz, who then used them in a motion filed with a U.S. federal judge on Cohen’s behalf, the filing said.

Cohen’s admission comes after U.S. District Judge Jesse Furman of the Southern District of New York said in a Dec. 12 order that he could not find any of the three cases cited by Schwartz and asked for a “thorough explanation” of how these cases came to be included and “what role, if any” Cohen may have played in the motion before it was filed.

Advertisement

In the filing, Cohen wrote that he had not kept up with “emerging trends (and related risks) in legal technology and did not realize that Google Bard was a generative text service that, like ChatGPT, could show citations and descriptions that looked real but actually were not.” To him, he said, Google Bard seemed to be a “supercharged search engine.”

Share this article Share

Cohen added that at no point did Schwartz or his paralegal “raise any concerns about the citations” he had suggested. “It did not occur to me then — and remains surprising to me now — that Mr. Schwartz would drop the cases into his submission wholesale without even confirming they had existed,” Cohen wrote.

Schwartz did not immediately return a request for comment.

The episode comes as Cohen is expected to play a prominent role in a Manhattan criminal case against Trump. It is also an indication of how common AI is becoming in legal case work, as a new generation of AI language tools make their way into the legal industry.

Advertisement

According to Cohen’s filing, the mistake was caught by E. Danya Perry, a former federal prosecutor who is now representing Cohen in his effort to cut short his probation. Cohen said Schwartz made an “honest mistake,” and Perry has provided real case citations that make the case for why Cohen’s probation should be terminated.. . . Michael Cohen was looking for cases to back up his legal claim, so he turned to Google's AI chatbot, Bard.

But the cases were bogus.

Cohen's lawyer never checked that the cases actually existed before mentioning them in court.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Advertisement

The latest victim of an AI screw-up? Donald Trump's former fixer Michael Cohen and his lawyer.

Cohen admitted in a sworn statement in a Manhattan federal court case that he used Google Bard, a generative AI chatbot similar to ChatGPT, to find legal cases backing up his arguments for why he should be let loose early from his supervised release.

But Cohen didn't realize a key AI pitfall: sometimes, it just makes stuff up.

Cohen wrote that he misunderstood Google Bard as a search engine, not a generative AI service like ChatGPT, and that he trusted his lawyer to verify the cases.

Advertisement

"I understood it to be a super charged search engine and had repeatedly used it in other contexts to (successfully) find accurate information online," Cohen wrote. "I did not know that Google Bard could generate non-existent cases."

Cohen fed Bard's hallucinated results to his lawyer at the time, David Schwartz, who included three of them in his November 29 filing without checking that the cases were actually legit, according to the court papers.

The Friday legal filing was first reported by Inner City Press' Matthew Russell Lee.

Related stories

Cohen, in the court documents, deflects the blame on his lawyer for not double-checking what he sent.

Advertisement

"It did not occur to me then— and remains surprising to me now—that Mr. Schwartz would drop the cases into his submission wholesale without even confirming that they existed," Cohen wrote in the filing.

Cohen pleaded guilty in 2018 to campaign finance violations and served time in prison before he was placed on supervised release.

The court filings had argued that he complied with all the terms of release and that his supervision should now end.

US District Judge Jesse Furman, who's overseeing the case, asked Schwartz "to explain why he should not be sanctioned for citing cases that appear not to exist," leading to Cohen explaining his side of the story.

Advertisement

Schwartz, in his own court filing, said he included the hallucinated cases as citations because he wrongly understood them to come from another one of Cohen's attorneys, Danya Perry, rather than Cohen himself. Perry is still working to try to end Cohen's supervised release and says he should not suffer for his lawyer's alleged misstep.

The incident could have consequences for one of the criminal cases against former President Donald Trump.

Cohen is expected to be a star witness in the Manhattan District Attorney's case against Trump, alleging he falsified business documents to cover up hush money payments to Stormy Daniels ahead of the 2016 election.

Trump and his attorneys have long argued that Cohen could not be trusted, given his criminal history, which also resulted in him losing his own legal license. With the AI snafu, they may have yet another example to bring in front of a jury to try to discredit him.. Michael Cohen, a former lawyer for Donald Trump, confessed to mistakenly giving his attorney incorrect case citations created by the artificial intelligence (AI) chatbot Google Bard.

In a recent court filing, Cohen, who is set to be a witness against Trump in his upcoming criminal trials, admitted to sending Google Bard-generated legal citations to his lawyer, David Schwartz, in support of his case.

“The invalid citations at issue — and many others that Mr. Cohen found but were not used in the motion — were produced by Google Bard, which Mr. Cohen misunderstood to be a supercharged search engine, not a generative AI service like Chat-GPT.”

United States v. Michael Cohen. Source: Reuters

However, it was argued that Cohen is not an active legal professional and was only passing on the information to his attorney, suggesting the information should have been reviewed before being included in official court documents.

“Mr. Cohen is not a practicing attorney and has no concept of the risks of using AI services for legal research, nor does he have an ethical obligation to verify the accuracy of his research,” the statement further stated, reiterating further review was required:

“To summarize: Mr. Cohen provided Mr. Schwartz with citations (and case summaries) he had found online and believed to be real. Mr. Schwartz added them to the motion but failed to check those citations or summaries.”

Related: Searches for ‘AI’ on Google smashes Bitcoin and crypto this year

This isn’t the first instance of a lawyer being exposed for relying on AI, only to realize it generated inaccurate results.

Earlier this year, Cointelegraph reported that Steven Schwartz, an attorney with the New York law firm Levidow, Levidow & Oberman, faced criticism for using AI in creating what turned out to be false court citations.

Despite Schwartz claiming it was his first time using ChatGPT for legal research, the judge strongly critiqued him for the inaccuracies.

“Six of the submitted cases appear to be bogus judicial decisions with bogus quotes and bogus internal citations,” the judge stated.

Magazine: Top AI tools of 2023, weird DEI image guardrails, ‘based’ AI bots: AI Eye. Donald Trump’s former “fixer,” Michael Cohen, used Google Bard to cite made-up legal cases that ended up in a federal court. The New York Times reported Friday that Cohen admitted in unsealed court papers that he passed on documents referencing bogus cases to his lawyer, who then relayed them to a federal judge. Cohen reportedly wrote in the sworn declaration he hadn’t stayed on top of “emerging trends (and related risks) in legal technology.”

Cohen’s legal team filed the paperwork in a motion asking for an early end to court supervision from his 2018 campaign finance case, for which he served three years in prison. After Cohen’s attorney, David M. Schwartz, presented the legal documents to the federal court, Judge Jesse M. Furman of the Federal District Court said he was having trouble finding the three decisions cited by Schwartz (via Cohen).

Judge Furman told Schwartz that if he couldn’t provide documentation of the cases, the attorney needed to provide “a thorough explanation of how the motion came to cite cases that do not exist and what role, if any, Mr. Cohen played in drafting or reviewing the motion before it was filed.” Schwartz must also explain why he shouldn’t be sanctioned “for citing nonexistent cases to the court.” Cohen is a former lawyer who was disbarred after pleading guilty to multiple felonies.

ADVERTISEMENT

Enter Bard. Cohen said he didn’t realize the AI bot “was a generative text service that, like ChatGPT, could show citations and descriptions that looked real but actually were not.” Cohen also blamed his lawyer, saying he didn’t realize Schwartz “would drop the cases into his submission wholesale without even confirming that they existed.”

Although lawyers using AI chatbots to cite hallucinated cases makes for easy comedy, this flub could have profound implications for a critical case with potential political ramifications. Cohen is expected to be the star witness in the Manhattan criminal case against Trump for allegedly falsifying business records. The Bard flub gives Trump’s lawyers new ammunition to discredit the onetime fixer.

Cohen joins the company of ChatGPT Lawyer Steven Schwartz, who cited made-up cases (sourced through OpenAI’s chatbot) in a civil case earlier this year. He was allegedly joined by the attorney for Fugees rapper Pras Michel. In October, the artist accused his lawyer of using an AI program he may have had a financial stake in to produce his closing arguments.. Soon after news of lawyers using ChatGPT to supercharge legal research but ending up with a disaster gripped the media, Google Bard is emerging as a second option. In the latest move, Michael Cohen, the former lawyer of Donald Trump, had acknowledged that he cited AI-generated fake cases in a legal document, according to The New York Times.

The filing said Cohen used California-based tech giant's AI model Bard for research and assumed it to be a "super-charged search engine" and not an AI tool. The document was a motion to ask the federal judge to reduce the length of Cohen's probation, The Verge noted. After scanning the brief, US District Judge Jesse Furman observed that "none of these cases exist" and demanded an explanation from David Schwartz, Cohen's lawyer.

Also Read: AI News: ChatGPT Cites Non-existent Cases, Lands Lawyer In Trouble; Full Story Here

As a response, Cohen admitted in writing that he used Google's ChatGPT rival for legal research and shared findings with his lawyer, but the purpose was not to mislead the court. Cohen added that he was not aware these cases may be fake, and his lawyer would add them without any background check.

Tech companies and experts have cautioned about the accuracy of the information shared by AI models at regular intervals. (Image:Unsplash)

"As a non-lawyer I have not kept up with emerging trends (and related risks) in legal technology and did not know that Google Bard was a generative text service that, like Chat-GPT, could show citations and descriptions that looked real but actually were not," Cohen stated.

Also Read: ChatGPT Falsely Accuses Law Professor Of Sexual Harassment, He Calls It 'Quite Chilling'

He added that he used Bard repeatedly (in the past) in other contexts to find accurate information. This is not the first time instances of AI citing non-existent cases have floated in the media. Top companies (including OpenAI and Google) competing in the AI space and experts have cautioned about the accuracy of the information shared by the models at regular intervals.

The output from these must be verified via human review to assign them the legitimate tag. Meanwhile, a Radio host filed a lawsuit against OpenAI's viral ChatGPT model for framing false defamation charges. Moreover, in another instance, the language model falsely accused a law professor of sexual harassment. These cases serve as a stark reminder of the limitations of the evolving technology.. The former Trump attorney pleaded guilty to campaign finance violations in 2018.

Former President Donald Trump's onetime fixer Michael Cohen sent his attorney non-existent legal cases produced by the artificial intelligence program Google Bard as he sought to beef up his petition for early termination of his supervised release, according to a letter to the court made public Friday.

Cohen, who pleaded guilty to campaign finance violations in 2018, sought an early end to his term of supervised release in a motion that included three cases he believed backed up his argument. His lawyer said Cohen mistakenly believed Google Bard "to be a supercharged search engine, not a generative AI service like Chat-GPT."

That the invalid citations were included in Cohen's motion his attorney insisted "was a mistake driven by sloppiness, not malicious intent" but Judge Jesse Furman is now considering whether to impose sanctions.

Michael Cohen, former personal lawyer to President Donald Trump, arrives at New York State Supreme Court, Oct. 25, 2023, in New York. Stephanie Keith/Bloomberg via Getty Images, FILE

"As a non-lawyer, I have not kept up with emerging trends (and related risks) in legal technology and did not realize that Google Bard was a generative text service that, like ChatGPT, could show citations and descriptions that looked real but actually were not," Cohen said in a sworn statement to the court made public Friday.

In his own letter to the court, Cohen's attorney David M. Schwartz said he believed the legal citations came from a different attorney for Cohen, Danya Perry.

"If I had believed that Mr. Cohen had found these cases, I would have researched them. It was my belief, however, that Mr. Cohen had sent me cases found by Ms. Perry," Schwartz said.

Judge Furman gave all parties until January 3 to submit additional comments about possible sanctions and whether Cohen deserves early termination of supervised release.. Michael Cohen, the former lawyer for Donald Trump, admitted to citing fake, AI-generated court cases in a legal document that wound up in front of a federal judge, as reported earlier by The New York Times. A filing unsealed on Friday says Cohen used Google’s Bard to perform research after mistaking it for “a super-charged search engine” rather than an AI chatbot.

The document in question was a motion that asked a federal judge to shorten the length of Cohen’s three-year probation, which he’s now facing following prison time and a guilty plea to tax evasion and other charges. But after reviewing the letter brief, US District Judge Jesse Furman wrote in a filing that “none of these cases exist” and asked Cohen’s lawyer, David Schwartz, to explain why the three cases are included in the motion as well as whether his now-disbarred client helped draft it.

In response, Cohen submitted a written statement saying he didn’t intend to mislead the court, adding that he used Google Bard to do legal research and sent some of his findings to Schwartz. However, Cohen says he didn't realize the cases cited by Bard had the potential to be fake, nor did he think Schwartz would add the citations to the motion “without even confirming that they existed.” Schwartz facing potential sanctions for including the phony citations.

“As a non-lawyer I have not kept up with emerging trends (and related risks) in legal technology”. Sign up for the daily Inside Washington email for exclusive US coverage and analysis sent to your inbox Get our free Inside Washington email Please enter a valid email address Please enter a valid email address SIGN UP I would like to be emailed about offers, events and updates from The Independent. Read our privacy notice Thanks for signing up to the

Inside Washington email {{ #verifyErrors }} {{ message }} {{ /verifyErrors }} {{ ^verifyErrors }} Something went wrong. Please try again later {{ /verifyErrors }}

Michael Cohen, Donald Trump’s one-time lawyer and “fixer” used Google Bard, the artificial intelligence program, to provide his lawyer with fictitious legal citations, according to newly unsealed court papers.

The fake citations were then included in a motion filed with a Manhattan federal judge to argue for an early end to Cohen’s court supervision having been released from prison for campaign finance violation charges that he pleaded guilty to in 2018.

Cohen explained in a sworn declaration released on Friday (29 December) that he had not kept abreast of “emerging trends (and related risks) in legal technology and did not realize that Google Bard was a generative text service that, like ChatGPT, could show citations and descriptions that looked real but actually were not”.

He added that he also didn’t realise that his lawyer, David Schwartz, “would drop the cases into his submission wholesale without even confirming that they existed”.

The existence of the bogus case citations came to light in mid-December when Judge Jesse Furman asked Mr Schwartz to provide the court with copies of them having found that as far as he could tell, “none of these cases exist”.

Donald Trump’s former attorney Michael Cohen at former president’s fraud trial in New York ( AFP via Getty Images )

Judge Furman wrote: “Moreover, the Court contacted the Clerk of the Court for the United States Court of Appeals for the Second Circuit, who found no record of any of the three decisions and reported that the one listed docket number ... is not a valid docket number.”

Cohen’s new lawyer, Danya Perry, also told the court that she could not find the court cases cited.

There are wider implications to this embarrassing episode for Cohen.

The former Trump confidant is expected to be the star witness in the Manhattan criminal case against the former president for the hush-money payments to adult film star Stormy Daniels.

Mr Trump’s legal team — as well as the former president himself — have long portrayed Cohen as a liar and serial fabulist, and mocked his performance on the stand for the plaintiffs in the New York state Trump Organization civil fraud trial.

The new revelation that both Cohen and his lawyer submitted fictitious citations provided by a free AI program will only add ammunition to their attacks and attempts to undermine his credibility on the witness stand.

This is not the first time this year a Manhattan court has had to deal with bogus legal citations generated by AI.

In June, two apologetic lawyers responding to an angry judge in federal court blamed ChatGPT for tricking them into including fictitious legal research in a court filing.

Attorneys Steven Schwartz and Peter LoDuca submitted a filing in a lawsuit against an airline that included references to past court cases that Mr Schwartz thought were real but were actually invented by the AI chatbot.

Mr Schwartz explained that he used the groundbreaking program as he hunted for legal precedents supporting a client’s case against the Colombian airline Avianca for an injury incurred on a 2019 flight.

Included in the relevant court decisions were Martinez v Delta Air Lines, Zicherman v Korean Air Lines, and Varghese v China Southern Airlines.

As with the Cohen case, the problem was that several of the cases weren’t real and others involved airlines that didn’t exist.

The Manhattan criminal case against Mr Trump is currently scheduled to go to trial on 25 March 2024.. 