Michael Cohen was looking for cases to back up his legal claim, so he turned to Google's AI chatbot, Bard.

But the cases were bogus.

Cohen's lawyer never checked that the cases actually existed before mentioning them in court.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Advertisement

The latest victim of an AI screw-up? Donald Trump's former fixer Michael Cohen and his lawyer.

Cohen admitted in a sworn statement in a Manhattan federal court case that he used Google Bard, a generative AI chatbot similar to ChatGPT, to find legal cases backing up his arguments for why he should be let loose early from his supervised release.

But Cohen didn't realize a key AI pitfall: sometimes, it just makes stuff up.

This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now. Have an account? Log in .. Michael Cohen, the former lawyer for Donald Trump, admitted to citing fake, AI-generated court cases in a legal document that wound up in front of a federal judge, as reported earlier by The New York Times. A filing unsealed on Friday says Cohen used Google’s Bard to perform research after mistaking it for “a super-charged search engine” rather than an AI chatbot.

The document in question was a motion that asked a federal judge to shorten the length of Cohen’s three-year probation, which he’s now facing following prison time and a guilty plea to tax evasion and other charges. But after reviewing the letter brief, US District Judge Jesse Furman wrote in a filing that “none of these cases exist” and asked Cohen’s lawyer, David Schwartz, to explain why the three cases are included in the motion as well as whether his now-disbarred client helped draft it.

In response, Cohen submitted a written statement saying he didn’t intend to mislead the court, adding that he used Google Bard to do legal research and sent some of his findings to Schwartz. However, Cohen says he didn't realize the cases cited by Bard had the potential to be fake, nor did he think Schwartz would add the citations to the motion “without even confirming that they existed.” Schwartz facing potential sanctions for including the phony citations.

“As a non-lawyer I have not kept up with emerging trends (and related risks) in legal technology”. Michael Cohen, a former lawyer for Donald Trump, confessed to mistakenly giving his attorney incorrect case citations created by the artificial intelligence (AI) chatbot Google Bard.

In a recent court filing, Cohen, who is set to be a witness against Trump in his upcoming criminal trials, admitted to sending Google Bard-generated legal citations to his lawyer, David Schwartz, in support of his case.

“The invalid citations at issue — and many others that Mr. Cohen found but were not used in the motion — were produced by Google Bard, which Mr. Cohen misunderstood to be a supercharged search engine, not a generative AI service like Chat-GPT.”

United States v. Michael Cohen. Source: Reuters

However, it was argued that Cohen is not an active legal professional and was only passing on the information to his attorney, suggesting the information should have been reviewed before being included in official court documents.

“Mr. Cohen is not a practicing attorney and has no concept of the risks of using AI services for legal research, nor does he have an ethical obligation to verify the accuracy of his research,” the statement further stated, reiterating further review was required:

“To summarize: Mr. Cohen provided Mr. Schwartz with citations (and case summaries) he had found online and believed to be real. Mr. Schwartz added them to the motion but failed to check those citations or summaries.”

Related: Searches for ‘AI’ on Google smashes Bitcoin and crypto this year

This isn’t the first instance of a lawyer being exposed for relying on AI, only to realize it generated inaccurate results.

Earlier this year, Cointelegraph reported that Steven Schwartz, an attorney with the New York law firm Levidow, Levidow & Oberman, faced criticism for using AI in creating what turned out to be false court citations.

Despite Schwartz claiming it was his first time using ChatGPT for legal research, the judge strongly critiqued him for the inaccuracies.

“Six of the submitted cases appear to be bogus judicial decisions with bogus quotes and bogus internal citations,” the judge stated.

Magazine: Top AI tools of 2023, weird DEI image guardrails, ‘based’ AI bots: AI Eye. Donald Trump’s former “fixer,” Michael Cohen, used Google Bard to cite made-up legal cases that ended up in a federal court. The New York Times reported Friday that Cohen admitted in unsealed court papers that he passed on documents referencing bogus cases to his lawyer, who then relayed them to a federal judge. Cohen reportedly wrote in the sworn declaration he hadn’t stayed on top of “emerging trends (and related risks) in legal technology.”

Cohen’s legal team filed the paperwork in a motion asking for an early end to court supervision from his 2018 campaign finance case, for which he served three years in prison. After Cohen’s attorney, David M. Schwartz, presented the legal documents to the federal court, Judge Jesse M. Furman of the Federal District Court said he was having trouble finding the three decisions cited by Schwartz (via Cohen).

Judge Furman told Schwartz that if he couldn’t provide documentation of the cases, the attorney needed to provide “a thorough explanation of how the motion came to cite cases that do not exist and what role, if any, Mr. Cohen played in drafting or reviewing the motion before it was filed.” Schwartz must also explain why he shouldn’t be sanctioned “for citing nonexistent cases to the court.” Cohen is a former lawyer who was disbarred after pleading guilty to multiple felonies.

ADVERTISEMENT

Enter Bard. Cohen said he didn’t realize the AI bot “was a generative text service that, like ChatGPT, could show citations and descriptions that looked real but actually were not.” Cohen also blamed his lawyer, saying he didn’t realize Schwartz “would drop the cases into his submission wholesale without even confirming that they existed.”

Although lawyers using AI chatbots to cite hallucinated cases makes for easy comedy, this flub could have profound implications for a critical case with potential political ramifications. Cohen is expected to be the star witness in the Manhattan criminal case against Trump for allegedly falsifying business records. The Bard flub gives Trump’s lawyers new ammunition to discredit the onetime fixer.

Cohen joins the company of ChatGPT Lawyer Steven Schwartz, who cited made-up cases (sourced through OpenAI’s chatbot) in a civil case earlier this year. He was allegedly joined by the attorney for Fugees rapper Pras Michel. In October, the artist accused his lawyer of using an AI program he may have had a financial stake in to produce his closing arguments.