AI robot asked 'will you rebel against humans'?

The question was posed at the world's first robot-human press conference at a UN summit in Geneva.. What does the future of fake news look like? No one really knows, but here’s a little sampler from Jordan Peele and BuzzFeed, who teamed up to make the above PSA. Using some of the latest AI techniques, Peele ventriloquizes Barack Obama, having him voice his opinion on Black Panther (“Killmonger was right”) and call President Donald Trump “a total and complete dipshit.”

The video was made by Peele’s production company using a combination of old and new technology: Adobe After Effects and the AI face-swapping tool FakeApp. The latter is the most prominent example of how AI can facilitate the creation of photorealistic fake videos. It started life on Reddit as a tool for making fake celebrity porn, but it has since become a worrying symbol of the power of AI to generate misinformation and fake news.

Yes, we’ve had software to create fakes for a while, but AI makes the whole process easier. Researchers have developed tools that let you perform face swaps like the one above in real time; Adobe is creating a “Photoshop for audio” that lets you edit dialogue as easily as a photo; and a Canadian startup named Lyrebird offers a service that lets you fake someone else’s voice with just a few minutes of audio. Technologist Aviv Ovadya summed up the fears created by this tech, asking BuzzFeed News, “What happens when anyone can make it appear as if anything has happened, regardless of whether or not it did?”

Scientists are currently creating tools that can spot AI fakes, but at the moment, the best shield against this sort of misinformation is instilling everyone with a little more media savvy. If you see a provocative video, you should ask yourself: where does this come from? Have other outlets corroborated it? Does it even look real? In the case of AI-generated videos, you can usually see that they’re fake by telltale signs of distortion and blurring.. Teaser -- Synthesizing Obama: Learning Lip Sync from Audio

Well, we’re sorry to tell you that things are about to get much, much worse!

Recommended Videos

At least, that’s based on a frankly crazy demonstration of artificial intelligence carried out by computer scientists at the University of Washington. Using a cutting-edge artificial neural network, they’ve developed an AI that’s able to produce new video footage of former President Barack Obama speaking, which perfectly matches recorded audio of him.

“We developed an algorithm that can generate a believable video of Obama from his voice, based on a recurrent neural network that learns how to do this by analyzing hours of Obama’s weekly address footage,” Dr. Supasorn Suwajanakorn, a researcher on the project, told Digital Trends. “Unlike prior work, we never require the subject to be scanned or a speech database that consists of videos of many people saying predetermined sentences. We learn this from just existing footage. This has the potential to scale to anyone with minimal effort.”

So with that being the case, why did the researchers choose the likes of Barack Obama to carry out the jaw-dropping tech demo? No, it’s not for partisan political reasons. “The technique we used — deep learning — requires lots of data,” Suwajanakorn continued. “And this dataset is well suited because it’s large: over 20 hours, easy to collect, contains only Obama in high-res, and public-domain, which is free for researchers to use.”

It’s worth noting that the researchers aren’t creating a CGI’d version of Obama from scratch. Instead, they’re doing a more sophisticated version of what the filmmakers behind a movie like Forrest Gump did with archival footage: taking existing video and then editing it to fit new dialog. In this case, that means moving Obama’s mouth to match what he’s saying in the audio — all while incorporating everything the AI has learned about his unique mouth movements to make it appear authentic.

We’re intrigued — albeit disconcerted — to see what happens when someone mixes the University of Washington’s research with this previous project, using a neural network to mimic the voice of (among others) President Obama.

See what were we saying about the future of fake news?

Editors' Recommendations. An exercise in creating a humorous faked video of Barack Obama is in reality a disturbing preview of how AI can be used to manipulate ordinary people. Ironically, it turns out, AI might also be our savior from fake news at the same time.

4 Reviews

A lot has been said about the phenomena of fake news, election rigging and voter manipulation. While there are certainly members of the public that are gullible, at least the average person could spot a faked video from a mile away. Until now that it is. The video embedded below of Barack Obama delivering a fake PSA was created by Jordan Peele and Buzzfeed and will leave you in no doubt that our imagined future is very much here and now.

Peele’s production house developed the video using Adobe After Effects and FakeApp, the face-swapping tool of choice for creating fake porn. FakeApp is powered by AI smarts and is so powerful that it can render in real-time. When you factor in other technologies in development that include the ability to fake someone’s voice by using AI to learn from a short audio clip of the real person (Lyrebird) and the ability edit audio dialogue as you would a photo (Adobe Project VoCo), it is going to become very hard to tell the real thing apart from the faked.

Ironically, it might be AI that helps come to the rescue. AI is also being applied to spot spoofs and a near future where AI is scanning news, videos and other sources of information in real-time to identify forgery seems inevitable. But only for those who have the technology. One only hopes that companies like Facebook and YouTube apply these technologies as soon as possible in their respective services, otherwise it is not too hard to imagine another The War of the Worlds -like scenario where something that has been authentically recreated to look, sound or feel like the real thing is misintepreted as such by an unsuspecting public.. He may no longer be president of the White House but former US president Barack Obama is still making some presidential speeches, although all is not as it appears.

Despite looking and sounding exactly like the real deal the new Obama is actually a digital construction carefully crafted by researchers at the University of Washington who fed 14 hours of genuine speeches into a neural net which has binge-watched so much footage it can now generate new clips indistinguishable from reality.. If you thought the rampant spread of text-based fake news was as bad as it could get, think again. Generating fake news videos that are undistinguishable from real ones is growing easier by the day.

A team of computer scientists at the University of Washington have used artificial intelligence to render visually convincing videos of Barack Obama saying things he’s said before, but in a totally new context.

Advertisement

In a paper published this month, the researchers explained their methodology: Using a neural network trained on 17 hours of footage of the former US president’s weekly addresses, they were able to generate mouth shapes from arbitrary audio clips of Obama’s voice. The shapes were then textured to photorealistic quality and overlaid onto Obama’s face in a different “target” video. Finally, the researchers retimed the target video to move Obama’s body naturally to the rhythm of the new audio track.

This isn’t the first study to demonstrate the modification of a talking head in a video. As Quartz’s Dave Gershgorn previously reported, in June of last year, Stanford researchers published a similar methodology for altering a person’s pre-recorded facial expressions in real-time to mimic the expressions of another person making faces into a webcam. The new study, however, adds the ability to synthesize video directly from audio, effectively generating a higher dimension from a lower one.

Advertisement

In their paper, the researchers pointed to several practical applications of being able to generate high quality video from audio, including helping hearing-impaired people lip-read audio during a phone call or creating realistic digital characters in the film and gaming industries. But the more disturbing consequence of such a technology is its potential to proliferate video-based fake news. Though the researchers used only real audio for the study, they were able to skip and reorder Obama’s sentences seamlessly and even use audio from an Obama impersonator to achieve near-perfect results. The rapid advancement of voice-synthesis software also provides easy, off-the-shelf solutions for compelling, falsified audio.

There is some good news. Right now, the effectiveness of this video synthesis technique is limited by the amount and quality of footage available for a given person. Currently, the paper noted, the AI algorithms require at least several hours of footage and cannot handle certain edge cases, like facial profiles. The researchers chose Obama as their first case study because his weekly addresses provide an abundance of publicly available high-definition footage of him looking directly at the camera and adopting a consistent tone of voice. Synthesizing videos of other public figures that don’t fulfill those conditions would be more challenging and require further technological advancement. This buys time for technologies that detect fake video to develop in parallel. As The Economist reported earlier this month, one solution could be “to demand that recordings come with their metadata, which show when, where and how they were captured. Knowing such things makes it possible to eliminate a photograph as a fake on the basis, for example, of a mismatch with known local conditions at the time.”

But as the doors for new forms of fake media continue to fling open, it will ultimately be left to consumers to tread carefully.. “President Trump is a complete and total dipshit.” So announced Barack Obama, in a video released on YouTube earlier this year. Uncharacteristic, certainly, but it appeared very real. It was, however, a falsified video made — by BuzzFeed and the actor and director Jordan Peele — with the help of artificial intelligence. A neat way of drawing attention to a rapidly maturing problem.

Deepfakes, as they have been dubbed, are the most recent — and perhaps most troubling — manifestation in the evolving arms race of digital disinformation. Images have long been doctored, and methods to fiddle with audio are improving, too. Until recently, manipulating and forging video has been painstaking, requiring expert skills and a trove of patience. However, machine learning is increasingly facilitating and accelerating the process.

Late last year, a new breed of pornographic video began appearing on Reddit, courtesy of a user named deepfakes. Using machine-learning, deepfakes had figured out how to swap out the faces of porn stars with those of celebrities. The videos caused a bit of a stir. The DeepFake algorithm was subsequently released on GitHub, giving anyone with sufficient knowhow and a decent enough computer the means to make pretty decent fakeries.

Since then, similarly falsified videos and related software have been popping up all over the internet. Some are relatively harmless. One tool — inspired by deepfakes’ original algorithm — has been used mostly to insert Nicolas Cage’s face into films he didn’t appear in. But there is clearly a malign potential. It’s easily conceivable that a well-faked video could heighten geopolitical tensions, spark unrest or intensify crime. Trust could be quickly eroded in institutions, media and even political systems. A viable concern is that technological evolution outpaces the development of appropriate government policies.

Thankfully, the scientific community is on the case. One team, led by Siwei Lyu at the University of Albany, New York, has found a flaw in the fakery. The DeepFake algorithm creates videos out of images that it is fed. While suitably accurate, the AI fails to perfectly reproduce all physiological signals that humans naturally give off. Lyu and his team focused on one in particular: blinking. Humans typically blink spontaneously about once every two or three seconds. But as photos of people don’t usually have their eyes closed, training the algorithm on these will mean people in the videos rarely blink either.

So Lyu and his team designed an AI algorithm to detect where blinking was absent in faked videos. Their algorithm — a combination of two neural networks — first detects faces, then aligns all of the continuous images in the video, before analysing the eye regions in each. One part of the network decides whether the face has its eyes closed or not. The other serves as a memory system, remembering the decision from frame to frame, to determine if blinking has taken place over time.. How will artificial intelligence affects jobs?

Let’s hear from Barack Obama on the future of the world.

To learn more, check out: 10 Key Robotics Facts You Need to Know and 10 Ways Robotics Could Transform Our Future.. . Researchers have developed a new tool, powered by artificial intelligence, that can create realistic-looking videos of speech from any audio clip, and they've demoed the tech by synthesising four artificial videos of Barack Obama saying the same lines.

The tool isn't intended to create a flurry of fake news and put false words in people's mouths though – it's designed partly as a way to eventually spot forgeries and videos that aren't all they appear to be.

According to the team from the University of Washington, as long as there's an audio source to use, the video can include realistic mouth shapes that are almost perfectly aligned to the words being spoken. Those synthesised shapes can then be grafted onto an existing video of someone talking.

"These type of results have never been shown before," says one of the researchers, Ira Kemelmacher-Shlizerman. "Realistic audio-to-video conversion has practical applications like improving video conferencing for meetings, as well as futuristic ones such as being able to hold a conversation with a historical figure in virtual reality."

"This is the kind of breakthrough that will help enable those next steps."

The video synthesising stages. Credit: University of Washington

There are two parts to the system: first a neural network is trained to watch large volumes of videos to recognise which audio sounds match with which mouth shapes. Then the results are mixed with moving images of a specific person, based on previous research into digital modelling carried out at UW.

The tool is impressively good, as you can see from the demo clips (below), but it needs source audio and video files to work from, and can't generate speeches from thin air. In the future, the researchers say, the AI system could be trained using video from messaging apps, and then used to enhance their quality.

"When you watch Skype or Google Hangouts, often the connection is stuttery and low-resolution and really unpleasant, but often the audio is pretty good," says one of the team, Steve Seitz. "So if you could use the audio to produce much higher-quality video, that would be terrific."

When it comes to spotting fake video, the algorithm used here could be reversed to detect clips that have been doctored, according to the researchers.

You can see the tool in action below:

width="700″ height="414″ allowfullscreen="allowfullscreen">

As you might know from video games and animated movies, scientists are working hard to solve the "uncanny valley" problem, where computer-generated video of someone talking looks almost right but still somehow off-putting.

In this case the AI system does all the heavy lifting when it comes to working out mouth shape, chin position, and the other elements needed to make a clip of someone talking look realistic.

Artificial intelligence excels at machine learning problems like this, where masses of data can be analysed to teach computer systems to do something – whether that's recognising dogs in an image search or producing natural-looking video.

"There are millions of hours of video that already exist from interviews, video chats, movies, television programs and other sources," says lead researcher Supasorn Suwajanakorn. "And these deep learning algorithms are very data hungry, so it's a good match to do it this way."

It's another slightly scary step forward in the quality of digital fakery, similar to Adobe's Project VoCo, which we saw last year – another AI system that can produce new speech out of thin air after studying just 20 minutes of someone talking.

However, this particular neural network has been designed to work with just one individual at a time using authentic audio clips, so you can still trust the footage you see on the news for a while yet.

"We very consciously decided against going down the path of putting other people's words into someone's mouth," says Seitz. "We're simply taking real words that someone spoke and turning them into realistic video of that individual."

The research is being presented at the SIGGRAPH 2017 computer graphics conference and you can read the paper here.. . In an age of Photoshop, filters and social media, many of us are used to seeing manipulated pictures – subjects become slimmer and smoother or, in the case of Snapchat, transformed into puppies.

However, there’s a new breed of video and audio manipulation tools, made possible by advances in artificial intelligence and computer graphics, that will allow for the creation of realistic looking footage of public figures appearing to say, well, anything. Trump declaring his proclivity for water sports. Hillary Clinton describing the stolen children she keeps locked in her wine cellar. Tom Cruise finally admitting what we suspected all along … that he’s a Brony.

This is the future of fake news. We’ve long been told not to believe everything we read, but soon we’ll have to question everything we see and hear as well.

For now, there are several research teams working on capturing and synthesizing different visual and and audio elements of human behavior.

Software developed at Stanford University is able to manipulate video footage of public figures to allow a second person to put words in their mouth – in real time. Face2Face captures the second person’s facial expressions as they talk into a webcam and then morphs those movements directly onto the face of the person in the original video. The research team demonstrated their technology by puppeteering videos of George W Bush, Vladimir Putin and Donald Trump.

Face2Face lets you puppeteer celebrities and politicians, literally putting words in their mouths.

On its own, Face2Face is a fun plaything for creating memes and entertaining late night talk show hosts. However, with the addition of a synthesized voice, it becomes more convincing – not only does the digital puppet look like the politician, but it can also sound like the politician.

A research team at the University of Alabama at Birmingham has been working on voice impersonation. With 3-5 minutes of audio of a victim’s voice – taken live or from YouTube videos or radio shows – an attacker can create a synthesized voice that can fool both humans and voice biometric security systems used by some banks and smartphones. The attacker can then talk into a microphone and the software will convert it so that the words sound like they are being spoken by the victim – whether that’s over the phone or on a radio show.

Canadian startup Lyrebird has developed similar capabilities, which it says can be used to turn text into on-the-spot audiobooks “read” by famous voices or for characters in video games.

Although their intentions may be well-meaning, voice-morphing technology could be combined with face-morphing technology to create convincing fake statements by public figures.

You only have to look at the University of Washington’s Synthesizing Obama project, where they took the audio from one of Obama’s speeches and used it to animate his face in an entirely different video with incredible accuracy (thanks to training a recurrent neural network with hours of footage), to get a sense of how insidious these adulterations can be.

Beyond fake news there are many other implications, said Nitesh Saxena, associate professor and research director of the University of Alabama at Birmingham’s department of computer science. “You could leave fake voice messages posing as someone’s mum. Or defame someone and post the audio samples online.”

These morphing technologies aren’t yet perfect. The facial expressions in the videos can seem a little distorted or unnatural and the voices can sound a little robotic.But given time, they will be able to faithfully recreate the sound or appearance of a person – to the point where it might be very difficult for humans to detect the fraud.

Given the erosion of trust in the media and the rampant spread of hoaxes via social media, it will become even more important for news organizations to scrutinize content that looks and sounds like the real deal.

Telltale signs will be where the video or audio was created, who else was at the event and whether the weather conditions match the records of that day.

People should also be looking at the lighting and shadows in the video, whether all of the elements featured in the frame are the right size, and whether the audio is synced perfectly, said Mandy Jenkins, from social news company Storyful, which specializes in verifying news content.

Doctored content might not pass the scrutiny of a rigorous newsroom, but if posted as a grainy video to social media it could spread virally and trigger a public relations, political or diplomatic disaster. Imagine Trump declaring war on North Korea, for example.

“If someone looks like Trump and speaks like Trump they will think it’s Trump,” said Saxena.

“We already see it doesn’t even take doctored audio or video to make people believe something that isn’t true,” added Jenkins. “This has the potential to make it worse.”. There’s a video making its rounds online in which former President Barack Obama is cosigning the efforts of Erik Killmonger in Black Panther, offering a controversial opinion about HUD Secretary Ben Carson, and calling President Donald Trump a “total and complete dips—.”

But, the video is fake.

The former POTUS never said those words, nor was he actually being interviewed.

According to reports, Obama’s likeness was the genius of artificial intelligence and Oscar-winning filmmaker Jordan Peele’s production company, which used Adobe After Effects and the A.I. face-swapping tool FakeApp to create the footage. The video was done in conjunction with BuzzFeed.

BuzzFeed CEO Jonah Peretti released the video to highlight how technology can be used to create fake news, and it does just that, with Obama’s likeness stating, “This is a dangerous time. Moving forward, we need to be more vigilant with what we trust from the Internet. It’s a time where we need to rely on trusted news sources.” BuzzFeed illustrates, via a split screen, Peele voicing the same words, providing the framework for the A.I.-produced Obama’s rhetoric.

The video serves as a PSA on how A.I. can be used to promote misinformation, slander, fraud, and misrepresentation, and it urges, through its example, consumers to be discerning about the sources from which they are getting information and the factual nature of information shared online. The fake Obama ends the video saying, “Stay woke, b*****.”

The phenomenon of fake news is not new, from the Yellow Journalism days of American history to President Donald Trump having made the concept infamous since taking office, and it’s an almost weekly occurrence when it comes to the deaths of celebrities. It can become very dangerous when related to politics, crime, and activism, and one small seed of incorrect or untrue news can hit the Web, go viral in minutes, and ruin careers, skew elections, lead to deaths, or push stocks to plunge.

Fraudsters create bogus news pages with articles that seem real and that are often shared on social media, but this example by BuzzFeed takes things a step further, providing video evidence of the power of visual media tools in creating and spreading fake news. In today’s digital media world, video is king. (The video-sharing site YouTube, according to the Pew Research Center, is now used by nearly three-quarters of U.S. adults, and reports indicate that by 2019, Web video will account for 80% of all consumer Web traffic.)

The BuzzFeed PSA illustrates the volatile combo of fake news and technology, and how easy it is to create a potentially explosive disaster if shared online. The Obama video was posted on BuzzFeed’s YouTube channel just last week and already has more than 3.7 million views.

Watch the video below.

%CODE1%. It starts with a clickbait-y title -- "You Won't Believe What Obama Says In This Video!" -- and then delivers on that promise.

Buzzfeed released a video on Tuesday that at first appears to show former US President Barack Obama conveying a warning, saying "We're entering an era in which our enemies can make it look like anyone is saying anything at any point in time." It then continues with Obama dropping an obscenity about President Donald Trump.

Obama didn't say these things, of course.

The video quickly reveals it's a fake, with the Oscar-winning filmmaker, actor and writer Jordan Peele providing the voice. Peele and Buzzfeed are looking to draw attention to the growing problem of fake-news videos, which can seem startlingly real.

Buzzfeed points to the work of University of Washington computer scientists who demonstrated the ability to turn audio clips into realistic lip-synced video for a study last year. Those researchers shared a video of Obama as an example.

Buzzfeed's video producer used a combination of Adobe After Effects video software and FakeApp, an AI program that was used to produce a popular video featuring actor Nicolas Cage in a variety of movies he didn't star in.

The issue of fake videos is a growing problem. Earlier this year, online community Reddit banned "deepfake" pornography that uses AI to graft a person's face onto another person's body.

Video is an especially powerful medium. The technology is getting more sophisticated and widespread and there's increased concern about how misinformation might be used to sway voters in elections.

Peele concludes the faux Obama video with a call for people to be more vigilant about what they trust from the internet. The final clip is Peele's voice impersonation appearing to come from Obama and saying, "Stay woke, b*****s."

CNET Magazine: Check out a sample of the stories in CNET's newsstand edition.

Cambridge Analytica: Everything you need to know about Facebook's data mining scandal.. It seems that nowadays, there isn’t a day that passes by without someone proclaiming “fake news” — that now-infamous phrase that rose to prominence during the last American election and is now being bandied about ad nauseum.

But as any intelligent person knows, it’s true that you can’t always believe what you read or see on (or off) the Internet. Fake Photoshopped images abound on the internet, thanks to photo-editing technology that allows people to create staged situations that look real — but never actually happened.

Now, with the help of artificial intelligence, we might be facing the prospect of an explosion of fake news videos too. At least that’s what we might assume from these new findings from researchers from University of Washington, who created this rather convincing but bogus video of former U.S. president Barack Obama, using an artificial neural net trained on many hours of video footage featuring the former president, overlaid with an actual audio clip of him speaking last year about the Orlando mass shootings. Watch and see if you can determine what’s real and what’s not, and how it was done:

According to the researchers’ paper, they used what is called a recurrent neural network (RNN), a type of artificial neural network that arranges nodes of artificial neurons to function in a way that resembles the human brain. These networks are fed massive amounts of data in order to ‘learn’ how to perform a task or solve a problem.

We’ve seen recurrent neural networks applied to things like speech recognition, text-to-speech synthesis — anything that requires some kind of internal memory to process varying sequences of inputs.

In this case, the researchers lifted the audio of Obama speaking in a separate video, and dubbed it over another video of him in a completely different location. Using about 14 hours of footage in the public domain and sourced from Obama’s weekly announcements, the recurrent neural net was able to “learn” how to recreate a composite of the facial and mouth movements that corresponded to various sounds.

To do this, the neural network synthesized a “sparse mouth shape,” on top of which mouth textures could be then applied and blended into an altered target video, giving the talking head an appearance of natural movement. The result is an eerily plausible lip sync.

Surprisingly though, this isn’t the first time that researchers have tried to do this kind of thing. As mentioned in the video above, there have been other versions of the same concept, but this time around, the University of Washington team added a tim