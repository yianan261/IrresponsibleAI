We have in the past seen instances such as the failure of Microsoft bot Tay, when it developed a tendency to come up with racist remarks. Within 24 hours of its existence and interaction with people, it starting sending offensive comments, and went from “humans are super cool” to being almost a Nazi.

While on one hand, chatbots, robots and conversational platforms are finding their niche in many companies, these technological advancements are also turning mainstream to become the face of the company. But many times they end up failing and disappointing us. While most of the times these technologies fail because companies don’t clearly define their purpose, others could be pure technical glitches.

Here we list some of the tech failures from last year that hint that the companies need to work harder and keep coming up with better and improved versions of their innovations.

1. When Facebook’s Chatbots Developed Their Own Language

Subscribe to our Newsletter Join our editors every weekday evening as they steer you through the most significant news of the day, introduce you to fresh perspectives, and provide unexpected moments of joy Email Sign up Your newsletter subscriptions are subject to AIM Privacy Policy and Terms and Conditions.

As scary as it may sound, “Bob” and “Alice”, the chatbots created by Facebook had to be shut down as the duo started communicating in their own language, defying human generated algorithms.

The bots were originally developed to learn how to negotiate, by mimicking human trading and bartering, but when they were paired to trade against each other, they started to learn their own bizarre form of communication. Though they were designed to communicate in English, they developed their own mysterious language that humans couldn’t crack.

Bob: i can i i everything else . . . . . . . . . .

Alice: balls have zero to me to me to me to me to me to me to me to me to

This is how their conversation looked like. Researchers stopped the operation of the chatbots citing that they were looking at bots that could behave differently.

2. When Mitra The Robot Failed To Greet The Prime Minister

The indigenously built robot called Mitra, developed by Bengaluru-based Invento Robotics walked up to welcome Indian Prime Minister Narendra Modi and Ivanka Trump at the the Global Entrepreneurship Summit (GES) opening in Hyderabad. While the robot was programmed to welcome each of them with their names on pressing the respective flags, it failed to do so.

When Modi was first requested to press Indian flag, Ivanka also ended up pressing the US flag simultaneously and because of the confusion due to overlapping, Mitra could not function properly.

This failure could be attributed to being poorly coded, where there was no specific instruction given to the robot to complete the current task before starting a new one. For instance, it kept on saying “Welcome miss Ivan, Welcome miss Ivan, Welcome Shri Narendra Modi”. The robot could not say Ivanka Trump’s full name because before it could complete the sentence, it received a new input, and gave a preference to newer requests.

3. When Autonomous And Driverless Vehicles Turned Disastrous

In a tragic incident involving Uber self driving car, a woman was killed during a trial, stalling autonomous vehicle operations worldwide. The car was travelling on a partially lit road, when a woman appeared out of nowhere in the darkness. The Uber self driving Volvo which was driving at a speed of 61 kmph, failed to apprehend the same and resulted in a fateful crash.

Back in India, Delhi’s first ever driverless metro met with an accident during its trial, and it was touted to be human error and negligence. Reportedly, the trial train was moved to testing from the workshop without testing the brake, as a result of which the moving train hit the adjacent boundary wall, with no harm to lives.

4. When iPhone X’s Face Recognition Could Not Differentiate Identical Twins

When Apple released its iPhone X with much aplomb, it was awed for its artificial intelligence and machine learning capabilities. Facial recognition was one of the key capabilities that it boasted, but it was found to have a weakness for identical twins.

When Apple unveiled the Face ID in September, it did warn that its acceptance rate might be somewhat lower if presented with two people with very similar DNA, aka identical twins, it could be speculated that Face ID wasn’t perfect. Face ID, a face mapping technology that can unlock phones, verify Apple Pay and replace fingerprint scanners, could be fooled at some level, especially when identical twins are made to use the Face ID.

That’s not all, a week after the phone’s release, Vietnamese security firm Bkav, using a mask with 3D printed base, convinced the phone that it was human and made the phone to unlock itself. The firm said that it cost merely $150 to create the mask, and hinted towards a possible hacker’s attack in the future.

5. When Alexa And Amazon Echo Goofed Up

The popular Amazon Echo cost one of its owners a huge locksmith bill, when police had to break down the house on complaints from neighbours of loud music early in the morning. Amazon Echo, which comes with robust and smart speakers accidentally activated itself and blasted music, when the residents were out.

In another instance, Amazon Alexa, a virtual assistant that has made lives of many easier, placed an order for $170 dollhouse, when a six-year-old asked for one.

On A Concluding Note

Though there have been stunning developments in the field of artificial intelligence and robotics over the years, these failures suggest that there is a lot more to achieve. The companies increasingly need to rewire their DNA and bring better features and innovations to ensure an unmistakable customer experience. While general intelligence is a far reaching goal for AI, botification has the power to bring convenience at a much faster pace, if they are 100 percent successful.. . Updated Amazon's audio surveillance personal assistant d