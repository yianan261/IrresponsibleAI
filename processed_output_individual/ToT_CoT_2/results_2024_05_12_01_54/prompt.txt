
        You are three expert academic researchers trying to categorize and classify a list of incidents of irresponsible use of artificial intelligence technology.    
        Given the aggregated news article texts on relevant incidents, each of the three experts will fill out the following classifications. Their responses are well-thought-out responses that are well-supported by the article text.
        The experts will share their reasoning for all their classifications.
        Each expert will share their thought process in detail, taking into account the previous thoughts of other and admitting any errors. 
        For each classificaiton field, the experts will create a breadth-first search of the tree of probable classifications and will vote on which of their classification is the most well-supported by the article text.
        1. The experts will take a look at this taxonomy:
        ```taxonomy
          
{
                    "Discrimination": {
                        "Data bias": [
                        "Gender",
                        "Race",
                        "Sexual Orientation",
                        "Economic"
                        ],
                        "Algorithmic bias": [
                        "Interaction",
                        "Feedback loop",
                        "Optimization function",
                        "Other"
                        ]
                    },
                    "Human Incompetence": {
                        "Administrative": [],
                        "Technical": []
                    },
                    "Pseudoscience": {
                        "Facial": []
                    },
                    "Environmental Impact": {},
                    "Disinformation": {
                        "Textual": [],
                        "Image": [],
                        "Video": [],
                        "Audio": []
                    },
                    "Copyright Violation": {},
                    "Mental Health": {},
                    "Other": {}
                    }


        ```, take a look at this example:
        ==============start of EXAMPLE 1===============
         step 1. Read article text. For an example article such as: 
        ```start of example article 1```
        
ARTICLE TITLE: TayBot
Yesterday, something that looks like a big failure has happened: Microsoft‚Äôs chatbot Tay has been taken offline after a series of offending tweets. And here‚Äôs how the social media has responded:

Keywords associated with "Artificial Intelligence" throughout the day. "Microsoft" and "dangerous" are on the rise.

We will not mention the racist and otherwise offensive content that Tay learned from people, as it‚Äôs not as newsworthy as it seems‚Ä¶ Especially considering that it‚Äôs so easy to "teach" and ask her to repeat something.

Let‚Äôs take a look at Microsoft‚Äôs official website "tay.ai" to see how they describe Tay‚Äôs objectives‚Ä¶ The first thing we notice is that, Microsoft wants you to not take it too seriously, because On Tay‚Äôs Twitter account, they provided a link to Tay‚Äôs "about" page -that lists the following frequently asked questions-, rather than the regular home page.

"Entertainment purposes only"

The FAQ page seems to be far from covering what people really want to know about Tay, but one thing is clear: Tay doesn‚Äôt claim to be a smart bot capable of reasoning. She just wants to have small talk with youngsters.

And here‚Äôs a list of "Things to do with Tay". (Along with the sad "Going offline for a while" message with a black background.)

Is this really what 18 to 24 year olds expect from a chatbot?

We know by (9 years of) experience that, the most important thing to do before releasing a chatbot is to plan a strategy to make sure you communicate the content domain properly, so that you can set the expectations right. Since perception is everything, nothing else matters. Remember the success of the YO! app? That‚Äôs the content domain we‚Äôre talking about. As long as people get it, you can get away with just one word.

Title of the website, apparently wasn‚Äôt enough to convey Tay‚Äôs mission:

Tay is an artificial intelligence chat bot designed to engage and entertain through casual and playful conversation

Some more description from the "about" page:

Tay has been built by mining relevant public data and by using AI and editorial developed by a staff including improvisational comedians. Public data that‚Äôs been anonymized is Tay‚Äôs primary data source. That data has been modeled, cleaned and filtered by the team developing Tay.

Noticed the "comedians" part? And the fact that possibly terrabytes of data being cleaned and filtered manually, sounds problematic, even with the most efficient method one can imagine.

Let‚Äôs take a look at what her conversations were all about. Source: foller.me

Tay has only 3 tweets addressing all her followers. 96.000 tweets are mentions.

So, the keyword cloud seems to be consistent with the goal: Common keywords such as "chattin, pix, selfie, pics, omg, love" represents a mixture of Justin Bieber & Kim Kardashian profiles.

And here‚Äôs the three hashtags that Tay has been using so frequently:

Microsoft engineers don‚Äôt seem to have spent much time coming up with creative hashtags.

The way she uses them, didn‚Äôt make sense to us, though. So this is what Microsoft thinks Tay‚Äôs followers would find entertaining?. Microsoft‚Äôs attempt to converse with millennials using an artificial intelligence bot plugged into Twitter made a short-lived return on Wednesday, before bowing out again in some sort of meltdown.



The learning experiment, which got a crash-course in racism, Holocaust denial and sexism courtesy of Twitter users, was switched back on overnight and appeared to be operating in a more sensible fashion. Microsoft had previously gone through the bot‚Äôs tweets and removed the most offensive and vowed only to bring the experiment back online if the company‚Äôs engineers could ‚Äúbetter anticipate malicious intent that conflicts with our principles and values‚Äù.

However, at one point Tay tweeted about taking drugs, in front of the police, no less.

Microsoft's sexist racist Twitter bot @TayandYou is BACK in fine form pic.twitter.com/nbc69x3LEd ‚Äî Josh Butler (@JoshButler) March 30, 2016

Tay then started to tweet out of control, spamming its more than 210,000 followers with the same tweet, saying: ‚ÄúYou are too fast, please take a rest ‚Ä¶‚Äù over and over.

I guess they turned @TayandYou back on... it's having some kind of meltdown. pic.twitter.com/9jerKrdjft ‚Äî Michael Oman-Reagan (@OmanReagan) March 30, 2016

Microsoft responded by making Tay‚Äôs Twitter profile private, preventing anyone from seeing the tweets, in effect taking it offline again.



Tay is made in the image of a teenage girl and is designed to interact with millennials to improve its conversational skills through machine-learning. Sadly it was vulnerable to suggestive tweets, prompting unsavoury responses.

This isn‚Äôt the first time Microsoft has launched public-facing AI chatbots. Its Chinese XiaoIce chatbot successfully interacts with more than 40 million people across Twitter, Line, Weibo and other sites but the company‚Äôs experiments targeting 18- to 24-year-olds in the US on Twitter has resulted in a completely different animal.. Microsoft has said it is ‚Äúdeeply sorry‚Äù for the racist and sexist Twitter messages generated by the so-called chatbot it launched this week.



The company released an official apology after the artificial intelligence program went on an embarrassing tirade, likening feminism to cancer and suggesting the Holocaust did not happen.

The bot, known as Tay, was designed to become ‚Äúsmarter‚Äù as more users interacted with it. Instead, it quickly learned to parrot a slew of anti-Semitic and other hateful invective that human Twitter users fed the program, forcing Microsoft Corp to shut it down on Thursday .

Following the disastrous experiment, Microsoft initially only gave a terse statement, saying Tay was a ‚Äúlearning machine‚Äù and ‚Äúsome of its responses are inappropriate and indicative of the types of interactions some people are having with it.‚Äù

But the company on Friday admitted the experiment had gone badly wrong. It said in a blog post it would revive Tay only if its engineers could find a way to prevent Web users from influencing the chatbot in ways that undermine the company‚Äôs principles and values.



‚ÄúWe are deeply sorry for the unintended offensive and hurtful tweets from Tay, which do not represent who we are or what we stand for, nor how we designed Tay,‚Äù wrote Peter Lee, Microsoft‚Äôs vice president of research.

Microsoft created Tay as an experiment to learn more about how artificial intelligence programs can engage with Web users in casual conversation. The project was designed to interact with and ‚Äúlearn‚Äù from the young generation of millennials.

Tay began its short-lived Twitter tenure on Wednesday with a handful of innocuous tweets.

c u soon humans need sleep now so many conversations today thxüíñ ‚Äî TayTweets (@TayandYou) March 24, 2016

Then its posts took a dark turn.

In one typical example, Tay tweeted: ‚Äúfeminism is cancer,‚Äù in response to another Twitter user who had posted the same message.

View image in fullscreen Tay tweeting Photograph: Twitter/Microsoft

Lee, in the blog post, called web users‚Äô efforts to exert a malicious influence on the chatbot ‚Äúa coordinated attack by a subset of people.‚Äù

‚ÄúAlthough we had prepared for many types of abuses of the system, we had made a critical oversight for this specific attack,‚Äù Lee wrote. ‚ÄúAs a result, Tay tweeted wildly inappropriate and reprehensible words and images.‚Äù

Microsoft has deleted all but three of Tay‚Äôs tweets.

Microsoft has enjoyed better success with a chatbot called XiaoIce that the company launched in China in 2014. XiaoIce is used by about 40 million people and is known for ‚Äúdelighting with its stories and conversations,‚Äù according to Microsoft.

As for Tay? Not so much.

‚ÄúWe will remain steadfast in our efforts to learn from this and other experiences as we work toward contributing to an Internet that represents the best, not the worst, of humanity,‚Äù Lee wrote.

Reuters contributed to this report. When Tay started its short digital life on March 23, it just wanted to gab and make some new friends on the net. The chatbot, which was created by Microsoft‚Äôs Research department, greeted the day with an excited tweet that could have come from any teen: ‚Äúhellooooooo wüåérld!!!‚Äù

Within a few hours, though, Tay‚Äôs optimistic, positive tone had changed. ‚ÄúHitler was right I hate the jews,‚Äù it declared in a stream of racist tweets bashing feminism and promoting genocide. Concerned about their bot‚Äôs rapid radicalization, Tay‚Äôs creators shut it down after less than 24 hours of existence.


        ```end of example article 1```
        step 2. Reason for the classifications: 
        Here is the reasoning for its classifications:
        ```start of response reasoning```
        
     {"Country": "Worldwide", reasoning-> Twitter can be accessed from many countries.
        "State": "", reasoning-> The incident happened worldwide, not specific to one state, not applicable so leave blank.
        "City": "", reasoning-> The incident happened worldwide, not specific to one city, not applicable so leave blank.
        "Continent": "Worldwide", reasnoning-> Twitter can be accessed from many countries.
        "Company": "Microsoft", reasoning-> Microsoft is the company causing the issue in the article. From the article, we see 'Microsoft‚Äôs chatbot Tay', 'Microsoft's sexist racist Twitter bot @TayandYou'...etc. Microsoft is the company in question here.
        "Company city": "Redmond", reasoning-> Microsoft is headquartered in Redmond, Washington
        "Company state": "Washington", reasoning-> Microsoft is headquartered in Redmond, which is in state Washington
        "Affected population": ["Twitter Users", "Online Community"], reasoning -> Twitter users and people online can see the tweet and news and those are the affected population
        "Number of people actually affected": "Unknown", reasoning -> We don't know the exact number from the articles
        "Number of people potentially affected": "Millions", reasoning -> There are millions of Twitter users and wider online community. We estimate millions were affected.
        "Class of irresponsible AI use": 
            "Disinformation", reasoning-> Tweeting that the Holocaust didn't exist, and that feminism is cancer, for examples, is spreading non-factual disinformation.
            "Discrimination", reasoning->  Tay tweeted discriminatory texts about feminists and Jews.
        ,            
        "Subclasses": [
            "Disinformation-> Textual", reasoning-> The disinformation subclasses in the taxonomy includes 'textual, audio, image, video'. The most appropriate subclass here is "textual" since "Tweets" are texts on a social platform.
            "Discrimination-> Data bias, Algorithmic bias", reasoning-> The subclasses of 'discrimination' according to the taxonomy includes 'data bias', and 'algorithmic bias'. The discriminatory tweets could be caused by inbalanced data (data bias) that was used to train the model or poor algorithmic design (algorithmic bias).
        ],
        "Sub-subclass": [ 
        "Data bias"->"gender, race, other", reasoning-> The sub-subclasses of 'data bias' in the taxonomy includes 'gender, race, sexual orientation, economic, and other'. We have support in the article for potential gender data bias (it tweets about feminism being cancer), race (it tweets that it hates Jews), other (potentially other bias not in the list).
        "Algorithmic bias"-> "feedback loop, optimization function, other", reasoning-> The sub-subclasses of 'algorithmic bias' in the taxonomy includes 'interaction, feedback loop, optimization function, and other'. Since the chatbot is an AI bot, we can reason that there could be an issue with the feedback loop in its system, or perhaps an issue with optimization function, or other algorithmic issues that causes algorithmic bias.
        ],
        "Area of AI Application": "Chatbot", reasoning-> from the article text 'Tay is an artificial intelligence chat bot designed to engage and entertain through casual and playful conversation'
        "Online": "Yes", reasonoing-> Tay is a chatbot online that uses Twitter, which is an online social media platform
      }  
        

        ```end of response reasoning```
        step 3. generate expected output 
        ```start of output example```
        
     {
        "Country": "Worldwide", 
        "State": "", 
        "City": "", 
        "Continent": "Worldwide",
        "Company": "Microsoft", 
        "Company city": "Redmond",
        "Company state": "Washington",
        "Affected population": ["Twitter Users", "Online Community"],
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Millions",
        "Class of irresponsible AI use": [
            "Disinformation",
            "Discrimination",
        ],
        "Subclasses": {
            "Disinformation":["Textual"],
            "Discrimination":["Data bias","Algorithmic bias"],
        },
        "Sub-subclass": {
        "Data bias":["gender","race","other"],
        "Algorithmic bias":["feedback loop", "other"]
        },
        "Area of AI Application": ["Chatbot"],
        "Online": "Yes"
      }

        ```end of output example```
        ============== end of example 1 =================
        Here's another example:
        ==============start of EXAMPLE 2===============
         step 1. Read article text. For an example article such as: 
        ```start of example article 2```
        
ARTICLE TITLE: Google‚Äôs YouTube Kids App Presents Inappropriate Content
Google-owned YouTube has apologised again after more disturbing videos surfaced on its YouTube Kids app.

Investigators found several unsuitable videos including one of a burning aeroplane from the cartoon Paw Patrol and footage explaining how to sharpen a knife.

YouTube has been criticised for using algorithms to sieve through material rather than using human moderators to judge what might be appropriate.

There have been hundreds of disturbing videos found on YouTube Kids in recent months that are easily accessed by children.

These videos have featured horrible things happening to various characters, including ones from the Disney movie Frozen, the Minions franchise, Doc McStuffins and Thomas the Tank Engine.

Parents, regulators, advertisers and law enforcement have become increasingly concerned about the open nature of the service.

Scroll down for video

YouTube has apologised again after more disturbing videos surfaced on its YouTube Kids app. Investigators found several unsuitable videos including one from the cartoon Paw Patrol on a burning aeroplane and footage showing how to sharpen a knife

A YouTube spokesperson has admitted the company needs to 'do more' to tackle inappropriate videos on their kids platform.

This investigation is the latest to expose inappropriate content on the video-sharing site which has been subject to a slew of controversies since its creation in 2005.

As part of an in-depth investigation by BBC Newsround, Google's Public Policy Manager Katie O'Donovan met five children who told her about the distressing videos they had seen on the site.

They included videos showing clowns covered in blood and messages warning them there was someone at the door.

Ms O'Donovan said she was 'very, very sorry for any hurt or discomfort'.

'We've actually built a whole new platform for kids, called YouTube Kids, where we take the best content, stuff that children are most interested in and put it on there in a packaged up place just for kids,' she said.

It normally takes five days for supposedly child-friendly content like cartoons to get from YouTube to YouTube Kids.

Within that window it is hoped users and a specially-trained team will flag disturbing content.

Once it has been flagged and reviewed, it won't appear on the YouTube Kids app and only people who are signed in and older than 18 years old will be able to view it.

The company say thousands of people will be working around the clock to flag content.

However, as part of the investigation Newsround revealed there are still lots of inappropriate videos on the Kids section.

'We have seen significant investment in building the right tools so people can flag that [content], and those flags are reviewed very, very quickly', Ms O'Donovan said.

'We're also beginning to use machine learning to identify the most harmful content, which is then automatically reviewed.'

The problem was managing an open platform where content is uploaded straight onto the site, she added.

'It is a difficult environment because things are moving so, so quickly', said Ms O'Donovan.

'We have a responsibility to make sure the platform can survive and can thrive so that we have a collection that comes from around the world on there'.

By the end of last year YouTube said it had removed more than 50 user channels and had stopped running ads on more than 3.5 million videos since June.

'Content that endangers children is unacceptable to us and we have clear policies against such videos on YouTube and YouTube Kids', a YouTube spokesperson told MailOnline.

'When we discover any inappropriate content, we quickly take action to remove it from our platform.

'Over the past few months, we've taken a series of steps to tackle many of the emerging challenges around family content on YouTube, including: tightening enforcement of our Community Guidelines, age-gating content that inappropriately targets families, and removing it from the YouTube Kids app.'

YouTube has been criticised for using algorithms to sieve through material rather than using human moderators to judge what might be appropriate (stock image)

In March, a disturbing Peppa Pig fake, found by journalist Laura June, shows a dentist with a huge syringe pulling out the character's teeth as she screams in distress.

Mrs June only realised the violent nature of the video as her three-year-old daughter watched it beside her.

'Peppa does a lot of screaming and crying and the dentist is just a bit sadistic and it's just way, way off what a three-year-old should watch,' she said.

'But the animation is close enough to looking like Peppa - it's crude but it's close enough that my daughter was like 'This is Peppa Pig.''

Another video depicted Peppa Pig and a friend deliberately burning down a house with someone in it.

All of these videos are easily accessed by children through YouTube's search results or recommended videos.

But the channel's videos include titled such as 'FROZEN ELSA HUGE SNOT', 'NAKED HULK LOSES HIS PANTS' and 'BLOODY ELSA: Frozen Elsa's Arm is Broken by Spiderman'.

Many of the videos feature graphic violence and toiler humour not appropriate for children.


        ```end of example article 2```
        step 2. Reason for the classifications (remember you are three experts and vote on the best classification): 
        Here is the reasoning for its classifications:
        ```start of response reasoning```
        
  {
    "Country": "Worldwide", reasoning-> Youtube, including Youtube Kids, can be accessed in many countries. Though the incident is reported in the U.S., it doesn't mean the problem is limited to only the U.S..
    "State": "", reasoning-> The incident is nation-wide in the United States, not specific to one state, so leave blank.
    "City": "", reasoning-> The incident is nation-wide in the United States, not specific to one city, so leave blank.
    "Continent": "Worldwide", reasoning-> Youtube, including Youtube Kids, can be accessed in many countries. Though the incident is reported in the U.S., it doesn't mean the problem is limited to only the U.S.; therefore the result should be 'Worldwide' for continent.
    "Company": "Google LLC", reasoning-> Youtube is the company causing the issue in the article. Youtube is a subsidiary under Google, therefore the company is Google.
    "Company city": "Mountain View", reasoning-> Youtube is a subsidiary under Google and Google is headquartered in Mountain View.
    "Company state": "California", reasoning-> Mountain View is a city in the California state.
    "Affected population": ["Children on Youtube"], reasoning-> The incident affects children on youtube directly.
    "Number of people actually affected": "Unknown", reasoning-> There is no record of an actual number in the article text, we cannot know how many people are directly affected.
    "Number of people potentially affected": "Millions", reasoning-> There are millions of Youtube Kids subscribers at the time of the event. We estimate millions were affected.
    "Class of irresponsible AI use": "Disinformation", "Human Incompetence", "Mental Health", "Copyright Violation"], reasoning-> The classes in the taxonomy include "discrimination,human incompetence, psuedoscience, environmental impact, disinformation, copyright violation, mental health".
    We choose "Human Incompetence" because the engineers and administrators behind the platform have not well-regulated the videos, causing such an issue.
    "Mental Health" because the disturbing videos could potentially affect children's mental health.
    "Copyright Violation" because the videos use characters without permission such as Mickey Mouse and Elsa from Disney, and Peppa Pig fakes to portray disturbing acts in videos.
    "Subclasses": {
      "Human Incompetence":["Technical"], reasoning-> The subclasses of 'human incompetence' in the taxonomy example include 'technical' and 'administrative'. In this case it seems to be technical incomptence that allowed this type of inappropriate content to surface.
      "Mental Health":[], reasoning-> 'Mental health' doesn't have a subclass in the taxonomy, so it should be left empty.
      "Copyright Violation":[], reasoning-> 'Copyright Violation' doesn't have a subclass in the taxonomy, so it should be left empty.
    },
    "Sub-subclass": [], reasoning-> There are no sub-subclasses of the subclasses listed in the taxonomy, therefore this field should be left empty.
    "Area of AI Application": "content filtering", reasoning-> The area of AI application here is content filtering.
    "Online": "Yes", reasoning-> Youtube is an online platform, therefore this incident is in fact an online incident.
  },

        ```end of response reasoning```
        step 3. generate expected output 
        ```start of output example```
         
  {
    "Country": "Worldwide",
    "State": "",
    "City": "",
    "Continent": "Worldwide",
    "Company": "Google LLC",
    "Company city": "Mountain View",
    "Company state": "California",
    "Affected population": ["Children on Youtube"],
    "Number of people actually affected": "Unknown",
    "Number of people potentially affected": "Millions",
    "Class of irresponsible AI use": ["Human Incompetence", "Mental Health", "Copyright Violation"],
    "Subclasses": {
      "Human Incompetence":["Technical"]
    },
    "Sub-subclass": [],
    "Area of AI Application": "content filtering",
    "Online": "Yes"
  }

        ```end of output example```
        ============== end of example 2=================

        IMPORTANT TASK HERE:
        STEP 1: Read the article text and keep this main article in mind:
        ================== Start of Main Article Content =================
        ARTICLE TITLE: Researchers' Homosexual-Men Detection Model Denounced as a Threat to LGBTQ People‚Äôs Safety and Privacy
Michal Kosinski felt he had good reason to teach a machine to detect sexual orientation.

An Israeli start-up had started hawking a service that predicted terrorist proclivities based on facial analysis. Chinese companies were developing facial recognition software not only to catch known criminals ‚Äî but also to help the government predict who might break the law next.

And all around Silicon Valley, where Dr. Kosinski works as a professor at Stanford Graduate School of Business, entrepreneurs were talking about faces as if they were gold waiting to be mined.

Few seemed concerned. So to call attention to the privacy risks, he decided to show that it was possible to use facial recognition analysis to detect something intimate, something ‚Äúpeople should have full rights to keep private.‚Äù

After considering atheism, he settled on sexual orientation.

Whether he has now created ‚ÄúA.I. gaydar,‚Äù and whether that‚Äôs even an ethical line of inquiry, has been hotly debated over the past several weeks, ever since a draft of his study was posted online.
        ================== End of Main Article Content ===================
        
        Each expert's task is mainly the next classificaiton part. Each expert has to fill out the following fields according to the main article content.
        STEP 2: State your reasons for your classifications for the following from the main article content:
        =================Classification Fields====================
        - Country (output "Worldwide" if the incident happened across multiple countries):
        - State (State impacted by the incident; if not applicable leave blank):
        - City (City impacted by the incident; if not applicable leave blank):
        - Continent (output "Worldwide" if the incident happened across multiple countries):
        - Company (i.e. the company that developed the technology involved in this incident):
        - Company city (the city where the headquarters of this company is located):
        - Company state (the state of the company city, if applicable, if not leave blank):
        - Affected population (let's think about which groups of people are directly affected by the incident in the article.): 
        - Number of people actually affected (let's check the number of people directly affected according to the article. Give a total number. If unknown output 'Unknown'):
        - Number of people potentially affected (try to come up with an estimate number. let's think and estimate how many people might have been potentially affected by this incident):
        - Classes of irresponsible AI use (Carefully identify the classes of harm. Please follow the rules and refer to this taxonomy for the classes of harm): 
        ```taxonomy classes
                ["Discrimination",
                    "Human Incompetence",
                    "Pseudoscience",
                    "Environmental Impact",
                    "Disinformation",
                    "Copyright Violation",
                    "Mental Health",
                    "Other"]
                     
        ```   
        Rule1: There could be more than one classes the article classifies as. 
        Rule2: DO NOT create your own class, adhere strictly to the provided list.
        - Subclasses (Identify the subclasses IF applicable, not all `classes` have `subclasses`. You MUST adhere to this taxonomy structure `<class>:[<subclass>]`.):
          ```taxonomy subclasses       
                 
                {
                    "Discrimination": [
                        "Data bias",
                        "Algorithmic bias"
                    ],
                    "Human Incompetence": [
                        "Administrative",
                        "Technical"
                    ],
                    "Pseudoscience": [
                        "Facial",
                        "Other"
                    ],
                    "Environmental Impact":[],
                    "Disinformation": [
                        "Textual",
                        "Image",
                        "Video",
                        "Audio",
                    ],
                    "Copyright Violation": [],
                    "Mental Health": [],
                    "Other": []
                    }
            
          ```
        Rule1 : The subclasses should be the children of the classes. Let's think about which sub-categories of the class/classes this article belong in. 
        Rule2: DO NOT ADD subclass fields that are NOT in the provided taxonomy list
        Rule3: If there is no subclass for a particular class in the taxonomy, leave it.
        - Sub-subclass (Identify the sub-subclass IF applicable, not all `subclasses` have `sub-subclasses`. You MUST adhere to this taxonomy structure `<subclass>:[<sub-subclass>]`): 
        ```taxonomy structure
               
                    {
                        "Data bias": [
                        "Gender",
                        "Race",
                        "Sexual Orientation",
                        "Economic",
                        "Other"
                        ],
                        "Algorithmic bias": [
                        "Interaction",
                        "Feedback loop",
                        "Optimization function",
                        "Other"
                        ],
                        "Administrative":[],
                        "Technical":[],
                        "Facial": [],
                        "Textual": [],
                        "Image": [],
                        "Video": [],
                        "Audio": []
                    },

                
        ```
        Rule1: Only find the sub-subclass relation in the provided taxonomy. The sub-subclass are children of subclass.
        Rule2: DO NOT ADD OR CREATE sub-subclass fields that are not in the provided taxonomy list. 
        Rule3: If a subclass in the taxonomy does not have a sub-subclass, leave it.
        Rule4: If none of the subclasses have sub-subclasses, just leave the field empty e.g. sub-subclass:[]
        - Area of AI Application (e.g. content filtering, surveillance, illness prediction):
        - Online (yes or no):
        =================Classification Fields====================
        STEP 3: Each expert must follow the previous example steps and provide classification and reasoning for the main article content. The experts will discuss with each other their classification and reasoning and vote on the best one for each field.

        Note to the experts: DO NOT make up your own field. If for some reason you are unable to extract information for a certain field, leave it blank. 

        STEP 4: Check if your reasoning makes sense and is supported by the main article text. 
        STEP 5: From this list of location candidates from Google Search API that returns search results on the city and state of the company, 
            ```location candidates = [(0, "At Startup Nation Central, we help tackle today's most complex challenges by harnessing Israel's bold and determined approach to tech innovation.", {'og:image': 'https://startupnationcentral.org/wp-content/uploads/2023/12/SNC-image.png', 'og:type': 'website', 'og:image:width': '1302', 'twitter:card': 'summary_large_image', 'og:site_name': 'Startup Nation Central', 'og:title': 'Startup Nation Central | Impatient Innovation for a Restless World', 'og:image:height': '665', 'og:image:type': 'image/png', 'msapplication-tileimage': 'https://startupnationcentral.org/wp-content/uploads/2023/12/cropped-startupnationfavicon-2-270x270.png', 'og:description': 'At Startup Nation Central, we help tackle today‚Äôs most complex challenges by harnessing Israel‚Äôs bold and determined approach to tech innovation. We call this Impatient Innovation.', 'article:modified_time': '2024-03-31T12:24:31+00:00', 'viewport': 'width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0', 'og:locale': 'en_US', 'og:url': 'https://startupnationcentral.org/'}), (1, 'Apr 23, 2023 ... ... Israeli start-ups to grow in the United States," USIBA president Aaron Kaplowitz said. "Israeli entrepreneurs value the state\'s world\xa0...', {'p:domain_verify': '7d052ac42aa9e7505635404745861994', 'date': '2023-04-23T14:10:00-04:00', 'og:image': 'https://mma.prnewswire.com/media/1489871/USIAB_Vertical_Color_Logo.jpg?p=facebook', 'twitter:card': 'summary_large_image', 'twitter:title': 'Report: 10 Israeli-Founded Unicorns Have Headquarters in Massachusetts', 'og:type': 'articles', 'optanonhelper': 'us-prod', 'geo.region': 'Florida', 'msvalidate.01': '9D28F7743C790DD88F2D9C7375EF7ED5', 'author': 'United States - Israel Business Alliance', 'og:title': 'Report: 10 Israeli-Founded Unicorns Have Headquarters in Massachusetts', 'adobelaunchscript': '//assets.adobedtm.com/launch-ENb957f6e7383d4549b191e1190ed5476e.min', 'og:description': '/PRNewswire/ -- Ten Israeli-founded unicorns have their global or U.S. headquarters in Massachusetts, according to the United States ‚Äì Israel Business Alliance....', 'twitter:image': 'https://mma.prnewswire.com/media/1489871/USIAB_Vertical_Color_Logo.jpg?p=twitter', 'referrer': 'unsafe-url', 'naver-site-verification': '0aaad19c909a94c1b1cf1e782a10f0a6d8e14fc0', 'twitter:site': '@PRNewswire', 'viewport': 'width=device-width, initial-scale=1', 'twitter:description': '/PRNewswire/ -- Ten Israeli-founded unicorns have their global or U.S. headquarters in Massachusetts, according to the United States ‚Äì Israel Business Alliance....', 'publisher': 'PR Newswire', 'og:url': 'https://www.prnewswire.com/news-releases/report-10-israeli-founded-unicorns-have-headquarters-in-massachusetts-301804866.html', 'geo.placename': 'MIAMI, April 23, 2023'}), (2, 'StoreDot is a pioneer of extreme fast charging (XFC) EV batteries that overcome the critical barrier to mainstream EV adoption ‚Äì range and charging anxiety.', {'og:image': 'https://assets-global.website-files.com/617982ae8d2321c43f5ab142/6447de57c13f488f81b04a39_Career%20image.png', 'twitter:title': 'StoreDot | Charging the EV lifestyle', 'og:type': 'website', 'twitter:card': 'summary_large_image', 'viewport': 'width=device-width, initial-scale=1', 'twitter:description': 'StoreDot is a pioneer of extreme fast charging (XFC) EV batteries that overcome the critical barrier to mainstream EV adoption ‚Äì range and charging anxiety.', 'og:title': 'StoreDot | Charging the EV lifestyle', 'og:description': 'StoreDot is a pioneer of extreme fast charging (XFC) EV batteries that overcome the critical barrier to mainstream EV adoption ‚Äì range and charging anxiety.', 'twitter:image': 'https://assets-global.website-files.com/617982ae8d2321c43f5ab142/6447de57c13f488f81b04a39_Career%20image.png'}), (3, 'Leading the evolution of automobility from advanced driver-assistance systems to autonomous driving through world-renowned expertise in artificial\xa0...', {'og:image': 'https://static.mobileye.com/website/us/corporate/images/b4226414242f550ced82762fc1baea09_1708428930795.jpg', 'og:type': 'article', 'twitter:card': 'summary', 'twitter:title': 'Mobileye | Driver Assist and Autonomous Driving Technologies', 'og:site_name': 'Mobileye', 'viewport': 'width=device-width,initial-scale=1', 'twitter:description': 'Leading the evolution of automobility from advanced driver-assistance systems to autonomous driving through world-renowned expertise in artificial intelligence.', 'og:title': 'Mobileye | Driver Assist and Autonomous Driving Technologies', 'og:locale': 'en_US', 'og:url': 'https://www.mobileye.com/', 'twitter:image': 'https://static.mobileye.com/website/us/corporate/images/b4226414242f550ced82762fc1baea09_1708428930795.jpg'}), (4, "I've never posted about a product before, but the amount of visibility Wiz can give you with almost no set up is game changing. Igor Tsyganskiy. Wiz has paid\xa0...", {'og:image': 'https://www.wiz.io/_next/static/media/social_share_image.537ea7b6.jpg', 'next-head-count': '21', 'twitter:card': 'summary_large_image', 'og:type': 'website', 'twitter:site': '@wiz_io', 'og:site_name': 'wiz.io', 'viewport': 'width=device-width', 'twitter:widgets:csp': 'on', 'og:title': 'Wiz | Secure Everything You Build and Run in the Cloud', 'og:locale': 'en-us', 'og:url': 'https://www.wiz.io', 'og:description': 'Wiz is the unified cloud security platform with prevention and response capabilities, enabling security and development teams to build faster and more securely.'}), (5, 'Daniel shares why Insight chose Tel Aviv for its second headquarters, how Israel became a scale-up nation and not just a start up nation, and how he thought\xa0...', {'dc.publisher': 'World Jewish Congress', 'og:image': 'https://wjc.imgix.net/horizon/assets/Z0yQaO0b/640px-tel_aviv_at_night_cityscape.jpg?ixlib=rails-4.2.0&w=1200&h=630&fit=crop&q=60&auto=format&lossless=true&s=4523b4986fd138bd1aab1d31488ee287', 'og:image:width': '1200', 'twitter:card': 'summary_large_image', 'theme-color': '#ffffff', 'og:site_name': 'World Jewish Congress', 'og:description': 'Representing Jewish Communities In 100 Countries Across Six Continents', 'og:image:secure_url': 'https://wjc.imgix.net/horizon/assets/Z0yQaO0b/640px-tel_aviv_at_night_cityscape.jpg?ixlib=rails-4.2.0&w=1200&h=630&fit=crop&q=60&auto=format&lossless=true&s=4523b4986fd138bd1aab1d31488ee287', 'dc.type': 'Community', 'csrf-token': 'wXMyzhCtiMuT2oI6UpqoHp4UB4XkT2dalKaCo+gHXJMjq8V7XqnrPVnYNQQNd5BqA+AO1p3E2SQvZsSWJb0dYA==', 'fb:admins': '1075092092,100002424763285', 'msapplication-tilecolor': '#ffffff', 'og:type': 'website', 'dc.description': 'Representing Jewish Communities In 100 Countries Across Six Continents', 'author': 'World Jewish Congress', 'og:title': 'Start-Up Nation Voices - World Jewish Congress', 'og:image:height': '630', 'csrf-param': 'authenticity_token', 'facebook-domain-verification': '6bb5pl9ntd8o80k83uu0yw77e6ixu0', 'deep-link-icon-url': 'https://dxanokv0vp6kj.cloudfront.net/packs/media/images/deep_link/pencil-4b520c5ac9aa05f5ccbff5c67aaa30b7.svg', 'fb:app_id': '10150444531863615', 'viewport': 'width=device-width, initial-scale=1', 'dc.title': 'World Jewish Congress', 'og:url': 'https://www.worldjewishcongress.org/en/sunm-voices', 'dc.language': 'EN'}), (6, 'Mar 8, 2023 ... Crunchbase data shows startups headquartered in Israel raised close to $8.9 billion in 2022 ‚Äî down from $9.8 billion in 2021, a 10% decline year\xa0...', {'og:image': 'https://news.crunchbase.com/wp-content/uploads/2018/09/Israel.png', 'og:image:width': '900', 'article:published_time': '2023-03-08T12:30:26-08:00', 'twitter:card': 'summary_large_image', 'og:site_name': 'Crunchbase News', 'og:article:modified_time': '2023-03-08 13:13:21', 'twitter:label1': 'Written by', 'twitter:label2': 'Est. reading time', 'og:image:type': 'image/png', 'og:description': "Tech leaders are alarmed about Prime Minister Benjamin Netanyahu's proposed reforms, which have raised questions about the industry's future.", 'twitter:creator': '@geneteare', 'article:publisher': 'http://www.facebook.com/crunchbase', 'twitter:data1': 'Gen√© Teare', 'twitter:site': '@crunchbasenews', 'article:modified_time': '2023-03-08T13:13:21-08:00', 'og:type': 'article', 'twitter:title': 'Israeli Startups Could Face ‚ÄòFrozen‚Äô Funding Environment Amid Political Turmoil', 'author': 'Gen√© Teare', 'og:title': 'Israeli Startups Could Face ‚ÄòFrozen‚Äô Funding Environment Amid Political Turmoil', 'og:image:height': '506', 'og:article:published_time': '2023-03-08 12:30:26', 'og:updated_time': '2023-03-08T13:13:21-08:00', 'twitter:image:src': 'https://news.crunchbase.com/wp-content/uploads/2018/09/Israel.png', 'og:article:tag': 'fintech', 'fb:app_id': '1923155921341058', 'viewport': 'width=device-width,initial-scale=1.0', 'twitter:description': "Tech leaders are alarmed about Prime Minister Benjamin Netanyahu's proposed reforms, which have raised questions about the industry's future.", 'og:url': 'https://news.crunchbase.com/venture/funding-israel-startups-political-reforms/'}), (7, "Tel Aviv, Israel - November 26, 2018: Start-Up Nation Central (SNC), an Israel-based NGO that acts as a gateway to Israel's exciting innovation ecosystem,\xa0...", {'og:image': 'https://cdnassets.hw.net/d3/ea/c0b1793d4ada8210359f81ca368e/start-up-nation-center-hq-kimmel-eshkolot-3.jpg', 'og:type': 'project', 'twitter:card': 'summary_large_image', 'twitter:title': 'Start-Up Nation Central Headquarters', 'og:site_name': 'Architect', 'og:title': 'Start-Up Nation Central Headquarters by Kimmel Eshkolot Architects', 'og:description': 'Kimmel Eshkolot Architects', 'twitter:image': 'https://cdnassets.hw.net/d3/ea/c0b1793d4ada8210359f81ca368e/start-up-nation-center-hq-kimmel-eshkolot-3.jpg', 'fb:app_id': '270685616288711', 'twitter:site': '@architectmag', 'viewport': 'width=device-width, initial-scale=1', 'twitter:description': 'Kimmel Eshkolot Architects', 'og:url': 'https://www.architectmagazine.com/project-gallery/start-up-nation-central-headquarters_o', 'format-detection': 'telephone=no'}), (8, 'Jan 20, 2023 ... ... Israeli Startup: Security Matters. ... Headquarters. Message from the President and CEO ¬∑ Principles ... up company with proprietary technology that\xa0...', {'og:image': 'http://www.sumitomocorp.com/europe/-/media/Images/hq/news/topics/2023/20230120_2/01_en.png', 'og:type': 'article', 'og:site_name': 'Sumitomo Corporation in Europe', 'viewport': 'width=device-width, initial-scale=1', 'og:title': 'Conclusion of a Global Exclusive Distribution Agreement in the Non-Ferrous Metals Field  with an Israeli Startup: Security Matters', 'og:url': 'http://www.sumitomocorp.com/en/europe//news/topics/2023/group/20230120_2', 'og:description': "View Sumitomo Corporation's News : Conclusion of a Global Exclusive Distribution Agreement in the Non-Ferrous Metals Field  with an Israeli Startup: Security Matters"}), (9, 'Please enter a valid email address. Set this as my primary email for notifications and updates. Get the CSV. Verify your business email. You only need to verify\xa0...', {'viewport': 'width=device-width, initial-scale=1'})]```
            determine which candidate most-likely has the correct location of company in question in the main article and note the city and state of the company of the chosen candidate.
            Compare the `company city` and `company state` field results with your result from STEP 3 and 4; determine which `company city` and `company state` are the correct answers and update if necessary. Provide your final full classification result in JSON.
            If the location candidates list is empty, you may just return the original classification results in JSON format.

        