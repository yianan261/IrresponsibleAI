{
    "367": {
        "Country": "Worldwide",
        "State": "",
        "City": "",
        "Continent": "Worldwide",
        "Company": "OpenAI, Google",
        "Company city": "San Francisco",
        "Company state": "California",
        "Affected population": "Women, minorities, individuals targeted by deepfake pornography, job candidates analyzed by AI",
        "Number of people actually affected": "Unknown",
        "Number of people potentially affected": "Unknown",
        "Classes of irresponsible AI use": [
            "Discrimination",
            "Disinformation"
        ],
        "Subclasses": {
            "Discrimination": [
                "Data bias",
                "Algorithmic bias"
            ],
            "Disinformation": [
                "Image"
            ]
        },
        "Sub-subclass": {
            "Data bias": [
                "Gender",
                "Race"
            ],
            "Algorithmic bias": [
                "Interaction",
                "Feedback loop"
            ],
            "Image": []
        },
        "Area of AI Application": "Computer Vision",
        "Online": "No"
    }
}